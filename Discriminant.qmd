---
title: "Discriminant Analysis"
format: 
  html:
    theme: cosmo
    smooth-scroll: true
    toc: true
    toc-location: right
    # self-contained: true
# author: 
#     - name: J.I. Seo
#       affiliations:
#       - Gyeongguk National University
#     - name: J.W. Lee
#       # affiliations:
#       # - University of Missouri
      
number-sections: true
highlight-style: pygments
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
options(width=200)
```

> Discriminant Analysis의 장점
 
- 고차원의 데이터셋을 관리가 훨씬 쉬운 저차원으로 축소하여 예측을 수행한다.
- 차원축소를 통해 얻은 판별점수는 다른 분류 예측 알고리듬의 예측 변수로 활용 가능하다.
- 정규성을 만족할 경우, 로지스틱 회귀분석보다 더 효과적이다.
    - 30% 정도 더 효과적인 성능을 발휘한다.
- 데이터셋의 크기가 작을 때 유용하게 적용할 수 있다.    

</br>

> Discriminant Analysis의 단점

- 연속형 예측 변수만 가능하다.

</br>

> 실습 자료 : 1912년 4월 15일 타이타닉호 침몰 당시 탑승객들의 정보를 기록한 데이터셋이며, 총 11개의 변수를 포함하고 있다. 이 자료에서 **Target**은 `Survived`이다.

<center>![](./image/그림_titanic.png)</center>

<br />

<center><img src="./image/Titanic_표.png" width="400" height="400"></center>

<br />


## 데이터 불러오기

```{r, eval=F}
pacman::p_load("data.table", 
               "tidyverse", 
               "dplyr", "tidyr",
               "caret",
               "ggplot2", "GGally",
               "biotools",                 # For boxM
               "MASS",                     # For lda and qda
               "DescTools",                # For Desc
               "klaR"                      # For partimat
               )

titanic <- fread("../Titanic.csv")                                      # 데이터 불러오기

titanic %>%
  as_tibble
```

```{r, echo=F}
pacman::p_load("data.table", 
               "tidyverse", 
               "dplyr", "tidyr",
               "caret",
               "ggplot2", "GGally",
               "biotools",                 # For boxM
               "MASS",                     # For lda and qda
               "DescTools",                # For Desc
               "klaR"                      # For partimat
               )

titanic <- fread(paste(getwd(), "/DATA/Titanic.csv", sep = "/"))             # 데이터 불러오기

titanic %>%
  as_tibble
```

## 데이터 전처리 I

```{r}
titanic %<>%
  data.frame() %>%                                                      # Data Frame 형태로 변환 
  mutate(Survived = ifelse(Survived == 1, "yes", "no"))                 # Target을 문자형 변수로 변환

# 1. Convert to Factor
titanic$Survived <- factor(titanic$Survived)                            # Target을 범주형으로 변환

# 2. Generate New Variable
titanic <- titanic %>%
  mutate(FamSize = SibSp + Parch)                                       # "FamSize = 형제 및 배우자 수 + 부모님 및 자녀 수"로 가족 수를 의미하는 새로운 변수

glimpse(titanic)                                                        # 데이터 구조 확인

# 3. Select Variables used for Analysis
titanic1 <- titanic %>% 
  dplyr::select(Survived, Age, Fare, FamSize)                           # 분석에 사용할 변수 선택 -> 판별분석에서 예측 변수들은 다변량 정규분포를 가정하기 때문에 범주형 예측 변수는 제거

glimpse(titanic1)                                                       # 데이터 구조 확인
```


## 데이터 탐색

```{r}
ggpairs(titanic1,                                        
        aes(colour = Survived)) +                         # Target의 범주에 따라 색깔을 다르게 표현
  theme_bw()

ggpairs(titanic1,                                     
        aes(colour = Survived, alpha = 0.8)) +            # Target의 범주에 따라 색깔을 다르게 표현
  scale_colour_manual(values = c("purple", "cyan4")) +    # 특정 색깔 지정
  scale_fill_manual(values = c("purple", "cyan4")) +      # 특정 색깔 지정
  theme_bw()
```


## 데이터 분할

```{r}
# Partition (Training Dataset : Test Dataset = 7:3)
y      <- titanic1$Survived                             # Target

set.seed(200)
ind    <- createDataPartition(y, p = 0.7, list  =T)     # Index를 이용하여 7:3으로 분할
titanic.trd <- titanic1[ind$Resample1,]                 # Training Dataset
titanic.ted <- titanic1[-ind$Resample1,]                # Test Dataset
```

## 데이터 전처리 II

```{r}
# 1. Imputation
titanic.trd.Imp <- titanic.trd %>% 
  mutate(Age = replace_na(Age, mean(Age, na.rm = TRUE)))                 # 평균으로 결측값 대체

titanic.ted.Imp <- titanic.ted %>% 
  mutate(Age = replace_na(Age, mean(titanic.trd$Age, na.rm = TRUE)))     # Training Dataset을 이용하여 결측값 대체

# 2. Standardization
preProcValues <- preProcess(titanic.trd.Imp, 
                            method = c("center", "scale"))               # Standardization 정의 -> Training Dataset에 대한 평균과 표준편차 계산 

titanic.trd.Imp <- predict(preProcValues, titanic.trd.Imp)               # Standardization for Training Dataset
titanic.ted.Imp <- predict(preProcValues, titanic.ted.Imp)               # Standardization for Test Dataset

glimpse(titanic.trd.Imp)                                                 # 데이터 구조 확인
glimpse(titanic.ted.Imp)                                                 # 데이터 구조 확인
```

## 모공분산행렬의 동일성 검정

```{r}
titanic.boxM <- boxM(titanic.trd.Imp[,-1],             # Training Dataset including Only 예측 변수 -> Target 제외
                     titanic.trd.Imp$Survived)         # Target

titanic.boxM
```

`Caution!` Package `"biotools"`에서 제공하는 함수 `boxM()`를 이용하여 모공분산행렬의 동일성 검정을 수행할 수 있다. 해당 검정에서 귀무가설 $H_0$은 "Target의 모든 클래스의 모공분산행렬은 동일하다."이며, 귀무가설 $H_0$을 기각할 증거가 부족할 경우 원칙적으로는 선형판별분석을 수행한다.  
`Result!` 가설 $H_0 :\Sigma_{\text{yes}}=\Sigma_{\text{no}}$ vs $H_1 :\Sigma_{\text{yes}}\ne\Sigma_{\text{no}}$에 대하여, 카이제곱 검정통계량 $\chi^2$값은 269.33이며 $p$값은 거의 0값에 가깝다. 이에 근거하여, 유의수준 5%에서 $p$값이 0.05보다 작기 때문에 귀무가설 $H_0$를 기각할 수 있다. 즉, `Training Dataset`에서 Target "Survived"의 두 클래스 "no"와 "yes"의 모공분산행렬은 동일하지 않다.


## 선형판별분석(LDA)

</br>

### 모형 훈련

`Caution!` Package `"MASS"`에서 제공하는 함수 `lda()`를 통해 선형판별함수 $L(x)$를 얻을 수 있다. 함수 `lda()`는 예측 변수의 평균을 0으로 변환(중심화)한 후 분석을 수행하며, 정규화된 판별계수벡터 $\boldsymbol{b}$를 계산한다. 여기서, 정규화된 판별계수벡터란 합동공분산행렬을 $\boldsymbol{S}$라 할 때 $\boldsymbol{b}^T \boldsymbol{S}\boldsymbol{b}=1$을 만족하는 $\boldsymbol{b}$를 의미한다.

```{r}
titanic.lda <- lda(Survived ~ .,     
                   # prior = c(1/2, 1/2),            # 사전확률
                   data = titanic.trd.Imp)        

titanic.lda
```

`Caution!` "Prior probabilities of groups"는 Target의 각 클래스에 대한 사전확률을 의미하며, 함수 `lda()`의 옵션 `prior`을 이용하여 직접 지정할 수 있다. 옵션을 따로 지정해주지 않으면, `Training Dataset`에서 Target의 클래스 비율을 사전확률로 사용한다.  
"Group means"는 Target의 클래스별 예측 변수들의 평균을 의미한다.  
"Coefficients of linear discriminants"는 선형판별함수의 정규화된 판별계수벡터를 의미한다.  
`Result!` `Training Dataset` "titanic.trd.Imp"에서 Target "Survived"의 클래스별 비율은 각각 "no" 61.6%, "yes" 38.4%이다. "Coefficients of linear discriminants"에 출력된 결과를 이용하여 선형판별함수 $L(x)$를 다음과 같이 얻을 수 있다.

$$
\begin{align*}
L(x) = &\; -0.454Z_{\text{Age}}+1.047 Z_{\text{Fare}} -0.352 Z_{\text{FamSize}} 
\end{align*}
$$
여기서, $Z_{\text{예측 변수}}$는 표준화한 예측 변수를 의미한다. 
판별계수의 부호를 이용하여 해석해보면, 판별계수가 양수인 예측 변수 "Fare"의 값이 클수록 선형판별함수 $L(x)$의 값이 커지며, 이는 탑승객이 생존할 가능성(Target "Survived = yes"일 확률)이 커진다는 것을 의미한다.


```{r}
# Target "Survived" 클래스별 판별점수 히스토그램
plot(titanic.lda, dimen = 1, type = "b")
```

`Result!` 각 case에 대하여 예측 변수들의 관측값을 위에서 구한 선형판별함수 $L(x)$에 대입하여 얻은 값을 "판별점수"라고 한다. `Training Dataset`의 Target "Survived"의 클래스별 판별점수 히스토그램을 살펴보면, "no"에 속하는 case의 판별점수는 대체로 0보다 작은 음수값이고 "yes"에 속하는 case의 판별점수는 대체로 0보다 큰 양수값이다. 


```{r}
# 두 예측 변수 "Age"와 "Fare"에 대해 선형판별분석에 기초한 관측값의 분류 결과
partimat(Survived ~ Age + Fare,      
         data = titanic.trd.Imp,
         method = "lda")
```

`Result!` 빨간색은 잘못 분류된 case를 의미하며, 직선형태로 분류 영역이 나뉘어져 있다는 것을 알 수 있다.


### 모형 평가

`Caution!` 모형 평가를 위해 `Test Dataset`에 대한 `예측 class/확률`이 필요하며, 함수 `predict()`를 이용하여 생성한다.

```{r}
# 예측 class와 예측 확률 생성
titanic.lda.pred <- predict(titanic.lda, 
                            newdata = titanic.ted.Imp[,-1])   # Test Dataset including Only 예측 변수   

titanic.lda.pred %>%                                       
  as_tibble
```

`Result!` 함수 `predict()`는 3개의 결과를 리스트로 반환한다.  

1. `class` : 예측 class
2. `posterior` : 각 클래스에 대한 예측 확률(사후 확률)
3.  `x` : 판별점수

<br />

#### ConfusionMatrix

```{r}
CM   <- caret::confusionMatrix(titanic.lda.pred$class, titanic.ted.Imp$Survived, 
                               positive = "yes")        # confusionMatrix(예측 class, 실제 class, positive = "관심 class")
CM
```

<br />

####  ROC 곡선

```{r}
ac  <- titanic.ted.Imp$Survived                         # Test Dataset의 실제 class 
pp  <- as.numeric(titanic.lda.pred$posterior[,2])       # "Survived = yes"에 대한 예측 확률을 수치형으로 변환
```

##### Package "pROC"

```{r}
pacman::p_load("pROC")

lda.roc  <- roc(ac, pp, plot = T, col = "gray")         # roc(실제 class, 예측 확률)
auc      <- round(auc(lda.roc), 3)
legend("bottomright", legend = auc, bty = "n")
```

`Caution!` Package `"pROC"`를 통해 출력한 ROC 곡선은 다양한 함수를 이용해서 그래프를 수정할 수 있다.

```{r}
# 함수 plot.roc() 이용
plot.roc(lda.roc,   
         col="gray",                                    # Line Color
         print.auc = TRUE,                              # AUC 출력 여부
         print.auc.col = "red",                         # AUC 글씨 색깔
         print.thres = TRUE,                            # Cutoff Value 출력 여부
         print.thres.pch = 19,                          # Cutoff Value를 표시하는 도형 모양
         print.thres.col = "red",                       # Cutoff Value를 표시하는 도형의 색깔
         auc.polygon = TRUE,                            # 곡선 아래 면적에 대한 여부
         auc.polygon.col = "gray90")                    # 곡선 아래 면적의 색깔
```


```{r}
# 함수 ggroc() 이용
ggroc(lda.roc) +
annotate(geom = "text", x = 0.9, y = 1.0,
label = paste("AUC = ", auc),
size = 5,
color="red") +
theme_bw()
```


##### Package "Epi"

```{r}
pacman::p_load("Epi")       
# install_version("etm", version = "1.1", repos = "http://cran.us.r-project.org")

ROC(pp, ac, plot = "ROC")                                  # ROC(예측 확률, 실제 class)  
```


##### Package "ROCR"

```{r}
pacman::p_load("ROCR")

lda.pred <- prediction(pp, ac)                             # prediction(예측 확률, 실제 class)    

lda.perf <- performance(lda.pred, "tpr", "fpr")            # performance(, "민감도", "1-특이도")                      
plot(lda.perf, col = "gray")                               # ROC Curve

perf.auc   <- performance(lda.pred, "auc")                 # AUC
auc        <- attributes(perf.auc)$y.values 
legend("bottomright", legend = auc, bty = "n")
```

<br />

#### 향상 차트

##### Package "ROCR"

```{r}
lda.pred <- performance(lda.pred, "lift", "rpp")          # Lift Chart
plot(lda.pred, main = "lift curve", 
     colorize = T,                                        # Coloring according to cutoff
     lwd = 2)  
```


<br />

#### 오분류표

```{r}
# 오분류표
lda.ctbl <- table(titanic.ted.Imp$Survived,                # Test Dataset의 실제 class 
                  titanic.lda.pred$class)                  # 예측 class

lda.ctbl

Desc(lda.ctbl,                                         
     digits = 4)
```

`Result!` `Test Dataset`에 대해서 Target "Survived"의 "no"에 속하는 164개의 case 중 159개(159/164=97.0%)는 "no"로 제대로 분류되었으나 5개(5/164=3.0%)는 "yes"로 잘못 분류되었다. 또한, Target "Survived"의 "yes"에 속하는 102개의 case 중 17개(17/102=16.7%)는 "yes"로 제대로 분류되었으나 85개(85/102=83.3%)는 "no"로 잘못 분류되었다. 유도된 선형판별함수에 대한 오분류율은 (5+85)/266=33.8%이며, 정확도는 (159+17)/266=66.2%이다.


## 이차판별분석(QDA)

</br>

### 모형 훈련

`Caution!` Package `"MASS"`에서 제공하는 함수 `qda()`를 통해 이차판별함수를 얻을 수 있다. 

```{r}
titanic.qda <- qda(Survived ~ .,     
                   # prior = c(1/2, 1/2),            # 사전확률
                   data = titanic.trd.Imp)      

titanic.qda
```

`Caution!` 이차판별분석에서는 판별계수를 출력하지 않는다.


```{r}
# 두 예측 변수 "Age"와 "Fare"에 대해 이차판별분석에 기초한 관측값의 분류 결과
partimat(Survived ~ Age + Fare,    
         data = titanic.trd.Imp,
         method = "qda")
```

`Result!` 빨간색은 잘못 분류된 case를 의미한다. [선형판별분석][선형판별분석(LDA)]에서 살펴본 그림과 달리 곡선형태로 분류 영역이 나뉘어져 있다는 것을 알 수 있다.


### 모형 평가

`Caution!` 모형 평가를 위해 `Test Dataset`에 대한 `예측 class/확률`이 필요하며, 함수 `predict()`를 이용하여 생성한다.

```{r}
# 예측 class와 예측 확률 생성
titanic.qda.pred <- predict(titanic.qda, 
                            newdata = titanic.ted.Imp[,-1])   # Test Dataset including Only 예측 변수   

titanic.qda.pred %>%                                       
  as_tibble
```

<br />

#### ConfusionMatrix

```{r}
CM   <- caret::confusionMatrix(titanic.qda.pred$class, titanic.ted.Imp$Survived, 
                               positive = "yes")        # confusionMatrix(예측 class, 실제 class, positive = "관심 class")
CM
```

<br />

#### ROC 곡선

```{r}
ac  <- titanic.ted.Imp$Survived                         # Test Dataset의 실제 class 
pp  <- as.numeric(titanic.qda.pred$posterior[,2])       # "Survived = yes"에 대한 예측 확률을 수치형으로 변환
```


##### Package "pROC"

```{r}
pacman::p_load("pROC")

qda.roc  <- roc(ac, pp, plot = T, col = "gray")         # roc(실제 class, 예측 확률)
auc      <- round(auc(qda.roc), 3)
legend("bottomright", legend = auc, bty = "n")
```

`Caution!` Package `"pROC"`를 통해 출력한 ROC 곡선은 다양한 함수를 이용해서 그래프를 수정할 수 있다.

```{r}
# 함수 plot.roc() 이용
plot.roc(qda.roc,   
         col="gray",                                    # Line Color
         print.auc = TRUE,                              # AUC 출력 여부
         print.auc.col = "red",                         # AUC 글씨 색깔
         print.thres = TRUE,                            # Cutoff Value 출력 여부
         print.thres.pch = 19,                          # Cutoff Value를 표시하는 도형 모양
         print.thres.col = "red",                       # Cutoff Value를 표시하는 도형의 색깔
         auc.polygon = TRUE,                            # 곡선 아래 면적에 대한 여부
         auc.polygon.col = "gray90")                    # 곡선 아래 면적의 색깔
```


```{r}
# 함수 ggroc() 이용
ggroc(qda.roc) +
annotate(geom = "text", x = 0.9, y = 1.0,
label = paste("AUC = ", auc),
size = 5,
color="red") +
theme_bw()
```


##### Package "Epi"

```{r}
pacman::p_load("Epi")       
# install_version("etm", version = "1.1", repos = "http://cran.us.r-project.org")

ROC(pp, ac, plot = "ROC")                                  # ROC(예측 확률, 실제 class)  
```


##### Package "ROCR"

```{r}
pacman::p_load("ROCR")

qda.pred <- prediction(pp, ac)                             # prediction(예측 확률, 실제 class)    

qda.perf <- performance(qda.pred, "tpr", "fpr")            # performance(, "민감도", "1-특이도")                      
plot(qda.perf, col = "gray")                               # ROC Curve

perf.auc   <- performance(qda.pred, "auc")                 # AUC
auc        <- attributes(perf.auc)$y.values 
legend("bottomright", legend = auc, bty = "n")
```

<br />

#### 향상 차트

##### Package "ROCR"

```{r}
qda.pred <- performance(qda.pred, "lift", "rpp")          # Lift Chart
plot(qda.pred, main = "lift curve", 
     colorize = T,                                        # Coloring according to cutoff
     lwd = 2)  
```


<br />

#### 오분류표

```{r}
# 오분류표
qda.ctbl <- table(titanic.ted.Imp$Survived,                # Test Dataset의 실제 class 
                  titanic.qda.pred$class)                  # 예측 class

qda.ctbl

Desc(qda.ctbl,                                          
     digits = 4)
```

`Result!` `Test Dataset`에 대해서 Target "Survived"의 "no"에 속하는 164개의 case 중 157개(157/164=95.7%)는 "no"로 제대로 분류되었으나 7개(7/164=4.3%)는 "yes"로 잘못 분류되었다. 또한, Target "Survived"의 "yes"에 속하는 102개의 case 중 21개(21/102=20.6%)는 "yes"로 제대로 분류되었으나 81개(81/102=79.4%)는 "no"로 잘못 분류되었다. 유도된 이차판별함수에 대한 오분류율은 (7+81)/266=33.1%이며, 정확도는 (157+21)/266=66.9%이다.


