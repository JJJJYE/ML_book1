[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Mining",
    "section": "",
    "text": "About\nThis book provides a practical introduction to applying data mining techniques using R, focusing on implementing and interpreting key algorithms without complex model tuning.\nThis book takes a data mining-oriented perspective, guiding readers through the basic workflow of data preprocessing, modeling, and result interpretation. It is designed to be approachable for beginners, with clear explanations and example-based demonstrations.\nKey features of the book include:\n\nConceptual overviews and practical motivations behind each algorithm\nA step-by-step analysis process in R: from preprocessing to modeling and evaluation\nApplication of algorithms using default settings, without hyperparameter tuning\nExample code using real-world datasets\nSimple interpretation of analysis results\n\nThis book is intended for students, graduate researchers, data analysis beginners, and practitioners, focusing more on practical implementation and interpretation than on theoretical depth or algorithmic comparisons.\nBy prioritizing understanding the structure of the data and following a consistent analysis workflow, readers will gain the ability to independently apply fundamental data mining techniques using R in real-world settings.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "KNN.html",
    "href": "KNN.html",
    "title": "1  Nearest Neighborhood Algorithm",
    "section": "",
    "text": "1.1 데이터 불러오기\npacman::p_load(\"data.table\", \"dplyr\", \"tidyr\",\n               \"caret\",\n               \"ggplot2\", \"GGally\")\n\ntitanic &lt;- fread(\"../Titanic.csv\")                                       # 데이터 불러오기\n\ntitanic %&gt;%\n  as_tibble\n# A tibble: 891 × 11\n   Survived Pclass Name                                                Sex      Age SibSp Parch Ticket            Fare Cabin  Embarked\n      &lt;int&gt;  &lt;int&gt; &lt;chr&gt;                                               &lt;chr&gt;  &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;   \n 1        0      3 Braund, Mr. Owen Harris                             male      22     1     0 A/5 21171         7.25 \"\"     S       \n 2        1      1 Cumings, Mrs. John Bradley (Florence Briggs Thayer) female    38     1     0 PC 17599         71.3  \"C85\"  C       \n 3        1      3 Heikkinen, Miss. Laina                              female    26     0     0 STON/O2. 3101282  7.92 \"\"     S       \n 4        1      1 Futrelle, Mrs. Jacques Heath (Lily May Peel)        female    35     1     0 113803           53.1  \"C123\" S       \n 5        0      3 Allen, Mr. William Henry                            male      35     0     0 373450            8.05 \"\"     S       \n 6        0      3 Moran, Mr. James                                    male      NA     0     0 330877            8.46 \"\"     Q       \n 7        0      1 McCarthy, Mr. Timothy J                             male      54     0     0 17463            51.9  \"E46\"  S       \n 8        0      3 Palsson, Master. Gosta Leonard                      male       2     3     1 349909           21.1  \"\"     S       \n 9        1      3 Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)   female    27     0     2 347742           11.1  \"\"     S       \n10        1      2 Nasser, Mrs. Nicholas (Adele Achem)                 female    14     1     0 237736           30.1  \"\"     C       \n# ℹ 881 more rows",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Nearest Neighborhood Algorithm</span>"
    ]
  },
  {
    "objectID": "KNN.html#데이터-전처리-i",
    "href": "KNN.html#데이터-전처리-i",
    "title": "1  Nearest Neighborhood Algorithm",
    "section": "1.2 데이터 전처리 I",
    "text": "1.2 데이터 전처리 I\n\ntitanic %&lt;&gt;%\n  data.frame() %&gt;%                                                      # Data Frame 형태로 변환 \n  mutate(Survived = ifelse(Survived == 1, \"yes\", \"no\"))                 # Target을 문자형 변수로 변환\n\n# 1. Convert to Factor\nfac.col &lt;- c(\"Pclass\", \"Sex\",\n             # Target\n             \"Survived\")\n\ntitanic &lt;- titanic %&gt;% \n  mutate_at(fac.col, as.factor)                                         # 범주형으로 변환\n\nglimpse(titanic)                                                        # 데이터 구조 확인\n\nRows: 891\nColumns: 11\n$ Survived &lt;fct&gt; no, yes, yes, yes, no, no, no, no, yes, yes, yes, yes, no, no, no, yes, no, yes, no, yes, no, yes, yes, yes, no, yes, no, no, yes, no, no, yes, yes, no, no, no, yes, no, no, yes, no…\n$ Pclass   &lt;fct&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3, 2, 2, 3, 1, 3, 3, 3, 1, 3, 3, 1, 1, 3, 2, 1, 1, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 1, 1, 2, 3, 2, 3, 3…\n$ Name     &lt;chr&gt; \"Braund, Mr. Owen Harris\", \"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\", \"Heikkinen, Miss. Laina\", \"Futrelle, Mrs. Jacques Heath (Lily May Peel)\", \"Allen, Mr. William Henry…\n$ Sex      &lt;fct&gt; male, female, female, female, male, male, male, male, female, female, female, female, male, male, female, female, male, male, female, female, male, male, female, male, female, femal…\n$ Age      &lt;dbl&gt; 22.0, 38.0, 26.0, 35.0, 35.0, NA, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, NA, 31.0, NA, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, NA, 19.0, NA, NA, 40.0, NA, NA, 66.…\n$ SibSp    &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0, 0, 0, 0, 0, 3, 1, 0, 3, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 1, 0, 0, 1, 0, 2, 1, 4, 0, 1, 1, 0, 0, 0, 0, 1, 5, 0…\n$ Parch    &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 5, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 2, 2, 0…\n$ Ticket   &lt;chr&gt; \"A/5 21171\", \"PC 17599\", \"STON/O2. 3101282\", \"113803\", \"373450\", \"330877\", \"17463\", \"349909\", \"347742\", \"237736\", \"PP 9549\", \"113783\", \"A/5. 2151\", \"347082\", \"350406\", \"248706\", \"38…\n$ Fare     &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625, 21.0750, 11.1333, 30.0708, 16.7000, 26.5500, 8.0500, 31.2750, 7.8542, 16.0000, 29.1250, 13.0000, 18.0000, 7.2250, 26.0000,…\n$ Cabin    &lt;chr&gt; \"\", \"C85\", \"\", \"C123\", \"\", \"\", \"E46\", \"\", \"\", \"\", \"G6\", \"C103\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"D56\", \"\", \"A6\", \"\", \"\", \"\", \"C23 C25 C27\", \"\", \"\", \"\", \"B78\", \"\", \"\", \"\", \"\", \"\"…\n$ Embarked &lt;chr&gt; \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"C\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"Q\", \"S\", \"C\", \"C\", \"Q\", \"S\", \"C\", \"S\", \"…\n\n# 2. Generate New Variable\ntitanic &lt;- titanic %&gt;%\n  mutate(FamSize = SibSp + Parch)                                       # \"FamSize = 형제 및 배우자 수 + 부모님 및 자녀 수\"로 가족 수를 의미하는 새로운 변수\n\nglimpse(titanic)                                                        # 데이터 구조 확인\n\nRows: 891\nColumns: 12\n$ Survived &lt;fct&gt; no, yes, yes, yes, no, no, no, no, yes, yes, yes, yes, no, no, no, yes, no, yes, no, yes, no, yes, yes, yes, no, yes, no, no, yes, no, no, yes, yes, no, no, no, yes, no, no, yes, no…\n$ Pclass   &lt;fct&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3, 2, 2, 3, 1, 3, 3, 3, 1, 3, 3, 1, 1, 3, 2, 1, 1, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 1, 1, 2, 3, 2, 3, 3…\n$ Name     &lt;chr&gt; \"Braund, Mr. Owen Harris\", \"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\", \"Heikkinen, Miss. Laina\", \"Futrelle, Mrs. Jacques Heath (Lily May Peel)\", \"Allen, Mr. William Henry…\n$ Sex      &lt;fct&gt; male, female, female, female, male, male, male, male, female, female, female, female, male, male, female, female, male, male, female, female, male, male, female, male, female, femal…\n$ Age      &lt;dbl&gt; 22.0, 38.0, 26.0, 35.0, 35.0, NA, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, NA, 31.0, NA, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, NA, 19.0, NA, NA, 40.0, NA, NA, 66.…\n$ SibSp    &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0, 0, 0, 0, 0, 3, 1, 0, 3, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 1, 0, 0, 1, 0, 2, 1, 4, 0, 1, 1, 0, 0, 0, 0, 1, 5, 0…\n$ Parch    &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 5, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 2, 2, 0…\n$ Ticket   &lt;chr&gt; \"A/5 21171\", \"PC 17599\", \"STON/O2. 3101282\", \"113803\", \"373450\", \"330877\", \"17463\", \"349909\", \"347742\", \"237736\", \"PP 9549\", \"113783\", \"A/5. 2151\", \"347082\", \"350406\", \"248706\", \"38…\n$ Fare     &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625, 21.0750, 11.1333, 30.0708, 16.7000, 26.5500, 8.0500, 31.2750, 7.8542, 16.0000, 29.1250, 13.0000, 18.0000, 7.2250, 26.0000,…\n$ Cabin    &lt;chr&gt; \"\", \"C85\", \"\", \"C123\", \"\", \"\", \"E46\", \"\", \"\", \"\", \"G6\", \"C103\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"D56\", \"\", \"A6\", \"\", \"\", \"\", \"C23 C25 C27\", \"\", \"\", \"\", \"B78\", \"\", \"\", \"\", \"\", \"\"…\n$ Embarked &lt;chr&gt; \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"C\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"Q\", \"S\", \"C\", \"C\", \"Q\", \"S\", \"C\", \"S\", \"…\n$ FamSize  &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 4, 2, 1, 2, 0, 0, 6, 0, 0, 5, 0, 1, 0, 0, 0, 0, 0, 4, 6, 0, 5, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 3, 0, 0, 1, 0, 2, 1, 5, 0, 1, 1, 1, 0, 0, 0, 3, 7, 0…\n\n# 3. Select Variables used for Analysis\ntitanic1 &lt;- titanic %&gt;% \n  select(Survived, Pclass, Sex, Age, Fare, FamSize)                     # 분석에 사용할 변수 선택\n\n# 4. Convert One-hot Encoding for 범주형 예측 변수\ndummies &lt;- dummyVars(formula = ~ .,                                     # formula : ~ 예측 변수 / \".\" : data에 포함된 모든 변수를 의미\n                     data = titanic1[,-1],                              # Dataset including Only 예측 변수 -&gt; Target 제외\n                     fullRank = FALSE)                                  # fullRank = TRUE : Dummy Variable, fullRank = FALSE : One-hot Encoding\n\ntitanic.Var   &lt;- predict(dummies, newdata = titanic1) %&gt;%               # 범주형 예측 변수에 대한 One-hot Encoding 변환\n  data.frame()                                                          # Data Frame 형태로 변환 \n\nglimpse(titanic.Var)                                                    # 데이터 구조 확인\n\nRows: 891\nColumns: 8\n$ Pclass.1   &lt;dbl&gt; 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,…\n$ Pclass.2   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,…\n$ Pclass.3   &lt;dbl&gt; 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1,…\n$ Sex.female &lt;dbl&gt; 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0,…\n$ Sex.male   &lt;dbl&gt; 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1,…\n$ Age        &lt;dbl&gt; 22.0, 38.0, 26.0, 35.0, 35.0, NA, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, NA, 31.0, NA, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, NA, 19.0, NA, NA, 40.0, NA, NA, 6…\n$ Fare       &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625, 21.0750, 11.1333, 30.0708, 16.7000, 26.5500, 8.0500, 31.2750, 7.8542, 16.0000, 29.1250, 13.0000, 18.0000, 7.2250, 26.000…\n$ FamSize    &lt;dbl&gt; 1, 1, 0, 1, 0, 0, 0, 4, 2, 1, 2, 0, 0, 6, 0, 0, 5, 0, 1, 0, 0, 0, 0, 0, 4, 6, 0, 5, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 3, 0, 0, 1, 0, 2, 1, 5, 0, 1, 1, 1, 0, 0, 0, 3, 7,…\n\n# Combine Target with 변환된 예측 변수\ntitanic.df &lt;- data.frame(Survived = titanic1$Survived, \n                         titanic.Var)\n\ntitanic.df %&gt;%\n  as_tibble\n\n# A tibble: 891 × 9\n   Survived Pclass.1 Pclass.2 Pclass.3 Sex.female Sex.male   Age  Fare FamSize\n   &lt;fct&gt;       &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n 1 no              0        0        1          0        1    22  7.25       1\n 2 yes             1        0        0          1        0    38 71.3        1\n 3 yes             0        0        1          1        0    26  7.92       0\n 4 yes             1        0        0          1        0    35 53.1        1\n 5 no              0        0        1          0        1    35  8.05       0\n 6 no              0        0        1          0        1    NA  8.46       0\n 7 no              1        0        0          0        1    54 51.9        0\n 8 no              0        0        1          0        1     2 21.1        4\n 9 yes             0        0        1          1        0    27 11.1        2\n10 yes             0        1        0          1        0    14 30.1        1\n# ℹ 881 more rows\n\nglimpse(titanic.df)                                                     # 데이터 구조 확인\n\nRows: 891\nColumns: 9\n$ Survived   &lt;fct&gt; no, yes, yes, yes, no, no, no, no, yes, yes, yes, yes, no, no, no, yes, no, yes, no, yes, no, yes, yes, yes, no, yes, no, no, yes, no, no, yes, yes, no, no, no, yes, no, no, yes, …\n$ Pclass.1   &lt;dbl&gt; 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,…\n$ Pclass.2   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,…\n$ Pclass.3   &lt;dbl&gt; 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1,…\n$ Sex.female &lt;dbl&gt; 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0,…\n$ Sex.male   &lt;dbl&gt; 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1,…\n$ Age        &lt;dbl&gt; 22.0, 38.0, 26.0, 35.0, 35.0, NA, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, NA, 31.0, NA, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, NA, 19.0, NA, NA, 40.0, NA, NA, 6…\n$ Fare       &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625, 21.0750, 11.1333, 30.0708, 16.7000, 26.5500, 8.0500, 31.2750, 7.8542, 16.0000, 29.1250, 13.0000, 18.0000, 7.2250, 26.000…\n$ FamSize    &lt;dbl&gt; 1, 1, 0, 1, 0, 0, 0, 4, 2, 1, 2, 0, 0, 6, 0, 0, 5, 0, 1, 0, 0, 0, 0, 0, 4, 6, 0, 5, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 3, 0, 0, 1, 0, 2, 1, 5, 0, 1, 1, 1, 0, 0, 0, 3, 7,…",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Nearest Neighborhood Algorithm</span>"
    ]
  },
  {
    "objectID": "KNN.html#데이터-탐색",
    "href": "KNN.html#데이터-탐색",
    "title": "1  Nearest Neighborhood Algorithm",
    "section": "1.3 데이터 탐색",
    "text": "1.3 데이터 탐색\n\nggpairs(titanic.df,                                        \n        aes(colour = Survived)) +                     # Target의 범주에 따라 색깔을 다르게 표현\n  theme_bw()\n\n\n\n\n\n\n\nggpairs(titanic.df,                                     \n        aes(colour = Survived, alpha = 0.8)) +        # Target의 범주에 따라 색깔을 다르게 표현\n  scale_colour_manual(values = c(\"purple\",\"cyan4\")) + # 특정 색깔 지정\n  scale_fill_manual(values = c(\"purple\",\"cyan4\")) +   # 특정 색깔 지정\n  theme_bw()",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Nearest Neighborhood Algorithm</span>"
    ]
  },
  {
    "objectID": "KNN.html#데이터-분할",
    "href": "KNN.html#데이터-분할",
    "title": "1  Nearest Neighborhood Algorithm",
    "section": "1.4 데이터 분할",
    "text": "1.4 데이터 분할\n\n# Partition (Training Dataset : Test Dataset = 7:3)\ny      &lt;- titanic.df$Survived                         # Target\n\nset.seed(200)\nind    &lt;- createDataPartition(y, p = 0.7, list  =T)   # Index를 이용하여 7:3으로 분할\ntitanic.trd &lt;- titanic.df[ind$Resample1,]             # Training Dataset\ntitanic.ted &lt;- titanic.df[-ind$Resample1,]            # Test Dataset",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Nearest Neighborhood Algorithm</span>"
    ]
  },
  {
    "objectID": "KNN.html#데이터-전처리-ii",
    "href": "KNN.html#데이터-전처리-ii",
    "title": "1  Nearest Neighborhood Algorithm",
    "section": "1.5 데이터 전처리 II",
    "text": "1.5 데이터 전처리 II\n\n# 1. Imputation\ntitanic.trd.Imp &lt;- titanic.trd %&gt;% \n  mutate(Age = replace_na(Age, mean(Age, na.rm = TRUE)))                 # 평균으로 결측값 대체\n\ntitanic.ted.Imp &lt;- titanic.ted %&gt;% \n  mutate(Age = replace_na(Age, mean(titanic.trd$Age, na.rm = TRUE)))     # Training Dataset을 이용하여 결측값 대체\n\n# 2. Standardization\npreProcValues &lt;- preProcess(titanic.trd.Imp, \n                            method = c(\"center\", \"scale\"))               # Standardization 정의 -&gt; Training Dataset에 대한 평균과 표준편차 계산 \n\ntitanic.trd.Imp &lt;- predict(preProcValues, titanic.trd.Imp)               # Standardization for Training Dataset\ntitanic.ted.Imp &lt;- predict(preProcValues, titanic.ted.Imp)               # Standardization for Test Dataset\n\nglimpse(titanic.trd.Imp)                                                 # 데이터 구조 확인\n\nRows: 625\nColumns: 9\n$ Survived   &lt;fct&gt; no, yes, yes, no, no, no, yes, yes, yes, yes, no, no, yes, no, yes, no, yes, no, no, no, yes, no, no, yes, yes, no, no, no, no, no, yes, no, no, no, yes, no, yes, no, no, no, yes,…\n$ Pclass.1   &lt;dbl&gt; -0.593506, -0.593506, 1.682207, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, 1.682207, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, 1.682…\n$ Pclass.2   &lt;dbl&gt; -0.4694145, -0.4694145, -0.4694145, -0.4694145, -0.4694145, -0.4694145, -0.4694145, 2.1269048, -0.4694145, -0.4694145, -0.4694145, -0.4694145, 2.1269048, -0.4694145, -0.4694145, 2…\n$ Pclass.3   &lt;dbl&gt; 0.888575, 0.888575, -1.123597, 0.888575, 0.888575, 0.888575, 0.888575, -1.123597, 0.888575, -1.123597, 0.888575, 0.888575, -1.123597, 0.888575, 0.888575, -1.123597, -1.123597, 0.8…\n$ Sex.female &lt;dbl&gt; -0.7572241, 1.3184999, 1.3184999, -0.7572241, -0.7572241, -0.7572241, 1.3184999, 1.3184999, 1.3184999, 1.3184999, -0.7572241, 1.3184999, -0.7572241, 1.3184999, 1.3184999, -0.75722…\n$ Sex.male   &lt;dbl&gt; 0.7572241, -1.3184999, -1.3184999, 0.7572241, 0.7572241, 0.7572241, -1.3184999, -1.3184999, -1.3184999, -1.3184999, 0.7572241, -1.3184999, 0.7572241, -1.3184999, -1.3184999, 0.757…\n$ Age        &lt;dbl&gt; -0.61306970, -0.30411628, 0.39102893, 0.39102893, 0.00000000, -2.15783684, -0.22687792, -1.23097656, -2.00336012, 2.16751113, 0.69998236, -1.23097656, 0.00000000, 0.08207551, 0.00…\n$ Fare       &lt;dbl&gt; -0.51776394, -0.50463325, 0.37414970, -0.50220165, -0.49425904, -0.24882814, -0.44222264, -0.07383411, -0.33393441, -0.14232374, -0.05040897, -0.50601052, -0.40590999, -0.30864569…\n$ FamSize    &lt;dbl&gt; 0.04506631, -0.55421976, 0.04506631, -0.55421976, -0.55421976, 1.84292454, 0.64435239, 0.04506631, 0.64435239, -0.55421976, 3.04149669, -0.55421976, -0.55421976, 0.04506631, -0.55…\n\nglimpse(titanic.ted.Imp)                                                 # 데이터 구조 확인\n\nRows: 266\nColumns: 9\n$ Survived   &lt;fct&gt; yes, no, no, yes, no, yes, yes, yes, yes, yes, no, no, yes, yes, no, yes, no, yes, yes, no, yes, no, no, no, no, no, no, yes, yes, no, no, no, no, no, no, no, no, no, no, yes, no,…\n$ Pclass.1   &lt;dbl&gt; 1.682207, 1.682207, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, 1.682…\n$ Pclass.2   &lt;dbl&gt; -0.4694145, -0.4694145, -0.4694145, 2.1269048, -0.4694145, 2.1269048, -0.4694145, -0.4694145, -0.4694145, 2.1269048, -0.4694145, -0.4694145, 2.1269048, 2.1269048, -0.4694145, 2.12…\n$ Pclass.3   &lt;dbl&gt; -1.123597, -1.123597, 0.888575, -1.123597, 0.888575, -1.123597, 0.888575, 0.888575, 0.888575, -1.123597, 0.888575, 0.888575, -1.123597, -1.123597, 0.888575, -1.123597, -1.123597, …\n$ Sex.female &lt;dbl&gt; 1.3184999, -0.7572241, -0.7572241, 1.3184999, -0.7572241, -0.7572241, 1.3184999, 1.3184999, -0.7572241, 1.3184999, -0.7572241, -0.7572241, 1.3184999, 1.3184999, -0.7572241, 1.3184…\n$ Sex.male   &lt;dbl&gt; -1.3184999, 0.7572241, 0.7572241, -1.3184999, 0.7572241, 0.7572241, -1.3184999, -1.3184999, 0.7572241, -1.3184999, 0.7572241, 0.7572241, -1.3184999, -1.3184999, 0.7572241, -1.3184…\n$ Age        &lt;dbl&gt; 0.62274400, 1.85855771, -0.76754642, 1.93579607, -2.15783684, 0.31379058, -1.15373820, 0.62274400, 0.00000000, -2.08059848, 0.00000000, -0.69030806, -0.07240121, -0.69030806, -0.1…\n$ Fare       &lt;dbl&gt; 0.727866891, 0.350076786, -0.502201647, -0.347551409, -0.092232621, -0.405909990, -0.502606266, -0.048220525, -0.518168555, 0.150037190, -0.502201647, -0.507064862, -0.153022808, …\n$ FamSize    &lt;dbl&gt; 0.04506631, -0.55421976, -0.55421976, -0.55421976, 2.44221062, -0.55421976, -0.55421976, 3.04149669, -0.55421976, 1.24363847, -0.55421976, -0.55421976, 0.04506631, -0.55421976, -0…",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Nearest Neighborhood Algorithm</span>"
    ]
  },
  {
    "objectID": "KNN.html#모형-훈련",
    "href": "KNN.html#모형-훈련",
    "title": "1  Nearest Neighborhood Algorithm",
    "section": "1.6 모형 훈련",
    "text": "1.6 모형 훈련\nNearest Neighborhood Algorithm은 다양한 Package(예를 들어, \"caret\", \"class\")를 통해 수행할 수 있다. Package \"class\"의 함수 knn()를 이용하면 특정 class에 대한 예측 확률만 얻을 수 있는 반면, Package \"caret\"의 함수 knn3()를 이용하면 각 class에 대한 예측 확률을 얻을 수 있다. 그래서 여기서는 Package \"caret\"을 이용하여 모형 훈련을 수행한다.\n\nknn.model &lt;- knn3(Survived ~ .,                             # Target ~ 예측 변수\n                  data = titanic.trd.Imp,                   # Training Dataset\n                  k = 4)                                    # 이웃 개수\n\nknn.model\n\n4-nearest neighbor model\nTraining set outcome distribution:\n\n no yes \n385 240 \n\n\nCaution! Package \"caret\"에서 제공하는 함수 knn3Train()를 이용하면 Training Dataset에 대한 모형 훈련과 Test Dataset에 대한 예측을 한 번에 수행할 수 있다.\n\n# 모형 훈련 & 예측 한꺼번에\nknn3Train(titanic.trd.Imp[, -1],                              # Training Dataset including Only 예측 변수\n          titanic.ted.Imp[, -1],                              # Test Dataset including Only 예측 변수\n          cl = titanic.trd.Imp[, 1],                          # Target of Training Dataset\n          k = 4)                                              # 이웃 개수\n\n  [1] \"yes\" \"no\"  \"no\"  \"yes\" \"no\"  \"no\"  \"yes\" \"no\"  \"no\"  \"yes\" \"no\"  \"no\"  \"yes\" \"yes\" \"no\"  \"yes\" \"no\"  \"no\"  \"yes\" \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"yes\" \"no\"  \"yes\" \"no\" \n [33] \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"yes\" \"no\"  \"no\"  \"no\"  \"yes\" \"no\"  \"no\"  \"no\"  \"no\"  \"yes\" \"no\"  \"no\"  \"no\"  \"no\"  \"yes\" \"no\"  \"yes\" \"no\"  \"no\"  \"no\"  \"yes\" \"no\"  \"no\"  \"yes\" \"no\" \n [65] \"yes\" \"no\"  \"no\"  \"yes\" \"no\"  \"no\"  \"no\"  \"no\"  \"yes\" \"yes\" \"no\"  \"no\"  \"yes\" \"no\"  \"no\"  \"no\"  \"yes\" \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"yes\" \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"yes\" \"yes\" \"yes\"\n [97] \"yes\" \"yes\" \"no\"  \"no\"  \"no\"  \"yes\" \"yes\" \"yes\" \"no\"  \"yes\" \"no\"  \"yes\" \"no\"  \"yes\" \"yes\" \"no\"  \"yes\" \"yes\" \"no\"  \"no\"  \"yes\" \"no\"  \"no\"  \"no\"  \"yes\" \"no\"  \"no\"  \"yes\" \"yes\" \"yes\" \"no\"  \"yes\"\n[129] \"yes\" \"yes\" \"no\"  \"yes\" \"no\"  \"no\"  \"yes\" \"yes\" \"no\"  \"no\"  \"no\"  \"no\"  \"yes\" \"no\"  \"no\"  \"no\"  \"yes\" \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"yes\" \"no\"  \"yes\" \"no\"  \"no\" \n[161] \"yes\" \"no\"  \"yes\" \"yes\" \"no\"  \"yes\" \"yes\" \"no\"  \"no\"  \"no\"  \"yes\" \"no\"  \"yes\" \"yes\" \"yes\" \"no\"  \"yes\" \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"yes\" \"no\"  \"no\"  \"no\"  \"yes\" \"no\"  \"yes\" \"no\"  \"no\" \n[193] \"yes\" \"no\"  \"no\"  \"no\"  \"no\"  \"yes\" \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"yes\" \"no\"  \"no\"  \"yes\" \"yes\" \"no\"  \"no\"  \"no\"  \"yes\" \"yes\" \"no\"  \"no\"  \"yes\" \"no\"  \"no\"  \"yes\"\n[225] \"yes\" \"yes\" \"no\"  \"no\"  \"no\"  \"no\"  \"yes\" \"no\"  \"no\"  \"no\"  \"yes\" \"no\"  \"no\"  \"yes\" \"yes\" \"no\"  \"no\"  \"yes\" \"no\"  \"no\"  \"no\"  \"yes\" \"no\"  \"yes\" \"no\"  \"no\"  \"yes\" \"no\"  \"no\"  \"no\"  \"no\"  \"yes\"\n[257] \"yes\" \"yes\" \"no\"  \"yes\" \"no\"  \"yes\" \"yes\" \"no\"  \"yes\" \"yes\"\nattr(,\"prob\")\n              no        yes\n  [1,] 0.0000000 1.00000000\n  [2,] 0.7500000 0.25000000\n  [3,] 0.7500000 0.25000000\n  [4,] 0.5000000 0.50000000\n  [5,] 0.7500000 0.25000000\n  [6,] 1.0000000 0.00000000\n  [7,] 0.2500000 0.75000000\n  [8,] 1.0000000 0.00000000\n  [9,] 1.0000000 0.00000000\n [10,] 0.0000000 1.00000000\n [11,] 1.0000000 0.00000000\n [12,] 0.8000000 0.20000000\n [13,] 0.2500000 0.75000000\n [14,] 0.2500000 0.75000000\n [15,] 0.7500000 0.25000000\n [16,] 0.0000000 1.00000000\n [17,] 0.5000000 0.50000000\n [18,] 0.5000000 0.50000000\n [19,] 0.0000000 1.00000000\n [20,] 1.0000000 0.00000000\n [21,] 1.0000000 0.00000000\n [22,] 0.8571429 0.14285714\n [23,] 1.0000000 0.00000000\n [24,] 1.0000000 0.00000000\n [25,] 1.0000000 0.00000000\n [26,] 1.0000000 0.00000000\n [27,] 0.7500000 0.25000000\n [28,] 0.5000000 0.50000000\n [29,] 0.2500000 0.75000000\n [30,] 0.7500000 0.25000000\n [31,] 0.0000000 1.00000000\n [32,] 1.0000000 0.00000000\n [33,] 1.0000000 0.00000000\n [34,] 0.8000000 0.20000000\n [35,] 0.7500000 0.25000000\n [36,] 0.7500000 0.25000000\n [37,] 1.0000000 0.00000000\n [38,] 1.0000000 0.00000000\n [39,] 0.7500000 0.25000000\n [40,] 0.0000000 1.00000000\n [41,] 1.0000000 0.00000000\n [42,] 0.7500000 0.25000000\n [43,] 1.0000000 0.00000000\n [44,] 0.0000000 1.00000000\n [45,] 1.0000000 0.00000000\n [46,] 0.5000000 0.50000000\n [47,] 1.0000000 0.00000000\n [48,] 0.7500000 0.25000000\n [49,] 0.0000000 1.00000000\n [50,] 1.0000000 0.00000000\n [51,] 1.0000000 0.00000000\n [52,] 0.7500000 0.25000000\n [53,] 0.7500000 0.25000000\n [54,] 0.2500000 0.75000000\n [55,] 1.0000000 0.00000000\n [56,] 0.2500000 0.75000000\n [57,] 1.0000000 0.00000000\n [58,] 0.7500000 0.25000000\n [59,] 0.7500000 0.25000000\n [60,] 0.0000000 1.00000000\n [61,] 0.7500000 0.25000000\n [62,] 1.0000000 0.00000000\n [63,] 0.0000000 1.00000000\n [64,] 0.7500000 0.25000000\n [65,] 0.0000000 1.00000000\n [66,] 0.7500000 0.25000000\n [67,] 0.7500000 0.25000000\n [68,] 0.2500000 0.75000000\n [69,] 1.0000000 0.00000000\n [70,] 1.0000000 0.00000000\n [71,] 1.0000000 0.00000000\n [72,] 1.0000000 0.00000000\n [73,] 0.5000000 0.50000000\n [74,] 0.0000000 1.00000000\n [75,] 1.0000000 0.00000000\n [76,] 0.7500000 0.25000000\n [77,] 0.2000000 0.80000000\n [78,] 1.0000000 0.00000000\n [79,] 1.0000000 0.00000000\n [80,] 0.7500000 0.25000000\n [81,] 0.2500000 0.75000000\n [82,] 1.0000000 0.00000000\n [83,] 0.7500000 0.25000000\n [84,] 1.0000000 0.00000000\n [85,] 0.5000000 0.50000000\n [86,] 1.0000000 0.00000000\n [87,] 0.5000000 0.50000000\n [88,] 0.7500000 0.25000000\n [89,] 1.0000000 0.00000000\n [90,] 0.8000000 0.20000000\n [91,] 1.0000000 0.00000000\n [92,] 1.0000000 0.00000000\n [93,] 0.7500000 0.25000000\n [94,] 0.2000000 0.80000000\n [95,] 0.0000000 1.00000000\n [96,] 0.0000000 1.00000000\n [97,] 0.0000000 1.00000000\n [98,] 0.0000000 1.00000000\n [99,] 0.8000000 0.20000000\n[100,] 1.0000000 0.00000000\n[101,] 1.0000000 0.00000000\n[102,] 0.0000000 1.00000000\n[103,] 0.0000000 1.00000000\n[104,] 0.5000000 0.50000000\n[105,] 1.0000000 0.00000000\n[106,] 0.0000000 1.00000000\n[107,] 1.0000000 0.00000000\n[108,] 0.0000000 1.00000000\n[109,] 1.0000000 0.00000000\n[110,] 0.0000000 1.00000000\n[111,] 0.0000000 1.00000000\n[112,] 1.0000000 0.00000000\n[113,] 0.2000000 0.80000000\n[114,] 0.4000000 0.60000000\n[115,] 1.0000000 0.00000000\n[116,] 1.0000000 0.00000000\n[117,] 0.0000000 1.00000000\n[118,] 0.5000000 0.50000000\n[119,] 0.8000000 0.20000000\n[120,] 1.0000000 0.00000000\n[121,] 0.0000000 1.00000000\n[122,] 0.7500000 0.25000000\n[123,] 0.5000000 0.50000000\n[124,] 0.0000000 1.00000000\n[125,] 0.5000000 0.50000000\n[126,] 0.5000000 0.50000000\n[127,] 0.7500000 0.25000000\n[128,] 0.2500000 0.75000000\n[129,] 0.5000000 0.50000000\n[130,] 0.5000000 0.50000000\n[131,] 0.7500000 0.25000000\n[132,] 0.2500000 0.75000000\n[133,] 1.0000000 0.00000000\n[134,] 1.0000000 0.00000000\n[135,] 0.0000000 1.00000000\n[136,] 0.0000000 1.00000000\n[137,] 0.5000000 0.50000000\n[138,] 1.0000000 0.00000000\n[139,] 1.0000000 0.00000000\n[140,] 1.0000000 0.00000000\n[141,] 0.0000000 1.00000000\n[142,] 1.0000000 0.00000000\n[143,] 1.0000000 0.00000000\n[144,] 1.0000000 0.00000000\n[145,] 0.0000000 1.00000000\n[146,] 1.0000000 0.00000000\n[147,] 0.7500000 0.25000000\n[148,] 1.0000000 0.00000000\n[149,] 1.0000000 0.00000000\n[150,] 1.0000000 0.00000000\n[151,] 0.7500000 0.25000000\n[152,] 0.5000000 0.50000000\n[153,] 0.8000000 0.20000000\n[154,] 1.0000000 0.00000000\n[155,] 0.7500000 0.25000000\n[156,] 0.2500000 0.75000000\n[157,] 0.7500000 0.25000000\n[158,] 0.5000000 0.50000000\n[159,] 1.0000000 0.00000000\n[160,] 1.0000000 0.00000000\n[161,] 0.5000000 0.50000000\n[162,] 0.7500000 0.25000000\n[163,] 0.0000000 1.00000000\n[164,] 0.2500000 0.75000000\n[165,] 0.7500000 0.25000000\n[166,] 0.0000000 1.00000000\n[167,] 0.0000000 1.00000000\n[168,] 0.5000000 0.50000000\n[169,] 1.0000000 0.00000000\n[170,] 0.7500000 0.25000000\n[171,] 0.5000000 0.50000000\n[172,] 1.0000000 0.00000000\n[173,] 0.0000000 1.00000000\n[174,] 0.2000000 0.80000000\n[175,] 0.0000000 1.00000000\n[176,] 1.0000000 0.00000000\n[177,] 0.0000000 1.00000000\n[178,] 1.0000000 0.00000000\n[179,] 1.0000000 0.00000000\n[180,] 1.0000000 0.00000000\n[181,] 0.7500000 0.25000000\n[182,] 1.0000000 0.00000000\n[183,] 1.0000000 0.00000000\n[184,] 0.0000000 1.00000000\n[185,] 1.0000000 0.00000000\n[186,] 1.0000000 0.00000000\n[187,] 1.0000000 0.00000000\n[188,] 0.0000000 1.00000000\n[189,] 1.0000000 0.00000000\n[190,] 0.0000000 1.00000000\n[191,] 1.0000000 0.00000000\n[192,] 1.0000000 0.00000000\n[193,] 0.5000000 0.50000000\n[194,] 1.0000000 0.00000000\n[195,] 1.0000000 0.00000000\n[196,] 1.0000000 0.00000000\n[197,] 0.7500000 0.25000000\n[198,] 0.5000000 0.50000000\n[199,] 1.0000000 0.00000000\n[200,] 1.0000000 0.00000000\n[201,] 0.8571429 0.14285714\n[202,] 0.5000000 0.50000000\n[203,] 1.0000000 0.00000000\n[204,] 1.0000000 0.00000000\n[205,] 1.0000000 0.00000000\n[206,] 1.0000000 0.00000000\n[207,] 1.0000000 0.00000000\n[208,] 0.7500000 0.25000000\n[209,] 0.1666667 0.83333333\n[210,] 1.0000000 0.00000000\n[211,] 0.8000000 0.20000000\n[212,] 0.2500000 0.75000000\n[213,] 0.0000000 1.00000000\n[214,] 1.0000000 0.00000000\n[215,] 0.7500000 0.25000000\n[216,] 1.0000000 0.00000000\n[217,] 0.0000000 1.00000000\n[218,] 0.0000000 1.00000000\n[219,] 1.0000000 0.00000000\n[220,] 1.0000000 0.00000000\n[221,] 0.5000000 0.50000000\n[222,] 0.7500000 0.25000000\n[223,] 1.0000000 0.00000000\n[224,] 0.0000000 1.00000000\n[225,] 0.0000000 1.00000000\n[226,] 0.0000000 1.00000000\n[227,] 0.7500000 0.25000000\n[228,] 0.7500000 0.25000000\n[229,] 1.0000000 0.00000000\n[230,] 1.0000000 0.00000000\n[231,] 0.2500000 0.75000000\n[232,] 0.7500000 0.25000000\n[233,] 1.0000000 0.00000000\n[234,] 1.0000000 0.00000000\n[235,] 0.5000000 0.50000000\n[236,] 1.0000000 0.00000000\n[237,] 1.0000000 0.00000000\n[238,] 0.0000000 1.00000000\n[239,] 0.5000000 0.50000000\n[240,] 0.6000000 0.40000000\n[241,] 0.7500000 0.25000000\n[242,] 0.0000000 1.00000000\n[243,] 1.0000000 0.00000000\n[244,] 0.7500000 0.25000000\n[245,] 1.0000000 0.00000000\n[246,] 0.0000000 1.00000000\n[247,] 1.0000000 0.00000000\n[248,] 0.0000000 1.00000000\n[249,] 1.0000000 0.00000000\n[250,] 1.0000000 0.00000000\n[251,] 0.2500000 0.75000000\n[252,] 0.7500000 0.25000000\n[253,] 0.7500000 0.25000000\n[254,] 1.0000000 0.00000000\n[255,] 1.0000000 0.00000000\n[256,] 0.0000000 1.00000000\n[257,] 0.0000000 1.00000000\n[258,] 0.0000000 1.00000000\n[259,] 0.9166667 0.08333333\n[260,] 0.0000000 1.00000000\n[261,] 0.7500000 0.25000000\n[262,] 0.2500000 0.75000000\n[263,] 0.2500000 0.75000000\n[264,] 1.0000000 0.00000000\n[265,] 0.2500000 0.75000000\n[266,] 0.5000000 0.50000000",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Nearest Neighborhood Algorithm</span>"
    ]
  },
  {
    "objectID": "KNN.html#모형-평가",
    "href": "KNN.html#모형-평가",
    "title": "1  Nearest Neighborhood Algorithm",
    "section": "1.7 모형 평가",
    "text": "1.7 모형 평가\nCaution! 모형 평가를 위해 Test Dataset에 대한 예측 class/확률 이 필요하며, 함수 predict()를 이용하여 생성한다.\n\n# 예측 class 생성\nknn.pred &lt;- predict(knn.model,                                        \n                    newdata = titanic.ted.Imp[,-1],   # Test Dataset including Only 예측 변수   \n                    type = \"class\")                   # 예측 class 생성\n\nknn.pred %&gt;%\n  as_tibble\n\n# A tibble: 266 × 1\n   value\n   &lt;fct&gt;\n 1 yes  \n 2 no   \n 3 no   \n 4 no   \n 5 no   \n 6 no   \n 7 yes  \n 8 no   \n 9 no   \n10 yes  \n# ℹ 256 more rows\n\n\n\n\n1.7.1 ConfusionMatrix\n\nCM   &lt;- caret::confusionMatrix(knn.pred, titanic.ted.Imp$Survived, \n                               positive = \"yes\")     # confusionMatrix(예측 class, 실제 class, positive = \"관심 class\")\nCM\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  no yes\n       no  148  28\n       yes  16  74\n                                          \n               Accuracy : 0.8346          \n                 95% CI : (0.7844, 0.8772)\n    No Information Rate : 0.6165          \n    P-Value [Acc &gt; NIR] : 7.118e-15       \n                                          \n                  Kappa : 0.6422          \n                                          \n Mcnemar's Test P-Value : 0.09725         \n                                          \n            Sensitivity : 0.7255          \n            Specificity : 0.9024          \n         Pos Pred Value : 0.8222          \n         Neg Pred Value : 0.8409          \n             Prevalence : 0.3835          \n         Detection Rate : 0.2782          \n   Detection Prevalence : 0.3383          \n      Balanced Accuracy : 0.8140          \n                                          \n       'Positive' Class : yes             \n                                          \n\n\n\n\n\n1.7.2 ROC 곡선\n\n# 예측 확률 생성\ntest.knn.prob &lt;- predict(knn.model, \n                         newdata = titanic.ted.Imp[,-1],   # Test Dataset including Only 예측 변수  \n                         type = \"prob\")                    # 예측 확률 생성 \n\ntest.knn.prob %&gt;%\n  as_tibble\n\n# A tibble: 266 × 2\n      no   yes\n   &lt;dbl&gt; &lt;dbl&gt;\n 1  0     1   \n 2  0.75  0.25\n 3  0.75  0.25\n 4  0.5   0.5 \n 5  0.75  0.25\n 6  1     0   \n 7  0.25  0.75\n 8  1     0   \n 9  1     0   \n10  0     1   \n# ℹ 256 more rows\n\n\n\ntest.knn.prob &lt;- test.knn.prob[,2]                  # \"Survived = yes\"에 대한 예측 확률\n\nac &lt;- titanic.ted.Imp$Survived                      # Test Dataset의 실제 class         \npp &lt;- as.numeric(test.knn.prob)                     # 예측 확률을 수치형으로 변환\n\n\n1.7.2.1 Package “pROC”\n\npacman::p_load(\"pROC\")\n\nknn.roc  &lt;- roc(ac, pp, plot=T, col=\"gray\")         # roc(실제 class, 예측 확률)\nauc      &lt;- round(auc(knn.roc),3)\nlegend(\"bottomright\", legend = auc, bty = \"n\")\n\n\n\n\n\n\n\n\nCaution! Package \"pROC\"를 통해 출력한 ROC 곡선은 다양한 함수를 이용해서 그래프를 수정할 수 있다.\n\n# 함수 plot.roc() 이용\nplot.roc(knn.roc,   \n         col=\"gray\",                                # Line Color\n         print.auc = TRUE,                          # AUC 출력 여부\n         print.auc.col = \"red\",                     # AUC 글씨 색깔\n         print.thres = TRUE,                        # Cutoff Value 출력 여부\n         print.thres.pch = 19,                      # Cutoff Value를 표시하는 도형 모양\n         print.thres.col = \"red\",                   # Cutoff Value를 표시하는 도형의 색깔\n         auc.polygon = TRUE,                        # 곡선 아래 면적에 대한 여부\n         auc.polygon.col = \"gray90\")                # 곡선 아래 면적의 색깔\n\n\n\n\n\n\n\n\n\n# 함수 ggroc() 이용\nggroc(knn.roc) +\nannotate(geom = \"text\", x = 0.9, y = 1.0,\nlabel = paste(\"AUC = \", auc),\nsize = 5,\ncolor=\"red\") +\ntheme_bw()\n\n\n\n\n\n\n\n\n\n\n1.7.2.2 Package “Epi”\n\npacman::p_load(\"Epi\")       \n# install_version(\"etm\", version = \"1.1\", repos = \"http://cran.us.r-project.org\")\n\nROC(pp, ac, plot=\"ROC\")                             # ROC(예측 확률, 실제 class)  \n\n\n\n\n\n\n\n\n\n\n1.7.2.3 Package “ROCR”\n\npacman::p_load(\"ROCR\")\n\nknn.pred &lt;- prediction(pp, ac)                      # prediction(예측 확률, 실제 class)  \n\nknn.perf &lt;- performance(knn.pred, \"tpr\", \"fpr\")     # performance(, \"민감도\", \"1-특이도\")                      \nplot(knn.perf, col = \"gray\")                        # ROC Curve\n\nperf.auc   &lt;- performance(knn.pred, \"auc\")          # AUC\nauc        &lt;- attributes(perf.auc)$y.values \nlegend(\"bottomright\", legend = auc, bty = \"n\")\n\n\n\n\n\n\n\n\n\n\n\n\n1.7.3 향상 차트\n\n1.7.3.1 Package “ROCR”\n\nknn.perf       &lt;- performance(knn.pred, \"lift\", \"rpp\")  # Lift Chart\nplot(knn.perf, main = \"lift curve\", \n     colorize = T,                                      # Coloring according to cutoff\n     lwd = 2)",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Nearest Neighborhood Algorithm</span>"
    ]
  },
  {
    "objectID": "Naive.html",
    "href": "Naive.html",
    "title": "2  Naive Bayes Classification",
    "section": "",
    "text": "2.1 데이터 불러오기\npacman::p_load(\"data.table\",\n               \"dplyr\",  \"tidyr\", \"magrittr\",\n               \"ggplot2\",\n               \"e1071\",                                         # For naiveBayes\n               \"caret\")                                         # For confusionMatrix    \n                                              \ndelays.df &lt;- fread(\"../FlightDelays.csv\")                       # 데이터 불러오기\n\ndelays.df %&gt;%\n  as_tibble\n# A tibble: 2,201 × 13\n   CRS_DEP_TIME CARRIER DEP_TIME DEST  DISTANCE FL_DATE    FL_NUM ORIGIN Weather DAY_WEEK DAY_OF_MONTH TAIL_NUM `Flight Status`\n          &lt;int&gt; &lt;chr&gt;      &lt;int&gt; &lt;chr&gt;    &lt;int&gt; &lt;chr&gt;       &lt;int&gt; &lt;chr&gt;    &lt;int&gt;    &lt;int&gt;        &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;          \n 1         1455 OH          1455 JFK        184 01/01/2004   5935 BWI          0        4            1 N940CA   ontime         \n 2         1640 DH          1640 JFK        213 01/01/2004   6155 DCA          0        4            1 N405FJ   ontime         \n 3         1245 DH          1245 LGA        229 01/01/2004   7208 IAD          0        4            1 N695BR   ontime         \n 4         1715 DH          1709 LGA        229 01/01/2004   7215 IAD          0        4            1 N662BR   ontime         \n 5         1039 DH          1035 LGA        229 01/01/2004   7792 IAD          0        4            1 N698BR   ontime         \n 6          840 DH           839 JFK        228 01/01/2004   7800 IAD          0        4            1 N687BR   ontime         \n 7         1240 DH          1243 JFK        228 01/01/2004   7806 IAD          0        4            1 N321UE   ontime         \n 8         1645 DH          1644 JFK        228 01/01/2004   7810 IAD          0        4            1 N301UE   ontime         \n 9         1715 DH          1710 JFK        228 01/01/2004   7812 IAD          0        4            1 N328UE   ontime         \n10         2120 DH          2129 JFK        228 01/01/2004   7814 IAD          0        4            1 N685BR   ontime         \n# ℹ 2,191 more rows",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Naive Bayes Classification</span>"
    ]
  },
  {
    "objectID": "Naive.html#데이터-전처리",
    "href": "Naive.html#데이터-전처리",
    "title": "2  Naive Bayes Classification",
    "section": "2.2 데이터 전처리",
    "text": "2.2 데이터 전처리\n\n전처리는 2단계의 과정을 거친다.\n\n출발시간(CRS_DEP_TIME)을 시간 단위(Hourly)로 변환한다.\n\n예를 들어, 1455이면 14시 55분을 의미하며, 이것을 14로 변환한다.\n\n\n범주형 변수들을 범주형으로 변환한다.\n\n\n\n# 1. 출발시간(CRS_DEP_TIME)을 시간 단위(hourly)로 변환\n# 예) 출발시간이 오전 6시와 오전 7시 사이라면, CRS_DEP_TIME = 6\ndelays.df %&lt;&gt;%\n  data.frame() %&gt;%                                                      # Data Frame 형태로 변환\n  mutate(CRS_DEP_TIME = floor( CRS_DEP_TIME/100 ))                      \n\n# 2. Convert to Factor\nselected.var &lt;- c(\"CRS_DEP_TIME\", \"CARRIER\", \"DEST\",                    # 범주형 변수 선택\n                  \"ORIGIN\", \"DAY_WEEK\", \"Flight.Status\")\n\ndelays.df %&lt;&gt;%\n  mutate_at(selected.var, as.factor)                                    # 범주형으로 변환\n\n# 3. Select Variables used for Analysis\ndelays.df1 &lt;- delays.df %&gt;%\n  select(selected.var)                                                  # 분석에 사용할 변수만 선택\n\ndelays.df1 %&gt;%\n  as_tibble\n\n# A tibble: 2,201 × 6\n   CRS_DEP_TIME CARRIER DEST  ORIGIN DAY_WEEK Flight.Status\n   &lt;fct&gt;        &lt;fct&gt;   &lt;fct&gt; &lt;fct&gt;  &lt;fct&gt;    &lt;fct&gt;        \n 1 14           OH      JFK   BWI    4        ontime       \n 2 16           DH      JFK   DCA    4        ontime       \n 3 12           DH      LGA   IAD    4        ontime       \n 4 17           DH      LGA   IAD    4        ontime       \n 5 10           DH      LGA   IAD    4        ontime       \n 6 8            DH      JFK   IAD    4        ontime       \n 7 12           DH      JFK   IAD    4        ontime       \n 8 16           DH      JFK   IAD    4        ontime       \n 9 17           DH      JFK   IAD    4        ontime       \n10 21           DH      JFK   IAD    4        ontime       \n# ℹ 2,191 more rows\n\nglimpse(delays.df1)                                                     # 데이터 구조 확인  \n\nRows: 2,201\nColumns: 6\n$ CRS_DEP_TIME  &lt;fct&gt; 14, 16, 12, 17, 10, 8, 12, 16, 17, 21, 21, 14, 9, 12, 14, 17, 20, 15, 6, 18, 9, 13, 14, 15, 19, 8, 9, 11, 13, 15, 17, 21, 14, 17, 10, 7, 13, 17, 8, 17, 12, 21, 17, 19, 15, 19, …\n$ CARRIER       &lt;fct&gt; OH, DH, DH, DH, DH, DH, DH, DH, DH, DH, DH, DL, DL, DL, DL, DL, DL, MQ, MQ, MQ, MQ, MQ, MQ, MQ, MQ, UA, US, US, US, US, US, US, RU, RU, RU, RU, CO, CO, DH, DH, DH, DH, RU, RU, …\n$ DEST          &lt;fct&gt; JFK, JFK, LGA, LGA, LGA, JFK, JFK, JFK, JFK, JFK, LGA, JFK, LGA, LGA, LGA, LGA, LGA, JFK, JFK, JFK, LGA, LGA, LGA, LGA, LGA, LGA, LGA, LGA, LGA, LGA, LGA, LGA, EWR, EWR, EWR, E…\n$ ORIGIN        &lt;fct&gt; BWI, DCA, IAD, IAD, IAD, IAD, IAD, IAD, IAD, IAD, IAD, DCA, DCA, DCA, DCA, DCA, DCA, DCA, DCA, DCA, DCA, DCA, DCA, DCA, DCA, IAD, DCA, DCA, DCA, DCA, DCA, DCA, BWI, BWI, BWI, B…\n$ DAY_WEEK      &lt;fct&gt; 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5,…\n$ Flight.Status &lt;fct&gt; ontime, ontime, ontime, ontime, ontime, ontime, ontime, ontime, ontime, ontime, ontime, ontime, ontime, ontime, ontime, ontime, ontime, ontime, ontime, ontime, ontime, ontime, …",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Naive Bayes Classification</span>"
    ]
  },
  {
    "objectID": "Naive.html#데이터-탐색",
    "href": "Naive.html#데이터-탐색",
    "title": "2  Naive Bayes Classification",
    "section": "2.3 데이터 탐색",
    "text": "2.3 데이터 탐색\n\n# 데이터 구조 변환\nvisual.df &lt;- pivot_longer(delays.df1,\n                          cols = -Flight.Status,          # Target 제외\n                          names_to = \"Variables\",         # 변수 이름이 입력될 새로운 열 이름\n                          values_to = \"values\"            # 변수에 입력된 값에 대한 새로운 열 이름\n                          )\n\nvisual.df\n\n# A tibble: 11,005 × 3\n   Flight.Status Variables    values\n   &lt;fct&gt;         &lt;chr&gt;        &lt;fct&gt; \n 1 ontime        CRS_DEP_TIME 14    \n 2 ontime        CARRIER      OH    \n 3 ontime        DEST         JFK   \n 4 ontime        ORIGIN       BWI   \n 5 ontime        DAY_WEEK     4     \n 6 ontime        CRS_DEP_TIME 16    \n 7 ontime        CARRIER      DH    \n 8 ontime        DEST         JFK   \n 9 ontime        ORIGIN       DCA   \n10 ontime        DAY_WEEK     4     \n# ℹ 10,995 more rows\n\nggplot(visual.df, aes(values, fill = Flight.Status)) +\n  facet_wrap(~ Variables, scales = \"free\") +\n  geom_bar(position = \"dodge\") +\n  scale_fill_manual(values=c(\"#E69F00\", \"#56B4E9\")) +     # 막대 색깔 지정\n  theme_bw()\n\n\n\n\n\n\n\nggplot(visual.df, aes(values, fill = Flight.Status)) +\n  facet_wrap(~ Variables, scales = \"free\") +\n  geom_bar(position = \"fill\") +\n  scale_fill_manual(values=c(\"#E69F00\", \"#56B4E9\")) +     # 막대 색깔 지정\n  theme_bw()\n\n\n\n\n\n\n\nggplot(visual.df, aes(values, fill = Flight.Status)) +\n  facet_wrap(~ Variables, scales = \"free\") +\n  geom_bar(position = \"stack\") +\n  scale_fill_manual(values=c(\"#E69F00\", \"#56B4E9\")) +     # 막대 색깔 지정\n  theme_bw()",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Naive Bayes Classification</span>"
    ]
  },
  {
    "objectID": "Naive.html#데이터-분할",
    "href": "Naive.html#데이터-분할",
    "title": "2  Naive Bayes Classification",
    "section": "2.4 데이터 분할",
    "text": "2.4 데이터 분할\n\n# Partition (Training Dataset : Test Dataset = 7:3)\ny &lt;- delays.df1$Flight.Status                                           # Target\n\nset.seed(200)\nind         &lt;- createDataPartition(y, p = 0.7, list = T)                # Index를 이용하여 7:3으로 분할\ndelays.trd  &lt;- delays.df1[ind$Resample1, ]                              # Training Dataset\ndelays.ted  &lt;- delays.df1[-ind$Resample1, ]                             # Test Dataset",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Naive Bayes Classification</span>"
    ]
  },
  {
    "objectID": "Naive.html#모형-훈련",
    "href": "Naive.html#모형-훈련",
    "title": "2  Naive Bayes Classification",
    "section": "2.5 모형 훈련",
    "text": "2.5 모형 훈련\n\n함수 naiveBayes를 이용하여 Naive Bayes를 수행할 수 있다. 함수에서 사용할 수 있는 자세한 옵션은 여기를 참고한다.\n\n\nnaiveBayes(formula, data, laplace = 0, ...)\n\n\nformula : Target과 예측 변수의 관계를 표현하기 위한 함수로써 일반적으로 Target ~ 예측 변수의 형태로 표현한다.\ndata : formula에 포함된 변수들의 데이터셋\nlaplace : 라플라스 스무딩(Laplace Smoothing)을 위한 가중치 \\(\\alpha\\)\n\n범주형 예측 변수에 대해 사건 발생 가능성이 매우 희박하여 우도가 0이 되는 경우를 방지하기 위해 사용하는 옵션\n예를 들어, 스팸 메일 분류(나이브 베이즈 PPT, p.7)에서 스팸 메일 중 “비아그라 단어가 포함”된 메일이 있을 확률, 즉, 우도 \\(P(\\text{비아그라 포함}|\\text{스팸})\\)에 라플라스 스무딩을 적용하면 다음과 같다. \\[\n\\begin{align*}\nP(\\text{비아그라 포함}|\\text{스팸})=\\frac{\\text{비아그라가 포함된 스팸 메일 수}+\\alpha}{\\text{전체 스팸 메일 수} + k\\times \\alpha}\n\\end{align*}\n\\]\n\n\\(k\\) : 범주형 예측 변수의 class 개수로 해당 예제에서는 “비아그라 포함 O/비아그라 포함 X”로 \\(k=2\\)이다.\n\n\n\n\ndelays.nb &lt;- naiveBayes(Flight.Status ~ .,                              # Target ~ 예측 변수\n                        data = delays.trd)\ndelays.nb\n\n\nNaive Bayes Classifier for Discrete Predictors\n\nCall:\nnaiveBayes.default(x = X, y = Y, laplace = laplace)\n\nA-priori probabilities:\nY\n  delayed    ontime \n0.1945525 0.8054475 \n\nConditional probabilities:\n         CRS_DEP_TIME\nY                  6          7          8          9         10         11         12         13         14         15         16         17         18         19         20         21\n  delayed 0.02666667 0.04666667 0.07000000 0.02666667 0.01666667 0.01666667 0.04333333 0.05333333 0.17000000 0.07000000 0.08333333 0.15666667 0.03000000 0.07666667 0.02333333 0.09000000\n  ontime  0.06682770 0.06521739 0.06924316 0.06199678 0.04991948 0.03623188 0.06280193 0.07568438 0.09581320 0.06682770 0.08132045 0.10064412 0.04508857 0.04186795 0.02415459 0.05636071\n\n         CARRIER\nY                 CO         DH         DL         MQ         OH         RU         UA         US\n  delayed 0.07666667 0.32000000 0.11666667 0.18000000 0.01333333 0.19333333 0.01333333 0.08666667\n  ontime  0.03542673 0.23349436 0.17632850 0.12962963 0.01529791 0.18115942 0.01368760 0.21497585\n\n         DEST\nY               EWR       JFK       LGA\n  delayed 0.3766667 0.2100000 0.4133333\n  ontime  0.2882448 0.1723027 0.5394525\n\n         ORIGIN\nY                BWI        DCA        IAD\n  delayed 0.07666667 0.52666667 0.39666667\n  ontime  0.06280193 0.64492754 0.29227053\n\n         DAY_WEEK\nY                 1         2         3         4         5         6         7\n  delayed 0.1900000 0.1500000 0.1166667 0.1466667 0.1766667 0.0600000 0.1600000\n  ontime  0.1264090 0.1336554 0.1545894 0.1876006 0.1626409 0.1336554 0.1014493\n\n\nResult! 첫 번째 Table A-priori probabilities는 Target \\(Y\\)의 각 class에 대한 사전확률 \\(P(Y=y)\\)이고, 두 번째 Table Conditional probabilities는 예측 변수 \\(X\\)가 범주형일 때는 \\(P(X|Y)\\)를 나타내며, 연속형일 때는 평균과 표준편차를 나타낸다.",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Naive Bayes Classification</span>"
    ]
  },
  {
    "objectID": "Naive.html#모형-평가",
    "href": "Naive.html#모형-평가",
    "title": "2  Naive Bayes Classification",
    "section": "2.6 모형 평가",
    "text": "2.6 모형 평가\nCaution! 모형 평가를 위해 Test Dataset에 대한 예측 class/확률 이 필요하며, 함수 predict()를 이용하여 생성한다.\n\n# 예측 class 생성 \npred.class &lt;- predict(delays.nb,\n                      newdata = delays.ted[,-6])         # 함수 predict에서는 Target 제외\n\n# 예측 확률( 사후확률 P(Y|X) ) 생성\npred.prob  &lt;- predict(delays.nb, \n                      newdata = delays.ted[,-6],         # 함수 predict에서는 Target 제외\n                      type = \"raw\")                      \n \n# Test Dataset의 실제값과 예측 결과\ndf &lt;- data.frame(actual = delays.ted$Flight.Status, \n                 pred.class = pred.class, pred.prob)\ndf %&gt;%\n  as_tibble\n\n# A tibble: 659 × 4\n   actual pred.class delayed ontime\n   &lt;fct&gt;  &lt;fct&gt;        &lt;dbl&gt;  &lt;dbl&gt;\n 1 ontime ontime      0.303   0.697\n 2 ontime ontime      0.302   0.698\n 3 ontime ontime      0.0325  0.967\n 4 ontime ontime      0.122   0.878\n 5 ontime ontime      0.0702  0.930\n 6 ontime ontime      0.162   0.838\n 7 ontime ontime      0.0690  0.931\n 8 ontime ontime      0.0969  0.903\n 9 ontime ontime      0.187   0.813\n10 ontime ontime      0.241   0.759\n# ℹ 649 more rows\n\n\n\n# 일요일 오전 10시와 오전 11시 사이에 DCA (레이건 국립공항)에서 LGA (라 과디아 공항)로 가는 DL (델타 항공)의 연착 여부 예측 결과\ndf[delays.ted$DAY_WEEK == 7 & delays.ted$CRS_DEP_TIME == 10 & delays.ted$ORIGIN == \"DCA\" &   \n   delays.ted$DEST == \"LGA\" & delays.ted$CARRIER == \"DL\",]\n\n    actual pred.class    delayed    ontime\n215 ontime     ontime 0.05002181 0.9499782\n\n\n\n2.6.1 ConfusionMatrix\n\nCM &lt;- caret::confusionMatrix(pred.class, delays.ted$Flight.Status,\n                             positive = \"delayed\")            # confusionMatrix(예측 class, 실제 class, positive = \"관심 class\")\nCM\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction delayed ontime\n   delayed      12     21\n   ontime      116    510\n                                          \n               Accuracy : 0.7921          \n                 95% CI : (0.7591, 0.8225)\n    No Information Rate : 0.8058          \n    P-Value [Acc &gt; NIR] : 0.8256          \n                                          \n                  Kappa : 0.0755          \n                                          \n Mcnemar's Test P-Value : 9.671e-16       \n                                          \n            Sensitivity : 0.09375         \n            Specificity : 0.96045         \n         Pos Pred Value : 0.36364         \n         Neg Pred Value : 0.81470         \n             Prevalence : 0.19423         \n         Detection Rate : 0.01821         \n   Detection Prevalence : 0.05008         \n      Balanced Accuracy : 0.52710         \n                                          \n       'Positive' Class : delayed         \n                                          \n\n\n\n\n\n2.6.2 ROC 곡선\n\n# 예측 확률( 사후확률 P(Y|X) ) \npred.prob %&gt;%\n  as_tibble\n\n# A tibble: 659 × 2\n   delayed ontime\n     &lt;dbl&gt;  &lt;dbl&gt;\n 1  0.303   0.697\n 2  0.302   0.698\n 3  0.0325  0.967\n 4  0.122   0.878\n 5  0.0702  0.930\n 6  0.162   0.838\n 7  0.0690  0.931\n 8  0.0969  0.903\n 9  0.187   0.813\n10  0.241   0.759\n# ℹ 649 more rows\n\n\n\ndelayed.pred.prob &lt;- pred.prob[,1]                            # \"Flight.Status = delayed\"에 대한 예측 확률\n\nac &lt;- ifelse(delays.ted$Flight.Status == \"delayed\", 1, 0)     # 실제 class를 수치형으로 변환               \npp &lt;- as.numeric(delayed.pred.prob)                           # 예측 확률을 수치형으로 변환\n\n\n2.6.2.1 Package “pROC”\n\npacman::p_load(\"pROC\")\n\nnb.roc  &lt;- roc(ac, pp, plot = T, col = \"gray\")                # roc(실제 class, 예측 확률)\nauc     &lt;- round(auc(nb.roc), 3)\nlegend(\"bottomright\", legend = auc, bty = \"n\")\n\n\n\n\n\n\n\n\nCaution! Package \"pROC\"를 통해 출력한 ROC 곡선은 다양한 함수를 이용해서 그래프를 수정할 수 있다.\n\n# 함수 plot.roc() 이용\nplot.roc(nb.roc,   \n         col=\"gray\",                                          # Line Color\n         print.auc = TRUE,                                    # AUC 출력 여부\n         print.auc.col = \"red\",                               # AUC 글씨 색깔\n         print.thres = TRUE,                                  # Cutoff Value 출력 여부\n         print.thres.pch = 19,                                # Cutoff Value를 표시하는 도형 모양\n         print.thres.col = \"red\",                             # Cutoff Value를 표시하는 도형의 색깔\n         auc.polygon = TRUE,                                  # 곡선 아래 면적에 대한 여부\n         auc.polygon.col = \"gray90\")                          # 곡선 아래 면적의 색깔\n\n\n\n\n\n\n\n\n\n# 함수 ggroc() 이용\nggroc(nb.roc) +\nannotate(geom = \"text\", x = 0.9, y = 1.0,\nlabel = paste(\"AUC = \", auc),\nsize = 5,\ncolor=\"red\") +\ntheme_bw()\n\n\n\n\n\n\n\n\n\n\n2.6.2.2 Package “Epi”\n\npacman::p_load(\"Epi\")       \n# install_version(\"etm\", version = \"1.1\", repos = \"http://cran.us.r-project.org\")\n\nROC(pp, ac, plot = \"ROC\")                                     # ROC(예측 확률, 실제 class)  \n\n\n\n\n\n\n\n\n\n\n2.6.2.3 Package “ROCR”\n\npacman::p_load(\"ROCR\")\n\npred &lt;- prediction(pp, ac)                                    # prediction(예측 확률, 실제 class)  \n\nperf &lt;- performance(pred, \"tpr\", \"fpr\")                       # performance(, \"민감도\", \"1-특이도\")                      \nplot(perf, col = \"gray\")                                      # ROC Curve\n\nperf.auc   &lt;- performance(pred, \"auc\")                        # AUC\nauc        &lt;- attributes(perf.auc)$y.values \nlegend(\"bottomright\", legend = auc, bty = \"n\")\n\n\n\n\n\n\n\n\n\n\n\n\n2.6.3 향상 차트\n\n2.6.3.1 Package “ROCR”\n\n# 향상 차트(Curve)\nperf &lt;- performance(pred, \"lift\", \"rpp\")       # Lift Chart\nplot(perf, main = \"lift curve\",\n     colorize = T,                             # Coloring according to cutoff\n     lwd = 2)\n\n\n\n\n\n\n\n\n\n\n2.6.3.2 Package “gains”\n\n# 향상 차트(십분위)\npacman::p_load(\"gains\")\n\ngain &lt;- gains(ac, pp)                           # gains(실제 class, 예측 확률)\n\nbarplot(gain$mean.resp / mean(ac), \n        names.arg = gain$depth, \n        xlab = \"Percentile\", \n        ylab = \"Mean Response\", \n        main = \"Decile-wise lift chart\")",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Naive Bayes Classification</span>"
    ]
  },
  {
    "objectID": "Decision_tree.html",
    "href": "Decision_tree.html",
    "title": "3  Decision Tree",
    "section": "",
    "text": "3.1 데이터 불러오기\npacman::p_load(\"data.table\", \n               \"tidyverse\", \n               \"dplyr\", \"tidyr\",\n               \"ggplot2\", \"GGally\",\n               \"caret\",\n               \"rpart\",                                                 # For Decision Tree\n               \"rattle\", \"rpart.plot\",                                  # For fancyRpartPlot\n               \"visNetwork\", \"sparkline\")                               # For visTree\n\ntitanic &lt;- fread(\"../Titanic.csv\")                                      # 데이터 불러오기\n\ntitanic %&gt;%\n  as_tibble\n# A tibble: 891 × 11\n   Survived Pclass Name                                                Sex      Age SibSp Parch Ticket            Fare Cabin  Embarked\n      &lt;int&gt;  &lt;int&gt; &lt;chr&gt;                                               &lt;chr&gt;  &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;   \n 1        0      3 Braund, Mr. Owen Harris                             male      22     1     0 A/5 21171         7.25 \"\"     S       \n 2        1      1 Cumings, Mrs. John Bradley (Florence Briggs Thayer) female    38     1     0 PC 17599         71.3  \"C85\"  C       \n 3        1      3 Heikkinen, Miss. Laina                              female    26     0     0 STON/O2. 3101282  7.92 \"\"     S       \n 4        1      1 Futrelle, Mrs. Jacques Heath (Lily May Peel)        female    35     1     0 113803           53.1  \"C123\" S       \n 5        0      3 Allen, Mr. William Henry                            male      35     0     0 373450            8.05 \"\"     S       \n 6        0      3 Moran, Mr. James                                    male      NA     0     0 330877            8.46 \"\"     Q       \n 7        0      1 McCarthy, Mr. Timothy J                             male      54     0     0 17463            51.9  \"E46\"  S       \n 8        0      3 Palsson, Master. Gosta Leonard                      male       2     3     1 349909           21.1  \"\"     S       \n 9        1      3 Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)   female    27     0     2 347742           11.1  \"\"     S       \n10        1      2 Nasser, Mrs. Nicholas (Adele Achem)                 female    14     1     0 237736           30.1  \"\"     C       \n# ℹ 881 more rows",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Decision Tree</span>"
    ]
  },
  {
    "objectID": "Decision_tree.html#데이터-전처리-i",
    "href": "Decision_tree.html#데이터-전처리-i",
    "title": "3  Decision Tree",
    "section": "3.2 데이터 전처리 I",
    "text": "3.2 데이터 전처리 I\n\ntitanic %&lt;&gt;%\n  data.frame() %&gt;%                                                      # Data Frame 형태로 변환 \n  mutate(Survived = ifelse(Survived == 1, \"yes\", \"no\"))                 # Target을 문자형 변수로 변환\n\n# 1. Convert to Factor\nfac.col &lt;- c(\"Pclass\", \"Sex\",\n             # Target\n             \"Survived\")\n\ntitanic &lt;- titanic %&gt;% \n  mutate_at(fac.col, as.factor)                                         # 범주형으로 변환\n\nglimpse(titanic)                                                        # 데이터 구조 확인\n\nRows: 891\nColumns: 11\n$ Survived &lt;fct&gt; no, yes, yes, yes, no, no, no, no, yes, yes, yes, yes, no, no, no, yes, no, yes, no, yes, no, yes, yes, yes, no, yes, no, no, yes, no, no, yes, yes, no, no, no, yes, no, no, yes, no…\n$ Pclass   &lt;fct&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3, 2, 2, 3, 1, 3, 3, 3, 1, 3, 3, 1, 1, 3, 2, 1, 1, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 1, 1, 2, 3, 2, 3, 3…\n$ Name     &lt;chr&gt; \"Braund, Mr. Owen Harris\", \"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\", \"Heikkinen, Miss. Laina\", \"Futrelle, Mrs. Jacques Heath (Lily May Peel)\", \"Allen, Mr. William Henry…\n$ Sex      &lt;fct&gt; male, female, female, female, male, male, male, male, female, female, female, female, male, male, female, female, male, male, female, female, male, male, female, male, female, femal…\n$ Age      &lt;dbl&gt; 22.0, 38.0, 26.0, 35.0, 35.0, NA, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, NA, 31.0, NA, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, NA, 19.0, NA, NA, 40.0, NA, NA, 66.…\n$ SibSp    &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0, 0, 0, 0, 0, 3, 1, 0, 3, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 1, 0, 0, 1, 0, 2, 1, 4, 0, 1, 1, 0, 0, 0, 0, 1, 5, 0…\n$ Parch    &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 5, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 2, 2, 0…\n$ Ticket   &lt;chr&gt; \"A/5 21171\", \"PC 17599\", \"STON/O2. 3101282\", \"113803\", \"373450\", \"330877\", \"17463\", \"349909\", \"347742\", \"237736\", \"PP 9549\", \"113783\", \"A/5. 2151\", \"347082\", \"350406\", \"248706\", \"38…\n$ Fare     &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625, 21.0750, 11.1333, 30.0708, 16.7000, 26.5500, 8.0500, 31.2750, 7.8542, 16.0000, 29.1250, 13.0000, 18.0000, 7.2250, 26.0000,…\n$ Cabin    &lt;chr&gt; \"\", \"C85\", \"\", \"C123\", \"\", \"\", \"E46\", \"\", \"\", \"\", \"G6\", \"C103\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"D56\", \"\", \"A6\", \"\", \"\", \"\", \"C23 C25 C27\", \"\", \"\", \"\", \"B78\", \"\", \"\", \"\", \"\", \"\"…\n$ Embarked &lt;chr&gt; \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"C\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"Q\", \"S\", \"C\", \"C\", \"Q\", \"S\", \"C\", \"S\", \"…\n\n# 2. Generate New Variable\ntitanic &lt;- titanic %&gt;%\n  mutate(FamSize = SibSp + Parch)                                       # \"FamSize = 형제 및 배우자 수 + 부모님 및 자녀 수\"로 가족 수를 의미하는 새로운 변수\n\nglimpse(titanic)                                                        # 데이터 구조 확인\n\nRows: 891\nColumns: 12\n$ Survived &lt;fct&gt; no, yes, yes, yes, no, no, no, no, yes, yes, yes, yes, no, no, no, yes, no, yes, no, yes, no, yes, yes, yes, no, yes, no, no, yes, no, no, yes, yes, no, no, no, yes, no, no, yes, no…\n$ Pclass   &lt;fct&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3, 2, 2, 3, 1, 3, 3, 3, 1, 3, 3, 1, 1, 3, 2, 1, 1, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 1, 1, 2, 3, 2, 3, 3…\n$ Name     &lt;chr&gt; \"Braund, Mr. Owen Harris\", \"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\", \"Heikkinen, Miss. Laina\", \"Futrelle, Mrs. Jacques Heath (Lily May Peel)\", \"Allen, Mr. William Henry…\n$ Sex      &lt;fct&gt; male, female, female, female, male, male, male, male, female, female, female, female, male, male, female, female, male, male, female, female, male, male, female, male, female, femal…\n$ Age      &lt;dbl&gt; 22.0, 38.0, 26.0, 35.0, 35.0, NA, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, NA, 31.0, NA, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, NA, 19.0, NA, NA, 40.0, NA, NA, 66.…\n$ SibSp    &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0, 0, 0, 0, 0, 3, 1, 0, 3, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 1, 0, 0, 1, 0, 2, 1, 4, 0, 1, 1, 0, 0, 0, 0, 1, 5, 0…\n$ Parch    &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 5, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 2, 2, 0…\n$ Ticket   &lt;chr&gt; \"A/5 21171\", \"PC 17599\", \"STON/O2. 3101282\", \"113803\", \"373450\", \"330877\", \"17463\", \"349909\", \"347742\", \"237736\", \"PP 9549\", \"113783\", \"A/5. 2151\", \"347082\", \"350406\", \"248706\", \"38…\n$ Fare     &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625, 21.0750, 11.1333, 30.0708, 16.7000, 26.5500, 8.0500, 31.2750, 7.8542, 16.0000, 29.1250, 13.0000, 18.0000, 7.2250, 26.0000,…\n$ Cabin    &lt;chr&gt; \"\", \"C85\", \"\", \"C123\", \"\", \"\", \"E46\", \"\", \"\", \"\", \"G6\", \"C103\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"D56\", \"\", \"A6\", \"\", \"\", \"\", \"C23 C25 C27\", \"\", \"\", \"\", \"B78\", \"\", \"\", \"\", \"\", \"\"…\n$ Embarked &lt;chr&gt; \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"C\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"Q\", \"S\", \"C\", \"C\", \"Q\", \"S\", \"C\", \"S\", \"…\n$ FamSize  &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 4, 2, 1, 2, 0, 0, 6, 0, 0, 5, 0, 1, 0, 0, 0, 0, 0, 4, 6, 0, 5, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 3, 0, 0, 1, 0, 2, 1, 5, 0, 1, 1, 1, 0, 0, 0, 3, 7, 0…\n\n# 3. Select Variables used for Analysis\ntitanic1 &lt;- titanic %&gt;% \n  select(Survived, Pclass, Sex, Age, Fare, FamSize)                     # 분석에 사용할 변수 선택\n\nglimpse(titanic1)                                                       # 데이터 구조 확인\n\nRows: 891\nColumns: 6\n$ Survived &lt;fct&gt; no, yes, yes, yes, no, no, no, no, yes, yes, yes, yes, no, no, no, yes, no, yes, no, yes, no, yes, yes, yes, no, yes, no, no, yes, no, no, yes, yes, no, no, no, yes, no, no, yes, no…\n$ Pclass   &lt;fct&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3, 2, 2, 3, 1, 3, 3, 3, 1, 3, 3, 1, 1, 3, 2, 1, 1, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 1, 1, 2, 3, 2, 3, 3…\n$ Sex      &lt;fct&gt; male, female, female, female, male, male, male, male, female, female, female, female, male, male, female, female, male, male, female, female, male, male, female, male, female, femal…\n$ Age      &lt;dbl&gt; 22.0, 38.0, 26.0, 35.0, 35.0, NA, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, NA, 31.0, NA, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, NA, 19.0, NA, NA, 40.0, NA, NA, 66.…\n$ Fare     &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625, 21.0750, 11.1333, 30.0708, 16.7000, 26.5500, 8.0500, 31.2750, 7.8542, 16.0000, 29.1250, 13.0000, 18.0000, 7.2250, 26.0000,…\n$ FamSize  &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 4, 2, 1, 2, 0, 0, 6, 0, 0, 5, 0, 1, 0, 0, 0, 0, 0, 4, 6, 0, 5, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 3, 0, 0, 1, 0, 2, 1, 5, 0, 1, 1, 1, 0, 0, 0, 3, 7, 0…",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Decision Tree</span>"
    ]
  },
  {
    "objectID": "Decision_tree.html#데이터-탐색",
    "href": "Decision_tree.html#데이터-탐색",
    "title": "3  Decision Tree",
    "section": "3.3 데이터 탐색",
    "text": "3.3 데이터 탐색\n\nggpairs(titanic1,                                        \n        aes(colour = Survived)) +                         # Target의 범주에 따라 색깔을 다르게 표현\n  theme_bw()\n\n\n\n\n\n\n\nggpairs(titanic1,                                     \n        aes(colour = Survived, alpha = 0.8)) +            # Target의 범주에 따라 색깔을 다르게 표현\n  scale_colour_manual(values = c(\"#00798c\", \"#d1495b\")) + # 특정 색깔 지정\n  scale_fill_manual(values = c(\"#00798c\", \"#d1495b\")) +   # 특정 색깔 지정\n  theme_bw()",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Decision Tree</span>"
    ]
  },
  {
    "objectID": "Decision_tree.html#데이터-분할",
    "href": "Decision_tree.html#데이터-분할",
    "title": "3  Decision Tree",
    "section": "3.4 데이터 분할",
    "text": "3.4 데이터 분할\n\n# Partition (Training Dataset : Test Dataset = 7:3)\ny      &lt;- titanic1$Survived                           # Target\n\nset.seed(200)\nind    &lt;- createDataPartition(y, p = 0.7, list  =T)   # Index를 이용하여 7:3으로 분할\ntitanic.trd &lt;- titanic1[ind$Resample1,]               # Training Dataset\ntitanic.ted &lt;- titanic1[-ind$Resample1,]              # Test Dataset",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Decision Tree</span>"
    ]
  },
  {
    "objectID": "Decision_tree.html#데이터-전처리-ii",
    "href": "Decision_tree.html#데이터-전처리-ii",
    "title": "3  Decision Tree",
    "section": "3.5 데이터 전처리 II",
    "text": "3.5 데이터 전처리 II\n\n# Imputation\ntitanic.trd.Imp &lt;- titanic.trd %&gt;% \n  mutate(Age = replace_na(Age, mean(Age, na.rm = TRUE)))                 # 평균으로 결측값 대체\n\ntitanic.ted.Imp &lt;- titanic.ted %&gt;% \n  mutate(Age = replace_na(Age, mean(titanic.trd$Age, na.rm = TRUE)))     # Training Dataset을 이용하여 결측값 대체\n\nglimpse(titanic.trd.Imp)                                                 # 데이터 구조 확인\n\nRows: 625\nColumns: 6\n$ Survived &lt;fct&gt; no, yes, yes, no, no, no, yes, yes, yes, yes, no, no, yes, no, yes, no, yes, no, no, no, yes, no, no, yes, yes, no, no, no, no, no, yes, no, no, no, yes, no, yes, no, no, no, yes, n…\n$ Pclass   &lt;fct&gt; 3, 3, 1, 3, 3, 3, 3, 2, 3, 1, 3, 3, 2, 3, 3, 2, 1, 3, 3, 1, 3, 3, 1, 1, 3, 2, 1, 1, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3, 1, 3, 1, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 1, 2, 3…\n$ Sex      &lt;fct&gt; male, female, female, male, male, male, female, female, female, female, male, female, male, female, female, male, male, female, male, male, female, male, male, female, female, male,…\n$ Age      &lt;dbl&gt; 22.00000, 26.00000, 35.00000, 35.00000, 29.93737, 2.00000, 27.00000, 14.00000, 4.00000, 58.00000, 39.00000, 14.00000, 29.93737, 31.00000, 29.93737, 35.00000, 28.00000, 8.00000, 29.9…\n$ Fare     &lt;dbl&gt; 7.2500, 7.9250, 53.1000, 8.0500, 8.4583, 21.0750, 11.1333, 30.0708, 16.7000, 26.5500, 31.2750, 7.8542, 13.0000, 18.0000, 7.2250, 26.0000, 35.5000, 21.0750, 7.2250, 263.0000, 7.8792,…\n$ FamSize  &lt;int&gt; 1, 0, 1, 0, 0, 4, 2, 1, 2, 0, 6, 0, 0, 1, 0, 0, 0, 4, 0, 5, 0, 0, 0, 1, 0, 0, 1, 1, 0, 2, 1, 1, 1, 0, 0, 1, 0, 2, 1, 5, 1, 1, 0, 7, 0, 0, 5, 0, 2, 7, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 3…\n\nglimpse(titanic.ted.Imp)                                                 # 데이터 구조 확인\n\nRows: 266\nColumns: 6\n$ Survived &lt;fct&gt; yes, no, no, yes, no, yes, yes, yes, yes, yes, no, no, yes, yes, no, yes, no, yes, yes, no, yes, no, no, no, no, no, no, yes, yes, no, no, no, no, no, no, no, no, no, no, yes, no, n…\n$ Pclass   &lt;fct&gt; 1, 1, 3, 2, 3, 2, 3, 3, 3, 2, 3, 3, 2, 2, 3, 2, 1, 3, 2, 3, 3, 2, 2, 3, 3, 3, 3, 1, 2, 2, 3, 3, 3, 3, 3, 2, 3, 2, 2, 2, 3, 3, 2, 1, 3, 1, 3, 2, 1, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 1, 3…\n$ Sex      &lt;fct&gt; female, male, male, female, male, male, female, female, male, female, male, male, female, female, male, female, male, male, female, male, female, male, male, male, male, male, male,…\n$ Age      &lt;dbl&gt; 38.00000, 54.00000, 20.00000, 55.00000, 2.00000, 34.00000, 15.00000, 38.00000, 29.93737, 3.00000, 29.93737, 21.00000, 29.00000, 21.00000, 28.50000, 5.00000, 45.00000, 29.93737, 29.0…\n$ Fare     &lt;dbl&gt; 71.2833, 51.8625, 8.0500, 16.0000, 29.1250, 13.0000, 8.0292, 31.3875, 7.2292, 41.5792, 8.0500, 7.8000, 26.0000, 10.5000, 7.2292, 27.7500, 83.4750, 15.2458, 10.5000, 8.1583, 7.9250, …\n$ FamSize  &lt;int&gt; 1, 0, 0, 0, 5, 0, 0, 6, 0, 3, 0, 0, 1, 0, 0, 3, 1, 2, 0, 0, 6, 0, 0, 0, 0, 4, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 6, 2, 1, 0, 0, 1, 0, 2, 0, 0, 0, 0, 1, 0, 0, 1, 5, 2, 5, 0, 5, 0, 4, 0, 6…",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Decision Tree</span>"
    ]
  },
  {
    "objectID": "Decision_tree.html#모형-훈련",
    "href": "Decision_tree.html#모형-훈련",
    "title": "3  Decision Tree",
    "section": "3.6 모형 훈련",
    "text": "3.6 모형 훈련\nPackage \"rpart\"는 수정된 CART를 알고리듬으로 사용하며, CP (Complexity Parameter)를 이용하여 최적의 모형을 찾아낸다. CP는 최적의 나무 크기를 찾기 위한 모수로써, 노드를 분할할 때 분할 전과 비교하여 오분류율이 CP 값 이상으로 향상되지 않으면 분할을 멈춘다. 최적의 모형을 얻기 위해 필요한 CP는 Cross Validation (CV) 기법을 이용하여 얻을 수 있으며, 해당 Package에서는 기본값으로 10-Fold CV를 이용한다. 마지막으로, Package \"rpart\"는 가독성 좋은 그래프로 결과를 표현할 수 있어 의사결정나무를 시각화하기에 좋은 Package이다.\n\nrpart(formula, data, method, ...)\n\n\nformula : Target과 예측 변수의 관계를 표현하기 위한 함수로써 일반적으로 Target ~ 예측 변수의 형태로 표현한다.\ndata : formula에 포함하고 있는 변수들의 데이터셋(Data Frame)\nmethod : Target이 범주형이면 \"class\", 그렇지 않으면 \"anova\"를 입력한다.\n\n\nset.seed(200)                                         # For Cross Validation (CV)  \nrContol      &lt;- rpart.control(xval = 5)               # xval : xval-Fold CV\ntitanic.trd.rtree &lt;- rpart(Survived ~ ., data = titanic.trd.Imp,                 \n                           method = \"class\", \n                           control = rContol)         \n\nsummary(titanic.trd.rtree)\n\nCall:\nrpart(formula = Survived ~ ., data = titanic.trd.Imp, method = \"class\", \n    control = rContol)\n  n= 625 \n\n          CP nsplit rel error    xerror       xstd\n1 0.40833333      0 1.0000000 1.0000000 0.05066228\n2 0.03958333      1 0.5916667 0.5916667 0.04364821\n3 0.03750000      3 0.5125000 0.5666667 0.04298062\n4 0.01388889      4 0.4750000 0.5083333 0.04128694\n5 0.01000000      7 0.4333333 0.5375000 0.04215843\n\nVariable importance\n    Sex    Fare     Age  Pclass FamSize \n     42      20      13      13      12 \n\nNode number 1: 625 observations,    complexity param=0.4083333\n  predicted class=no   expected loss=0.384  P(node) =1\n    class counts:   385   240\n   probabilities: 0.616 0.384 \n  left son=2 (397 obs) right son=3 (228 obs)\n  Primary splits:\n      Sex     splits as  RL,           improve=78.61042, (0 missing)\n      Pclass  splits as  RRL,          improve=32.46336, (0 missing)\n      Fare    &lt; 51.2479  to the left,  improve=29.66020, (0 missing)\n      Age     &lt; 6.5      to the right, improve=11.36591, (0 missing)\n      FamSize &lt; 0.5      to the left,  improve=11.20358, (0 missing)\n  Surrogate splits:\n      Fare    &lt; 56.9646  to the left,  agree=0.674, adj=0.105, (0 split)\n      FamSize &lt; 0.5      to the left,  agree=0.666, adj=0.083, (0 split)\n      Age     &lt; 16.5     to the right, agree=0.642, adj=0.018, (0 split)\n\nNode number 2: 397 observations,    complexity param=0.0375\n  predicted class=no   expected loss=0.1939547  P(node) =0.6352\n    class counts:   320    77\n   probabilities: 0.806 0.194 \n  left son=4 (378 obs) right son=5 (19 obs)\n  Primary splits:\n      Age     &lt; 6.5      to the right, improve=11.762560, (0 missing)\n      Fare    &lt; 26.26875 to the left,  improve= 9.994963, (0 missing)\n      Pclass  splits as  RLL,          improve= 8.547643, (0 missing)\n      FamSize &lt; 0.5      to the left,  improve= 2.466746, (0 missing)\n\nNode number 3: 228 observations,    complexity param=0.03958333\n  predicted class=yes  expected loss=0.2850877  P(node) =0.3648\n    class counts:    65   163\n   probabilities: 0.285 0.715 \n  left son=6 (115 obs) right son=7 (113 obs)\n  Primary splits:\n      Pclass  splits as  RRL,          improve=24.114900, (0 missing)\n      FamSize &lt; 3.5      to the right, improve=14.973800, (0 missing)\n      Fare    &lt; 49.45    to the left,  improve= 8.673891, (0 missing)\n      Age     &lt; 32.5     to the left,  improve= 1.974352, (0 missing)\n  Surrogate splits:\n      Fare    &lt; 25.69795 to the left,  agree=0.842, adj=0.681, (0 split)\n      Age     &lt; 29.96869 to the left,  agree=0.667, adj=0.327, (0 split)\n      FamSize &lt; 1.5      to the right, agree=0.566, adj=0.124, (0 split)\n\nNode number 4: 378 observations\n  predicted class=no   expected loss=0.1666667  P(node) =0.6048\n    class counts:   315    63\n   probabilities: 0.833 0.167 \n\nNode number 5: 19 observations\n  predicted class=yes  expected loss=0.2631579  P(node) =0.0304\n    class counts:     5    14\n   probabilities: 0.263 0.737 \n\nNode number 6: 115 observations,    complexity param=0.03958333\n  predicted class=no   expected loss=0.4869565  P(node) =0.184\n    class counts:    59    56\n   probabilities: 0.513 0.487 \n  left son=12 (19 obs) right son=13 (96 obs)\n  Primary splits:\n      FamSize &lt; 3.5      to the right, improve=10.794200, (0 missing)\n      Fare    &lt; 24.80835 to the right, improve= 9.460870, (0 missing)\n      Age     &lt; 6.5      to the right, improve= 4.334995, (0 missing)\n  Surrogate splits:\n      Fare &lt; 24.80835 to the right, agree=0.983, adj=0.895, (0 split)\n      Age  &lt; 38       to the right, agree=0.843, adj=0.053, (0 split)\n\nNode number 7: 113 observations\n  predicted class=yes  expected loss=0.05309735  P(node) =0.1808\n    class counts:     6   107\n   probabilities: 0.053 0.947 \n\nNode number 12: 19 observations\n  predicted class=no   expected loss=0  P(node) =0.0304\n    class counts:    19     0\n   probabilities: 1.000 0.000 \n\nNode number 13: 96 observations,    complexity param=0.01388889\n  predicted class=yes  expected loss=0.4166667  P(node) =0.1536\n    class counts:    40    56\n   probabilities: 0.417 0.583 \n  left son=26 (85 obs) right son=27 (11 obs)\n  Primary splits:\n      Age     &lt; 7        to the right, improve=2.6367200, (0 missing)\n      Fare    &lt; 15.3729  to the left,  improve=1.3557420, (0 missing)\n      FamSize &lt; 1.5      to the left,  improve=0.1111111, (0 missing)\n\nNode number 26: 85 observations,    complexity param=0.01388889\n  predicted class=yes  expected loss=0.4588235  P(node) =0.136\n    class counts:    39    46\n   probabilities: 0.459 0.541 \n  left son=52 (52 obs) right son=53 (33 obs)\n  Primary splits:\n      Fare    &lt; 7.9021   to the right, improve=1.6989440, (0 missing)\n      Age     &lt; 29.96869 to the right, improve=1.0885760, (0 missing)\n      FamSize &lt; 0.5      to the right, improve=0.2330413, (0 missing)\n  Surrogate splits:\n      FamSize &lt; 0.5      to the right, agree=0.812, adj=0.515, (0 split)\n\nNode number 27: 11 observations\n  predicted class=yes  expected loss=0.09090909  P(node) =0.0176\n    class counts:     1    10\n   probabilities: 0.091 0.909 \n\nNode number 52: 52 observations,    complexity param=0.01388889\n  predicted class=no   expected loss=0.4615385  P(node) =0.0832\n    class counts:    28    24\n   probabilities: 0.538 0.462 \n  left son=104 (30 obs) right son=105 (22 obs)\n  Primary splits:\n      Fare    &lt; 15.3729  to the left,  improve=2.3310020, (0 missing)\n      Age     &lt; 23.5     to the left,  improve=1.6011090, (0 missing)\n      FamSize &lt; 0.5      to the left,  improve=0.6930007, (0 missing)\n  Surrogate splits:\n      FamSize &lt; 1.5      to the left,  agree=0.731, adj=0.364, (0 split)\n      Age     &lt; 29.46869 to the left,  agree=0.692, adj=0.273, (0 split)\n\nNode number 53: 33 observations\n  predicted class=yes  expected loss=0.3333333  P(node) =0.0528\n    class counts:    11    22\n   probabilities: 0.333 0.667 \n\nNode number 104: 30 observations\n  predicted class=no   expected loss=0.3333333  P(node) =0.048\n    class counts:    20    10\n   probabilities: 0.667 0.333 \n\nNode number 105: 22 observations\n  predicted class=yes  expected loss=0.3636364  P(node) =0.0352\n    class counts:     8    14\n   probabilities: 0.364 0.636 \n\n\nResult! 첫 번째 Table에서,\n\nCP : Complexity Parameter로 Training Dataset에 대한 오분류율과 나무 크기에 대한 패널티를 이용하여 아래와 같이 계산한다. \\[\n\\begin{align*}\ncp = \\frac{p(\\text{incorrect}_{l}) - p(\\text{incorrect}_{l+1})}{n(\\text{splits}_{l+1}) - n(\\text{splits}_{l})}.\n\\end{align*}\n\\]\n\n\\(p(\\text{incorrect}_{l})\\) : 현재 Depth에서 오분류율\n\\(n(\\text{splits}_{l})\\) :현재 Depth에서 분할 횟수\n\\(p(\\text{incorrect}_{l+1})\\) : 다음 Depth에서 오분류율\n\\(n(\\text{splits}_{l+1})\\) :다음 Depth에서 분할 횟수\n예를 들어, 첫 번째 분할에서 CP값은 다음과 같다.\n\n\n\\[ cp = \\frac{1.00-0.592}{1-0} = 0.408 \\]\n\nnsplit : 분할 횟수\nrel error : 현재 Depth에서 잘못 분류된 Case들의 비율(오분류율)\nxerror : CV에 대한 오차\nxstd : xerror의 표준오차\n\n두 번째 Table Variable importance은 변수 중요도에 대한 결과이며, 수치가 높을수록 중요한 변수임을 의미한다.",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Decision Tree</span>"
    ]
  },
  {
    "objectID": "Decision_tree.html#tree-plot",
    "href": "Decision_tree.html#tree-plot",
    "title": "3  Decision Tree",
    "section": "3.7 Tree Plot",
    "text": "3.7 Tree Plot\n\n3.7.1 “fancyRpartPlot”\n\nfancyRpartPlot(titanic.trd.rtree)                  # Plot\n\n\n\n\n\n\n\n\n\n\n\n3.7.2 “visTree”\n\nvisTree(titanic.trd.rtree)                        # Network-based Plot",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Decision Tree</span>"
    ]
  },
  {
    "objectID": "Decision_tree.html#가지치기",
    "href": "Decision_tree.html#가지치기",
    "title": "3  Decision Tree",
    "section": "3.8 가지치기",
    "text": "3.8 가지치기\n가지치기(Pruning)는 생성된 가지를 잘라내어 모형을 단순화하는 과정을 의미한다. 의사결정나무 학습에서는 Training Dataset을 이용하여 노드에 대한 분할과정이 최대한 정확한 분류를 위해 계속 반복된다. 하지만, 과도한 반복은 많은 가지를 생성하게 되어 모형이 복잡해지고, 결과적으로 과대적합이 발생할 수 있다. 여기서 과대적합은 Training Dataset에 대해서는 정확하게 분류하지만 새로운 데이터셋인 Test Dataset에 대해서는 예측 성능이 현저히 떨어지는 현상을 의미한다. 따라서 의사결정나무는 가지치기를 통해 모형을 단순화하고 과대적합을 방지하는 과정이 필요하다.\nPackage \"rpart\"에서는 CP의 최적값을 이용하여 가지치기를 수행할 수 있다. 함수 rpart()를 이용하여 얻은 위의 결과를 기반으로 xerror가 최소가 되는 CP를 가지는 트리 모형을 생성한다.\n\ntable              &lt;- titanic.trd.rtree$cptable                    # CP Table\n\nlow.error          &lt;- which.min(table[ , \"xerror\"])                # min(\"xerror\")에 해당하는 Index 추출\ncp.best            &lt;- table[low.error, \"CP\"]                       # min(\"xerror\")에 해당하는 CP 추출\n\n# 가지치기 수행\ntitanic.trd.prune.rtree &lt;- prune(titanic.trd.rtree, cp = cp.best)  # prune(트리 모형, CP의 최적값)\n\ntitanic.trd.prune.rtree$cptable                                    # Best 모형의 CP Table  \n\n          CP nsplit rel error    xerror       xstd\n1 0.40833333      0 1.0000000 1.0000000 0.05066228\n2 0.03958333      1 0.5916667 0.5916667 0.04364821\n3 0.03750000      3 0.5125000 0.5666667 0.04298062\n4 0.01388889      4 0.4750000 0.5083333 0.04128694\n\n\n\n\nfancyRpartPlot(titanic.trd.prune.rtree)                            # Plot           \n\n\n\n\n\n\n\n\n\n\nvisTree(titanic.trd.prune.rtree)                                   # Network-based Plot",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Decision Tree</span>"
    ]
  },
  {
    "objectID": "Decision_tree.html#모형-평가",
    "href": "Decision_tree.html#모형-평가",
    "title": "3  Decision Tree",
    "section": "3.9 모형 평가",
    "text": "3.9 모형 평가\nCaution! 모형 평가를 위해 Test Dataset에 대한 예측 class/확률 이 필요하며, 함수 predict()를 이용하여 생성한다.\n\n# 예측 class 생성 \ntest.rtree.class &lt;- predict(titanic.trd.prune.rtree,\n                            newdata = titanic.ted.Imp[,-1],     # Test Dataset including Only 예측 변수  \n                            type = \"class\")                     # 예측 class 생성       \n\ntest.rtree.class %&gt;%\n  as_tibble\n\n# A tibble: 266 × 1\n   value\n   &lt;fct&gt;\n 1 yes  \n 2 no   \n 3 no   \n 4 yes  \n 5 yes  \n 6 no   \n 7 yes  \n 8 no   \n 9 no   \n10 yes  \n# ℹ 256 more rows\n\n\n\n\n3.9.1 ConfusionMatrix\n\nCM   &lt;- caret::confusionMatrix(test.rtree.class, titanic.ted.Imp$Survived, \n                               positive = \"yes\")                # confusionMatrix(예측 class, 실제 class, positive = \"관심 class\")\nCM\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  no yes\n       no  150  33\n       yes  14  69\n                                          \n               Accuracy : 0.8233          \n                 95% CI : (0.7721, 0.8672)\n    No Information Rate : 0.6165          \n    P-Value [Acc &gt; NIR] : 1.974e-13       \n                                          \n                  Kappa : 0.6127          \n                                          \n Mcnemar's Test P-Value : 0.00865         \n                                          \n            Sensitivity : 0.6765          \n            Specificity : 0.9146          \n         Pos Pred Value : 0.8313          \n         Neg Pred Value : 0.8197          \n             Prevalence : 0.3835          \n         Detection Rate : 0.2594          \n   Detection Prevalence : 0.3120          \n      Balanced Accuracy : 0.7956          \n                                          \n       'Positive' Class : yes             \n                                          \n\n\n\n\n\n3.9.2 ROC 곡선\n\n# 예측 확률 생성\ntest.rtree.prob &lt;- predict(titanic.trd.prune.rtree, \n                           newdata = titanic.ted.Imp[,-1],     # Test Dataset including Only 예측 변수  \n                           type = \"prob\")                      # 예측 확률 생성    \n\ntest.rtree.prob %&gt;%\n  as_tibble\n\n# A tibble: 266 × 2\n       no   yes\n    &lt;dbl&gt; &lt;dbl&gt;\n 1 0.0531 0.947\n 2 0.833  0.167\n 3 0.833  0.167\n 4 0.0531 0.947\n 5 0.263  0.737\n 6 0.833  0.167\n 7 0.417  0.583\n 8 1      0    \n 9 0.833  0.167\n10 0.0531 0.947\n# ℹ 256 more rows\n\n\n\ntest.rtree.prob &lt;- test.rtree.prob[,2]                          # \"Survived = yes\"에 대한 예측 확률\n\nac  &lt;- titanic.ted.Imp$Survived                                 # Test Dataset의 실제 class \npp  &lt;- as.numeric(test.rtree.prob)                              # 예측 확률을 수치형으로 변환\n\n\n3.9.2.1 Package “pROC”\n\npacman::p_load(\"pROC\")\n\nrtree.roc  &lt;- roc(ac, pp, plot = T, col = \"gray\")      # roc(실제 class, 예측 확률)\nauc        &lt;- round(auc(rtree.roc), 3)\nlegend(\"bottomright\", legend = auc, bty = \"n\")\n\n\n\n\n\n\n\n\nCaution! Package \"pROC\"를 통해 출력한 ROC 곡선은 다양한 함수를 이용해서 그래프를 수정할 수 있다.\n\n# 함수 plot.roc() 이용\nplot.roc(rtree.roc,   \n         col=\"gray\",                                   # Line Color\n         print.auc = TRUE,                             # AUC 출력 여부\n         print.auc.col = \"red\",                        # AUC 글씨 색깔\n         print.thres = TRUE,                           # Cutoff Value 출력 여부\n         print.thres.pch = 19,                         # Cutoff Value를 표시하는 도형 모양\n         print.thres.col = \"red\",                      # Cutoff Value를 표시하는 도형의 색깔\n         auc.polygon = TRUE,                           # 곡선 아래 면적에 대한 여부\n         auc.polygon.col = \"gray90\")                   # 곡선 아래 면적의 색깔\n\n\n\n\n\n\n\n\n\n# 함수 ggroc() 이용\nggroc(rtree.roc) +\nannotate(geom = \"text\", x = 0.9, y = 1.0,\nlabel = paste(\"AUC = \", auc),\nsize = 5,\ncolor=\"red\") +\ntheme_bw()\n\n\n\n\n\n\n\n\n\n\n3.9.2.2 Package “Epi”\n\npacman::p_load(\"Epi\")       \n# install_version(\"etm\", version = \"1.1\", repos = \"http://cran.us.r-project.org\")\n\nROC(pp, ac, plot = \"ROC\")                              # ROC(예측 확률, 실제 class)  \n\n\n\n\n\n\n\n\n\n\n3.9.2.3 Package “ROCR”\n\npacman::p_load(\"ROCR\")\n\nrtree.pred &lt;- prediction(pp, ac)                       # prediction(예측 확률, 실제 class) \n\nrtree.perf &lt;- performance(rtree.pred, \"tpr\", \"fpr\")    # performance(, \"민감도\", \"1-특이도\")                      \nplot(rtree.perf, col = \"gray\")                         # ROC Curve\n\nperf.auc   &lt;- performance(rtree.pred, \"auc\")           # AUC\nauc        &lt;- attributes(perf.auc)$y.values\nlegend(\"bottomright\", legend = auc, bty = \"n\")\n\n\n\n\n\n\n\n\n\n\n\n\n3.9.3 향상 차트\n\n3.9.3.1 Package “ROCR”\n\nrtree.perf &lt;- performance(rtree.pred, \"lift\", \"rpp\")   # Lift Chart                      \nplot(rtree.perf, main = \"lift curve\",\n     colorize = T,                                     # Coloring according to cutoff \n     lwd = 2)",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Decision Tree</span>"
    ]
  },
  {
    "objectID": "SVM_li.html",
    "href": "SVM_li.html",
    "title": "4  Support Vector Machine with Linear Kernel",
    "section": "",
    "text": "4.1 데이터 불러오기\npacman::p_load(\"data.table\", \"dplyr\", \"tidyr\",\n               \"caret\",\n               \"ggplot2\", \"GGally\",\n               \"e1071\")\n\ntitanic &lt;- fread(\"../Titanic.csv\")                                      # 데이터 불러오기\n\ntitanic %&gt;%\n  as_tibble\n# A tibble: 891 × 11\n   Survived Pclass Name                                                Sex      Age SibSp Parch Ticket            Fare Cabin  Embarked\n      &lt;int&gt;  &lt;int&gt; &lt;chr&gt;                                               &lt;chr&gt;  &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;   \n 1        0      3 Braund, Mr. Owen Harris                             male      22     1     0 A/5 21171         7.25 \"\"     S       \n 2        1      1 Cumings, Mrs. John Bradley (Florence Briggs Thayer) female    38     1     0 PC 17599         71.3  \"C85\"  C       \n 3        1      3 Heikkinen, Miss. Laina                              female    26     0     0 STON/O2. 3101282  7.92 \"\"     S       \n 4        1      1 Futrelle, Mrs. Jacques Heath (Lily May Peel)        female    35     1     0 113803           53.1  \"C123\" S       \n 5        0      3 Allen, Mr. William Henry                            male      35     0     0 373450            8.05 \"\"     S       \n 6        0      3 Moran, Mr. James                                    male      NA     0     0 330877            8.46 \"\"     Q       \n 7        0      1 McCarthy, Mr. Timothy J                             male      54     0     0 17463            51.9  \"E46\"  S       \n 8        0      3 Palsson, Master. Gosta Leonard                      male       2     3     1 349909           21.1  \"\"     S       \n 9        1      3 Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)   female    27     0     2 347742           11.1  \"\"     S       \n10        1      2 Nasser, Mrs. Nicholas (Adele Achem)                 female    14     1     0 237736           30.1  \"\"     C       \n# ℹ 881 more rows",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Support Vector Machine with Linear Kernel</span>"
    ]
  },
  {
    "objectID": "SVM_li.html#데이터-전처리-i",
    "href": "SVM_li.html#데이터-전처리-i",
    "title": "4  Support Vector Machine with Linear Kernel",
    "section": "4.2 데이터 전처리 I",
    "text": "4.2 데이터 전처리 I\n\ntitanic %&lt;&gt;%\n  data.frame() %&gt;%                                                      # Data Frame 형태로 변환 \n  mutate(Survived = ifelse(Survived == 1, \"yes\", \"no\"))                 # Target을 문자형 변수로 변환\n\n# 1. Convert to Factor\nfac.col &lt;- c(\"Pclass\", \"Sex\",\n             # Target\n             \"Survived\")\n\ntitanic &lt;- titanic %&gt;% \n  mutate_at(fac.col, as.factor)                                         # 범주형으로 변환\n\nglimpse(titanic)                                                        # 데이터 구조 확인\n\nRows: 891\nColumns: 11\n$ Survived &lt;fct&gt; no, yes, yes, yes, no, no, no, no, yes, yes, yes, yes, no, no, no, yes, no, yes, no, yes, no, yes, yes, yes, no, yes, no, no, yes, no, no, yes, yes, no, no, no, yes, no, no, yes, no…\n$ Pclass   &lt;fct&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3, 2, 2, 3, 1, 3, 3, 3, 1, 3, 3, 1, 1, 3, 2, 1, 1, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 1, 1, 2, 3, 2, 3, 3…\n$ Name     &lt;chr&gt; \"Braund, Mr. Owen Harris\", \"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\", \"Heikkinen, Miss. Laina\", \"Futrelle, Mrs. Jacques Heath (Lily May Peel)\", \"Allen, Mr. William Henry…\n$ Sex      &lt;fct&gt; male, female, female, female, male, male, male, male, female, female, female, female, male, male, female, female, male, male, female, female, male, male, female, male, female, femal…\n$ Age      &lt;dbl&gt; 22.0, 38.0, 26.0, 35.0, 35.0, NA, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, NA, 31.0, NA, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, NA, 19.0, NA, NA, 40.0, NA, NA, 66.…\n$ SibSp    &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0, 0, 0, 0, 0, 3, 1, 0, 3, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 1, 0, 0, 1, 0, 2, 1, 4, 0, 1, 1, 0, 0, 0, 0, 1, 5, 0…\n$ Parch    &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 5, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 2, 2, 0…\n$ Ticket   &lt;chr&gt; \"A/5 21171\", \"PC 17599\", \"STON/O2. 3101282\", \"113803\", \"373450\", \"330877\", \"17463\", \"349909\", \"347742\", \"237736\", \"PP 9549\", \"113783\", \"A/5. 2151\", \"347082\", \"350406\", \"248706\", \"38…\n$ Fare     &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625, 21.0750, 11.1333, 30.0708, 16.7000, 26.5500, 8.0500, 31.2750, 7.8542, 16.0000, 29.1250, 13.0000, 18.0000, 7.2250, 26.0000,…\n$ Cabin    &lt;chr&gt; \"\", \"C85\", \"\", \"C123\", \"\", \"\", \"E46\", \"\", \"\", \"\", \"G6\", \"C103\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"D56\", \"\", \"A6\", \"\", \"\", \"\", \"C23 C25 C27\", \"\", \"\", \"\", \"B78\", \"\", \"\", \"\", \"\", \"\"…\n$ Embarked &lt;chr&gt; \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"C\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"Q\", \"S\", \"C\", \"C\", \"Q\", \"S\", \"C\", \"S\", \"…\n\n# 2. Generate New Variable\ntitanic &lt;- titanic %&gt;%\n  mutate(FamSize = SibSp + Parch)                                       # \"FamSize = 형제 및 배우자 수 + 부모님 및 자녀 수\"로 가족 수를 의미하는 새로운 변수\n\nglimpse(titanic)                                                        # 데이터 구조 확인\n\nRows: 891\nColumns: 12\n$ Survived &lt;fct&gt; no, yes, yes, yes, no, no, no, no, yes, yes, yes, yes, no, no, no, yes, no, yes, no, yes, no, yes, yes, yes, no, yes, no, no, yes, no, no, yes, yes, no, no, no, yes, no, no, yes, no…\n$ Pclass   &lt;fct&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3, 2, 2, 3, 1, 3, 3, 3, 1, 3, 3, 1, 1, 3, 2, 1, 1, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 1, 1, 2, 3, 2, 3, 3…\n$ Name     &lt;chr&gt; \"Braund, Mr. Owen Harris\", \"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\", \"Heikkinen, Miss. Laina\", \"Futrelle, Mrs. Jacques Heath (Lily May Peel)\", \"Allen, Mr. William Henry…\n$ Sex      &lt;fct&gt; male, female, female, female, male, male, male, male, female, female, female, female, male, male, female, female, male, male, female, female, male, male, female, male, female, femal…\n$ Age      &lt;dbl&gt; 22.0, 38.0, 26.0, 35.0, 35.0, NA, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, NA, 31.0, NA, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, NA, 19.0, NA, NA, 40.0, NA, NA, 66.…\n$ SibSp    &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0, 0, 0, 0, 0, 3, 1, 0, 3, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 1, 0, 0, 1, 0, 2, 1, 4, 0, 1, 1, 0, 0, 0, 0, 1, 5, 0…\n$ Parch    &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 5, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 2, 2, 0…\n$ Ticket   &lt;chr&gt; \"A/5 21171\", \"PC 17599\", \"STON/O2. 3101282\", \"113803\", \"373450\", \"330877\", \"17463\", \"349909\", \"347742\", \"237736\", \"PP 9549\", \"113783\", \"A/5. 2151\", \"347082\", \"350406\", \"248706\", \"38…\n$ Fare     &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625, 21.0750, 11.1333, 30.0708, 16.7000, 26.5500, 8.0500, 31.2750, 7.8542, 16.0000, 29.1250, 13.0000, 18.0000, 7.2250, 26.0000,…\n$ Cabin    &lt;chr&gt; \"\", \"C85\", \"\", \"C123\", \"\", \"\", \"E46\", \"\", \"\", \"\", \"G6\", \"C103\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"D56\", \"\", \"A6\", \"\", \"\", \"\", \"C23 C25 C27\", \"\", \"\", \"\", \"B78\", \"\", \"\", \"\", \"\", \"\"…\n$ Embarked &lt;chr&gt; \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"C\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"Q\", \"S\", \"C\", \"C\", \"Q\", \"S\", \"C\", \"S\", \"…\n$ FamSize  &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 4, 2, 1, 2, 0, 0, 6, 0, 0, 5, 0, 1, 0, 0, 0, 0, 0, 4, 6, 0, 5, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 3, 0, 0, 1, 0, 2, 1, 5, 0, 1, 1, 1, 0, 0, 0, 3, 7, 0…\n\n# 3. Select Variables used for Analysis\ntitanic1 &lt;- titanic %&gt;% \n  select(Survived, Pclass, Sex, Age, Fare, FamSize)                     # 분석에 사용할 변수 선택\n\n# 4. Convert One-hot Encoding for 범주형 예측 변수\ndummies &lt;- dummyVars(formula = ~ .,                                     # formula : ~ 예측 변수 / \".\" : data에 포함된 모든 변수를 의미\n                     data = titanic1[,-1],                              # Dataset including Only 예측 변수 -&gt; Target 제외\n                     fullRank = FALSE)                                  # fullRank = TRUE : Dummy Variable, fullRank = FALSE : One-hot Encoding\n\ntitanic.Var   &lt;- predict(dummies, newdata = titanic1) %&gt;%               # 범주형 예측 변수에 대한 One-hot Encoding 변환\n  data.frame()                                                          # Data Frame 형태로 변환 \n\nglimpse(titanic.Var)                                                    # 데이터 구조 확인\n\nRows: 891\nColumns: 8\n$ Pclass.1   &lt;dbl&gt; 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,…\n$ Pclass.2   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,…\n$ Pclass.3   &lt;dbl&gt; 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1,…\n$ Sex.female &lt;dbl&gt; 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0,…\n$ Sex.male   &lt;dbl&gt; 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1,…\n$ Age        &lt;dbl&gt; 22.0, 38.0, 26.0, 35.0, 35.0, NA, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, NA, 31.0, NA, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, NA, 19.0, NA, NA, 40.0, NA, NA, 6…\n$ Fare       &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625, 21.0750, 11.1333, 30.0708, 16.7000, 26.5500, 8.0500, 31.2750, 7.8542, 16.0000, 29.1250, 13.0000, 18.0000, 7.2250, 26.000…\n$ FamSize    &lt;dbl&gt; 1, 1, 0, 1, 0, 0, 0, 4, 2, 1, 2, 0, 0, 6, 0, 0, 5, 0, 1, 0, 0, 0, 0, 0, 4, 6, 0, 5, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 3, 0, 0, 1, 0, 2, 1, 5, 0, 1, 1, 1, 0, 0, 0, 3, 7,…\n\n# Combine Target with 변환된 예측 변수\ntitanic.df &lt;- data.frame(Survived = titanic1$Survived, \n                         titanic.Var)\n\ntitanic.df %&gt;%\n  as_tibble\n\n# A tibble: 891 × 9\n   Survived Pclass.1 Pclass.2 Pclass.3 Sex.female Sex.male   Age  Fare FamSize\n   &lt;fct&gt;       &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n 1 no              0        0        1          0        1    22  7.25       1\n 2 yes             1        0        0          1        0    38 71.3        1\n 3 yes             0        0        1          1        0    26  7.92       0\n 4 yes             1        0        0          1        0    35 53.1        1\n 5 no              0        0        1          0        1    35  8.05       0\n 6 no              0        0        1          0        1    NA  8.46       0\n 7 no              1        0        0          0        1    54 51.9        0\n 8 no              0        0        1          0        1     2 21.1        4\n 9 yes             0        0        1          1        0    27 11.1        2\n10 yes             0        1        0          1        0    14 30.1        1\n# ℹ 881 more rows\n\nglimpse(titanic.df)                                                     # 데이터 구조 확인\n\nRows: 891\nColumns: 9\n$ Survived   &lt;fct&gt; no, yes, yes, yes, no, no, no, no, yes, yes, yes, yes, no, no, no, yes, no, yes, no, yes, no, yes, yes, yes, no, yes, no, no, yes, no, no, yes, yes, no, no, no, yes, no, no, yes, …\n$ Pclass.1   &lt;dbl&gt; 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,…\n$ Pclass.2   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,…\n$ Pclass.3   &lt;dbl&gt; 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1,…\n$ Sex.female &lt;dbl&gt; 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0,…\n$ Sex.male   &lt;dbl&gt; 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1,…\n$ Age        &lt;dbl&gt; 22.0, 38.0, 26.0, 35.0, 35.0, NA, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, NA, 31.0, NA, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, NA, 19.0, NA, NA, 40.0, NA, NA, 6…\n$ Fare       &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625, 21.0750, 11.1333, 30.0708, 16.7000, 26.5500, 8.0500, 31.2750, 7.8542, 16.0000, 29.1250, 13.0000, 18.0000, 7.2250, 26.000…\n$ FamSize    &lt;dbl&gt; 1, 1, 0, 1, 0, 0, 0, 4, 2, 1, 2, 0, 0, 6, 0, 0, 5, 0, 1, 0, 0, 0, 0, 0, 4, 6, 0, 5, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 3, 0, 0, 1, 0, 2, 1, 5, 0, 1, 1, 1, 0, 0, 0, 3, 7,…",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Support Vector Machine with Linear Kernel</span>"
    ]
  },
  {
    "objectID": "SVM_li.html#데이터-탐색",
    "href": "SVM_li.html#데이터-탐색",
    "title": "4  Support Vector Machine with Linear Kernel",
    "section": "4.3 데이터 탐색",
    "text": "4.3 데이터 탐색\n\nggpairs(titanic.df,                                        \n        aes(colour = Survived)) +                         # Target의 범주에 따라 색깔을 다르게 표현\n  theme_bw()\n\n\n\n\n\n\n\nggpairs(titanic.df,                                     \n        aes(colour = Survived, alpha = 0.8)) +            # Target의 범주에 따라 색깔을 다르게 표현\n  scale_colour_manual(values = c(\"purple\", \"cyan4\")) +    # 특정 색깔 지정\n  scale_fill_manual(values = c(\"purple\", \"cyan4\")) +      # 특정 색깔 지정\n  theme_bw()",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Support Vector Machine with Linear Kernel</span>"
    ]
  },
  {
    "objectID": "SVM_li.html#데이터-분할",
    "href": "SVM_li.html#데이터-분할",
    "title": "4  Support Vector Machine with Linear Kernel",
    "section": "4.4 데이터 분할",
    "text": "4.4 데이터 분할\n\n# Partition (Training Dataset : Test Dataset = 7:3)\ny      &lt;- titanic.df$Survived                           # Target\n\nset.seed(200)\nind    &lt;- createDataPartition(y, p = 0.7, list  =T)     # Index를 이용하여 7:3으로 분할\ntitanic.trd &lt;- titanic.df[ind$Resample1,]               # Training Dataset\ntitanic.ted &lt;- titanic.df[-ind$Resample1,]              # Test Dataset",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Support Vector Machine with Linear Kernel</span>"
    ]
  },
  {
    "objectID": "SVM_li.html#데이터-전처리-ii",
    "href": "SVM_li.html#데이터-전처리-ii",
    "title": "4  Support Vector Machine with Linear Kernel",
    "section": "4.5 데이터 전처리 II",
    "text": "4.5 데이터 전처리 II\n\n# 1. Imputation\ntitanic.trd.Imp &lt;- titanic.trd %&gt;% \n  mutate(Age = replace_na(Age, mean(Age, na.rm = TRUE)))                 # 평균으로 결측값 대체\n\ntitanic.ted.Imp &lt;- titanic.ted %&gt;% \n  mutate(Age = replace_na(Age, mean(titanic.trd$Age, na.rm = TRUE)))     # Training Dataset을 이용하여 결측값 대체\n\n# 2. Standardization\npreProcValues &lt;- preProcess(titanic.trd.Imp, \n                            method = c(\"center\", \"scale\"))               # Standardization 정의 -&gt; Training Dataset에 대한 평균과 표준편차 계산 \n\ntitanic.trd.Imp &lt;- predict(preProcValues, titanic.trd.Imp)               # Standardization for Training Dataset\ntitanic.ted.Imp &lt;- predict(preProcValues, titanic.ted.Imp)               # Standardization for Test Dataset\n\nglimpse(titanic.trd.Imp)                                                 # 데이터 구조 확인\n\nRows: 625\nColumns: 9\n$ Survived   &lt;fct&gt; no, yes, yes, no, no, no, yes, yes, yes, yes, no, no, yes, no, yes, no, yes, no, no, no, yes, no, no, yes, yes, no, no, no, no, no, yes, no, no, no, yes, no, yes, no, no, no, yes,…\n$ Pclass.1   &lt;dbl&gt; -0.593506, -0.593506, 1.682207, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, 1.682207, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, 1.682…\n$ Pclass.2   &lt;dbl&gt; -0.4694145, -0.4694145, -0.4694145, -0.4694145, -0.4694145, -0.4694145, -0.4694145, 2.1269048, -0.4694145, -0.4694145, -0.4694145, -0.4694145, 2.1269048, -0.4694145, -0.4694145, 2…\n$ Pclass.3   &lt;dbl&gt; 0.888575, 0.888575, -1.123597, 0.888575, 0.888575, 0.888575, 0.888575, -1.123597, 0.888575, -1.123597, 0.888575, 0.888575, -1.123597, 0.888575, 0.888575, -1.123597, -1.123597, 0.8…\n$ Sex.female &lt;dbl&gt; -0.7572241, 1.3184999, 1.3184999, -0.7572241, -0.7572241, -0.7572241, 1.3184999, 1.3184999, 1.3184999, 1.3184999, -0.7572241, 1.3184999, -0.7572241, 1.3184999, 1.3184999, -0.75722…\n$ Sex.male   &lt;dbl&gt; 0.7572241, -1.3184999, -1.3184999, 0.7572241, 0.7572241, 0.7572241, -1.3184999, -1.3184999, -1.3184999, -1.3184999, 0.7572241, -1.3184999, 0.7572241, -1.3184999, -1.3184999, 0.757…\n$ Age        &lt;dbl&gt; -0.61306970, -0.30411628, 0.39102893, 0.39102893, 0.00000000, -2.15783684, -0.22687792, -1.23097656, -2.00336012, 2.16751113, 0.69998236, -1.23097656, 0.00000000, 0.08207551, 0.00…\n$ Fare       &lt;dbl&gt; -0.51776394, -0.50463325, 0.37414970, -0.50220165, -0.49425904, -0.24882814, -0.44222264, -0.07383411, -0.33393441, -0.14232374, -0.05040897, -0.50601052, -0.40590999, -0.30864569…\n$ FamSize    &lt;dbl&gt; 0.04506631, -0.55421976, 0.04506631, -0.55421976, -0.55421976, 1.84292454, 0.64435239, 0.04506631, 0.64435239, -0.55421976, 3.04149669, -0.55421976, -0.55421976, 0.04506631, -0.55…\n\nglimpse(titanic.ted.Imp)                                                 # 데이터 구조 확인\n\nRows: 266\nColumns: 9\n$ Survived   &lt;fct&gt; yes, no, no, yes, no, yes, yes, yes, yes, yes, no, no, yes, yes, no, yes, no, yes, yes, no, yes, no, no, no, no, no, no, yes, yes, no, no, no, no, no, no, no, no, no, no, yes, no,…\n$ Pclass.1   &lt;dbl&gt; 1.682207, 1.682207, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, 1.682…\n$ Pclass.2   &lt;dbl&gt; -0.4694145, -0.4694145, -0.4694145, 2.1269048, -0.4694145, 2.1269048, -0.4694145, -0.4694145, -0.4694145, 2.1269048, -0.4694145, -0.4694145, 2.1269048, 2.1269048, -0.4694145, 2.12…\n$ Pclass.3   &lt;dbl&gt; -1.123597, -1.123597, 0.888575, -1.123597, 0.888575, -1.123597, 0.888575, 0.888575, 0.888575, -1.123597, 0.888575, 0.888575, -1.123597, -1.123597, 0.888575, -1.123597, -1.123597, …\n$ Sex.female &lt;dbl&gt; 1.3184999, -0.7572241, -0.7572241, 1.3184999, -0.7572241, -0.7572241, 1.3184999, 1.3184999, -0.7572241, 1.3184999, -0.7572241, -0.7572241, 1.3184999, 1.3184999, -0.7572241, 1.3184…\n$ Sex.male   &lt;dbl&gt; -1.3184999, 0.7572241, 0.7572241, -1.3184999, 0.7572241, 0.7572241, -1.3184999, -1.3184999, 0.7572241, -1.3184999, 0.7572241, 0.7572241, -1.3184999, -1.3184999, 0.7572241, -1.3184…\n$ Age        &lt;dbl&gt; 0.62274400, 1.85855771, -0.76754642, 1.93579607, -2.15783684, 0.31379058, -1.15373820, 0.62274400, 0.00000000, -2.08059848, 0.00000000, -0.69030806, -0.07240121, -0.69030806, -0.1…\n$ Fare       &lt;dbl&gt; 0.727866891, 0.350076786, -0.502201647, -0.347551409, -0.092232621, -0.405909990, -0.502606266, -0.048220525, -0.518168555, 0.150037190, -0.502201647, -0.507064862, -0.153022808, …\n$ FamSize    &lt;dbl&gt; 0.04506631, -0.55421976, -0.55421976, -0.55421976, 2.44221062, -0.55421976, -0.55421976, 3.04149669, -0.55421976, 1.24363847, -0.55421976, -0.55421976, 0.04506631, -0.55421976, -0…",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Support Vector Machine with Linear Kernel</span>"
    ]
  },
  {
    "objectID": "SVM_li.html#모형-훈련",
    "href": "SVM_li.html#모형-훈련",
    "title": "4  Support Vector Machine with Linear Kernel",
    "section": "4.6 모형 훈련",
    "text": "4.6 모형 훈련\nPackage \"e1071\"는 Support Vector Machine을 효율적으로 구현할 수 있는 “libsvm”을 R에서 사용할 수 있도록 만든 Package이며, 함수 svm()을 이용하여 Support Vector Machine을 수행할 수 있다. 함수에서 사용할 수 있는 자세한 옵션은 여기를 참고한다.\n\nsvm(formula, data, kernel, cost, probability, ...)\n\n\nformula : Target과 예측 변수의 관계를 표현하기 위한 함수로써 일반적으로 Target ~ 예측 변수의 형태로 표현한다.\ndata : formula에 포함하고 있는 변수들의 데이터셋(Data Frame)\nkernel : Kernel 함수\n\n\"linear\" : \\(k(\\boldsymbol{x}, \\boldsymbol{x}') = \\boldsymbol{x}\\boldsymbol{x}'\\)\n\"polynomial\" : \\(k(\\boldsymbol{x}, \\boldsymbol{x}') = (\\gamma \\boldsymbol{x}\\boldsymbol{x}' + \\text{coef0})^{\\text{degree}}\\)\n\"radial\" : \\(k(\\boldsymbol{x}, \\boldsymbol{x}') = \\exp\\left(-\\gamma||\\boldsymbol{x}-\\boldsymbol{x}'||^2 \\right)\\)\n\"sigmoid\" : \\(k(\\boldsymbol{x}, \\boldsymbol{x}') = tanh(\\gamma \\boldsymbol{x}\\boldsymbol{x}' + \\text{coef0})\\)\n\ncost : 데이터를 잘못 분류하는 선을 그을 경우 지불해야 할 cost\nprobability : Test Dataset에 대한 예측 확률의 생성 여부\n\nTRUE : 함수 predict()를 이용하여 Test Dataset에 대한 예측 확률을 생성할 수 있다.\n\n\n\nsvm.model.li &lt;- svm(Survived ~.,     \n                    data = titanic.trd.Imp,  \n                    kernel = \"linear\", \n                    cost = 1,              \n                    probability = TRUE)       \n\nsummary(svm.model.li)\n\n\nCall:\nsvm(formula = Survived ~ ., data = titanic.trd.Imp, kernel = \"linear\", cost = 1, probability = TRUE)\n\n\nParameters:\n   SVM-Type:  C-classification \n SVM-Kernel:  linear \n       cost:  1 \n\nNumber of Support Vectors:  287\n\n ( 143 144 )\n\n\nNumber of Classes:  2 \n\nLevels: \n no yes\n\n\nResult! Number of Support Vectors는 결정경계와 가까이 위치한 case의 수이다. 해당 데이터에서는 총 287개의 case로, \"Survived = no\"에 해당하는 case는 143개, \"Survived = yes\"에 해당하는 case는 144개이다. case의 행 번호는 svm.model.li$index를 이용하여 확인할 수 있다.\n\n# Support Vector Index\nsvm.model.li$index   \n\n  [1]  12  14  16  18  20  23  27  30  32  33  39  48  50  59  71  76  77  79  80  83  93  94  95 100 112 114 119 121 122 129 135 140 146 151 156 157 160 161 164 166 170 173 176 181 182 190 193 201\n [49] 202 203 205 229 232 234 237 238 243 252 261 270 281 283 287 291 293 305 307 315 321 330 336 340 344 346 347 348 349 351 359 367 371 373 376 377 379 384 389 393 395 397 401 402 405 408 416 423\n [97] 429 436 447 448 451 464 466 467 470 471 478 479 493 499 508 513 514 515 517 521 525 538 539 543 550 554 556 557 558 563 564 568 571 573 574 577 581 591 598 599 607 608 610 620 622 623 625   7\n[145]   9  13  15  17  21  25  31  37  43  52  55  56  57  58  61  74  75  86  87  88  92  97  99 116 123 124 125 130 134 139 155 163 165 171 172 180 187 188 189 191 195 197 206 208 212 223 226 228\n[193] 233 235 240 241 249 255 256 258 266 275 276 279 284 290 294 302 303 304 308 312 313 316 317 318 320 326 334 335 352 353 355 357 358 362 372 375 378 382 388 390 391 399 400 406 407 411 421 422\n[241] 424 426 427 431 434 437 439 440 445 446 455 456 457 459 463 468 474 475 480 485 487 492 496 498 500 509 511 518 524 527 530 535 536 553 565 566 576 578 582 583 584 589 600 602 603 609 612",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Support Vector Machine with Linear Kernel</span>"
    ]
  },
  {
    "objectID": "SVM_li.html#모형-평가",
    "href": "SVM_li.html#모형-평가",
    "title": "4  Support Vector Machine with Linear Kernel",
    "section": "4.7 모형 평가",
    "text": "4.7 모형 평가\nCaution! 모형 평가를 위해 Test Dataset에 대한 예측 class/확률 이 필요하며, 함수 predict()를 이용하여 생성한다.\n\n# 예측 class 생성 \nsvm.li.pred &lt;- predict(svm.model.li,\n                       newdata = titanic.ted.Imp[,-1],  # Test Dataset including Only 예측 변수   \n                       type = \"class\")                  # 예측 class 생성       \n\nsvm.li.pred %&gt;%\n  as_tibble\n\n# A tibble: 266 × 1\n   value\n   &lt;fct&gt;\n 1 yes  \n 2 no   \n 3 no   \n 4 yes  \n 5 no   \n 6 no   \n 7 yes  \n 8 no   \n 9 no   \n10 yes  \n# ℹ 256 more rows\n\n\n\n\n4.7.1 ConfusionMatrix\n\nCM   &lt;- caret::confusionMatrix(svm.li.pred, titanic.ted.Imp$Survived, \n                               positive = \"yes\")        # confusionMatrix(예측 class, 실제 class, positive=\"관심 class\")\nCM\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  no yes\n       no  150  34\n       yes  14  68\n                                         \n               Accuracy : 0.8195         \n                 95% CI : (0.768, 0.8638)\n    No Information Rate : 0.6165         \n    P-Value [Acc &gt; NIR] : 5.675e-13      \n                                         \n                  Kappa : 0.6037         \n                                         \n Mcnemar's Test P-Value : 0.006099       \n                                         \n            Sensitivity : 0.6667         \n            Specificity : 0.9146         \n         Pos Pred Value : 0.8293         \n         Neg Pred Value : 0.8152         \n             Prevalence : 0.3835         \n         Detection Rate : 0.2556         \n   Detection Prevalence : 0.3083         \n      Balanced Accuracy : 0.7907         \n                                         \n       'Positive' Class : yes            \n                                         \n\n\n\n\n\n4.7.2 ROC 곡선\n\n# 예측 확률 생성\ntest.svm.prob &lt;- predict(svm.model.li, \n                         newdata = titanic.ted.Imp[,-1],    # Test Dataset including Only 예측 변수  \n                         probability = TRUE)                # 예측 확률 생성       \n\nattr(test.svm.prob, \"probabilities\") %&gt;%\n  as_tibble\n\n# A tibble: 266 × 2\n      no    yes\n   &lt;dbl&gt;  &lt;dbl&gt;\n 1 0.227 0.773 \n 2 0.785 0.215 \n 3 0.807 0.193 \n 4 0.288 0.712 \n 5 0.921 0.0794\n 6 0.799 0.201 \n 7 0.242 0.758 \n 8 0.648 0.352 \n 9 0.825 0.175 \n10 0.303 0.697 \n# ℹ 256 more rows\n\n\n\ntest.svm.prob &lt;- attr(test.svm.prob, \"probabilities\")[,2]   # \"Survived = yes\"에 대한 예측 확률\n\nac  &lt;- titanic.ted.Imp$Survived                             # Test Dataset의 실제 class \npp  &lt;- as.numeric(test.svm.prob)                            # 예측 확률을 수치형으로 변환\n\n\n4.7.2.1 Package “pROC”\n\npacman::p_load(\"pROC\")\n\nsvm.roc  &lt;- roc(ac, pp, plot = T, col = \"gray\")             # roc(실제 class, 예측 확률)\nauc      &lt;- round(auc(svm.roc), 3)\nlegend(\"bottomright\", legend = auc, bty = \"n\")\n\n\n\n\n\n\n\n\nCaution! Package \"pROC\"를 통해 출력한 ROC 곡선은 다양한 함수를 이용해서 그래프를 수정할 수 있다.\n\n# 함수 plot.roc() 이용\nplot.roc(svm.roc,   \n         col=\"gray\",                                        # Line Color\n         print.auc = TRUE,                                  # AUC 출력 여부\n         print.auc.col = \"red\",                             # AUC 글씨 색깔\n         print.thres = TRUE,                                # Cutoff Value 출력 여부\n         print.thres.pch = 19,                              # Cutoff Value를 표시하는 도형 모양\n         print.thres.col = \"red\",                           # Cutoff Value를 표시하는 도형의 색깔\n         auc.polygon = TRUE,                                # 곡선 아래 면적에 대한 여부\n         auc.polygon.col = \"gray90\")                        # 곡선 아래 면적의 색깔\n\n\n\n\n\n\n\n\n\n# 함수 ggroc() 이용\nggroc(svm.roc) +\nannotate(geom = \"text\", x = 0.9, y = 1.0,\nlabel = paste(\"AUC = \", auc),\nsize = 5,\ncolor=\"red\") +\ntheme_bw()\n\n\n\n\n\n\n\n\n\n\n4.7.2.2 Package “Epi”\n\npacman::p_load(\"Epi\")       \n# install_version(\"etm\", version = \"1.1\", repos = \"http://cran.us.r-project.org\")\n\nROC(pp, ac, plot = \"ROC\")                                   # ROC(예측 확률, 실제 class)  \n\n\n\n\n\n\n\n\n\n\n4.7.2.3 Package “ROCR”\n\npacman::p_load(\"ROCR\")\n\nsvm.pred &lt;- prediction(pp, ac)                              # prediction(예측 확률, 실제 class)    \n\nsvm.perf &lt;- performance(svm.pred, \"tpr\", \"fpr\")             # performance(, \"민감도\", \"1-특이도\")                      \nplot(svm.perf, col = \"gray\")                                # ROC Curve\n\nperf.auc   &lt;- performance(svm.pred, \"auc\")                  # AUC\nauc        &lt;- attributes(perf.auc)$y.values \nlegend(\"bottomright\", legend = auc, bty = \"n\")\n\n\n\n\n\n\n\n\n\n\n\n\n4.7.3 향상 차트\n\n4.7.3.1 Package “ROCR”\n\nsvm.perf &lt;- performance(svm.pred, \"lift\", \"rpp\")            # Lift Chart\nplot(svm.perf, main = \"lift curve\", \n     colorize = T,                                          # Coloring according to cutoff\n     lwd = 2)",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Support Vector Machine with Linear Kernel</span>"
    ]
  },
  {
    "objectID": "SVM_po.html",
    "href": "SVM_po.html",
    "title": "5  Support Vector Machine with Polynomial Kernel",
    "section": "",
    "text": "5.1 데이터 불러오기\npacman::p_load(\"data.table\", \"dplyr\", \"tidyr\",\n               \"caret\",\n               \"ggplot2\", \"GGally\",\n               \"e1071\")\n\ntitanic &lt;- fread(\"../Titanic.csv\")                                      # 데이터 불러오기\n\ntitanic %&gt;%\n  as_tibble\n# A tibble: 891 × 11\n   Survived Pclass Name                                                Sex      Age SibSp Parch Ticket            Fare Cabin  Embarked\n      &lt;int&gt;  &lt;int&gt; &lt;chr&gt;                                               &lt;chr&gt;  &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;   \n 1        0      3 Braund, Mr. Owen Harris                             male      22     1     0 A/5 21171         7.25 \"\"     S       \n 2        1      1 Cumings, Mrs. John Bradley (Florence Briggs Thayer) female    38     1     0 PC 17599         71.3  \"C85\"  C       \n 3        1      3 Heikkinen, Miss. Laina                              female    26     0     0 STON/O2. 3101282  7.92 \"\"     S       \n 4        1      1 Futrelle, Mrs. Jacques Heath (Lily May Peel)        female    35     1     0 113803           53.1  \"C123\" S       \n 5        0      3 Allen, Mr. William Henry                            male      35     0     0 373450            8.05 \"\"     S       \n 6        0      3 Moran, Mr. James                                    male      NA     0     0 330877            8.46 \"\"     Q       \n 7        0      1 McCarthy, Mr. Timothy J                             male      54     0     0 17463            51.9  \"E46\"  S       \n 8        0      3 Palsson, Master. Gosta Leonard                      male       2     3     1 349909           21.1  \"\"     S       \n 9        1      3 Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)   female    27     0     2 347742           11.1  \"\"     S       \n10        1      2 Nasser, Mrs. Nicholas (Adele Achem)                 female    14     1     0 237736           30.1  \"\"     C       \n# ℹ 881 more rows",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Support Vector Machine with Polynomial Kernel</span>"
    ]
  },
  {
    "objectID": "SVM_po.html#데이터-전처리-i",
    "href": "SVM_po.html#데이터-전처리-i",
    "title": "5  Support Vector Machine with Polynomial Kernel",
    "section": "5.2 데이터 전처리 I",
    "text": "5.2 데이터 전처리 I\n\ntitanic %&lt;&gt;%\n  data.frame() %&gt;%                                                      # Data Frame 형태로 변환 \n  mutate(Survived = ifelse(Survived == 1, \"yes\", \"no\"))                 # Target을 문자형 변수로 변환\n\n# 1. Convert to Factor\nfac.col &lt;- c(\"Pclass\", \"Sex\",\n             # Target\n             \"Survived\")\n\ntitanic &lt;- titanic %&gt;% \n  mutate_at(fac.col, as.factor)                                         # 범주형으로 변환\n\nglimpse(titanic)                                                        # 데이터 구조 확인\n\nRows: 891\nColumns: 11\n$ Survived &lt;fct&gt; no, yes, yes, yes, no, no, no, no, yes, yes, yes, yes, no, no, no, yes, no, yes, no, yes, no, yes, yes, yes, no, yes, no, no, yes, no, no, yes, yes, no, no, no, yes, no, no, yes, no…\n$ Pclass   &lt;fct&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3, 2, 2, 3, 1, 3, 3, 3, 1, 3, 3, 1, 1, 3, 2, 1, 1, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 1, 1, 2, 3, 2, 3, 3…\n$ Name     &lt;chr&gt; \"Braund, Mr. Owen Harris\", \"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\", \"Heikkinen, Miss. Laina\", \"Futrelle, Mrs. Jacques Heath (Lily May Peel)\", \"Allen, Mr. William Henry…\n$ Sex      &lt;fct&gt; male, female, female, female, male, male, male, male, female, female, female, female, male, male, female, female, male, male, female, female, male, male, female, male, female, femal…\n$ Age      &lt;dbl&gt; 22.0, 38.0, 26.0, 35.0, 35.0, NA, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, NA, 31.0, NA, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, NA, 19.0, NA, NA, 40.0, NA, NA, 66.…\n$ SibSp    &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0, 0, 0, 0, 0, 3, 1, 0, 3, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 1, 0, 0, 1, 0, 2, 1, 4, 0, 1, 1, 0, 0, 0, 0, 1, 5, 0…\n$ Parch    &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 5, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 2, 2, 0…\n$ Ticket   &lt;chr&gt; \"A/5 21171\", \"PC 17599\", \"STON/O2. 3101282\", \"113803\", \"373450\", \"330877\", \"17463\", \"349909\", \"347742\", \"237736\", \"PP 9549\", \"113783\", \"A/5. 2151\", \"347082\", \"350406\", \"248706\", \"38…\n$ Fare     &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625, 21.0750, 11.1333, 30.0708, 16.7000, 26.5500, 8.0500, 31.2750, 7.8542, 16.0000, 29.1250, 13.0000, 18.0000, 7.2250, 26.0000,…\n$ Cabin    &lt;chr&gt; \"\", \"C85\", \"\", \"C123\", \"\", \"\", \"E46\", \"\", \"\", \"\", \"G6\", \"C103\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"D56\", \"\", \"A6\", \"\", \"\", \"\", \"C23 C25 C27\", \"\", \"\", \"\", \"B78\", \"\", \"\", \"\", \"\", \"\"…\n$ Embarked &lt;chr&gt; \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"C\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"Q\", \"S\", \"C\", \"C\", \"Q\", \"S\", \"C\", \"S\", \"…\n\n# 2. Generate New Variable\ntitanic &lt;- titanic %&gt;%\n  mutate(FamSize = SibSp + Parch)                                       # \"FamSize = 형제 및 배우자 수 + 부모님 및 자녀 수\"로 가족 수를 의미하는 새로운 변수\n\nglimpse(titanic)                                                        # 데이터 구조 확인\n\nRows: 891\nColumns: 12\n$ Survived &lt;fct&gt; no, yes, yes, yes, no, no, no, no, yes, yes, yes, yes, no, no, no, yes, no, yes, no, yes, no, yes, yes, yes, no, yes, no, no, yes, no, no, yes, yes, no, no, no, yes, no, no, yes, no…\n$ Pclass   &lt;fct&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3, 2, 2, 3, 1, 3, 3, 3, 1, 3, 3, 1, 1, 3, 2, 1, 1, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 1, 1, 2, 3, 2, 3, 3…\n$ Name     &lt;chr&gt; \"Braund, Mr. Owen Harris\", \"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\", \"Heikkinen, Miss. Laina\", \"Futrelle, Mrs. Jacques Heath (Lily May Peel)\", \"Allen, Mr. William Henry…\n$ Sex      &lt;fct&gt; male, female, female, female, male, male, male, male, female, female, female, female, male, male, female, female, male, male, female, female, male, male, female, male, female, femal…\n$ Age      &lt;dbl&gt; 22.0, 38.0, 26.0, 35.0, 35.0, NA, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, NA, 31.0, NA, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, NA, 19.0, NA, NA, 40.0, NA, NA, 66.…\n$ SibSp    &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0, 0, 0, 0, 0, 3, 1, 0, 3, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 1, 0, 0, 1, 0, 2, 1, 4, 0, 1, 1, 0, 0, 0, 0, 1, 5, 0…\n$ Parch    &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 5, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 2, 2, 0…\n$ Ticket   &lt;chr&gt; \"A/5 21171\", \"PC 17599\", \"STON/O2. 3101282\", \"113803\", \"373450\", \"330877\", \"17463\", \"349909\", \"347742\", \"237736\", \"PP 9549\", \"113783\", \"A/5. 2151\", \"347082\", \"350406\", \"248706\", \"38…\n$ Fare     &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625, 21.0750, 11.1333, 30.0708, 16.7000, 26.5500, 8.0500, 31.2750, 7.8542, 16.0000, 29.1250, 13.0000, 18.0000, 7.2250, 26.0000,…\n$ Cabin    &lt;chr&gt; \"\", \"C85\", \"\", \"C123\", \"\", \"\", \"E46\", \"\", \"\", \"\", \"G6\", \"C103\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"D56\", \"\", \"A6\", \"\", \"\", \"\", \"C23 C25 C27\", \"\", \"\", \"\", \"B78\", \"\", \"\", \"\", \"\", \"\"…\n$ Embarked &lt;chr&gt; \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"C\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"Q\", \"S\", \"C\", \"C\", \"Q\", \"S\", \"C\", \"S\", \"…\n$ FamSize  &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 4, 2, 1, 2, 0, 0, 6, 0, 0, 5, 0, 1, 0, 0, 0, 0, 0, 4, 6, 0, 5, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 3, 0, 0, 1, 0, 2, 1, 5, 0, 1, 1, 1, 0, 0, 0, 3, 7, 0…\n\n# 3. Select Variables used for Analysis\ntitanic1 &lt;- titanic %&gt;% \n  select(Survived, Pclass, Sex, Age, Fare, FamSize)                     # 분석에 사용할 변수 선택\n\n# 4. Convert One-hot Encoding for 범주형 예측 변수\ndummies &lt;- dummyVars(formula = ~ .,                                     # formula : ~ 예측 변수 / \".\" : data에 포함된 모든 변수를 의미\n                     data = titanic1[,-1],                              # Dataset including Only 예측 변수 -&gt; Target 제외\n                     fullRank = FALSE)                                  # fullRank = TRUE : Dummy Variable, fullRank = FALSE : One-hot Encoding\n\ntitanic.Var   &lt;- predict(dummies, newdata = titanic1) %&gt;%               # 범주형 예측 변수에 대한 One-hot Encoding 변환\n  data.frame()                                                          # Data Frame 형태로 변환  \n\nglimpse(titanic.Var)                                                    # 데이터 구조 확인\n\nRows: 891\nColumns: 8\n$ Pclass.1   &lt;dbl&gt; 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,…\n$ Pclass.2   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,…\n$ Pclass.3   &lt;dbl&gt; 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1,…\n$ Sex.female &lt;dbl&gt; 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0,…\n$ Sex.male   &lt;dbl&gt; 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1,…\n$ Age        &lt;dbl&gt; 22.0, 38.0, 26.0, 35.0, 35.0, NA, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, NA, 31.0, NA, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, NA, 19.0, NA, NA, 40.0, NA, NA, 6…\n$ Fare       &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625, 21.0750, 11.1333, 30.0708, 16.7000, 26.5500, 8.0500, 31.2750, 7.8542, 16.0000, 29.1250, 13.0000, 18.0000, 7.2250, 26.000…\n$ FamSize    &lt;dbl&gt; 1, 1, 0, 1, 0, 0, 0, 4, 2, 1, 2, 0, 0, 6, 0, 0, 5, 0, 1, 0, 0, 0, 0, 0, 4, 6, 0, 5, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 3, 0, 0, 1, 0, 2, 1, 5, 0, 1, 1, 1, 0, 0, 0, 3, 7,…\n\n# Combine Target with 변환된 예측 변수\ntitanic.df &lt;- data.frame(Survived = titanic1$Survived, \n                         titanic.Var)\n\ntitanic.df %&gt;%\n  as_tibble\n\n# A tibble: 891 × 9\n   Survived Pclass.1 Pclass.2 Pclass.3 Sex.female Sex.male   Age  Fare FamSize\n   &lt;fct&gt;       &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n 1 no              0        0        1          0        1    22  7.25       1\n 2 yes             1        0        0          1        0    38 71.3        1\n 3 yes             0        0        1          1        0    26  7.92       0\n 4 yes             1        0        0          1        0    35 53.1        1\n 5 no              0        0        1          0        1    35  8.05       0\n 6 no              0        0        1          0        1    NA  8.46       0\n 7 no              1        0        0          0        1    54 51.9        0\n 8 no              0        0        1          0        1     2 21.1        4\n 9 yes             0        0        1          1        0    27 11.1        2\n10 yes             0        1        0          1        0    14 30.1        1\n# ℹ 881 more rows\n\nglimpse(titanic.df)                                                     # 데이터 구조 확인\n\nRows: 891\nColumns: 9\n$ Survived   &lt;fct&gt; no, yes, yes, yes, no, no, no, no, yes, yes, yes, yes, no, no, no, yes, no, yes, no, yes, no, yes, yes, yes, no, yes, no, no, yes, no, no, yes, yes, no, no, no, yes, no, no, yes, …\n$ Pclass.1   &lt;dbl&gt; 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,…\n$ Pclass.2   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,…\n$ Pclass.3   &lt;dbl&gt; 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1,…\n$ Sex.female &lt;dbl&gt; 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0,…\n$ Sex.male   &lt;dbl&gt; 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1,…\n$ Age        &lt;dbl&gt; 22.0, 38.0, 26.0, 35.0, 35.0, NA, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, NA, 31.0, NA, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, NA, 19.0, NA, NA, 40.0, NA, NA, 6…\n$ Fare       &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625, 21.0750, 11.1333, 30.0708, 16.7000, 26.5500, 8.0500, 31.2750, 7.8542, 16.0000, 29.1250, 13.0000, 18.0000, 7.2250, 26.000…\n$ FamSize    &lt;dbl&gt; 1, 1, 0, 1, 0, 0, 0, 4, 2, 1, 2, 0, 0, 6, 0, 0, 5, 0, 1, 0, 0, 0, 0, 0, 4, 6, 0, 5, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 3, 0, 0, 1, 0, 2, 1, 5, 0, 1, 1, 1, 0, 0, 0, 3, 7,…",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Support Vector Machine with Polynomial Kernel</span>"
    ]
  },
  {
    "objectID": "SVM_po.html#데이터-탐색",
    "href": "SVM_po.html#데이터-탐색",
    "title": "5  Support Vector Machine with Polynomial Kernel",
    "section": "5.3 데이터 탐색",
    "text": "5.3 데이터 탐색\n\nggpairs(titanic.df,                                        \n        aes(colour = Survived)) +                         # Target의 범주에 따라 색깔을 다르게 표현\n  theme_bw()\n\n\n\n\n\n\n\nggpairs(titanic.df,                                     \n        aes(colour = Survived, alpha = 0.8)) +            # Target의 범주에 따라 색깔을 다르게 표현\n  scale_colour_manual(values = c(\"purple\", \"cyan4\")) +    # 특정 색깔 지정\n  scale_fill_manual(values = c(\"purple\", \"cyan4\")) +      # 특정 색깔 지정\n  theme_bw()",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Support Vector Machine with Polynomial Kernel</span>"
    ]
  },
  {
    "objectID": "SVM_po.html#데이터-분할",
    "href": "SVM_po.html#데이터-분할",
    "title": "5  Support Vector Machine with Polynomial Kernel",
    "section": "5.4 데이터 분할",
    "text": "5.4 데이터 분할\n\n# Partition (Training Dataset : Test Dataset = 7:3)\ny      &lt;- titanic.df$Survived                           # Target\n\nset.seed(200)\nind    &lt;- createDataPartition(y, p = 0.7, list  =T)     # Index를 이용하여 7:3으로 분할\ntitanic.trd &lt;- titanic.df[ind$Resample1,]               # Training Dataset\ntitanic.ted &lt;- titanic.df[-ind$Resample1,]              # Test Dataset",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Support Vector Machine with Polynomial Kernel</span>"
    ]
  },
  {
    "objectID": "SVM_po.html#데이터-전처리-ii",
    "href": "SVM_po.html#데이터-전처리-ii",
    "title": "5  Support Vector Machine with Polynomial Kernel",
    "section": "5.5 데이터 전처리 II",
    "text": "5.5 데이터 전처리 II\n\n# 1. Imputation\ntitanic.trd.Imp &lt;- titanic.trd %&gt;% \n  mutate(Age = replace_na(Age, mean(Age, na.rm = TRUE)))                 # 평균으로 결측값 대체\n\ntitanic.ted.Imp &lt;- titanic.ted %&gt;% \n  mutate(Age = replace_na(Age, mean(titanic.trd$Age, na.rm = TRUE)))     # Training Dataset을 이용하여 결측값 대체\n\n# 2. Standardization\npreProcValues &lt;- preProcess(titanic.trd.Imp, \n                            method = c(\"center\", \"scale\"))               # Standardization 정의 -&gt; Training Dataset에 대한 평균과 표준편차 계산 \n\ntitanic.trd.Imp &lt;- predict(preProcValues, titanic.trd.Imp)               # Standardization for Training Dataset\ntitanic.ted.Imp &lt;- predict(preProcValues, titanic.ted.Imp)               # Standardization for Test Dataset\n\nglimpse(titanic.trd.Imp)                                                 # 데이터 구조 확인\n\nRows: 625\nColumns: 9\n$ Survived   &lt;fct&gt; no, yes, yes, no, no, no, yes, yes, yes, yes, no, no, yes, no, yes, no, yes, no, no, no, yes, no, no, yes, yes, no, no, no, no, no, yes, no, no, no, yes, no, yes, no, no, no, yes,…\n$ Pclass.1   &lt;dbl&gt; -0.593506, -0.593506, 1.682207, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, 1.682207, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, 1.682…\n$ Pclass.2   &lt;dbl&gt; -0.4694145, -0.4694145, -0.4694145, -0.4694145, -0.4694145, -0.4694145, -0.4694145, 2.1269048, -0.4694145, -0.4694145, -0.4694145, -0.4694145, 2.1269048, -0.4694145, -0.4694145, 2…\n$ Pclass.3   &lt;dbl&gt; 0.888575, 0.888575, -1.123597, 0.888575, 0.888575, 0.888575, 0.888575, -1.123597, 0.888575, -1.123597, 0.888575, 0.888575, -1.123597, 0.888575, 0.888575, -1.123597, -1.123597, 0.8…\n$ Sex.female &lt;dbl&gt; -0.7572241, 1.3184999, 1.3184999, -0.7572241, -0.7572241, -0.7572241, 1.3184999, 1.3184999, 1.3184999, 1.3184999, -0.7572241, 1.3184999, -0.7572241, 1.3184999, 1.3184999, -0.75722…\n$ Sex.male   &lt;dbl&gt; 0.7572241, -1.3184999, -1.3184999, 0.7572241, 0.7572241, 0.7572241, -1.3184999, -1.3184999, -1.3184999, -1.3184999, 0.7572241, -1.3184999, 0.7572241, -1.3184999, -1.3184999, 0.757…\n$ Age        &lt;dbl&gt; -0.61306970, -0.30411628, 0.39102893, 0.39102893, 0.00000000, -2.15783684, -0.22687792, -1.23097656, -2.00336012, 2.16751113, 0.69998236, -1.23097656, 0.00000000, 0.08207551, 0.00…\n$ Fare       &lt;dbl&gt; -0.51776394, -0.50463325, 0.37414970, -0.50220165, -0.49425904, -0.24882814, -0.44222264, -0.07383411, -0.33393441, -0.14232374, -0.05040897, -0.50601052, -0.40590999, -0.30864569…\n$ FamSize    &lt;dbl&gt; 0.04506631, -0.55421976, 0.04506631, -0.55421976, -0.55421976, 1.84292454, 0.64435239, 0.04506631, 0.64435239, -0.55421976, 3.04149669, -0.55421976, -0.55421976, 0.04506631, -0.55…\n\nglimpse(titanic.ted.Imp)                                                 # 데이터 구조 확인\n\nRows: 266\nColumns: 9\n$ Survived   &lt;fct&gt; yes, no, no, yes, no, yes, yes, yes, yes, yes, no, no, yes, yes, no, yes, no, yes, yes, no, yes, no, no, no, no, no, no, yes, yes, no, no, no, no, no, no, no, no, no, no, yes, no,…\n$ Pclass.1   &lt;dbl&gt; 1.682207, 1.682207, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, 1.682…\n$ Pclass.2   &lt;dbl&gt; -0.4694145, -0.4694145, -0.4694145, 2.1269048, -0.4694145, 2.1269048, -0.4694145, -0.4694145, -0.4694145, 2.1269048, -0.4694145, -0.4694145, 2.1269048, 2.1269048, -0.4694145, 2.12…\n$ Pclass.3   &lt;dbl&gt; -1.123597, -1.123597, 0.888575, -1.123597, 0.888575, -1.123597, 0.888575, 0.888575, 0.888575, -1.123597, 0.888575, 0.888575, -1.123597, -1.123597, 0.888575, -1.123597, -1.123597, …\n$ Sex.female &lt;dbl&gt; 1.3184999, -0.7572241, -0.7572241, 1.3184999, -0.7572241, -0.7572241, 1.3184999, 1.3184999, -0.7572241, 1.3184999, -0.7572241, -0.7572241, 1.3184999, 1.3184999, -0.7572241, 1.3184…\n$ Sex.male   &lt;dbl&gt; -1.3184999, 0.7572241, 0.7572241, -1.3184999, 0.7572241, 0.7572241, -1.3184999, -1.3184999, 0.7572241, -1.3184999, 0.7572241, 0.7572241, -1.3184999, -1.3184999, 0.7572241, -1.3184…\n$ Age        &lt;dbl&gt; 0.62274400, 1.85855771, -0.76754642, 1.93579607, -2.15783684, 0.31379058, -1.15373820, 0.62274400, 0.00000000, -2.08059848, 0.00000000, -0.69030806, -0.07240121, -0.69030806, -0.1…\n$ Fare       &lt;dbl&gt; 0.727866891, 0.350076786, -0.502201647, -0.347551409, -0.092232621, -0.405909990, -0.502606266, -0.048220525, -0.518168555, 0.150037190, -0.502201647, -0.507064862, -0.153022808, …\n$ FamSize    &lt;dbl&gt; 0.04506631, -0.55421976, -0.55421976, -0.55421976, 2.44221062, -0.55421976, -0.55421976, 3.04149669, -0.55421976, 1.24363847, -0.55421976, -0.55421976, 0.04506631, -0.55421976, -0…",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Support Vector Machine with Polynomial Kernel</span>"
    ]
  },
  {
    "objectID": "SVM_po.html#모형-훈련",
    "href": "SVM_po.html#모형-훈련",
    "title": "5  Support Vector Machine with Polynomial Kernel",
    "section": "5.6 모형 훈련",
    "text": "5.6 모형 훈련\nPackage \"e1071\"는 Support Vector Machine을 효율적으로 구현할 수 있는 “libsvm”을 R에서 사용할 수 있도록 만든 Package이며, 함수 svm()을 이용하여 Support Vector Machine을 수행할 수 있다. 함수에서 사용할 수 있는 자세한 옵션은 여기를 참고한다.\n\nsvm(formula, data, kernel, cost, degree, gamma, coef0, probability, ...)\n\n\nformula : Target과 예측 변수의 관계를 표현하기 위한 함수로써 일반적으로 Target ~ 예측 변수의 형태로 표현한다.\ndata : formula에 포함하고 있는 변수들의 데이터셋(Data Frame)\nkernel : Kernel 함수\n\n\"linear\" : \\(k(\\boldsymbol{x}, \\boldsymbol{x}') = \\boldsymbol{x}\\boldsymbol{x}'\\)\n\"polynomial\" : \\(k(\\boldsymbol{x}, \\boldsymbol{x}') = (\\gamma \\boldsymbol{x}\\boldsymbol{x}' + \\text{coef0})^{\\text{degree}}\\)\n\"radial\" : \\(k(\\boldsymbol{x}, \\boldsymbol{x}') = \\exp\\left(-\\gamma||\\boldsymbol{x}-\\boldsymbol{x}'||^2 \\right)\\)\n\"sigmoid\" : \\(k(\\boldsymbol{x}, \\boldsymbol{x}') = tanh(\\gamma \\boldsymbol{x}\\boldsymbol{x}' + \\text{coef0})\\)\n\ncost : 데이터를 잘못 분류하는 선을 그을 경우 지불해야 할 cost\ndegree : 다항 커널의 차수\ngamma : 개별 case가 결정경계의 위치에 미치는 영향\ncoef0 : 다항 커널의 상수항\nprobability : Test Dataset에 대한 예측 확률의 생성 여부\n\nTRUE : 함수 predict()를 이용하여 Test Dataset에 대한 예측 확률을 생성할 수 있다.\n\n\n\nsvm.model.po &lt;- svm(Survived ~.,     \n                    data = titanic.trd.Imp,  \n                    kernel = \"polynomial\", \n                    cost = 1,              \n                    degree = 2,\n                    gamma = 2,\n                    coef0 = 1,\n                    probability = TRUE)\n\nsummary(svm.model.po)\n\n\nCall:\nsvm(formula = Survived ~ ., data = titanic.trd.Imp, kernel = \"polynomial\", cost = 1, degree = 2, gamma = 2, coef0 = 1, probability = TRUE)\n\n\nParameters:\n   SVM-Type:  C-classification \n SVM-Kernel:  polynomial \n       cost:  1 \n     degree:  2 \n     coef.0:  1 \n\nNumber of Support Vectors:  252\n\n ( 128 124 )\n\n\nNumber of Classes:  2 \n\nLevels: \n no yes\n\n\nResult! Number of Support Vectors는 결정경계와 가까이 위치한 case의 수이다. 해당 데이터에서는 총 252개의 case로, \"Survived = no\"에 해당하는 case는 128개, \"Survived = yes\"에 해당하는 case는 124개이다. case의 행 번호는 svm.model.po$index를 이용하여 확인할 수 있다.\n\n# Support Vector Index\nsvm.model.po$index   \n\n  [1]   6  12  14  18  20  23  27  28  30  32  33  39  42  47  48  66  70  71  77  79  80  82  85  94  95  98 100 106 112 114 135 140 154 156 161 169 170 173 176 181 182 193 202 203 205 214 229 232\n [49] 243 244 247 251 252 259 260 281 287 298 306 307 315 330 341 343 344 346 347 348 349 351 354 361 368 371 373 379 395 401 402 405 416 436 442 447 448 450 464 465 466 479 481 483 490 493 499 505\n [97] 510 512 513 514 516 521 525 538 539 542 543 550 554 558 563 568 570 573 574 577 579 581 586 591 594 597 598 599 606 614 620 625   2   7   9  13  15  17  25  31  35  37  43  52  57  58  61  73\n[145]  74  75  86  87  88  96  97  99 107 125 130 134 139 142 148 155 165 172 180 188 191 195 197 198 206 208 212 217 226 228 233 236 240 241 256 258 263 275 276 279 284 302 303 304 308 313 316 317\n[193] 318 320 326 335 350 353 355 357 378 382 386 391 399 400 406 411 421 424 426 431 439 440 445 446 455 456 457 459 461 468 474 475 477 480 485 487 492 496 498 500 509 511 518 524 527 530 535 548\n[241] 553 565 566 576 578 582 583 589 600 602 603 624",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Support Vector Machine with Polynomial Kernel</span>"
    ]
  },
  {
    "objectID": "SVM_po.html#모형-평가",
    "href": "SVM_po.html#모형-평가",
    "title": "5  Support Vector Machine with Polynomial Kernel",
    "section": "5.7 모형 평가",
    "text": "5.7 모형 평가\nCaution! 모형 평가를 위해 Test Dataset에 대한 예측 class/확률 이 필요하며, 함수 predict()를 이용하여 생성한다.\n\n# 예측 class 생성 \nsvm.po.pred &lt;- predict(svm.model.po,\n                       newdata = titanic.ted.Imp[,-1],  # Test Dataset including Only 예측 변수   \n                       type = \"class\")                  # 예측 class 생성       \n\nsvm.po.pred %&gt;%\n  as_tibble\n\n# A tibble: 266 × 1\n   value\n   &lt;fct&gt;\n 1 yes  \n 2 no   \n 3 no   \n 4 yes  \n 5 no   \n 6 no   \n 7 yes  \n 8 no   \n 9 no   \n10 yes  \n# ℹ 256 more rows\n\n\n\n\n5.7.1 ConfusionMatrix\n\nCM   &lt;- caret::confusionMatrix(svm.po.pred, titanic.ted.Imp$Survived, \n                               positive = \"yes\")        # confusionMatrix(예측 class, 실제 class, positive=\"관심 class\")\nCM\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  no yes\n       no  152  32\n       yes  12  70\n                                          \n               Accuracy : 0.8346          \n                 95% CI : (0.7844, 0.8772)\n    No Information Rate : 0.6165          \n    P-Value [Acc &gt; NIR] : 7.118e-15       \n                                          \n                  Kappa : 0.6367          \n                                          \n Mcnemar's Test P-Value : 0.004179        \n                                          \n            Sensitivity : 0.6863          \n            Specificity : 0.9268          \n         Pos Pred Value : 0.8537          \n         Neg Pred Value : 0.8261          \n             Prevalence : 0.3835          \n         Detection Rate : 0.2632          \n   Detection Prevalence : 0.3083          \n      Balanced Accuracy : 0.8066          \n                                          \n       'Positive' Class : yes             \n                                          \n\n\n\n\n\n5.7.2 ROC 곡선\n\n# 예측 확률 생성\ntest.svm.prob &lt;- predict(svm.model.po, \n                         newdata = titanic.ted.Imp[,-1],    # Test Dataset including Only 예측 변수   \n                         probability = TRUE)                # 예측 확률 생성       \n\nattr(test.svm.prob, \"probabilities\") %&gt;%\n  as_tibble\n\n# A tibble: 266 × 2\n       no      yes\n    &lt;dbl&gt;    &lt;dbl&gt;\n 1 0.141  0.859   \n 2 0.805  0.195   \n 3 0.809  0.191   \n 4 0.276  0.724   \n 5 0.766  0.234   \n 6 0.878  0.122   \n 7 0.255  0.745   \n 8 0.999  0.000998\n 9 0.814  0.186   \n10 0.0195 0.980   \n# ℹ 256 more rows\n\n\n\ntest.svm.prob &lt;- attr(test.svm.prob, \"probabilities\")[,2]   # \"Survived = yes\"에 대한 예측 확률\n\nac  &lt;- titanic.ted.Imp$Survived                             # Test Dataset의 실제 class \npp  &lt;- as.numeric(test.svm.prob)                            # 예측 확률을 수치형으로 변환\n\n\n5.7.2.1 Package “pROC”\n\npacman::p_load(\"pROC\")\n\nsvm.roc  &lt;- roc(ac, pp, plot = T, col = \"gray\")             # roc(실제 class, 예측 확률)\nauc      &lt;- round(auc(svm.roc), 3)\nlegend(\"bottomright\", legend = auc, bty = \"n\")\n\n\n\n\n\n\n\n\nCaution! Package \"pROC\"를 통해 출력한 ROC 곡선은 다양한 함수를 이용해서 그래프를 수정할 수 있다.\n\n# 함수 plot.roc() 이용\nplot.roc(svm.roc,   \n         col=\"gray\",                                        # Line Color\n         print.auc = TRUE,                                  # AUC 출력 여부\n         print.auc.col = \"red\",                             # AUC 글씨 색깔\n         print.thres = TRUE,                                # Cutoff Value 출력 여부\n         print.thres.pch = 19,                              # Cutoff Value를 표시하는 도형 모양\n         print.thres.col = \"red\",                           # Cutoff Value를 표시하는 도형의 색깔\n         auc.polygon = TRUE,                                # 곡선 아래 면적에 대한 여부\n         auc.polygon.col = \"gray90\")                        # 곡선 아래 면적의 색깔\n\n\n\n\n\n\n\n\n\n# 함수 ggroc() 이용\nggroc(svm.roc) +\nannotate(geom = \"text\", x = 0.9, y = 1.0,\nlabel = paste(\"AUC = \", auc),\nsize = 5,\ncolor=\"red\") +\ntheme_bw()\n\n\n\n\n\n\n\n\n\n\n5.7.2.2 Package “Epi”\n\npacman::p_load(\"Epi\")       \n# install_version(\"etm\", version = \"1.1\", repos = \"http://cran.us.r-project.org\")\n\nROC(pp, ac, plot = \"ROC\")                                   # ROC(예측 확률, 실제 class)  \n\n\n\n\n\n\n\n\n\n\n5.7.2.3 Package “ROCR”\n\npacman::p_load(\"ROCR\")\n\nsvm.pred &lt;- prediction(pp, ac)                              # prediction(예측 확률, 실제 class)    \n\nsvm.perf &lt;- performance(svm.pred, \"tpr\", \"fpr\")             # performance(, \"민감도\", \"1-특이도\")                      \nplot(svm.perf, col = \"gray\")                                # ROC Curve\n\nperf.auc   &lt;- performance(svm.pred, \"auc\")                  # AUC\nauc        &lt;- attributes(perf.auc)$y.values \nlegend(\"bottomright\", legend = auc, bty = \"n\")\n\n\n\n\n\n\n\n\n\n\n\n\n5.7.3 향상 차트\n\n5.7.3.1 Package “ROCR”\n\nsvm.perf &lt;- performance(svm.pred, \"lift\", \"rpp\")            # Lift Chart\nplot(svm.perf, main = \"lift curve\", \n     colorize = T,                                          # Coloring according to cutoff\n     lwd = 2)",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Support Vector Machine with Polynomial Kernel</span>"
    ]
  },
  {
    "objectID": "SVM_rd.html",
    "href": "SVM_rd.html",
    "title": "6  Support Vector Machine with Radial Basis Kernel",
    "section": "",
    "text": "6.1 데이터 불러오기\npacman::p_load(\"data.table\", \"dplyr\", \"tidyr\",\n               \"caret\",\n               \"ggplot2\", \"GGally\",\n               \"e1071\")\n\ntitanic &lt;- fread(\"../Titanic.csv\")                                      # 데이터 불러오기\n\ntitanic %&gt;%\n  as_tibble\n# A tibble: 891 × 11\n   Survived Pclass Name                                                Sex      Age SibSp Parch Ticket            Fare Cabin  Embarked\n      &lt;int&gt;  &lt;int&gt; &lt;chr&gt;                                               &lt;chr&gt;  &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;   \n 1        0      3 Braund, Mr. Owen Harris                             male      22     1     0 A/5 21171         7.25 \"\"     S       \n 2        1      1 Cumings, Mrs. John Bradley (Florence Briggs Thayer) female    38     1     0 PC 17599         71.3  \"C85\"  C       \n 3        1      3 Heikkinen, Miss. Laina                              female    26     0     0 STON/O2. 3101282  7.92 \"\"     S       \n 4        1      1 Futrelle, Mrs. Jacques Heath (Lily May Peel)        female    35     1     0 113803           53.1  \"C123\" S       \n 5        0      3 Allen, Mr. William Henry                            male      35     0     0 373450            8.05 \"\"     S       \n 6        0      3 Moran, Mr. James                                    male      NA     0     0 330877            8.46 \"\"     Q       \n 7        0      1 McCarthy, Mr. Timothy J                             male      54     0     0 17463            51.9  \"E46\"  S       \n 8        0      3 Palsson, Master. Gosta Leonard                      male       2     3     1 349909           21.1  \"\"     S       \n 9        1      3 Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)   female    27     0     2 347742           11.1  \"\"     S       \n10        1      2 Nasser, Mrs. Nicholas (Adele Achem)                 female    14     1     0 237736           30.1  \"\"     C       \n# ℹ 881 more rows",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Support Vector Machine with Radial Basis Kernel</span>"
    ]
  },
  {
    "objectID": "SVM_rd.html#데이터-전처리-i",
    "href": "SVM_rd.html#데이터-전처리-i",
    "title": "6  Support Vector Machine with Radial Basis Kernel",
    "section": "6.2 데이터 전처리 I",
    "text": "6.2 데이터 전처리 I\n\ntitanic %&lt;&gt;%\n  data.frame() %&gt;%                                                      # Data Frame 형태로 변환 \n  mutate(Survived = ifelse(Survived == 1, \"yes\", \"no\"))                 # Target을 문자형 변수로 변환\n\n# 1. Convert to Factor\nfac.col &lt;- c(\"Pclass\", \"Sex\",\n             # Target\n             \"Survived\")\n\ntitanic &lt;- titanic %&gt;% \n  mutate_at(fac.col, as.factor)                                         # 범주형으로 변환\n\nglimpse(titanic)                                                        # 데이터 구조 확인\n\nRows: 891\nColumns: 11\n$ Survived &lt;fct&gt; no, yes, yes, yes, no, no, no, no, yes, yes, yes, yes, no, no, no, yes, no, yes, no, yes, no, yes, yes, yes, no, yes, no, no, yes, no, no, yes, yes, no, no, no, yes, no, no, yes, no…\n$ Pclass   &lt;fct&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3, 2, 2, 3, 1, 3, 3, 3, 1, 3, 3, 1, 1, 3, 2, 1, 1, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 1, 1, 2, 3, 2, 3, 3…\n$ Name     &lt;chr&gt; \"Braund, Mr. Owen Harris\", \"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\", \"Heikkinen, Miss. Laina\", \"Futrelle, Mrs. Jacques Heath (Lily May Peel)\", \"Allen, Mr. William Henry…\n$ Sex      &lt;fct&gt; male, female, female, female, male, male, male, male, female, female, female, female, male, male, female, female, male, male, female, female, male, male, female, male, female, femal…\n$ Age      &lt;dbl&gt; 22.0, 38.0, 26.0, 35.0, 35.0, NA, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, NA, 31.0, NA, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, NA, 19.0, NA, NA, 40.0, NA, NA, 66.…\n$ SibSp    &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0, 0, 0, 0, 0, 3, 1, 0, 3, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 1, 0, 0, 1, 0, 2, 1, 4, 0, 1, 1, 0, 0, 0, 0, 1, 5, 0…\n$ Parch    &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 5, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 2, 2, 0…\n$ Ticket   &lt;chr&gt; \"A/5 21171\", \"PC 17599\", \"STON/O2. 3101282\", \"113803\", \"373450\", \"330877\", \"17463\", \"349909\", \"347742\", \"237736\", \"PP 9549\", \"113783\", \"A/5. 2151\", \"347082\", \"350406\", \"248706\", \"38…\n$ Fare     &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625, 21.0750, 11.1333, 30.0708, 16.7000, 26.5500, 8.0500, 31.2750, 7.8542, 16.0000, 29.1250, 13.0000, 18.0000, 7.2250, 26.0000,…\n$ Cabin    &lt;chr&gt; \"\", \"C85\", \"\", \"C123\", \"\", \"\", \"E46\", \"\", \"\", \"\", \"G6\", \"C103\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"D56\", \"\", \"A6\", \"\", \"\", \"\", \"C23 C25 C27\", \"\", \"\", \"\", \"B78\", \"\", \"\", \"\", \"\", \"\"…\n$ Embarked &lt;chr&gt; \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"C\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"Q\", \"S\", \"C\", \"C\", \"Q\", \"S\", \"C\", \"S\", \"…\n\n# 2. Generate New Variable\ntitanic &lt;- titanic %&gt;%\n  mutate(FamSize = SibSp + Parch)                                       # \"FamSize = 형제 및 배우자 수 + 부모님 및 자녀 수\"로 가족 수를 의미하는 새로운 변수\n\nglimpse(titanic)                                                        # 데이터 구조 확인\n\nRows: 891\nColumns: 12\n$ Survived &lt;fct&gt; no, yes, yes, yes, no, no, no, no, yes, yes, yes, yes, no, no, no, yes, no, yes, no, yes, no, yes, yes, yes, no, yes, no, no, yes, no, no, yes, yes, no, no, no, yes, no, no, yes, no…\n$ Pclass   &lt;fct&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3, 2, 2, 3, 1, 3, 3, 3, 1, 3, 3, 1, 1, 3, 2, 1, 1, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 1, 1, 2, 3, 2, 3, 3…\n$ Name     &lt;chr&gt; \"Braund, Mr. Owen Harris\", \"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\", \"Heikkinen, Miss. Laina\", \"Futrelle, Mrs. Jacques Heath (Lily May Peel)\", \"Allen, Mr. William Henry…\n$ Sex      &lt;fct&gt; male, female, female, female, male, male, male, male, female, female, female, female, male, male, female, female, male, male, female, female, male, male, female, male, female, femal…\n$ Age      &lt;dbl&gt; 22.0, 38.0, 26.0, 35.0, 35.0, NA, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, NA, 31.0, NA, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, NA, 19.0, NA, NA, 40.0, NA, NA, 66.…\n$ SibSp    &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0, 0, 0, 0, 0, 3, 1, 0, 3, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 1, 0, 0, 1, 0, 2, 1, 4, 0, 1, 1, 0, 0, 0, 0, 1, 5, 0…\n$ Parch    &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 5, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 2, 2, 0…\n$ Ticket   &lt;chr&gt; \"A/5 21171\", \"PC 17599\", \"STON/O2. 3101282\", \"113803\", \"373450\", \"330877\", \"17463\", \"349909\", \"347742\", \"237736\", \"PP 9549\", \"113783\", \"A/5. 2151\", \"347082\", \"350406\", \"248706\", \"38…\n$ Fare     &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625, 21.0750, 11.1333, 30.0708, 16.7000, 26.5500, 8.0500, 31.2750, 7.8542, 16.0000, 29.1250, 13.0000, 18.0000, 7.2250, 26.0000,…\n$ Cabin    &lt;chr&gt; \"\", \"C85\", \"\", \"C123\", \"\", \"\", \"E46\", \"\", \"\", \"\", \"G6\", \"C103\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"D56\", \"\", \"A6\", \"\", \"\", \"\", \"C23 C25 C27\", \"\", \"\", \"\", \"B78\", \"\", \"\", \"\", \"\", \"\"…\n$ Embarked &lt;chr&gt; \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"C\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"Q\", \"S\", \"C\", \"C\", \"Q\", \"S\", \"C\", \"S\", \"…\n$ FamSize  &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 4, 2, 1, 2, 0, 0, 6, 0, 0, 5, 0, 1, 0, 0, 0, 0, 0, 4, 6, 0, 5, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 3, 0, 0, 1, 0, 2, 1, 5, 0, 1, 1, 1, 0, 0, 0, 3, 7, 0…\n\n# 3. Select Variables used for Analysis\ntitanic1 &lt;- titanic %&gt;% \n  select(Survived, Pclass, Sex, Age, Fare, FamSize)                     # 분석에 사용할 변수 선택\n\n# 4. Convert One-hot Encoding for 범주형 예측 변수\ndummies &lt;- dummyVars(formula = ~ .,                                     # formula : ~ 예측 변수 / \".\" : data에 포함된 모든 변수를 의미\n                     data = titanic1[,-1],                              # Dataset including Only 예측 변수 -&gt; Target 제외\n                     fullRank = FALSE)                                  # fullRank = TRUE : Dummy Variable, fullRank = FALSE : One-hot Encoding\n\ntitanic.Var   &lt;- predict(dummies, newdata = titanic1) %&gt;%               # 범주형 예측 변수에 대한 One-hot Encoding 변환\n  data.frame()                                                          # Data Frame 형태로 변환 \n\nglimpse(titanic.Var)                                                    # 데이터 구조 확인\n\nRows: 891\nColumns: 8\n$ Pclass.1   &lt;dbl&gt; 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,…\n$ Pclass.2   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,…\n$ Pclass.3   &lt;dbl&gt; 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1,…\n$ Sex.female &lt;dbl&gt; 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0,…\n$ Sex.male   &lt;dbl&gt; 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1,…\n$ Age        &lt;dbl&gt; 22.0, 38.0, 26.0, 35.0, 35.0, NA, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, NA, 31.0, NA, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, NA, 19.0, NA, NA, 40.0, NA, NA, 6…\n$ Fare       &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625, 21.0750, 11.1333, 30.0708, 16.7000, 26.5500, 8.0500, 31.2750, 7.8542, 16.0000, 29.1250, 13.0000, 18.0000, 7.2250, 26.000…\n$ FamSize    &lt;dbl&gt; 1, 1, 0, 1, 0, 0, 0, 4, 2, 1, 2, 0, 0, 6, 0, 0, 5, 0, 1, 0, 0, 0, 0, 0, 4, 6, 0, 5, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 3, 0, 0, 1, 0, 2, 1, 5, 0, 1, 1, 1, 0, 0, 0, 3, 7,…\n\n# Combine Target with 변환된 예측 변수\ntitanic.df &lt;- data.frame(Survived = titanic1$Survived, \n                         titanic.Var)\n\ntitanic.df %&gt;%\n  as_tibble\n\n# A tibble: 891 × 9\n   Survived Pclass.1 Pclass.2 Pclass.3 Sex.female Sex.male   Age  Fare FamSize\n   &lt;fct&gt;       &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n 1 no              0        0        1          0        1    22  7.25       1\n 2 yes             1        0        0          1        0    38 71.3        1\n 3 yes             0        0        1          1        0    26  7.92       0\n 4 yes             1        0        0          1        0    35 53.1        1\n 5 no              0        0        1          0        1    35  8.05       0\n 6 no              0        0        1          0        1    NA  8.46       0\n 7 no              1        0        0          0        1    54 51.9        0\n 8 no              0        0        1          0        1     2 21.1        4\n 9 yes             0        0        1          1        0    27 11.1        2\n10 yes             0        1        0          1        0    14 30.1        1\n# ℹ 881 more rows\n\nglimpse(titanic.df)                                                     # 데이터 구조 확인\n\nRows: 891\nColumns: 9\n$ Survived   &lt;fct&gt; no, yes, yes, yes, no, no, no, no, yes, yes, yes, yes, no, no, no, yes, no, yes, no, yes, no, yes, yes, yes, no, yes, no, no, yes, no, no, yes, yes, no, no, no, yes, no, no, yes, …\n$ Pclass.1   &lt;dbl&gt; 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,…\n$ Pclass.2   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,…\n$ Pclass.3   &lt;dbl&gt; 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1,…\n$ Sex.female &lt;dbl&gt; 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0,…\n$ Sex.male   &lt;dbl&gt; 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1,…\n$ Age        &lt;dbl&gt; 22.0, 38.0, 26.0, 35.0, 35.0, NA, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, NA, 31.0, NA, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, NA, 19.0, NA, NA, 40.0, NA, NA, 6…\n$ Fare       &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625, 21.0750, 11.1333, 30.0708, 16.7000, 26.5500, 8.0500, 31.2750, 7.8542, 16.0000, 29.1250, 13.0000, 18.0000, 7.2250, 26.000…\n$ FamSize    &lt;dbl&gt; 1, 1, 0, 1, 0, 0, 0, 4, 2, 1, 2, 0, 0, 6, 0, 0, 5, 0, 1, 0, 0, 0, 0, 0, 4, 6, 0, 5, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 3, 0, 0, 1, 0, 2, 1, 5, 0, 1, 1, 1, 0, 0, 0, 3, 7,…",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Support Vector Machine with Radial Basis Kernel</span>"
    ]
  },
  {
    "objectID": "SVM_rd.html#데이터-탐색",
    "href": "SVM_rd.html#데이터-탐색",
    "title": "6  Support Vector Machine with Radial Basis Kernel",
    "section": "6.3 데이터 탐색",
    "text": "6.3 데이터 탐색\n\nggpairs(titanic.df,                                        \n        aes(colour = Survived)) +                         # Target의 범주에 따라 색깔을 다르게 표현\n  theme_bw()\n\n\n\n\n\n\n\nggpairs(titanic.df,                                     \n        aes(colour = Survived, alpha = 0.8)) +            # Target의 범주에 따라 색깔을 다르게 표현\n  scale_colour_manual(values = c(\"purple\", \"cyan4\")) +    # 특정 색깔 지정\n  scale_fill_manual(values = c(\"purple\", \"cyan4\")) +      # 특정 색깔 지정\n  theme_bw()",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Support Vector Machine with Radial Basis Kernel</span>"
    ]
  },
  {
    "objectID": "SVM_rd.html#데이터-분할",
    "href": "SVM_rd.html#데이터-분할",
    "title": "6  Support Vector Machine with Radial Basis Kernel",
    "section": "6.4 데이터 분할",
    "text": "6.4 데이터 분할\n\n# Partition (Training Dataset : Test Dataset = 7:3)\ny      &lt;- titanic.df$Survived                           # Target\n\nset.seed(200)\nind    &lt;- createDataPartition(y, p = 0.7, list  =T)     # Index를 이용하여 7:3으로 분할\ntitanic.trd &lt;- titanic.df[ind$Resample1,]               # Training Dataset\ntitanic.ted &lt;- titanic.df[-ind$Resample1,]              # Test Dataset",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Support Vector Machine with Radial Basis Kernel</span>"
    ]
  },
  {
    "objectID": "SVM_rd.html#데이터-전처리-ii",
    "href": "SVM_rd.html#데이터-전처리-ii",
    "title": "6  Support Vector Machine with Radial Basis Kernel",
    "section": "6.5 데이터 전처리 II",
    "text": "6.5 데이터 전처리 II\n\n# 1. Imputation\ntitanic.trd.Imp &lt;- titanic.trd %&gt;% \n  mutate(Age = replace_na(Age, mean(Age, na.rm = TRUE)))                 # 평균으로 결측값 대체\n\ntitanic.ted.Imp &lt;- titanic.ted %&gt;% \n  mutate(Age = replace_na(Age, mean(titanic.trd$Age, na.rm = TRUE)))     # Training Dataset을 이용하여 결측값 대체\n\n# 2. Standardization\npreProcValues &lt;- preProcess(titanic.trd.Imp, \n                            method = c(\"center\", \"scale\"))               # Standardization 정의 -&gt; Training Dataset에 대한 평균과 표준편차 계산 \n\ntitanic.trd.Imp &lt;- predict(preProcValues, titanic.trd.Imp)               # Standardization for Training Dataset\ntitanic.ted.Imp &lt;- predict(preProcValues, titanic.ted.Imp)               # Standardization for Test Dataset\n\nglimpse(titanic.trd.Imp)                                                 # 데이터 구조 확인\n\nRows: 625\nColumns: 9\n$ Survived   &lt;fct&gt; no, yes, yes, no, no, no, yes, yes, yes, yes, no, no, yes, no, yes, no, yes, no, no, no, yes, no, no, yes, yes, no, no, no, no, no, yes, no, no, no, yes, no, yes, no, no, no, yes,…\n$ Pclass.1   &lt;dbl&gt; -0.593506, -0.593506, 1.682207, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, 1.682207, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, 1.682…\n$ Pclass.2   &lt;dbl&gt; -0.4694145, -0.4694145, -0.4694145, -0.4694145, -0.4694145, -0.4694145, -0.4694145, 2.1269048, -0.4694145, -0.4694145, -0.4694145, -0.4694145, 2.1269048, -0.4694145, -0.4694145, 2…\n$ Pclass.3   &lt;dbl&gt; 0.888575, 0.888575, -1.123597, 0.888575, 0.888575, 0.888575, 0.888575, -1.123597, 0.888575, -1.123597, 0.888575, 0.888575, -1.123597, 0.888575, 0.888575, -1.123597, -1.123597, 0.8…\n$ Sex.female &lt;dbl&gt; -0.7572241, 1.3184999, 1.3184999, -0.7572241, -0.7572241, -0.7572241, 1.3184999, 1.3184999, 1.3184999, 1.3184999, -0.7572241, 1.3184999, -0.7572241, 1.3184999, 1.3184999, -0.75722…\n$ Sex.male   &lt;dbl&gt; 0.7572241, -1.3184999, -1.3184999, 0.7572241, 0.7572241, 0.7572241, -1.3184999, -1.3184999, -1.3184999, -1.3184999, 0.7572241, -1.3184999, 0.7572241, -1.3184999, -1.3184999, 0.757…\n$ Age        &lt;dbl&gt; -0.61306970, -0.30411628, 0.39102893, 0.39102893, 0.00000000, -2.15783684, -0.22687792, -1.23097656, -2.00336012, 2.16751113, 0.69998236, -1.23097656, 0.00000000, 0.08207551, 0.00…\n$ Fare       &lt;dbl&gt; -0.51776394, -0.50463325, 0.37414970, -0.50220165, -0.49425904, -0.24882814, -0.44222264, -0.07383411, -0.33393441, -0.14232374, -0.05040897, -0.50601052, -0.40590999, -0.30864569…\n$ FamSize    &lt;dbl&gt; 0.04506631, -0.55421976, 0.04506631, -0.55421976, -0.55421976, 1.84292454, 0.64435239, 0.04506631, 0.64435239, -0.55421976, 3.04149669, -0.55421976, -0.55421976, 0.04506631, -0.55…\n\nglimpse(titanic.ted.Imp)                                                 # 데이터 구조 확인\n\nRows: 266\nColumns: 9\n$ Survived   &lt;fct&gt; yes, no, no, yes, no, yes, yes, yes, yes, yes, no, no, yes, yes, no, yes, no, yes, yes, no, yes, no, no, no, no, no, no, yes, yes, no, no, no, no, no, no, no, no, no, no, yes, no,…\n$ Pclass.1   &lt;dbl&gt; 1.682207, 1.682207, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, -0.593506, 1.682…\n$ Pclass.2   &lt;dbl&gt; -0.4694145, -0.4694145, -0.4694145, 2.1269048, -0.4694145, 2.1269048, -0.4694145, -0.4694145, -0.4694145, 2.1269048, -0.4694145, -0.4694145, 2.1269048, 2.1269048, -0.4694145, 2.12…\n$ Pclass.3   &lt;dbl&gt; -1.123597, -1.123597, 0.888575, -1.123597, 0.888575, -1.123597, 0.888575, 0.888575, 0.888575, -1.123597, 0.888575, 0.888575, -1.123597, -1.123597, 0.888575, -1.123597, -1.123597, …\n$ Sex.female &lt;dbl&gt; 1.3184999, -0.7572241, -0.7572241, 1.3184999, -0.7572241, -0.7572241, 1.3184999, 1.3184999, -0.7572241, 1.3184999, -0.7572241, -0.7572241, 1.3184999, 1.3184999, -0.7572241, 1.3184…\n$ Sex.male   &lt;dbl&gt; -1.3184999, 0.7572241, 0.7572241, -1.3184999, 0.7572241, 0.7572241, -1.3184999, -1.3184999, 0.7572241, -1.3184999, 0.7572241, 0.7572241, -1.3184999, -1.3184999, 0.7572241, -1.3184…\n$ Age        &lt;dbl&gt; 0.62274400, 1.85855771, -0.76754642, 1.93579607, -2.15783684, 0.31379058, -1.15373820, 0.62274400, 0.00000000, -2.08059848, 0.00000000, -0.69030806, -0.07240121, -0.69030806, -0.1…\n$ Fare       &lt;dbl&gt; 0.727866891, 0.350076786, -0.502201647, -0.347551409, -0.092232621, -0.405909990, -0.502606266, -0.048220525, -0.518168555, 0.150037190, -0.502201647, -0.507064862, -0.153022808, …\n$ FamSize    &lt;dbl&gt; 0.04506631, -0.55421976, -0.55421976, -0.55421976, 2.44221062, -0.55421976, -0.55421976, 3.04149669, -0.55421976, 1.24363847, -0.55421976, -0.55421976, 0.04506631, -0.55421976, -0…",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Support Vector Machine with Radial Basis Kernel</span>"
    ]
  },
  {
    "objectID": "SVM_rd.html#모형-훈련",
    "href": "SVM_rd.html#모형-훈련",
    "title": "6  Support Vector Machine with Radial Basis Kernel",
    "section": "6.6 모형 훈련",
    "text": "6.6 모형 훈련\nPackage \"e1071\"는 Support Vector Machine을 효율적으로 구현할 수 있는 “libsvm”을 R에서 사용할 수 있도록 만든 Package이며, 함수 svm()을 이용하여 Support Vector Machine을 수행할 수 있다. 함수에서 사용할 수 있는 자세한 옵션은 여기를 참고한다.\n\nsvm(formula, data, kernel, cost, gamma, probability, ...)\n\n\nformula : Target과 예측 변수의 관계를 표현하기 위한 함수로써 일반적으로 Target ~ 예측 변수의 형태로 표현한다.\ndata : formula에 포함하고 있는 변수들의 데이터셋(Data Frame)\nkernel : Kernel 함수\n\n\"linear\" : \\(k(\\boldsymbol{x}, \\boldsymbol{x}') = \\boldsymbol{x}\\boldsymbol{x}'\\)\n\"polynomial\" : \\(k(\\boldsymbol{x}, \\boldsymbol{x}') = (\\gamma \\boldsymbol{x}\\boldsymbol{x}' + \\text{coef0})^{\\text{degree}}\\)\n\"radial\" : \\(k(\\boldsymbol{x}, \\boldsymbol{x}') = \\exp\\left(-\\gamma||\\boldsymbol{x}-\\boldsymbol{x}'||^2 \\right)\\)\n\"sigmoid\" : \\(k(\\boldsymbol{x}, \\boldsymbol{x}') = tanh(\\gamma \\boldsymbol{x}\\boldsymbol{x}' + \\text{coef0})\\)\n\ncost : 데이터를 잘못 분류하는 선을 그을 경우 지불해야 할 cost\ngamma : 개별 case가 결정경계의 위치에 미치는 영향\nprobability : Test Dataset에 대한 예측 확률의 생성 여부\n\nTRUE : 함수 predict()를 이용하여 Test Dataset에 대한 예측 확률을 생성할 수 있다.\n\n\n\nsvm.model.rd &lt;- svm(Survived ~.,     \n                    data = titanic.trd.Imp,  \n                    kernel = \"radial\", \n                    cost = 1,              \n                    gamma = 2,\n                    probability = TRUE)\n\nsummary(svm.model.rd)\n\n\nCall:\nsvm(formula = Survived ~ ., data = titanic.trd.Imp, kernel = \"radial\", cost = 1, gamma = 2, probability = TRUE)\n\n\nParameters:\n   SVM-Type:  C-classification \n SVM-Kernel:  radial \n       cost:  1 \n\nNumber of Support Vectors:  376\n\n ( 189 187 )\n\n\nNumber of Classes:  2 \n\nLevels: \n no yes\n\n\nResult! Number of Support Vectors는 결정경계와 가까이 위치한 case의 수이다. 해당 데이터에서는 총 376개의 case로, \"Survived = no\"에 해당하는 case는 189개, \"Survived = yes\"에 해당하는 case는 187개이다. case의 행 번호는 svm.model.rd$index를 이용하여 확인할 수 있다.\n\n# Support Vector Index\nsvm.model.rd$index   \n\n  [1]   6  11  12  14  16  18  19  20  23  26  27  28  30  32  33  38  39  42  44  48  50  59  66  67  70  71  77  79  80  83  85  94  95  98 100 102 103 104 106 114 120 122 129 133 135 137 140 143\n [49] 156 161 162 168 169 170 173 176 181 182 183 184 190 192 193 202 203 205 209 214 216 225 229 232 234 243 244 246 250 252 259 261 264 270 271 277 281 282 287 288 293 298 306 307 309 314 315 322\n [97] 325 330 340 341 344 347 348 349 351 354 359 361 367 368 369 371 373 376 379 383 384 395 397 401 405 408 416 418 420 429 430 436 442 444 450 451 464 465 466 470 478 479 488 489 490 493 499 505\n[145] 513 514 516 517 521 525 538 539 540 543 544 550 551 552 554 556 557 558 562 563 568 570 573 574 575 577 579 580 581 593 594 596 597 598 599 604 605 606 607 610 613 620 621 622 625   2   7   8\n[193]   9  10  13  15  17  24  25  31  35  37  41  43  46  52  56  57  58  60  61  73  74  86  87  88  96  97  99 107 110 123 124 125 131 134 139 142 147 155 163 165 171 172 179 180 185 186 187 188\n[241] 189 191 195 197 198 199 200 206 207 208 212 213 219 220 226 227 228 233 236 239 241 256 258 263 265 268 275 276 278 279 284 290 300 302 303 304 308 312 313 316 317 318 320 326 332 334 335 350\n[289] 352 353 355 357 374 375 378 381 382 386 388 391 399 400 406 411 419 421 422 424 426 428 431 434 437 439 440 445 446 455 456 457 459 461 463 468 473 474 475 477 480 484 485 486 487 491 492 496\n[337] 497 498 500 503 504 507 509 511 518 522 524 527 530 535 536 537 546 547 548 553 561 565 566 576 578 582 583 584 587 589 590 600 601 602 603 609 612 617 618 624",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Support Vector Machine with Radial Basis Kernel</span>"
    ]
  },
  {
    "objectID": "SVM_rd.html#모형-평가",
    "href": "SVM_rd.html#모형-평가",
    "title": "6  Support Vector Machine with Radial Basis Kernel",
    "section": "6.7 모형 평가",
    "text": "6.7 모형 평가\nCaution! 모형 평가를 위해 Test Dataset에 대한 예측 class/확률 이 필요하며, 함수 predict()를 이용하여 생성한다.\n\n# 예측 class 생성 \nsvm.rd.pred &lt;- predict(svm.model.rd,\n                       newdata = titanic.ted.Imp[,-1],  # Test Dataset including Only 예측 변수   \n                       type = \"class\")                  # 예측 class 생성      \n\nsvm.rd.pred %&gt;%\n  as_tibble\n\n# A tibble: 266 × 1\n   value\n   &lt;fct&gt;\n 1 yes  \n 2 no   \n 3 no   \n 4 no   \n 5 no   \n 6 no   \n 7 yes  \n 8 no   \n 9 no   \n10 yes  \n# ℹ 256 more rows\n\n\n\n\n6.7.1 ConfusionMatrix\n\nCM   &lt;- caret::confusionMatrix(svm.rd.pred, titanic.ted.Imp$Survived, \n                               positive = \"yes\")        # confusionMatrix(예측 class, 실제 class, positive=\"관심 class\")\nCM\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  no yes\n       no  155  30\n       yes   9  72\n                                          \n               Accuracy : 0.8534          \n                 95% CI : (0.8051, 0.8936)\n    No Information Rate : 0.6165          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.6774          \n                                          \n Mcnemar's Test P-Value : 0.001362        \n                                          \n            Sensitivity : 0.7059          \n            Specificity : 0.9451          \n         Pos Pred Value : 0.8889          \n         Neg Pred Value : 0.8378          \n             Prevalence : 0.3835          \n         Detection Rate : 0.2707          \n   Detection Prevalence : 0.3045          \n      Balanced Accuracy : 0.8255          \n                                          \n       'Positive' Class : yes             \n                                          \n\n\n\n\n\n6.7.2 ROC 곡선\n\n# 예측 확률 생성\ntest.svm.prob &lt;- predict(svm.model.rd, \n                         newdata = titanic.ted.Imp[,-1],    # Test Dataset including Only 예측 변수  \n                         probability = TRUE)                # 예측 확률 생성        \n\nattr(test.svm.prob, \"probabilities\") %&gt;%\n  as_tibble\n\n# A tibble: 266 × 2\n      no   yes\n   &lt;dbl&gt; &lt;dbl&gt;\n 1 0.153 0.847\n 2 0.833 0.167\n 3 0.852 0.148\n 4 0.615 0.385\n 5 0.852 0.148\n 6 0.850 0.150\n 7 0.228 0.772\n 8 0.840 0.160\n 9 0.848 0.152\n10 0.179 0.821\n# ℹ 256 more rows\n\n\n\ntest.svm.prob &lt;- attr(test.svm.prob, \"probabilities\")[,2]   # \"Survived = yes\"에 대한 예측 확률\n\nac  &lt;- titanic.ted.Imp$Survived                             # Test Dataset의 실제 class \npp  &lt;- as.numeric(test.svm.prob)                            # 예측 확률을 수치형으로 변환\n\n\n6.7.2.1 Package “pROC”\n\npacman::p_load(\"pROC\")\n\nsvm.roc  &lt;- roc(ac, pp, plot = T, col = \"gray\")             # roc(실제 class, 예측 확률)\nauc      &lt;- round(auc(svm.roc), 3)\nlegend(\"bottomright\", legend = auc, bty = \"n\")\n\n\n\n\n\n\n\n\nCaution! Package \"pROC\"를 통해 출력한 ROC 곡선은 다양한 함수를 이용해서 그래프를 수정할 수 있다.\n\n# 함수 plot.roc() 이용\nplot.roc(svm.roc,   \n         col=\"gray\",                                        # Line Color\n         print.auc = TRUE,                                  # AUC 출력 여부\n         print.auc.col = \"red\",                             # AUC 글씨 색깔\n         print.thres = TRUE,                                # Cutoff Value 출력 여부\n         print.thres.pch = 19,                              # Cutoff Value를 표시하는 도형 모양\n         print.thres.col = \"red\",                           # Cutoff Value를 표시하는 도형의 색깔\n         auc.polygon = TRUE,                                # 곡선 아래 면적에 대한 여부\n         auc.polygon.col = \"gray90\")                        # 곡선 아래 면적의 색깔\n\n\n\n\n\n\n\n\n\n# 함수 ggroc() 이용\nggroc(svm.roc) +\nannotate(geom = \"text\", x = 0.9, y = 1.0,\nlabel = paste(\"AUC = \", auc),\nsize = 5,\ncolor=\"red\") +\ntheme_bw()\n\n\n\n\n\n\n\n\n\n\n6.7.2.2 Package “Epi”\n\npacman::p_load(\"Epi\")       \n# install_version(\"etm\", version = \"1.1\", repos = \"http://cran.us.r-project.org\")\n\nROC(pp, ac, plot = \"ROC\")                                   # ROC(예측 확률, 실제 class)  \n\n\n\n\n\n\n\n\n\n\n6.7.2.3 Package “ROCR”\n\npacman::p_load(\"ROCR\")\n\nsvm.pred &lt;- prediction(pp, ac)                              # prediction(예측 확률, 실제 class)    \n\nsvm.perf &lt;- performance(svm.pred, \"tpr\", \"fpr\")             # performance(, \"민감도\", \"1-특이도\")                      \nplot(svm.perf, col = \"gray\")                                # ROC Curve\n\nperf.auc   &lt;- performance(svm.pred, \"auc\")                  # AUC\nauc        &lt;- attributes(perf.auc)$y.values \nlegend(\"bottomright\", legend = auc, bty = \"n\")\n\n\n\n\n\n\n\n\n\n\n\n\n6.7.3 향상 차트\n\n6.7.3.1 Package “ROCR”\n\nsvm.perf &lt;- performance(svm.pred, \"lift\", \"rpp\")            # Lift Chart\nplot(svm.perf, main = \"lift curve\", \n     colorize = T,                                          # Coloring according to cutoff\n     lwd = 2)",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Support Vector Machine with Radial Basis Kernel</span>"
    ]
  },
  {
    "objectID": "Clustering.html",
    "href": "Clustering.html",
    "title": "7  Cluster Analysis based on k-means",
    "section": "",
    "text": "7.1 데이터 불러오기\npacman::p_load(\"data.table\", \n               \"tidyverse\", \n               \"dplyr\",\n               \"caret\",\n               \"GGally\",                                       # For ggpairs\n               \"factoextra\",                                   # For fviz_dend, fviz_nbclust\n               \"NbClust\")                                      # For NbClust\n\n\nprotein &lt;- fread(\".../protein.csv\")                            # 데이터 불러오기\n\nprotein %&gt;%\n  as_tibble\n# A tibble: 25 × 10\n   country           x1    x2    x3    x4    x5    x6    x7    x8    x9\n   &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 Albania         10.1   1.4   0.5   8.9   0.2  42.3   0.6   5.5   1.7\n 2 Austria          8.9  14     4.3  19.9   2.1  28     3.6   1.3   4.3\n 3 Belgium         13.5   9.3   4.1  17.5   4.5  26.6   5.7   2.1   4  \n 4 Bulgaria         7.8   6     1.6   8.3   1.2  56.7   1.1   3.7   4.2\n 5 Czechoslovakia   9.7  11.4   2.8  12.5   2    34.3   5     1.1   4  \n 6 Denmark         10.6  10.8   3.7  25     9.9  21.9   4.8   0.7   2.4\n 7 E Germany        8.4  11.6   3.7  11.1   5.4  24.6   6.5   0.8   3.6\n 8 Finland          9.5   4.9   2.7  33.7   5.8  26.3   5.1   1     1.4\n 9 France          18     9.9   3.3  19.5   5.7  28.1   4.8   2.4   6.5\n10 Greece          10.2   3     2.8  17.6   5.9  41.7   2.2   7.8   6.5\n# ℹ 15 more rows",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Cluster Analysis based on k-means</span>"
    ]
  },
  {
    "objectID": "Clustering.html#데이터-전처리-i",
    "href": "Clustering.html#데이터-전처리-i",
    "title": "7  Cluster Analysis based on k-means",
    "section": "7.2 데이터 전처리 I",
    "text": "7.2 데이터 전처리 I\n\nprotein.df &lt;- protein %&gt;%\n  data.frame %&gt;%                                            # Data Frame 형태로 변환\n  select(-country)                                          # 변수 \"country\" 제거\n\nrownames(protein.df) &lt;- protein$country                     # 행 이름 변경\n\nprotein.df %&gt;%\n  head()                                                    # 처음 6개 case 확인\n\n                 x1   x2  x3   x4  x5   x6  x7  x8  x9\nAlbania        10.1  1.4 0.5  8.9 0.2 42.3 0.6 5.5 1.7\nAustria         8.9 14.0 4.3 19.9 2.1 28.0 3.6 1.3 4.3\nBelgium        13.5  9.3 4.1 17.5 4.5 26.6 5.7 2.1 4.0\nBulgaria        7.8  6.0 1.6  8.3 1.2 56.7 1.1 3.7 4.2\nCzechoslovakia  9.7 11.4 2.8 12.5 2.0 34.3 5.0 1.1 4.0\nDenmark        10.6 10.8 3.7 25.0 9.9 21.9 4.8 0.7 2.4",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Cluster Analysis based on k-means</span>"
    ]
  },
  {
    "objectID": "Clustering.html#데이터-탐색",
    "href": "Clustering.html#데이터-탐색",
    "title": "7  Cluster Analysis based on k-means",
    "section": "7.3 데이터 탐색",
    "text": "7.3 데이터 탐색\n\nggpairs(protein.df,\n        upper = list(continuous = \"density\"),\n        lower = list(continuous = wrap(\"points\", size = 0.5)),\n        diag = list(continuous = \"densityDiag\")) +\n  theme_bw()\n\n\n\n\n\n\n\n\n\n# 상관계수 그래프\nggcorr(protein.df,              # 데이터\n       label = TRUE,            # 라벨 명시 여부\n       label_round = 3,         # 상관계수 소숫점 이하 자릿수\n       label_size = 3,          # 상관계수 글자 크기\n       low = \"steelblue\",       # 상관계수가 음수일 때 색깔\n       mid = \"white\",           # 상관계수가 0에 가까울 때 색깔\n       high = \"darkred\")        # 상관계수가 양수일 때 색깔",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Cluster Analysis based on k-means</span>"
    ]
  },
  {
    "objectID": "Clustering.html#데이터-분할",
    "href": "Clustering.html#데이터-분할",
    "title": "7  Cluster Analysis based on k-means",
    "section": "7.4 데이터 분할",
    "text": "7.4 데이터 분할\n\n# Partition (Training Dataset : Test Dataset = 7:3)\nset.seed(200)\nind &lt;- sample(1:nrow(protein.df), 0.7*nrow(protein.df))     # Index를 이용하여 7:3로 분할\n\nprotein.trd &lt;- protein.df[ind,]                             # Training Dataset\nprotein.ted &lt;- protein.df[-ind,]                            # Test Dataset",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Cluster Analysis based on k-means</span>"
    ]
  },
  {
    "objectID": "Clustering.html#데이터-전처리-ii",
    "href": "Clustering.html#데이터-전처리-ii",
    "title": "7  Cluster Analysis based on k-means",
    "section": "7.5 데이터 전처리 II",
    "text": "7.5 데이터 전처리 II\n\n# Standardization\npreProcValues &lt;- preProcess(protein.trd,\n                            method = c(\"center\", \"scale\"))  # Standardization 정의 -&gt; Training Dataset에 대한 평균과 표준편차 계산 \n\nprotein.trd &lt;- predict(preProcValues, protein.trd)          # Standardization for Training Dataset\nprotein.ted &lt;- predict(preProcValues, protein.ted)          # Standardization for Test Dataset\n\nglimpse(protein.trd)                                        # 데이터 구조 확인\n\nRows: 17\nColumns: 9\n$ x1 &lt;dbl&gt; 0.18081182, -1.21348962, -0.19945221, -0.16776354, 1.22653789, 0.43432117, 0.97302854, 2.33564131, -0.70647091, -0.23114088, -1.78388566, -0.32620689, -0.99166894, -0.51633890, -0.1677635…\n$ x2 &lt;dbl&gt; 0.8964725, -0.4696659, -0.9554040, -0.8946867, 0.6536035, 1.4125693, 0.6839621, -0.6518177, -0.5607418, -0.9857626, -0.8643281, -0.8339695, 0.7143207, 1.1393416, 1.7465142, 0.4410931, -1.…\n$ x3 &lt;dbl&gt; 0.60866213, -1.46078912, -0.33199753, -0.33199753, 1.54932180, 0.98492600, 0.04426634, 1.54932180, -1.36672316, -0.89639332, -1.74298702, -0.14386560, -0.33199753, 0.60866213, 0.51459617,…\n$ x4 &lt;dbl&gt; 0.923106753, -1.136667805, 0.671191879, 2.212318167, 1.041654929, 0.004358389, 0.745284489, 0.271091785, -1.551586421, -0.321649095, -1.373764157, -0.751386233, 0.078450999, -1.136667805,…\n$ x5 &lt;dbl&gt; 2.1894978, -1.1166002, 2.1152035, 0.6664639, -0.6708342, -0.2250681, -0.6336870, 0.1092564, -1.0423058, -0.3736568, -1.2651889, -0.2250681, -0.3736568, 0.5178752, -0.5593927, 0.1835507, 0…\n$ x6 &lt;dbl&gt; -0.8752919, 1.3478740, -0.7870074, -0.5221537, -0.7067487, -1.1401456, -0.5783347, -0.6826711, 1.9177108, 0.8663218, 1.8535038, 0.3205627, 0.2643816, -0.6585934, -0.8351626, -0.4980760, 0…\n$ x7 &lt;dbl&gt; 0.28314770, -0.73972337, 0.16280993, 0.46365436, 1.12551212, 0.52382325, -0.92023003, 0.22297882, -1.94310111, 1.24584989, -0.79989226, -1.34141224, 0.94500546, 1.30601878, -0.07786562, 0…\n$ x8 &lt;dbl&gt; -1.1132630, 1.2269834, -0.6553887, -0.9606382, -0.6553887, -0.7062636, -0.2483893, 0.2603599, 0.4129847, 0.2603599, 1.4304831, 0.7182342, -0.4518890, -1.0623881, -0.5536389, -0.4010141, 2…\n$ x9 &lt;dbl&gt; -0.95800750, -0.69532803, -0.76099790, -1.61470619, -0.62965816, -0.03862933, 0.68373923, -0.36697868, 0.22405014, -0.62965816, -0.43264855, 1.86579687, 1.80012700, -0.16996907, -0.104299…\n\nglimpse(protein.ted)                                        # 데이터 구조 확인\n\nRows: 8\nColumns: 9\n$ x1 &lt;dbl&gt; 0.02236847, -0.35789556, -0.10438620, 2.52577332, -1.49868764, -1.21348962, -0.92829160, -0.04100887\n$ x2 &lt;dbl&gt; -1.95723882, 1.86794873, 1.07862431, 0.62324484, 1.38221063, -1.25899030, -1.35006619, -0.01428641\n$ x3 &lt;dbl&gt; -2.40144878, 1.17305793, -0.23793156, 0.23239827, -0.14386560, -1.83705299, 0.04426634, 0.42053020\n$ x4 &lt;dbl&gt; -1.4626753, 0.1673621, -0.9292085, 0.1080880, -1.3441271, -2.0554162, -1.5071309, -2.0850532\n$ x5 &lt;dbl&gt; -1.4137775, -0.7079813, -0.7451285, 0.6293167, -1.3766304, 3.7868261, 1.1122299, 1.2979658\n$ x6 &lt;dbl&gt; 0.7619855, -0.3857139, 0.1199159, -0.3776880, 0.5854164, -0.4659726, -0.2894034, -1.0679128\n$ x7 &lt;dbl&gt; -2.2439455, -0.4388789, 0.4034855, 0.2831477, -0.1982034, 0.9450055, 0.8246677, -0.3787101\n$ x8 &lt;dbl&gt; 1.3287333, -0.8080135, -0.9097633, -0.2483893, 1.2778583, 0.9217339, 1.5322329, -0.7571385\n$ x9 &lt;dbl&gt; -1.4176966, 0.2897200, 0.0927104, 1.7344571, 0.2240501, 2.6538353, 2.1941462, -1.2206870",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Cluster Analysis based on k-means</span>"
    ]
  },
  {
    "objectID": "Clustering.html#계층적-군집분석",
    "href": "Clustering.html#계층적-군집분석",
    "title": "7  Cluster Analysis based on k-means",
    "section": "7.6 계층적 군집분석",
    "text": "7.6 계층적 군집분석\n\n계층적 군집분석은 거리가 가까운 군집을 하나씩 묶어가면서 군집을 형성하는 방법이다.\n\n예를 들어, \\(n\\)개의 case가 있을 때 거리가 가장 가까운 두 개의 case를 묶어서 하나의 군집을 형성하고, 나머지 \\(n-2\\)개의 case는 각각이 하나의 군집을 이루도록 한다.\n그리고나서, \\(n-1\\)개의 군집 중에서 거리가 가장 가까운 두 개의 군집을 묶어 \\(n-2\\)개의 군집을 형성한다.\n이와 같은 과정은 최종적으로 \\(n\\)개의 case를 모두 묶어 하나의 군집을 형성할 때까지 반복한다.\n\n\n\n\n\n\n\n계층적 군집분석은 덴드로그램(Dendrogram)을 이용하여 시각적으로 군집 형성 과정을 볼 수 있으며, 이것은 전체 군집들 간의 구조적 관계를 살펴보는데 매우 유용하다.\n계층적 군집분석은 case의 개수가 비교적 작을 때 유용하다.\n\ncase의 개수가 많으면 거리행렬을 계산하는 데 매우 많은 시간과 컴퓨터 용량이 필요하므로 적용에 제약이 따른다.\n\n계층적 군집분석은 군집 간의 case 이동이 불가능하다는 단점이 있다.\n\n\n7.6.1 거리행렬 계산\n\n계층적 군집분석을 수행하기 전에 case 간의 거리를 계산하여 거리행렬을 생성한다.\n거리행렬을 생성하기 위해 함수 dist()를 이용하며, 거리를 계산하는 방법은 옵션 method에 지정할 수 있다.\n\n함수 dist()의 자세한 옵션은 여기를 참고한다.\n\n\n\nprotein.X.eucl &lt;- dist(protein.trd,                       \n                       method = \"euclidean\")                # 유클리드 거리 \nprotein.X.eucl\n\n             Denmark  Romania   Norway  Finland  Ireland W Germany Switzerland       UK Bulgaria     USSR Yugoslavia    Italy   Poland E Germany Netherlands  Belgium\nRomania     5.899193                                                                                                                                                 \nNorway      2.190572 5.017093                                                                                                                                        \nFinland     2.967850 5.245898 2.336933                                                                                                                               \nIreland     3.359817 5.698092 4.124494 3.546137                                                                                                                      \nW Germany   2.878437 5.127560 3.800557 4.003049 1.923184                                                                                                             \nSwitzerland 3.738040 4.469147 3.903220 3.935243 2.917500  2.356744                                                                                                   \nUK          3.867136 5.591679 3.905187 4.132260 2.420596  3.117714    3.060014                                                                                       \nBulgaria    6.313897 1.931986 5.500563 5.964271 6.225093  5.529229    4.441702 5.851565                                                                              \nUSSR        4.477896 2.806990 3.501849 3.582533 4.008542  3.961498    3.884788 4.096414 3.822901                                                                     \nYugoslavia  6.713206 1.004357 5.698797 5.962378 6.560893  5.996864    5.298535 6.426629 2.062393 3.407616                                                            \nItaly       5.277250 3.439932 4.454559 5.342612 5.114655  4.328910    3.122747 4.448760 2.953685 3.772778   3.819090                                                 \nPoland      4.399724 4.220409 4.275439 4.655450 4.049754  3.143036    3.160984 4.834137 4.493170 3.288055   4.702444 3.192257                                        \nE Germany   3.049396 4.874142 3.609905 4.382604 3.275421  1.990398    3.737112 4.163853 5.381543 3.551288   5.605003 4.525418 2.966305                               \nNetherlands 3.104750 4.718412 3.958992 3.789881 2.469626  1.324503    2.037250 3.815009 5.147099 4.011981   5.573208 4.210302 2.959231  2.681627                     \nBelgium     2.915357 4.886542 3.340291 3.805354 1.828405  1.484545    2.433729 2.074059 5.228214 3.266973   5.724063 3.895649 3.174653  2.239657    2.416333         \nGreece      5.917754 4.069820 4.853851 5.817338 5.983267  5.564533    4.319030 4.823118 4.018591 4.352319   4.324015 2.258867 4.579691  5.805825    5.463629 4.850338\n\nprotein.X.manh &lt;- dist(protein.trd,                       \n                       method = \"manhattan\")                # 맨해튼 거리\nprotein.X.manh\n\n              Denmark   Romania    Norway   Finland   Ireland W Germany Switzerland        UK  Bulgaria      USSR Yugoslavia     Italy    Poland E Germany Netherlands   Belgium\nRomania     16.044727                                                                                                                                                           \nNorway       4.362516 12.653687                                                                                                                                                 \nFinland      7.235608 13.911994  4.806928                                                                                                                                       \nIreland      7.005266 15.065397  9.247118  9.468623                                                                                                                             \nW Germany    6.311091 14.349831  8.813170  9.834368  5.275630                                                                                                                   \nSwitzerland  8.577085 12.171223  9.154543 10.313649  6.016994  6.543626                                                                                                         \nUK           9.593477 13.663230  8.600319  9.995946  6.070217  7.184453    8.227596                                                                                             \nBulgaria    17.753936  4.687965 14.180745 15.439051 16.643266 14.745643   11.680662 14.533589                                                                                   \nUSSR        12.013442  7.120222  7.891602  8.669654  9.812398  9.705856   10.574401  9.256640  8.515940                                                                         \nYugoslavia  18.709646  2.664919 14.529282 15.787588 17.598976 16.489391   14.190445 15.438486  5.039583  8.864477                                                               \nItaly       14.554763  8.544198 10.811381 12.069687 14.335626 11.546471    8.379349 11.152265  7.639620  7.664063   9.834813                                                    \nPoland      10.924142 11.435210 10.141752 10.798369  9.205546  7.582684    7.326023 11.798756 11.876059  7.469926  13.574770  6.958702                                          \nE Germany    6.749900 12.877025  9.027131  9.346129  7.631657  5.235333    9.516872 10.027053 13.535516  8.989430  15.016585 11.487171  7.812245                                \nNetherlands  6.093145 12.833723  7.316895  9.011894  5.947924  3.547303    4.999723  8.550044 13.360874  9.764597  14.973283 10.830351  7.624579  6.084633                      \nBelgium      7.549654 13.744660  8.862655  9.455895  4.474243  3.617701    5.629898  5.334180 13.877793  8.498996  15.884220 10.678620  7.146631  5.539266    6.249788          \nGreece      15.381876 11.152876 11.714511 13.105170 17.020097 14.230942   11.063821 13.168087 11.386135  9.937048  11.975775  4.983861 10.346909 14.602128   13.958464 12.575491\n\nprotein.X.canb &lt;- dist(protein.trd,                    \n                       method = \"canberra\")                 # 캔버라 거리\nprotein.X.canb\n\n             Denmark  Romania   Norway  Finland  Ireland W Germany Switzerland       UK Bulgaria     USSR Yugoslavia    Italy   Poland E Germany Netherlands  Belgium\nRomania     8.158879                                                                                                                                                 \nNorway      3.871710 6.733253                                                                                                                                        \nFinland     4.767715 7.096226 2.405164                                                                                                                               \nIreland     3.566184 7.298951 5.111712 5.554244                                                                                                                      \nW Germany   4.438168 8.559232 6.636858 6.534643 4.077482                                                                                                             \nSwitzerland 5.631496 7.384647 6.655474 7.136181 3.826983  5.915036                                                                                                   \nUK          5.431704 7.121411 5.091535 5.770405 4.848527  6.340807    6.905568                                                                                       \nBulgaria    9.000000 2.693889 7.429098 7.454773 8.216837  8.644828    7.107421 7.301777                                                                              \nUSSR        7.836442 4.248394 5.411981 5.563226 6.335265  7.540568    8.258134 6.163877 4.722732                                                                     \nYugoslavia  8.377778 1.237536 6.804002 7.102698 7.492452  8.534013    7.402525 6.914326 2.909789 4.561988                                                            \nItaly       9.000000 4.711358 6.704348 6.751228 8.497561  8.000000    7.125692 7.590486 4.318125 4.553765   4.836478                                                 \nPoland      6.917891 6.900790 6.345653 6.343996 5.459791  5.977593    5.829424 8.169304 6.785597 5.751088   7.259761 5.262433                                        \nE Germany   4.243672 7.010160 5.788280 5.086371 4.628132  4.869345    6.800052 6.180657 7.309833 6.538880   7.081395 7.429727 6.108030                               \nNetherlands 4.715536 7.638203 4.969986 5.904652 4.136367  4.567917    4.788712 6.592700 7.840648 7.073731   7.648998 7.637213 6.225068  4.476133                     \nBelgium     5.373320 8.715789 6.976183 6.282932 4.039578  4.848567    5.261781 5.566840 8.198201 7.464957   8.758929 8.504583 6.266166  4.686976    6.323095         \nGreece      8.053278 5.888016 6.878480 6.435935 8.915575  8.778626    7.493229 7.883260 6.100786 5.985242   5.742592 4.140892 6.643087  7.887254    8.885417 7.431991\n\nprotein.X.mink &lt;- dist(protein.trd,                         \n                       method = \"minkowski\")                # 민코우스키 거리\nprotein.X.mink\n\n             Denmark  Romania   Norway  Finland  Ireland W Germany Switzerland       UK Bulgaria     USSR Yugoslavia    Italy   Poland E Germany Netherlands  Belgium\nRomania     5.899193                                                                                                                                                 \nNorway      2.190572 5.017093                                                                                                                                        \nFinland     2.967850 5.245898 2.336933                                                                                                                               \nIreland     3.359817 5.698092 4.124494 3.546137                                                                                                                      \nW Germany   2.878437 5.127560 3.800557 4.003049 1.923184                                                                                                             \nSwitzerland 3.738040 4.469147 3.903220 3.935243 2.917500  2.356744                                                                                                   \nUK          3.867136 5.591679 3.905187 4.132260 2.420596  3.117714    3.060014                                                                                       \nBulgaria    6.313897 1.931986 5.500563 5.964271 6.225093  5.529229    4.441702 5.851565                                                                              \nUSSR        4.477896 2.806990 3.501849 3.582533 4.008542  3.961498    3.884788 4.096414 3.822901                                                                     \nYugoslavia  6.713206 1.004357 5.698797 5.962378 6.560893  5.996864    5.298535 6.426629 2.062393 3.407616                                                            \nItaly       5.277250 3.439932 4.454559 5.342612 5.114655  4.328910    3.122747 4.448760 2.953685 3.772778   3.819090                                                 \nPoland      4.399724 4.220409 4.275439 4.655450 4.049754  3.143036    3.160984 4.834137 4.493170 3.288055   4.702444 3.192257                                        \nE Germany   3.049396 4.874142 3.609905 4.382604 3.275421  1.990398    3.737112 4.163853 5.381543 3.551288   5.605003 4.525418 2.966305                               \nNetherlands 3.104750 4.718412 3.958992 3.789881 2.469626  1.324503    2.037250 3.815009 5.147099 4.011981   5.573208 4.210302 2.959231  2.681627                     \nBelgium     2.915357 4.886542 3.340291 3.805354 1.828405  1.484545    2.433729 2.074059 5.228214 3.266973   5.724063 3.895649 3.174653  2.239657    2.416333         \nGreece      5.917754 4.069820 4.853851 5.817338 5.983267  5.564533    4.319030 4.823118 4.018591 4.352319   4.324015 2.258867 4.579691  5.805825    5.463629 4.850338\n\n\nCaution! 모든 거리행렬을 이용하여 분석을 수행하면 시간이 오래 걸리기 때문에 본 예제에서는 유클리드 거리에 기반한 거리행렬만 이용한다.\n\n\n7.6.2 계층적 군집분석\n\n계층적 군집분석은 함수 hclust()를 이용하여 수행할 수 있으며, 옵션 method에 군집 간 거리를 정의하는 방법을 지정할 수 있다.\n\n\"single\" : 최단 연결법\n\n두 군집에 속한 case들의 최단 거리를 군집 간 거리로 정의\n\n\"complete\" : 최장 연결법\n\n두 군집에 속한 case들의 최장 거리를 군집 간 거리로 정의\n\n\"average\" : 평균 연결법\n\n두 군집에 속한 모든 case 간의 거리 평균을 군집 간 거리로 정의\n\n\"ward.D\" : Ward의 방법\n\n군집 내 제곱합과 군집 간 제곱합을 고려\n\n\n\"mcquitty\" : McQuitty의 평균 연결법\n\"centroid\" : 중심 연결법\n\"median\" : 중위수 연결법\n\n\n\nCaution! 옵션 method에 지정한 방법에 따라 군집 형성의 결과가 다르다.\n\nprotein.X.sing &lt;- hclust(protein.X.eucl,                     # 유클리드 거리에 기반한 거리행렬\n                         method = \"single\")                  # 최단 연결법\nprotein.X.sing\n\n\nCall:\nhclust(d = protein.X.eucl, method = \"single\")\n\nCluster method   : single \nDistance         : euclidean \nNumber of objects: 17 \n\nprotein.X.comp &lt;- hclust(protein.X.eucl,                     # 유클리드 거리에 기반한 거리행렬\n                         method = \"complete\")                # 최장 연결법\nprotein.X.comp\n\n\nCall:\nhclust(d = protein.X.eucl, method = \"complete\")\n\nCluster method   : complete \nDistance         : euclidean \nNumber of objects: 17 \n\nprotein.X.aver &lt;- hclust(protein.X.eucl,                     # 유클리드 거리에 기반한 거리행렬\n                         method = \"average\")                 # 평균 연결법\nprotein.X.aver\n\n\nCall:\nhclust(d = protein.X.eucl, method = \"average\")\n\nCluster method   : average \nDistance         : euclidean \nNumber of objects: 17 \n\nprotein.X.ward &lt;- hclust(protein.X.eucl,                     # 유클리드 거리에 기반한 거리행렬\n                           method = \"ward.D\")                # Ward 방법\nprotein.X.ward\n\n\nCall:\nhclust(d = protein.X.eucl, method = \"ward.D\")\n\nCluster method   : ward.D \nDistance         : euclidean \nNumber of objects: 17 \n\n\nCaution! 함수 cutree()는 case별 군집 번호를 생성하는 함수이다. 옵션 k에 형성하고자 하는 군집 개수를 입력하면 계층적 군집분석의 결과를 이용하여 각 case의 군집 번호를 출력해준다.\n\n# Training Dataset의 case별 군집 번호 생성\nhcluster &lt;- cutree(protein.X.ward,                          # Ward 방법을 이용한 계층적 군집분석           \n                   k = 3)                                   # 형성하고자 하는 군집 개수\nhcluster\n\n    Denmark     Romania      Norway     Finland     Ireland   W Germany Switzerland          UK    Bulgaria        USSR  Yugoslavia       Italy      Poland   E Germany Netherlands     Belgium \n          1           2           1           1           3           3           3           3           2           3           2           2           3           3           3           3 \n     Greece \n          2 \n\n# Training Dataset과 군집 번호 결합\nprotein.X.hclust &lt;- data.frame(protein.trd, hcluster)\nprotein.X.hclust\n\n                     x1         x2          x3           x4         x5         x6          x7         x8          x9 hcluster\nDenmark      0.18081182  0.8964725  0.60866213  0.923106753  2.1894978 -0.8752919  0.28314770 -1.1132630 -0.95800750        1\nRomania     -1.21348962 -0.4696659 -1.46078912 -1.136667805 -1.1166002  1.3478740 -0.73972337  1.2269834 -0.69532803        2\nNorway      -0.19945221 -0.9554040 -0.33199753  0.671191879  2.1152035 -0.7870074  0.16280993 -0.6553887 -0.76099790        1\nFinland     -0.16776354 -0.8946867 -0.33199753  2.212318167  0.6664639 -0.5221537  0.46365436 -0.9606382 -1.61470619        1\nIreland      1.22653789  0.6536035  1.54932180  1.041654929 -0.6708342 -0.7067487  1.12551212 -0.6553887 -0.62965816        3\nW Germany    0.43432117  1.4125693  0.98492600  0.004358389 -0.2250681 -1.1401456  0.52382325 -0.7062636 -0.03862933        3\nSwitzerland  0.97302854  0.6839621  0.04426634  0.745284489 -0.6336870 -0.5783347 -0.92023003 -0.2483893  0.68373923        3\nUK           2.33564131 -0.6518177  1.54932180  0.271091785  0.1092564 -0.6826711  0.22297882  0.2603599 -0.36697868        3\nBulgaria    -0.70647091 -0.5607418 -1.36672316 -1.551586421 -1.0423058  1.9177108 -1.94310111  0.4129847  0.22405014        2\nUSSR        -0.23114088 -0.9857626 -0.89639332 -0.321649095 -0.3736568  0.8663218  1.24584989  0.2603599 -0.62965816        3\nYugoslavia  -1.78388566 -0.8643281 -1.74298702 -1.373764157 -1.2651889  1.8535038 -0.79989226  1.4304831 -0.43264855        2\nItaly       -0.32620689 -0.8339695 -0.14386560 -0.751386233 -0.2250681  0.3205627 -1.34141224  0.7182342  1.86579687        2\nPoland      -0.99166894  0.7143207 -0.33199753  0.078450999 -0.3736568  0.2643816  0.94500546 -0.4518890  1.80012700        3\nE Germany   -0.51633890  1.1393416  0.60866213 -1.136667805  0.5178752 -0.6585934  1.30601878 -1.0623881 -0.16996907        3\nNetherlands -0.16776354  1.7465142  0.51459617  0.686010401 -0.5593927 -0.8351626 -0.07786562 -0.5536389 -0.10429920        3\nBelgium      1.09978322  0.4410931  0.98492600 -0.188282397  0.1835507 -0.4980760  0.82466768 -0.4010141  0.09271040        3\nGreece       0.05405714 -1.4715007 -0.23793156 -0.173463875  0.7036111  0.7138303 -1.28124336  2.4988565  1.73445713        2\n\n\n\n\n7.6.3 덴드로그램\n\n계층적 군집분석의 장점은 덴드로그램을 쉽게 얻을 수 있다는 것이며, 덴드로그램을 통해 case의 군집 형성 과정을 한 눈에 살펴볼 수 있다.\n\n\n# 최단 연결법을 이용한 계층적 군집분석의 덴드로그램\nplot(protein.X.sing, \n     main = \"최단 연결법\",                                 # 제목\n     xlab = \"\")                                            # x축 라벨 이름\n\n# 덴드로그램에 군집 구분 상자 추가\nrect.hclust(protein.X.sing,                                \n            k = 3,                                         # 형성하고자 하는 군집 개수\n            border = \"red\")                                # 상자 색깔\n\n\n\n\n\n\n\n\nResult! 덴드로그램을 살펴보면, 가장 아래쪽에 있는(=Height가 가장 짧은=군집 간 거리가 가장 짧은) “Romania”와 “Yugoslavia”가 제일 처음으로 묶여 군집을 형성하였다. 그리고, Height가 두 번째로 짧은 “W Germany”와 “Netherlands”가 묶여 군집을 형성하였다. 세 번째로는 군집 (“W Germany”, “Netherlands”)과 “Belgium”이 묶여 군집을 형성했다는 것을 알 수 있다.\n\n# 최장 연결법을 이용한 계층적 군집분석의 덴드로그램\nplot(protein.X.comp,                          \n     main = \"최장 연결법\",                                 # 제목\n     xlab = \"\")                                            # x축 라벨 이름\n\n# 덴드로그램에 군집 구분 상자 추가\nrect.hclust(protein.X.comp,                                \n            k = 3,                                         # 형성하고자 하는 군집 개수\n            border = \"red\")                                # 상자 색깔\n\n\n\n\n\n\n\n# 평균 연결법을 이용한 계층적 군집분석의 덴드로그램\nplot(protein.X.aver,                          \n     main = \"평균 연결법\",                                 # 제목\n     xlab = \"\")                                            # x축 라벨 이름\n\n# 덴드로그램에 군집 구분 상자 추가\nrect.hclust(protein.X.aver,                                \n            k = 3,                                         # 형성하고자 하는 군집 개수\n            border = \"red\")                                # 상자 색깔\n\n\n\n\n\n\n\n# Ward 방법을 이용한 계층적 군집분석의 덴드로그램\nplot(protein.X.ward,                          \n     main = \"Ward\",                                        # 제목\n     xlab = \"\")                                            # x축 라벨 이름\n\n# 덴드로그램에 군집 구분 상자 추가\nrect.hclust(protein.X.ward,                                \n            k = 3,                                         # 형성하고자 하는 군집 개수\n            border = \"red\")                                # 상자 색깔\n\n\n\n\n\n\n\n\nCaution! Package \"factoextra\"에서 제공하는 함수 fviz_dend()를 이용하면 덴드로그램의 시각화 옵션을 다양하게 변경할 수 있다.\n\nprotein.X.ward %&gt;%\n  fviz_dend(cex = 1,                                       # 라벨 크기\n            k = 3,                                         # 형성하고자 하는 군집 개수\n            palette = \"jco\")                               # 군집 색깔\n\n\n\n\n\n\n\nprotein.X.ward %&gt;%\n  fviz_dend(cex = 1,                                       # 라벨 크기\n            k = 3,                                         # 형성하고자 하는 군집 개수\n            palette = \"jco\",                               # 군집 색깔\n            # 덴드로그램에 군집 구분 상자 추가\n            rect = TRUE,                                   # 상자 표시 여부\n            rect_border = \"jco\",                           # 상자 색깔\n            rect_fill = TRUE)                              # 상자 색깔 채우기 여부 / FALSE : 선만 표시\n\n\n\n\n\n\n\nprotein.X.ward %&gt;%\n  fviz_dend(cex = 1,                                       # 라벨 크기\n            k = 3,                                         # 형성하고자 하는 군집 개수\n            palette = \"jco\",                               # 군집 색깔\n            # 덴드로그램에 군집 구분 상자 추가\n            rect = TRUE,                                   # 상자 표시 여부\n            rect_border = \"jco\",                           # 상자 색깔\n            rect_fill = TRUE,\n            horiz = TRUE)                                  # 가로로 회전\n\n\n\n\n\n\n\n\n\n\n7.6.4 거리행렬만 주어진 경우\n\nDataset의 예측 변수 값은 주어지지 않았으며, 거리행렬만 알고 있는 경우 계층적 군집분석을 수행하는 절차는 다음과 같다.\n\n주어진 거리행렬을 함수 as.dist()를 이용하여 “dist” 객체로 변환\n함수 hclust()를 이용하여 계층적 군집분석 수행\n\n\n\n# 거리행렬\nexam71 &lt;- c(0, 1, 7, 9, 1, 0, 3, 6, 7, 3, 0, 5, 9, 6, 5, 0)   \nexam71.matrix &lt;- matrix(exam71, nrow = 4)\nexam71.matrix\n\n     [,1] [,2] [,3] [,4]\n[1,]    0    1    7    9\n[2,]    1    0    3    6\n[3,]    7    3    0    5\n[4,]    9    6    5    0\n\nexam71.dist &lt;- as.dist(exam71.matrix)                       # \"dist\" 객체로 변환\nexam71.dist\n\n  1 2 3\n2 1    \n3 7 3  \n4 9 6 5\n\nexam71.sing &lt;- hclust(exam71.dist,                          \n                      method = \"single\")                    # 최단 연결법\n\n# 덴드로그램 Ver.1\nplot(exam71.sing,                                           \n     main = \"최단 연결법\",                                  # 제목\n     xlab = \"\")                                             # x축 라벨 이름\n\n\n\n\n\n\n\n# 덴드로그램 Ver.2\nexam71.sing %&gt;%\n  fviz_dend(cex = 1,                                       # 라벨 크기\n            k = 3,                                         # 형성하고자 하는 군집 개수\n            palette = \"jco\",                               # 군집 색깔\n            # 덴드로그램에 군집 구분 상자 추가\n            rect = TRUE,                                   # 상자 표시 여부\n            rect_border = \"jco\",                           # 상자 색깔\n            rect_fill = TRUE)                              # 상자 색깔 채우기 여부 / FALSE : 선만 표시\n\n\n\n\n\n\n\nexam71.comp &lt;- hclust(exam71.dist,                         \n                      method = \"complete\")                  # 최장 연결법\n\n# 덴드로그램 Ver.1\nplot(exam71.comp,\n     main = \"최장 연결법\",                                  # 제목\n     xlab = \"\")                                             # x축 라벨 이름\n\n\n\n\n\n\n\n# 덴드로그램 Ver.2\nexam71.comp %&gt;%\n  fviz_dend(cex = 1,                                       # 라벨 크기\n            k = 3,                                         # 형성하고자 하는 군집 개수\n            palette = \"jco\",                               # 군집 색깔\n            # 덴드로그램에 군집 구분 상자 추가\n            rect = TRUE,                                   # 상자 표시 여부\n            rect_border = \"jco\",                           # 상자 색깔\n            rect_fill = TRUE)                              # 상자 색깔 채우기 여부 / FALSE : 선만 표시",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Cluster Analysis based on k-means</span>"
    ]
  },
  {
    "objectID": "Clustering.html#군집-개수-결정",
    "href": "Clustering.html#군집-개수-결정",
    "title": "7  Cluster Analysis based on k-means",
    "section": "7.7 군집 개수 결정",
    "text": "7.7 군집 개수 결정\n\n군집 개수를 결정하는 것은 쉽지 않은 문제이며, 여러 가지 지표들을 이용하여 적절한 군집 개수를 찾는 것이 바람직하다.\n계층적 군집분석은 자료의 계층적 구조에 주된 관심이 있으며, 덴드로그램을 통해 적절한 군집 개수를 결정할 수 있다.\n\n예를 들어, 군집 형성 과정에서 거리의 측도 또는 어떤 지표의 값이 상대적으로 큰 변화를 보일 경우 이를 검토할 필요가 있다.\n특히, Ward 방법을 이용하는 경우 군집의 개수에 따른 Error Sum of Squares (ESS)의 증분을 검토하여 급격한 변화가 일어나는 위치에 대응하는 군집 개수를 최적의 군집 개수로 결정하기도 한다.\n\n자료의 모분포에 대한 적절한 가정 하에서 통계적 가설검정를 통해 군집의 개수를 알아보는 방법들도 있으나, 이들도 일반적으로 만족할 만한 타당성을 제공하지 않는다.\n\n\n7.7.1 “fviz_nbclust”\n\nPackage \"factoextra\"에서 제공하는 함수 fviz_nbclust()를 이용하여 군집 개수에 따른 특정 통계량의 변화를 알 수 있다.\n\n옵션 method에는 다음과 같은 통계량을 지정할 수 있다.\n\n\"wss\" (군집 내 제곱합, Within-Cluster Sum of Square) : 군집 내 변동의 합계를 의미하며, 해당 값이 작을수록 군집화가 잘 되었음을 나타낸다. 군집의 개수가 증가함에 따라 wss가 작아지게 되는데, wss가 급격히 감소하다가 감소량이 완만하게 되는 지점이 최적의 군집 개수에 대한 후보가 될 수 있다.\n\"silhouette\" (실루엣 계수, Silhouette Coefficient) : 각 case가 해당 군집에 얼마나 잘 위치하고 있는 지를 측정하는 계수이며, 해당 값이 클 때 군집화가 잘 되었음을 나타낸다. 일반적으로 평균 실루엣 계수가 가장 큰 지점의 군집 개수를 최적의 군집 개수로 선택한다.\n\n\n함수 fviz_nbclust()의 자세한 옵션은 여기를 참고한다.\n\n\n# Method = \"wss\"\nfviz_nbclust(protein.trd,                                    \n             kmeans,                                        # 군집분석에 사용할 함수\n             method = \"wss\",                                # 탐색할 통계량 \n             k.max = 10)                                    # 탐색할 최대 군집 개수\n\n\n\n\n\n\n\n\nResult! 군집의 개수가 2-5개일 때, 통계량 wss의 감소량이 완만하게 되기 때문에, 최적의 군집 개수를 2-5개로 선택할 수 있다.\n\n# Method = \"silhouette\"\nfviz_nbclust(protein.trd,                              \n             kmeans,                                        # 군집분석에 사용할 함수\n             method = \"silhouette\",                         # 탐색할 통계량 \n             k.max = 10)                                    # 탐색할 최대 군집 개수\n\n\n\n\n\n\n\n\nResult! 군집의 개수가 2개일 때, 평균 실루엣 계수가 가장 높으므로 최적의 군집 개수를 2개로 선택할 수 있다.\n\n\n7.7.2 “NbClust”\n\nPackage \"NbClust\"에서 제공하는 함수 NbClust()는 앞에서 설명한 통계량(\"wss\", \"silhouette\")을 포함하여 30개의 통계량에 의해 군집의 개수를 결정할 수 있다.\n함수 NbClust()의 자세한 옵션은 여기를 참고한다.\n\n\nnc &lt;- NbClust(data = protein.trd,                         \n              distance = \"euclidean\",                       # 거리를 계산할 측도\n              min.nc = 2,                                   # 탐색할 최소 군집 개수\n              max.nc = 8,                                   # 탐색할 최대 군집 개수\n              method = \"kmeans\")                            # 군집분석 방법\n\n\n\n\n\n\n\n\n*** : The Hubert index is a graphical method of determining the number of clusters.\n                In the plot of Hubert index, we seek a significant knee that corresponds to a \n                significant increase of the value of the measure i.e the significant peak in Hubert\n                index second differences plot. \n \n\n\n\n\n\n\n\n\n\n*** : The D index is a graphical method of determining the number of clusters. \n                In the plot of D index, we seek a significant knee (the significant peak in Dindex\n                second differences plot) that corresponds to a significant increase of the value of\n                the measure. \n \n******************************************************************* \n* Among all indices:                                                \n* 10 proposed 2 as the best number of clusters \n* 5 proposed 3 as the best number of clusters \n* 3 proposed 4 as the best number of clusters \n* 3 proposed 6 as the best number of clusters \n* 3 proposed 8 as the best number of clusters \n\n                   ***** Conclusion *****                            \n \n* According to the majority rule, the best number of clusters is  2 \n \n \n******************************************************************* \n\nnc\n\n$All.index\n      KL      CH Hartigan     CCC    Scott      Marriot   TrCovW  TraceW Friedman  Rubin Cindex     DB Silhouette   Duda Pseudot2   Beale Ratkowsky    Ball Ptbiserial    Frey McClain   Dunn Hubert\n2 4.9411 11.1225   3.2331 -0.1756  36.3456 1.421678e+07 146.0938 82.6873  30.9509 1.7415 0.5736 1.1046     0.3431 1.1970  -2.1394 -0.8894    0.4422 41.3436     0.7062  1.4601  0.6080 0.6460 0.0126\n3 0.6956  7.8181   3.7522 -1.0319  96.3353 9.385189e+05 114.7558 68.0250  96.6219 2.1169 0.5519 0.8772     0.3295 3.1874  -4.8039 -2.7473    0.4135 22.6750     0.6885  1.5743  0.7685 0.6110 0.0128\n4 3.6704  7.2983   1.4045 -1.3187 137.9082 1.446331e+05  67.7159 53.6468 106.0892 2.6842 0.5500 1.1372     0.2421 3.2865  -1.3914 -2.0889    0.3930 13.4117     0.5273 -0.1000  2.1838 0.3411 0.0122\n5 0.5133  5.9227   1.9786 -2.5078 185.0890 1.408551e+04  62.3318 48.4159 173.9386 2.9742 0.5037 1.0525     0.2789 0.8998   0.5569  0.5351    0.3619  9.6832     0.5768 36.1590  2.2269 0.4603 0.0133\n6 0.3615  5.4222   5.9440 -3.3386 234.5005 1.108751e+03  45.6726 41.5629 402.5724 3.4646 0.5027 1.0461     0.2133 0.2757   7.8820 11.8328    0.3428  6.9272     0.4746  0.0607  3.3942 0.3433 0.0131\n7 2.3162  7.2280   3.0544 -1.8743 284.9642 7.754320e+01  20.5620 26.9825 602.5454 5.3368 0.5381 0.9193     0.2820 1.6856  -0.4068  0.0000    0.3403  3.8546     0.5152  0.1602  4.2023 0.4515 0.0153\n8 2.8851  7.6717   1.1819 -1.6783 337.0101 4.741600e+00  13.4502 20.6693 749.7846 6.9669 0.5279 0.7813     0.3445 7.0565   0.0000  0.0000    0.3270  2.5837     0.5034  1.1889  4.9530 0.5005 0.0153\n  SDindex Dindex   SDbw\n2  1.0165 2.1448 0.6546\n3  0.8783 1.8881 0.4867\n4  1.0702 1.7046 0.4059\n5  1.0276 1.5839 0.3589\n6  1.1107 1.4546 0.3400\n7  1.0204 1.1810 0.2757\n8  0.9360 1.0175 0.1937\n\n$All.CriticalValues\n  CritValue_Duda CritValue_PseudoT2 Fvalue_Beale\n2         0.4954            13.2414       1.0000\n3         0.2098            26.3677       1.0000\n4         0.0985            18.3088       1.0000\n5         0.3418             9.6280       0.8391\n6         0.2857             7.4990       0.0000\n7        -0.0882           -12.3333          NaN\n8        -0.0882             0.0000          NaN\n\n$Best.nc\n                    KL      CH Hartigan     CCC   Scott  Marriot  TrCovW TraceW Friedman   Rubin Cindex     DB Silhouette  Duda PseudoT2   Beale Ratkowsky    Ball PtBiserial   Frey McClain  Dunn\nNumber_clusters 2.0000  2.0000   6.0000  2.0000  3.0000        3  4.0000 4.0000   6.0000  4.0000 6.0000 8.0000     8.0000 2.000   2.0000  2.0000    2.0000  3.0000     2.0000 3.0000   2.000 2.000\nValue_Index     4.9411 11.1225   3.9654 -0.1756 59.9897 12484378 47.0399 9.1472 228.6338 -0.2773 0.5027 0.7813     0.3445 1.197  -2.1394 -0.8894    0.4422 18.6686     0.7062 1.5743   0.608 0.646\n                Hubert SDindex Dindex   SDbw\nNumber_clusters      0  3.0000      0 8.0000\nValue_Index          0  0.8783      0 0.1937\n\n$Best.partition\n    Denmark     Romania      Norway     Finland     Ireland   W Germany Switzerland          UK    Bulgaria        USSR  Yugoslavia       Italy      Poland   E Germany Netherlands     Belgium \n          1           2           1           1           1           1           1           1           2           2           2           2           1           1           1           1 \n     Greece \n          2 \n\n\nCaution! “$All.index”에서는 군집 개수에 따른 각 통계량의 측정값을 볼 수 있으며, “$Best.nc”에서는 각 통계량에 대해 최적의 군집 개수를 보여준다. “$Best.partition”에서는 최적의 군집 개수에 대한 case별 군집 번호를 보여준다.\nResult! “$Best.nc”를 살펴보면, 10개의 통계량에서 최적의 군집 개수로 “2”개를 추천하고 있으며, 5개의 통계량에서 최적의 군집 개수를 “3”개로 추천하고 있다. 대다수의 통계량이 최적의 군집 개수로 “2”개를 추천하고 있으며, 이를 기반으로 나눠진 각 case의 군집 번호는 “$Best.partition”에서 볼 수 있다.\n\n# 여러 통계량의 최적의 군집 개수에 대한 막대 그래프\nbarplot(table(nc$Best.n[1,]),                               # 군집 개수에 대한 도수분포표\n        xlab = \"Number of Clusters\",\n        ylab = \"Number of Criteria\")\n\n\n\n\n\n\n\n\nCaution! 옵션 index에 특정 통계량의 이름을 지정하면, 해당 통계량에 대한 결과를 자세히 볼 수 있다.\n\n# Cubic Clustering Criterion 통계량에 대한 최적의 군집 개수\nNbClust(data = protein.trd,                         \n        distance = \"euclidean\",                             # 거리를 계산할 측도\n        min.nc = 2,                                         # 탐색할 최소 군집 개수\n        max.nc = 8,                                         # 탐색할 최대 군집 개수\n        method = \"kmeans\",                                  # 군집분석 방법\n        index = \"ccc\")                                      # Cubic Clustering Criterion 통계량\n\n$All.index\n      2       3       4       5       6       7       8 \n-0.1756 -1.0319 -1.3187 -2.5078 -3.3386 -1.8743 -1.6783 \n\n$Best.nc\nNumber_clusters     Value_Index \n         2.0000         -0.1756 \n\n$Best.partition\n    Denmark     Romania      Norway     Finland     Ireland   W Germany Switzerland          UK    Bulgaria        USSR  Yugoslavia       Italy      Poland   E Germany Netherlands     Belgium \n          1           2           1           1           1           1           1           1           2           2           2           2           1           1           1           1 \n     Greece \n          2",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Cluster Analysis based on k-means</span>"
    ]
  },
  {
    "objectID": "Clustering.html#비계층적-군집분석k-means",
    "href": "Clustering.html#비계층적-군집분석k-means",
    "title": "7  Cluster Analysis based on k-means",
    "section": "7.8 비계층적 군집분석(k-means)",
    "text": "7.8 비계층적 군집분석(k-means)\n\nk-means의 장점\n\n\n안정적인 결과를 찾을 때까지 각 반복마다 군집 간에 case 이동이 가능하다.\n예측 변수가 많은 경우, 다른 군집분석 알고리듬에 비해 수행하는 시간이 적게 걸린다.\n알고리듬 구현이 매우 간단하다.\n\n\n\nk-means의 단점\n\n\n범주형 예측 변수는 거리 계산을 할 수 없으므로 분석에 사용할 수 없다.\n군집의 개수를 미리 결정해야 한다.\n예측 변수들의 scale을 동일하게 설정해야 한다.\n이상치에 민감하다.\n초기 중심값 선택에 매우 민감하다.\n비구형 군집에는 잘 작동하지 않는다.\n\n\n\nk-means를 수행하기 위해 사용할 알고리듬\n\n\n\n\n\nCaution! 군집 개수 결정에서 다양한 통계량을 이용하여 결정된 최적의 군집 개수 “2”개를 기반으로 k-means를 수행한다.\n\n# k-means에서 함수 predict()를 사용하기 위해 Package 설치\npacman::p_load(\"twidlr\")                                       # For predict of \"kmeans\"\n# devtools::install_github(\"drsimonj/twidlr\")                  # Install Package \"twidlr\"\n\n\n7.8.1 Lloyd\n\n7.8.1.1 모형 훈련\n\nset.seed(200)\nprotein.Lloyd &lt;- kmeans(protein.trd, \n                        centers = 2,                         # 형성하고자 하는 군집 개수\n                        nstart = 10,                         # 수행 횟수\n                        iter.max = 100,                      # 최대 반복 수\n                        algorithm = \"Lloyd\")\nprotein.Lloyd\n\nK-means clustering with 2 clusters of sizes 11, 6\n\nCluster means:\n          x1         x2         x3         x4         x5        x6         x7         x8         x9\n1  0.3824670  0.4714517  0.5316991  0.4825925  0.3017463 -0.638164  0.4417748 -0.5952638 -0.1878790\n2 -0.7011895 -0.8643281 -0.9747816 -0.8847529 -0.5532015  1.169967 -0.8099204  1.0913170  0.3444449\n\nClustering vector:\n    Denmark     Romania      Norway     Finland     Ireland   W Germany Switzerland          UK    Bulgaria        USSR  Yugoslavia       Italy      Poland   E Germany Netherlands     Belgium \n          1           2           1           1           1           1           1           1           2           2           2           2           1           1           1           1 \n     Greece \n          2 \n\nWithin cluster sum of squares by cluster:\n[1] 54.69862 27.98864\n (between_SS / total_SS =  42.6 %)\n\nAvailable components:\n\n[1] \"cluster\"      \"centers\"      \"totss\"        \"withinss\"     \"tot.withinss\" \"betweenss\"    \"size\"         \"iter\"         \"ifault\"      \n\n\nCaution! k-means는 초기 중심값을 랜덤하게 선택하기 때문에 이 과정에서 다양한 결과가 나타날 수 있다. 그래서 nstart를 이용하여 수행 횟수를 늘려 최대한 다양한 초기 중심값에 대해 k-means를 수행하고 최적의 결과를 찾을 수 있다.\nResult! 각 군집에 속한 case 수는 11, 6이며, “Within cluster sum of squares by cluster”를 살펴보면 42.6%의 변동이 2개의 군집으로 설명되고 있다.\n\n\n7.8.1.2 예측\n\n# Test Dataset에 대한 군집 번호 예측\npred.Lloyd &lt;- predict(protein.Lloyd,\n                      protein.ted)\npred.Lloyd %&gt;%\n  as_tibble\n\n# A tibble: 8 × 1\n  value\n  &lt;int&gt;\n1     2\n2     1\n3     1\n4     1\n5     2\n6     2\n7     2\n8     1\n\n\n\n# Test Dataset과 예측한 군집 번호 결합\npred.protein.ted &lt;- data.frame(protein.ted, pred.Lloyd) %&gt;%\n  mutate(pred.Lloyd = factor(pred.Lloyd))                   # 군집 번호를 범주형으로 변환\n\npred.protein.ted %&gt;%\n  as_tibble\n\n# A tibble: 8 × 10\n       x1      x2      x3     x4     x5     x6     x7     x8      x9 pred.Lloyd\n    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;fct&gt;     \n1  0.0224 -1.96   -2.40   -1.46  -1.41   0.762 -2.24   1.33  -1.42   2         \n2 -0.358   1.87    1.17    0.167 -0.708 -0.386 -0.439 -0.808  0.290  1         \n3 -0.104   1.08   -0.238  -0.929 -0.745  0.120  0.403 -0.910  0.0927 1         \n4  2.53    0.623   0.232   0.108  0.629 -0.378  0.283 -0.248  1.73   1         \n5 -1.50    1.38   -0.144  -1.34  -1.38   0.585 -0.198  1.28   0.224  2         \n6 -1.21   -1.26   -1.84   -2.06   3.79  -0.466  0.945  0.922  2.65   2         \n7 -0.928  -1.35    0.0443 -1.51   1.11  -0.289  0.825  1.53   2.19   2         \n8 -0.0410 -0.0143  0.421  -2.09   1.30  -1.07  -0.379 -0.757 -1.22   1         \n\nggpairs(pred.protein.ted,                             \n        aes(colour = pred.Lloyd, alpha = 0.8),              # 군집에 따라 색깔을 다르게 표현\n        upper = list(continuous = \"density\")) +\n  scale_colour_manual(values = c(\"purple\",\"cyan4\")) +       # 특정 색깔 지정\n  scale_fill_manual(values = c(\"purple\",\"cyan4\")) +         # 특정 색깔 지정\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\n\n7.8.2 MacQueen\n\n7.8.2.1 모형 훈련\n\nset.seed(200)\nprotein.MacQ &lt;- kmeans(protein.trd, \n                       centers = 2,                         # 형성하고자 하는 군집 개수\n                       nstart = 10,                         # 수행 횟수\n                       iter.max = 100,                      # 최대 반복 수\n                       algorithm = \"MacQueen\")\nprotein.MacQ\n\nK-means clustering with 2 clusters of sizes 11, 6\n\nCluster means:\n          x1         x2         x3         x4         x5        x6         x7         x8         x9\n1  0.3824670  0.4714517  0.5316991  0.4825925  0.3017463 -0.638164  0.4417748 -0.5952638 -0.1878790\n2 -0.7011895 -0.8643281 -0.9747816 -0.8847529 -0.5532015  1.169967 -0.8099204  1.0913170  0.3444449\n\nClustering vector:\n    Denmark     Romania      Norway     Finland     Ireland   W Germany Switzerland          UK    Bulgaria        USSR  Yugoslavia       Italy      Poland   E Germany Netherlands     Belgium \n          1           2           1           1           1           1           1           1           2           2           2           2           1           1           1           1 \n     Greece \n          2 \n\nWithin cluster sum of squares by cluster:\n[1] 54.69862 27.98864\n (between_SS / total_SS =  42.6 %)\n\nAvailable components:\n\n[1] \"cluster\"      \"centers\"      \"totss\"        \"withinss\"     \"tot.withinss\" \"betweenss\"    \"size\"         \"iter\"         \"ifault\"      \n\n\nResult! 각 군집에 속한 case 수는 11, 6이며, “Within cluster sum of squares by cluster”를 살펴보면 42.6%의 변동이 2개의 군집으로 설명되고 있다.\n\n\n7.8.2.2 예측\n\n# Test Dataset에 대한 군집 번호 예측\npred.MacQ &lt;- predict(protein.MacQ,\n                     protein.ted)\npred.MacQ %&gt;%\n  as_tibble\n\n# A tibble: 8 × 1\n  value\n  &lt;int&gt;\n1     2\n2     1\n3     1\n4     1\n5     2\n6     2\n7     2\n8     1\n\n\n\n# Test Dataset과 예측한 군집 번호 결합\npred.protein.ted &lt;- data.frame(protein.ted, pred.MacQ) %&gt;%\n  mutate(pred.MacQ = factor(pred.MacQ))                     # 군집 번호를 범주형으로 변환\n\npred.protein.ted %&gt;%\n  as_tibble\n\n# A tibble: 8 × 10\n       x1      x2      x3     x4     x5     x6     x7     x8      x9 pred.MacQ\n    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;fct&gt;    \n1  0.0224 -1.96   -2.40   -1.46  -1.41   0.762 -2.24   1.33  -1.42   2        \n2 -0.358   1.87    1.17    0.167 -0.708 -0.386 -0.439 -0.808  0.290  1        \n3 -0.104   1.08   -0.238  -0.929 -0.745  0.120  0.403 -0.910  0.0927 1        \n4  2.53    0.623   0.232   0.108  0.629 -0.378  0.283 -0.248  1.73   1        \n5 -1.50    1.38   -0.144  -1.34  -1.38   0.585 -0.198  1.28   0.224  2        \n6 -1.21   -1.26   -1.84   -2.06   3.79  -0.466  0.945  0.922  2.65   2        \n7 -0.928  -1.35    0.0443 -1.51   1.11  -0.289  0.825  1.53   2.19   2        \n8 -0.0410 -0.0143  0.421  -2.09   1.30  -1.07  -0.379 -0.757 -1.22   1        \n\nggpairs(pred.protein.ted,                             \n        aes(colour = pred.MacQ, alpha = 0.8),               # 군집에 따라 색깔을 다르게 표현\n        upper = list(continuous = \"density\")) +\n  scale_colour_manual(values = c(\"#483DBB\",\"#FFB400\")) +    # 특정 색깔 지정\n  scale_fill_manual(values = c(\"#483DBB\",\"#FFB400\")) +      # 특정 색깔 지정\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\n\n7.8.3 Hartigan-Wong\n\n7.8.3.1 모형 훈련\n\nset.seed(200)\nprotein.HW &lt;- kmeans(protein.trd, \n                     centers = 2,                            # 형성하고자 하는 군집 개수\n                     nstart = 10,                            # 수행 횟수\n                     iter.max = 100,                         # 최대 반복 수\n                     algorithm = \"Hartigan-Wong\")\nprotein.HW\n\nK-means clustering with 2 clusters of sizes 11, 6\n\nCluster means:\n          x1         x2         x3         x4         x5        x6         x7         x8         x9\n1  0.3824670  0.4714517  0.5316991  0.4825925  0.3017463 -0.638164  0.4417748 -0.5952638 -0.1878790\n2 -0.7011895 -0.8643281 -0.9747816 -0.8847529 -0.5532015  1.169967 -0.8099204  1.0913170  0.3444449\n\nClustering vector:\n    Denmark     Romania      Norway     Finland     Ireland   W Germany Switzerland          UK    Bulgaria        USSR  Yugoslavia       Italy      Poland   E Germany Netherlands     Belgium \n          1           2           1           1           1           1           1           1           2           2           2           2           1           1           1           1 \n     Greece \n          2 \n\nWithin cluster sum of squares by cluster:\n[1] 54.69862 27.98864\n (between_SS / total_SS =  42.6 %)\n\nAvailable components:\n\n[1] \"cluster\"      \"centers\"      \"totss\"        \"withinss\"     \"tot.withinss\" \"betweenss\"    \"size\"         \"iter\"         \"ifault\"      \n\n\nResult! 각 군집에 속한 case 수는 11, 6이며, “Within cluster sum of squares by cluster”를 살펴보면 42.6%의 변동이 2개의 군집으로 설명되고 있다.\n\n\n7.8.3.2 예측\n\n# Test Dataset에 대한 군집 번호 예측\npred.HW &lt;- predict(protein.HW,\n                   protein.ted)\npred.HW %&gt;%\n  as_tibble\n\n# A tibble: 8 × 1\n  value\n  &lt;int&gt;\n1     2\n2     1\n3     1\n4     1\n5     2\n6     2\n7     2\n8     1\n\n\n\n# Test Dataset과 예측한 군집 번호 결합\npred.protein.ted &lt;- data.frame(protein.ted, pred.HW) %&gt;%\n  mutate(pred.HW = factor(pred.HW))                         # 군집 번호를 범주형으로 변환\n\npred.protein.ted %&gt;%\n  as_tibble\n\n# A tibble: 8 × 10\n       x1      x2      x3     x4     x5     x6     x7     x8      x9 pred.HW\n    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;fct&gt;  \n1  0.0224 -1.96   -2.40   -1.46  -1.41   0.762 -2.24   1.33  -1.42   2      \n2 -0.358   1.87    1.17    0.167 -0.708 -0.386 -0.439 -0.808  0.290  1      \n3 -0.104   1.08   -0.238  -0.929 -0.745  0.120  0.403 -0.910  0.0927 1      \n4  2.53    0.623   0.232   0.108  0.629 -0.378  0.283 -0.248  1.73   1      \n5 -1.50    1.38   -0.144  -1.34  -1.38   0.585 -0.198  1.28   0.224  2      \n6 -1.21   -1.26   -1.84   -2.06   3.79  -0.466  0.945  0.922  2.65   2      \n7 -0.928  -1.35    0.0443 -1.51   1.11  -0.289  0.825  1.53   2.19   2      \n8 -0.0410 -0.0143  0.421  -2.09   1.30  -1.07  -0.379 -0.757 -1.22   1      \n\nggpairs(pred.protein.ted,                             \n        aes(colour = pred.HW, alpha = 0.8),                 # 군집에 따라 색깔을 다르게 표현\n  upper = list(continuous = \"density\")) +\n  scale_colour_manual(values = c(\"#0064FF\",\"#FF9614\")) +    # 특정 색깔 지정\n  scale_fill_manual(values = c(\"#0064FF\",\"#FF9614\")) +      # 특정 색깔 지정\n  theme_bw()",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Cluster Analysis based on k-means</span>"
    ]
  },
  {
    "objectID": "Principal.html",
    "href": "Principal.html",
    "title": "8  Principal Component Analysis",
    "section": "",
    "text": "8.1 Package Loading\npacman::p_load(\"data.table\", \n               \"tidyverse\", \n               \"dplyr\", \"psych\", \n               \"ggplot2\", \"GGally\",\n               \"factoextra\",\n               \"ggbiplot\")\n\n# pacman::p_load(\"devtools\")\n# install_github(\"vqv/ggbiplot\")\n# library(ggbiplot)",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Principal Component Analysis</span>"
    ]
  },
  {
    "objectID": "Principal.html#예제-1",
    "href": "Principal.html#예제-1",
    "title": "8  Principal Component Analysis",
    "section": "8.2 예제 1",
    "text": "8.2 예제 1\n\n주성분분석을 수행하기 위해 사용되는 데이터는 자유아카데미에서 출판한 책 R을 활용한 다변량 자료분석 방법론의 데이터 파일 중 “satis.csv”이다.\n이 데이터는 어떤 제품에 대한 고객의 만족도를 조사하여 얻어진 데이터로 총 8개의 변수를 포함한다.\n\nID : 고객 아이디\ngender : 고객 성별\nage : 고객 나이\nx1 : 가격에 대한 만족도\nx2 : 성능에 대한 만족도\nx3 : 편리성에 대한 만족도\nx4 : 디자인에 대한 만족도\nx5 : 색상에 대한 만족도\n\n만족도는 5점 척도로 측정되어 있으며, “1 = 매우 만족하지 않는다.”, “2 = 만족하지 않는다.”, “3 = 보통이다.”, “4 = 만족한다.”, “5 = 매우 만족한다.”를 의미한다.\n\n\n8.2.1 데이터 불러오기\n\nsatis &lt;- read.csv(\"./DATA/satis.csv\")\nsatis\n\n   ID gender age x1 x2 x3 x4 x5\n1   1      F  10  1  2  4  1  1\n2   2      F  10  1  2  3  2  1\n3   3      F  20  2  5  5  2  2\n4   4      F  20  2  5  4  2  2\n5   5      F  30  1  2  3  4  3\n6   6      M  30  1  3  4  1  1\n7   7      M  40  4  5  5  3  3\n8   8      M  40  1  3  4  4  4\n9   9      M  50  3  3  5  5  4\n10 10      M  50  5  5  5  4  4\n\n\n\n\n8.2.2 데이터 탐색\n\n\n8.2.2.1 기술통계량\n\ndescribe(satis[,c(\"x1\", \"x2\", \"x3\", \"x4\", \"x5\")])\n\n   vars  n mean   sd median trimmed  mad min max range  skew kurtosis   se\nx1    1 10  2.1 1.45    1.5    1.88 0.74   1   5     4  0.83    -0.92 0.46\nx2    2 10  3.5 1.35    3.0    3.50 1.48   2   5     3  0.12    -1.94 0.43\nx3    3 10  4.2 0.79    4.0    4.25 1.48   3   5     2 -0.29    -1.50 0.25\nx4    4 10  2.8 1.40    2.5    2.75 2.22   1   5     4  0.10    -1.64 0.44\nx5    5 10  2.5 1.27    2.5    2.50 2.22   1   4     3  0.00    -1.82 0.40\n\n\nCaution! Package \"psych\"에서 제공하는 함수 describe()를 이용하여 기술통계량을 출력할 수 있다.\nResult! 변수 x1의 표준편차는 다른 변수들에 비해 상대적으로 큰 반면, 변수 x3는 다른 변수들에 비해 상대적으로 표준편차가 작다.\n\n\n8.2.2.2 상관행렬\n\ncor(satis[,c(\"x1\", \"x2\", \"x3\", \"x4\", \"x5\")])\n\n          x1         x2        x3         x4        x5\nx1 1.0000000 0.70784332 0.7581754 0.44960032 0.5738636\nx2 0.7078433 1.00000000 0.7282191 0.05868157 0.2909287\nx3 0.7581754 0.72821908 1.0000000 0.24174689 0.4438968\nx4 0.4496003 0.05868157 0.2417469 1.00000000 0.9389683\nx5 0.5738636 0.29092868 0.4438968 0.93896829 1.0000000\n\n\nResult! 상대적으로 표준편차가 큰 변수 x1는 다른 변수들과 상관관계가 강하며, 특히, 변수 x3와 강한 양의 상관성을 가지고 있다(\\(r=0.758\\)). 그리고, 변수x4와 x5도 매우 강한 양의 상관성을 가지고 있다(\\(r=0.939\\)).\n\n\n8.2.2.3 산점도행렬\n\nggpairs(satis[,-1],\n        mapping = aes(col = gender), alpha = 0.8) +         # 변수 gender의 범주에 따라 색깔을 다르게 표현\n    scale_colour_manual(values = c(\"#00798c\", \"#d1495b\")) + # 특정 색깔 지정\n  scale_fill_manual(values = c(\"#00798c\", \"#d1495b\")) +     # 특정 색깔 지정\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\n\n8.2.3 공분산행렬을 이용한 주성분분석\n\nsatis.prcomp &lt;- prcomp(satis[,c(\"x1\", \"x2\", \"x3\", \"x4\", \"x5\")])\nsatis.prcomp\n\nStandard deviations (1, .., p=5):\n[1] 2.2542944 1.5386966 0.6528647 0.4472292 0.2157445\n\nRotation (n x k) = (5 x 5):\n         PC1        PC2         PC3        PC4        PC5\nx1 0.5723794  0.2916057 -0.72250071  0.2316137  0.1081469\nx2 0.3966884  0.6003640  0.62118712  0.2716472 -0.1501190\nx3 0.2564469  0.2233868 -0.03232539 -0.9143660 -0.2173088\nx4 0.4617789 -0.5982335  0.07138977  0.1323191 -0.6373947\nx5 0.4858141 -0.3830720  0.29321981 -0.1378017  0.7157328\n\n\nCaution! 주성분분석은 함수 prcomp()를 통해 수행할 수 있다. 자세한 옵션은 ?prcomp를 통해 확인하거나 여기를 참고한다.\nResult! 함수 prcomp()는 5개의 결과를 리스트로 반환한다.\n\nsdev : 데이터셋을 주성분에 투영했을 때의 표준편차인 주성분의 표준편차(= 공분산행렬의 고유값의 제곱근)\n\n출력 결과의 “Standard deviations”와 동일\n\nrotation : 주축의 계수(= 공분산행렬의 단위 고유벡터)\n\n출력 결과의 “Rotation”과 동일\n\ncenter : 변수의 평균\nscale : 표준편차로 나누어 주는 작업 진행 여부\nx : 주성분 점수\n\n\nsatis.prcomp$sdev        # 주성분의 표준편차\n\n[1] 2.2542944 1.5386966 0.6528647 0.4472292 0.2157445\n\nsatis.prcomp$sdev^2      # 주성분의 분산 = 주성분에 의해 설명되는 분산의 양 = 공분산행렬의 고유값\n\n[1] 5.08184308 2.36758724 0.42623226 0.20001396 0.04654569\n\n\nCaution! 주성분의 분산은 함수 eigen(cov(satis[,c(\"x1\", \"x2\", \"x3\", \"x4\", \"x5\")]))를 통해 얻어진 공분산행렬의 고유값과 동일하며, 공분산행렬의 대각성분 합이 주성분 분산의 합(공분산행렬의 고유값의 합)과 같음을 알 수 있다.\n\nsatis.prcomp$rotation    # 주축의 계수 \n\n         PC1        PC2         PC3        PC4        PC5\nx1 0.5723794  0.2916057 -0.72250071  0.2316137  0.1081469\nx2 0.3966884  0.6003640  0.62118712  0.2716472 -0.1501190\nx3 0.2564469  0.2233868 -0.03232539 -0.9143660 -0.2173088\nx4 0.4617789 -0.5982335  0.07138977  0.1323191 -0.6373947\nx5 0.4858141 -0.3830720  0.29321981 -0.1378017  0.7157328\n\n\nCaution! 주축의 계수는 함수 eigen(cov(satis[,c(\"x1\", \"x2\", \"x3\", \"x4\", \"x5\")]))를 통해 얻어진 공분산행렬의 단위 고유벡터와 동일하다.\nResult! 첫 번째 주성분은 \\(Y_1=0.572C_{1}+0.397C_{2}+0.256C_{3}+0.462C_{4}+0.486C_5\\)이며, 두 번째 주성분은 \\(Y_2=0.292C_1+0.600C_2+0.223C_3-0.598C_4-0.383C_5\\)이다. 여기서 확률변수 \\(C_{i}\\)는 \\(X_i-\\mu_i\\)이며, \\(\\mu_i\\)는 \\(X_i\\)의 평균을 의미한다. 또한, 변수 x1-x5는 \\(X_1\\)-\\(X_5\\)로 표현한다.\n주성분의 의미를 해석해보면, 첫 번째 주성분은 계수가 서로 비슷하므로 전반적인 만족도를 나타낸다고 할 수 있으며, 두 번째 주성분은 변수 x1-x3와 변수 x4-x5의 부호가 반대이므로 가격, 성능, 편리성 제품의 “내형적 요인”과 디자인, 색상 등 제품의 “외형적 요인”의 만족도 차이를 나타낸다고 할 수 있다.\n\n# 요약\nsummary(satis.prcomp)    \n\nImportance of components:\n                          PC1    PC2     PC3     PC4     PC5\nStandard deviation     2.2543 1.5387 0.65286 0.44723 0.21574\nProportion of Variance 0.6257 0.2915 0.05248 0.02463 0.00573\nCumulative Proportion  0.6257 0.9172 0.96964 0.99427 1.00000\n\n\nResult! 처음 2개의 고유값은 5.082(= \\(2.2543^2\\)), 2.368(= \\(1.5387^2\\))로서 각각 전체 변동의 62.6%(= 5.082/8.122)와 29.2%(= 2.368/8.122)를 차지한다. 따라서, 처음 2개의 주성분에 의해 데이터 변동의 약 91.7%가 설명될 수 있음을 알 수 있다. 이는 2개의 주성분만으로 데이터 변동을 충분히 설명할 수 있음을 의미한다. 만약 처음 2개의 주성분을 새로운 변수로 고려할 경우, 이는 원래 다섯 개의 예측변수들이 가지고 있는 정보를 2차원으로 축소한다는 의미이다.\n\n# 변수 적재 Ver.1\n1:5 %&gt;%                                              # 첫 번째 변수부터 다섯 번째 변수에 function을 적용\n  map_df(function(x) satis.prcomp$rotation[,x]*satis.prcomp$sdev[x]) \n\n# A tibble: 5 × 5\n       x1      x2      x3      x4      x5\n    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1  1.29    0.894   0.578   1.04    1.10  \n2  0.449   0.924   0.344  -0.920  -0.589 \n3 -0.472   0.406  -0.0211  0.0466  0.191 \n4  0.104   0.121  -0.409   0.0592 -0.0616\n5  0.0233 -0.0324 -0.0469 -0.138   0.154 \n\n\nCaution! 주성분의 변수 적재(Variable Loading)는 단위 고유벡터(= 주축의 계수)와 고유값의 제곱근(= 주성분의 표준편차)을 곱함으로써 계산될 수 있다. 변수 적재를 계산하기 위해 함수 map_df()를 이용한다.\nResult! 변수 적재는 각 변수가 특정 주성분에 얼마나 기여하는지를 설명한다. 결과값의 부호는 양/음의 상관관계를 나타내며, 값의 절대값이 클수록 주성분과 변수는 강한 관계를 가지고 있다. 출력 결과는 주성분과 변수 사이의 공분산처럼 해석할 수 있다. 예를 들어, 변수 x1은 첫 번째 주성분과 양의 상관성(1.29)을 가지고 있으며, 변수 x4는 두 번째 주성분과 음의 상관성(-0.920)을 가지고 있다.\n\n# 변수 적재 Ver.2\npcaDat &lt;- get_pca(satis.prcomp)                      # 주성분 결과에서 변수에 대한 정보(좌표, 제곱 코사인, 기여) 추출\nround(pcaDat$coord,3)                                # 변수 적재\n\n   Dim.1  Dim.2  Dim.3  Dim.4  Dim.5\nx1 1.290  0.449 -0.472  0.104  0.023\nx2 0.894  0.924  0.406  0.121 -0.032\nx3 0.578  0.344 -0.021 -0.409 -0.047\nx4 1.041 -0.920  0.047  0.059 -0.138\nx5 1.095 -0.589  0.191 -0.062  0.154\n\n\nCaution! 변수 적재는 package \"factoextra\"에서 제공하는 함수 get_pca()를 이용하여 계산할 수 있다.\n\n# 변수 적재 그래프\nfviz_pca_var(satis.prcomp)\n\n\n\n\n\n\n\n\nCaution! 변수 적재 그래프는 package \"factoextra\"에서 제공하는 함수 fviz_pca_var()를 이용하여 만들 수 있다.\nResult! 그래프의 x축과 y축은 각각 첫 번째 주성분과 두 번째 주성분에 대한 변수 적재값을 의미하며, 특정 주축을 기준으로 화살표의 길이가 길수록 해당 변수와 해당 주성분은 강한 상관성을 가진다.\n\n# 주성분 점수\nsatis.score &lt;- satis.prcomp$x           \nsatis.score\n\n             PC1        PC2         PC3         PC4         PC5\n [1,] -2.8358625  0.3854386 -0.69889614 -0.51084444  0.22339007\n [2,] -2.6305305 -0.4361818 -0.59518098  0.53584068 -0.19669584\n [3,]  0.1306219  1.7202178  0.77444872 -0.38413777 -0.25779081\n [4,] -0.1258250  1.4968309  0.80677411  0.53022827 -0.04048198\n [5,] -0.7353444 -2.3987927  0.13403819  0.52487542 -0.04001978\n [6,] -2.4391741  0.9858026 -0.07770902 -0.23919722  0.07327109\n [7,]  2.2229738  1.3221236 -0.30594311  0.07360693  0.03684093\n [8,]  0.4036049 -1.9581138  1.01611974 -0.25564510  0.30828518\n [9,]  2.2665896 -1.7497491 -0.38981729 -0.57446472 -0.33012467\n[10,]  3.7429463  0.6324238 -0.66383422  0.29973796  0.22332582\n\n\nCaution! 주성분 점수는 각 case의 관측값을 주성분에 대입함으로써 얻을 수 있으며, 고차원의 원본 데이터셋 대신 차원이 축소된 데이터셋으로 유용하게 사용될 수 있다. 함수 prcomp()를 이용한 결과 satis.prcomp에는 주성분 점수가 포함되어 있다.\nResult! 첫 번째 주성분과 두 번째 주성분에 의해 얻어지는 \\(i\\)번째 case의 주성분 점수는 다음의 식을 이용하여 얻을 수 있다. \\[\n\\begin{align}\n\\begin{cases}\ny_{i1}=0.572c_{i1}+0.397c_{i2}+0.256c_{i3}+0.462c_{i4}+0.486c_{i5},\\\\\ny_{i2}=0.292c_{i1}+0.600c_{i2}+0.223c_{i3}-0.598c_{i4}-0.383c_{i5},\n\\end{cases}\n\\end{align}\n\\] 여기서 \\(c_{ij}=x_{ij}-\\bar{x}_{j}\\)는 \\(i\\)번째 case의 \\(j\\)번째 변수 관찰값 \\(x_{ij}\\)에서 \\(j\\)번째 변수의 평균값 \\(\\bar{x}_j\\)을 뺀 것을 의미한다.\n\n# 성별에 따른 주성분 점수 그래프 Ver.1\nplot(satis.score[,1:2],                              # 첫 번째와 두 번째 주성분 점수\n     xlim = c(-4, 4), ylim = c(-2, 2), main = \"성별에 따른 주성분 점수\")\nabline(v = 0, h = 0, lty = 2)\ntext(satis.score[,1:2],  labels = satis$gender, pos = 4, col = \"red\")\n\n\n\n\n\n\n\n# 성별에 따른 주성분 점수 그래프 Ver.2\nsatisPca &lt;- satis %&gt;%\n  mutate(PCA1 = satis.score[, 1], PCA2 = satis.score[, 2])\n\nggplot(satisPca, aes(PCA1, PCA2, \n                     col = gender)) +                # 변수 gender의 범주에 따라 색깔을 다르게 표현\n  geom_point() +\n  geom_hline(yintercept=0, linetype='dashed', color='black') + \n  geom_vline(xintercept=0, linetype='dashed', color='black') + \n  theme_bw()\n\n\n\n\n\n\n\n\nResult! 그래프의 수직선을 중심으로 오른쪽에 위치하는 점들은 첫 번째 주성분 점수가 높다는 것을 의미하고 왼쪽에 위치하는 점들은 첫 번째 주성분 점수가 낮다는 것을 의미한다. 오른쪽에 위치하는 점 5개 중 4개가 남자이므로, 전반적으로 남자가 여자보다 첫 번째 주성분 점수가 높으며, 이는 남자들의 전반적인 만족도가 높다고 해석할 수 있다. 마찬가지로 수평선을 중심으로 위쪽에 위치하는 점들은 두 번째 주성분 점수가 높다는 것을 의미하고 아래쪽에 위치하는 점들은 두 번째 주성분 점수가 낮다는 것을 의미한다. 두 번째 주성분 점수가 높다는 것은 가격, 성능, 편리성 등 제품의 내형적 요인에 대해서는 만족도가 높으나 디자인, 색상 등 외형적 요인에 대해서는 만족도가 낮다고 해석할 수 있다.\n\n# 주성분 점수 예측\npredict(satis.prcomp, newdata = tail(satis[,c(\"x1\", \"x2\", \"x3\", \"x4\", \"x5\")], 2))\n\n        PC1        PC2        PC3        PC4        PC5\n9  2.266590 -1.7497491 -0.3898173 -0.5744647 -0.3301247\n10 3.742946  0.6324238 -0.6638342  0.2997380  0.2233258\n\n\nCaution! 함수 predict()를 이용하여 새로운 case에 대한 주성분 점수를 예측할 수 있다. 여기서는 설명의 편의상 마지막 2개의 case를 새로운 자료로 취급하여 예측을 수행하였다.\n\n# Biplot\nfviz_pca_biplot(satis.prcomp, label = \"var\")\n\n\n\n\n\n\n\n\nCaution! 주성분 점수와 변수 적재를 하나의 그래프에 함께 표현한 것을 행렬도(Biplot)라고 한다. 위 Biplot에서는 주성분 점수를 점으로 표현하고, 변수 적재를 화살표로 표현한다. Biplot는 다음을 기준으로 해석할 수 있다.\n1. 점은 각 case(= 데이터셋에서 하나의 행)에 대한 주성분 점수를 나타낸다.\n2. 화살표는 변수 적재값을 의미하며, 정확한 변수 적재값은 알 수 없다.\n3. 화살표의 길이는 상관성의 정도를 표현한다. 즉, 주축을 기준으로 화살표의 길이가 길수록 변수와 해당 주성분은 강한 상관성을 가진다.\n4. 화살표와 주축이 평행에 가까울수록 해당 변수는 해당 주성분에만 큰 영향을 미친다.\n5. 화살표들 간의 각도가 작을수록 해당 변수들은 강한 양의 상관관계를 나타내며, 180도는 강한 음의 상관관계를 나타낸다. 또한, 직각은 상관성이 없음을 의미한다.\nBiplot을 통해서 군집성, 변수들의 상관구조 등을 시각적으로 파악할 수 있다.\nResult! Biplot의 x축과 y축은 각각 첫 번째와 두 번째 주성분 점수를 의미한다. 변수 x1과 x5는 첫 번째 주축(x축, 수평 점선)을 기준으로 화살표의 길이가 길며 이는 두 변수가 첫 번째 주성분과 강한 상관성을 가진다고 할 수 있다. 또한, 변수 x1, x2, x3의 화살표들 간의 각도가 작기 때문에(즉, 서로 가까이 위치해있기 때문에) 강한 양의 상관관계를 가지며, 변수 x4와 x5 또한 강한 양의 상관관계를 가진다.\n\n# ggbiplot을 이용한 Biplot\nggbiplot(satis.prcomp,                      # 함수 prcomp에 의한 객체\n         obs.scale = 1,                     # 관찰값에 적용할 scale\n         var.scale = 1,                     # 변수에 적용할 scale\n         labels = satis$ID,                 # 점에 대한 label\n         circle = TRUE) +\n  theme_bw()\n\n\n\n\n\n\n\n\nCaution! Package \"ggbiplot\"에서 제공하는 함수 ggbiplot()를 이용하여 Biplot을 만들 수 있으며, 함수에 대한 자세한 옵션은 여기를 참고한다.\n\n# 스크리 그래프 Ver.1 (y축 : 고유값)\npar(mfrow = c(1, 2))\nscreeplot(satis.prcomp, type = \"b\", main = \"\")  # 막대 그래프\nscreeplot(satis.prcomp, type = \"l\", main = \"\")  # 선 그래프\n\n\n\n\n\n\n\n# 스크리 그래프 Ver.2\nfviz_screeplot(satis.prcomp, \n               addlabels = TRUE,                # 막대 높이 표시 여부\n               # geom = \"line\",                 # 그래프 유형(bar / line)\n               choice = \"eigenvalue\",           # y축 (variance / eigenvalue)\n               linecolor = \"#FC4E07\",           # 선 색깔\n               barcolor = \"#00AFBB\",            # 막대의 윤곽선 색깔\n               barfill = \"#00AFBB\")             # 막대의 색깔\n\n\n\n\n\n\n\nfviz_screeplot(satis.prcomp, \n               addlabels = TRUE,                # 막대 높이 표시 여부\n               choice = \"variance\",             # y축(variance / eigenvalue)\n               linecolor = \"#FC4E07\",           # 선 색깔\n               barcolor = \"#00AFBB\",            # 막대의 윤곽선 색깔\n               barfill = \"#00AFBB\")             # 막대의 색깔\n\n\n\n\n\n\n\n\nResult! 스크리 그래프를 보면 첫 번째 주성분과 두 번째 주성분의 분산(고유값)이 크며 가파른 경사를 형성한다. 그러므로, 2개의 주성분 개수를 고려할 수 있다.\n\n\n8.2.4 상관행렬을 이용한 주성분분석\n\nsatis.cor.prcomp &lt;- prcomp(satis[,c(\"x1\", \"x2\", \"x3\", \"x4\", \"x5\")], center = TRUE, scale = TRUE) \nsatis.cor.prcomp\n\nStandard deviations (1, .., p=5):\n[1] 1.7628337 1.1829978 0.5033695 0.4610255 0.1643420\n\nRotation (n x k) = (5 x 5):\n         PC1        PC2         PC3         PC4        PC5\nx1 0.5106549  0.1714026 -0.05545212  0.83272782 -0.1155083\nx2 0.4065628  0.5002084 -0.64671083 -0.37226185  0.1663863\nx3 0.4650578  0.3439269  0.75415171 -0.29030512  0.1114166\nx4 0.3795169 -0.6205430 -0.05742977 -0.01399615  0.6836660\nx5 0.4621973 -0.4658899 -0.08153030 -0.28898535 -0.6922142\n\n\nCaution! 상관행렬에 기초하여 주성분분석을 수행한다는 것은 표준화된 변수를 이용하여 주성분분석을 수행한다는 것을 의미한다. 함수 prcomp()의 옵션 center = TRUE와 scale = TRUE를 지정하여 변수를 표준화한 후, 상관행렬에 기초한 주성분분석을 수행할 수 있다.\nResult! 상관행렬을 이용한 주성분분석 결과는 위에서 공분산행렬에 기초하여 수행한 주성분분석 결과와는 다른 것을 확인할 수 있다.\n\nsatis.cor.prcomp$sdev        # 주성분의 표준편차\n\n[1] 1.7628337 1.1829978 0.5033695 0.4610255 0.1643420\n\nsatis.cor.prcomp$sdev^2      # 주성분의 분산 = 주성분에 의해 설명되는 분산의 양 = 상관행렬의 고유값\n\n[1] 3.1075826 1.3994838 0.2533809 0.2125445 0.0270083\n\n\nCaution! 주성분의 분산은 함수 eigen(cor(satis[,c(\"x1\", \"x2\", \"x3\", \"x4\", \"x5\")]))를 통해 얻어진 상관행렬의 고유값과 동일하며, 상관행렬의 대각성분 합이 주성분 분산의 합(상관행렬의 고유값의 합)인 변수 개수 “5”와 같음을 알 수 있다.\n\nsatis.cor.prcomp$rotation    # 주축의 계수\n\n         PC1        PC2         PC3         PC4        PC5\nx1 0.5106549  0.1714026 -0.05545212  0.83272782 -0.1155083\nx2 0.4065628  0.5002084 -0.64671083 -0.37226185  0.1663863\nx3 0.4650578  0.3439269  0.75415171 -0.29030512  0.1114166\nx4 0.3795169 -0.6205430 -0.05742977 -0.01399615  0.6836660\nx5 0.4621973 -0.4658899 -0.08153030 -0.28898535 -0.6922142\n\n\nCaution! 주축의 계수는 함수 eigen(cor(satis[,c(\"x1\", \"x2\", \"x3\", \"x4\", \"x5\")]))를 통해 얻어진 상관행렬의 단위 고유벡터와 동일하다.\nResult! 첫 번째 주성분은 \\(Y_1=0.511Z_{1}+0.407Z_{2}+0.465Z_{3}+0.380Z_{4}+0.462Z_{5}\\)이며, 두 번째 주성분은 \\(Y_2=0.171Z_{1}+0.500Z_{2}+0.344Z_{3}-0.621Z_{4}-0.466Z_{5}\\)이 된다. 여기서 확률변수 \\(Z_{i}\\)는 \\((X_i-\\mu_i)/\\sigma_{i}\\)이며, \\(\\mu_i\\)와 \\(\\sigma_{i}\\)는 각각 \\(X_i\\)의 평균과 표준편차를 의미한다. 또한, 변수 x1-x5는 \\(X_1\\)-\\(X_5\\)로 표현한다.\n주성분의 의미를 해석해보면, 첫 번째 주성분은 계수가 서로 비슷하므로 전반적인 만족도를 나타낸다고 할 수 있으며, 두 번째 주성분은 변수 x1-x3와 변수 x4-x5의 부호가 반대이므로 가격, 성능, 편리성 제품의 “내형적 요인”과 디자인, 색상 등 제품의 “외형적 요인”의 만족도 차이를 나타낸다고 할 수 있다.\n\n# 요약\nsummary(satis.cor.prcomp)    \n\nImportance of components:\n                          PC1    PC2     PC3     PC4    PC5\nStandard deviation     1.7628 1.1830 0.50337 0.46103 0.1643\nProportion of Variance 0.6215 0.2799 0.05068 0.04251 0.0054\nCumulative Proportion  0.6215 0.9014 0.95209 0.99460 1.0000\n\n\nResult! 처음 2개의 고유값은 3.108(= \\(1.7628^2\\)), 1.399(= \\(1.1830^2\\))로서 각각 전체 변동의 62.2%(= 3.108/5)와 28.0%(= 1.399/5)를 차지한다. 따라서, 처음 2개의 주성분에 의해 데이터 변동의 약 90.1%가 설명될 수 있음을 알 수 있다. 이는 2개의 주성분만으로 데이터 변동을 충분히 설명할 수 있음을 의미한다. 만약 처음 2개의 주성분을 새로운 변수로 고려할 경우, 이는 원래 다섯 개의 예측변수들이 가지고 있는 정보를 2차원으로 축소한다는 의미이다.\n\n# 변수 적재 Ver.1\n1:5 %&gt;%                                              # 첫 번째 변수부터 다섯 번째 변수에 function을 적용\n  map_df(function(x) satis.cor.prcomp$rotation[,x]*satis.cor.prcomp$sdev[x]) \n\n# A tibble: 5 × 5\n       x1      x2      x3       x4      x5\n    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n1  0.900   0.717   0.820   0.669    0.815 \n2  0.203   0.592   0.407  -0.734   -0.551 \n3 -0.0279 -0.326   0.380  -0.0289  -0.0410\n4  0.384  -0.172  -0.134  -0.00645 -0.133 \n5 -0.0190  0.0273  0.0183  0.112   -0.114 \n\n\nCaution! 주성분의 변수 적재(Variable Loading)는 단위 고유벡터(= 주축의 계수)와 고유값의 제곱근(= 주성분의 표준편차)을 곱함으로써 계산될 수 있다. 변수 적재를 계산하기 위해 함수 map_df()를 이용한다.\nResult! 변수 적재는 각 변수가 특정 주성분에 얼마나 기여하는지를 설명한다. 결과값의 부호는 양/음의 상관관계를 나타내며, 값의 절대값이 클수록 주성분과 변수는 강한 관계를 가지고 있다. 출력 결과는 피어슨 상관계수처럼 해석할 수 있다. 예를 들어, 변수 x1은 첫 번째 주성분과 강한 양의 상관성(\\(r=0.900\\))을 가지며, 변수 x4는 두 번째 주성분과 강한 음의 상관성(\\(r=-0.734\\))을 가진다.\n\n# 변수 적재 Ver.2\npcaDat &lt;- get_pca(satis.cor.prcomp)                  # 주성분 결과에서 변수에 대한 정보(좌표, 제곱 코사인, 기여) 추출\nround(pcaDat$coord,3)                                # 변수 적재\n\n   Dim.1  Dim.2  Dim.3  Dim.4  Dim.5\nx1 0.900  0.203 -0.028  0.384 -0.019\nx2 0.717  0.592 -0.326 -0.172  0.027\nx3 0.820  0.407  0.380 -0.134  0.018\nx4 0.669 -0.734 -0.029 -0.006  0.112\nx5 0.815 -0.551 -0.041 -0.133 -0.114\n\n\nCaution! 변수 적재는 package \"factoextra\"에서 제공하는 함수 get_pca()를 이용하여 계산할 수 있다.\n\n# 변수 적재 그래프\nfviz_pca_var(satis.cor.prcomp)\n\n\n\n\n\n\n\n\nResult! 그래프의 x축과 y축은 각각 첫 번째 주성분과 두 번째 주성분에 대한 변수 적재값을 의미하며, 특정 주축을 기준으로 화살표의 길이가 길수록 해당 변수와 해당 주성분은 강한 상관성을 가진다.\n\n# 주성분 점수\nsatis.cor.score &lt;- satis.cor.prcomp$x           \nsatis.cor.score\n\n             PC1        PC2         PC3          PC4         PC5\n [1,] -1.9906473  0.5778652  0.73759241  0.213431924 -0.18686461\n [2,] -2.3088242 -0.3018902 -0.25953723  0.571452234  0.16077659\n [3,]  0.4876344  1.4296420  0.11720524 -0.642443414  0.18686107\n [4,] -0.1019340  0.9936350 -0.83885655 -0.274414499  0.04561479\n [5,] -1.0377676 -1.9234789 -0.47013838  0.096087391  0.04784539\n [6,] -1.6903807  0.9472936  0.25996481 -0.061501673 -0.06398017\n [7,]  1.8279334  0.8554056 -0.06462653  0.269147743 -0.02902117\n [8,]  0.2162042 -1.4850896 -0.05593690 -0.774548937 -0.23337697\n [9,]  1.7819347 -1.2562730  0.78252584 -0.003312879  0.23734016\n[10,]  2.8158471  0.1628903 -0.20819270  0.606102111 -0.16519509\n\n\nCaution! 주성분 점수는 각 case의 관측값을 주성분에 대입함으로써 얻을 수 있으며, 고차원의 원본 데이터셋 대신 차원이 축소된 데이터셋으로 유용하게 사용될 수 있다. 함수 prcomp()를 이용한 결과 satis.cor.prcomp에는 주성분 점수가 포함되어 있다.\nResult! 첫 번째 주성분과 두 번째 주성분에 의해 얻어지는 \\(i\\)번째 case의 주성분 점수는 다음의 식을 이용하여 얻을 수 있다. \\[\n\\begin{align}\n\\begin{cases}\ny_{i1}=0.511z_{i1}+0.407z_{i2}+0.465z_{i3}+0.380z_{i4}+0.462z_{i5},\\\\\ny_{i2}=0.171z_{i1}+0.500z_{i2}+0.344z_{i3}-0.621z_{i4}-0.466z_{i5},\n\\end{cases}\n\\end{align}\n\\] 여기서 \\(z_{ij}=(x_{ij}-\\bar{x}_{j})/s_{j}\\)는 \\(i\\)번째 case의 \\(j\\)번째 변수 관찰값 \\(x_{ij}\\)에서 \\(j\\)번째 변수의 평균값 \\(\\bar{x}_j\\)을 뺀 후 \\(j\\)번째 변수의 표준편차 값 \\(s_j\\)로 나눈 것을 의미한다.\n\n# 성별에 따른 주성분 점수 그래프 Ver.1\nplot(satis.cor.score[,1:2],                          # 첫 번째와 두 번째 주성분 점수\n     xlim = c(-4, 4), ylim = c(-2, 2), main = \"성별에 따른 주성분 점수\")\nabline(v = 0, h = 0, lty = 2)\ntext(satis.cor.score[,1:2],  labels = satis$gender, pos = 4, col = \"red\")\n\n\n\n\n\n\n\n# 성별에 따른 주성분 점수 그래프 Ver.2\nsatisPca &lt;- satis %&gt;%\n  mutate(PCA1 = satis.cor.score[, 1], PCA2 = satis.cor.score[, 2])\n\nggplot(satisPca, aes(PCA1, PCA2,\n                     col = gender)) +                # 변수 gender의 범주에 따라 색깔을 다르게 표현\n  geom_point() +\n  geom_hline(yintercept=0, linetype='dashed', color='black') + \n  geom_vline(xintercept=0, linetype='dashed', color='black') + \n  theme_bw()\n\n\n\n\n\n\n\n\nResult! 그래프의 수직선을 중심으로 오른쪽에 위치하는 점들은 첫 번째 주성분 점수가 높다는 것을 의미하며, 왼쪽에 위치하는 점들은 첫 번째 주성분 점수가 낮다는 것을 의미한다. 오른쪽에 위치하는 점 5개 중 4개가 남자이므로, 이는 남자들의 전반적인 만족도가 높다고 해석할 수 있다. 마찬가지로 수평선을 중심으로 위쪽에 위치하는 점들은 두 번째 주성분 점수가 높다는 것을 의미하며, 아래쪽에 위치하는 점들은 두 번째 주성분 점수가 낮다는 것을 의미한다. 두 번째 주성분 점수가 높다는 것은 가격, 성능, 편리성 등 제품의 내형적 요인에 대해서는 만족도가 높으나 디자인, 색상 등 외형적 요인에 대해서는 만족도가 낮다고 해석할 수 있다.\n\n# 주성분 점수 예측\npredict(satis.cor.prcomp, newdata = tail(satis[,c(\"x1\", \"x2\", \"x3\", \"x4\", \"x5\")], 2))\n\n        PC1        PC2        PC3          PC4        PC5\n9  1.781935 -1.2562730  0.7825258 -0.003312879  0.2373402\n10 2.815847  0.1628903 -0.2081927  0.606102111 -0.1651951\n\n\nCaution! 함수 predict()를 이용하여 새로운 case에 대한 주성분 점수를 예측할 수 있다. 여기서는 설명의 편의상 마지막 2개의 case를 새로운 자료로 취급하여 예측을 수행하였다.\n\n# Biplot\nfviz_pca_biplot(satis.cor.prcomp, label = \"var\")\n\n\n\n\n\n\n\n\nCaution! 주성분 점수와 변수 적재를 하나의 그래프에 함께 표현한 것을 행렬도(Biplot)라고 한다. 위 Biplot에서는 주성분 점수를 점으로 표현하고, 변수 적재를 화살표로 표현한다. Biplot는 다음을 기준으로 해석할 수 있다.\n1. 점은 각 case(데이터셋에서 하나의 행)에 대한 주성분 점수를 나타낸다.\n2. 화살표는 변수 적재값을 의미하며, 정확한 변수 적재값은 알 수 없다.\n3. 화살표의 길이는 상관성의 정도를 표현한다. 즉, 주축을 기준으로 화살표의 길이가 길수록 변수와 해당 주성분은 강한 상관성을 가진다.\n4. 화살표와 주축이 평행에 가까울수록 해당 변수는 해당 주성분에만 큰 영향을 미친다.\n5. 화살표들 간의 각도가 작을수록 해당 변수들은 강한 양의 상관관계를 나타내며, 180도는 강한 음의 상관관계를 나타낸다. 또한, 직각은 상관성이 없음을 의미한다.\nBiplot을 통해서 군집성, 변수들의 상관구조 등을 시각적으로 파악할 수 있다.\nResult! Biplot의 x축과 y축은 각각 첫 번째와 두 번째 주성분 점수를 의미한다. 변수 x1과 x5는 첫 번째 주축(x축, 수평 점선)을 기준으로 화살표의 길이가 길며 이는 두 변수가 첫 번째 주성분과 강한 상관성을 가진다고 할 수 있다. 또한, 변수 x1, x2, x3의 화살표들 간의 각도가 작기 때문에(즉, 서로 가까이 위치해있기 때문에) 강한 양의 상관관계를 가지며, 변수 x4와 x5 또한 강한 양의 상관관계를 가진다.\n\n# ggbiplot을 이용한 Biplot\nggbiplot(satis.cor.prcomp,                  # 함수 prcomp에 의한 객체\n         obs.scale = 1,                     # 관찰값에 적용할 스케일\n         var.scale = 1,                     # 변수에 적용할 스케일\n         labels = satis$ID,                 # 점에 대한 라벨\n         circle = TRUE) +\n  theme_bw()\n\n\n\n\n\n\n\n\nCaution! Package \"ggbiplot\"에서 제공하는 함수 ggbiplot()를 이용하여 Biplot을 만들 수 있으며, 함수에 대한 자세한 옵션은 여기를 참고한다.\n\n# 스크리 그래프 Ver.1 (y축 : 고유값)\npar(mfrow = c(1, 2))\nscreeplot(satis.cor.prcomp, type = \"b\", main = \"\")   # 막대그래프\nscreeplot(satis.cor.prcomp, type = \"l\", main = \"\")   # 선 그래프\n\n\n\n\n\n\n\n# 스크리 그래프 Ver.2\nfviz_screeplot(satis.cor.prcomp, \n               addlabels = TRUE,                     # 막대 높이 표시 여부\n               # geom = \"line\",                      # 그래프 유형(bar / line)\n               choice = \"eigenvalue\",                # y축 (variance / eigenvalue)\n               linecolor = \"#FC4E07\",                # 선 색깔\n               barcolor = \"#00AFBB\",                 # 막대의 윤곽선 색깔\n               barfill = \"#00AFBB\")                  # 막대의 색깔\n\n\n\n\n\n\n\nfviz_screeplot(satis.cor.prcomp, \n               addlabels = TRUE,                     # 막대 높이 표시 여부\n               choice = \"variance\",                  # y축(variance / eigenvalue)\n               linecolor = \"#FC4E07\",                # 선 색깔\n               barcolor = \"#00AFBB\",                 # 막대의 윤곽선 색깔\n               barfill = \"#00AFBB\")                  # 막대의 색깔\n\n\n\n\n\n\n\n\nResult! 스크리 그래프를 보면, 첫 번째 주성분과 두 번째 주성분의 분산(고유값)이 크며 가파른 경사를 형성한다. 그러므로, 2개의 주성분 개수를 고려할 수 있다.",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Principal Component Analysis</span>"
    ]
  },
  {
    "objectID": "Principal.html#예제-2",
    "href": "Principal.html#예제-2",
    "title": "8  Principal Component Analysis",
    "section": "8.3 예제 2",
    "text": "8.3 예제 2\n\n주성분분석을 수행하기 위해 사용되는 데이터는 자유아카데미에서 출판한 책 R을 활용한 다변량 자료분석 방법론의 데이터 파일 중 “student.csv”이다.\n이 데이터는 10명의 학생에 대한 5과목 점수 데이터로 총 6개의 변수를 포함한다.\n\nID : 학생 ID\nx1 : 국어 점수\nx2 : 영어 점수\nx3 : 제2외국어 점수\nx4 : 수학 점수\nx5 : 과학 점수\n\n\n\n8.3.1 데이터 불러오기\n\nstudent &lt;- read.csv(\"./DATA/student.csv\")\nstudent\n\n   ID x1 x2 x3 x4 x5\n1   1  3 33 73  8 12\n2   2  3 30 59 28 20\n3   3 35 83 91 32 34\n4   4 35 83 85 33 32\n5   5 15 40 55 68 52\n6   6  3 53 76 10  8\n7   7 68 83 85 48 50\n8   8 15 47 77 76 76\n9   9 46 60 83 83 68\n10 10 98 83 91 80 72\n\n\n\n\n8.3.2 데이터 탐색\n\n\n8.3.2.1 기술통계량\n\ndescribe(student[,c(\"x1\", \"x2\", \"x3\", \"x4\", \"x5\")])\n\n   vars  n mean    sd median trimmed   mad min max range  skew kurtosis   se\nx1    1 10 32.1 31.56   25.0   27.50 31.88   3  98    95  0.80    -0.69 9.98\nx2    2 10 59.5 22.01   56.5   60.25 37.06  30  83    53 -0.02    -1.87 6.96\nx3    3 10 77.5 12.38   80.0   78.62  8.90  55  91    36 -0.63    -1.09 3.91\nx4    4 10 46.6 28.55   40.5   46.88 43.00   8  83    75  0.01    -1.77 9.03\nx5    5 10 42.4 24.94   42.0   42.50 35.58   8  76    68  0.00    -1.71 7.89\n\n\nResult! 변수 x1의 표준편차는 다른 변수들에 비해 상대적으로 큰 반면, 변수 x3는 다른 변수들에 비해 상대적으로 표준편차가 작다.\n\n\n8.3.2.2 상관행렬\n\ncor(student[,c(\"x1\", \"x2\", \"x3\", \"x4\", \"x5\")])\n\n          x1        x2        x3        x4        x5\nx1 1.0000000 0.7838622 0.6833432 0.5592287 0.6102284\nx2 0.7838622 1.0000000 0.8604151 0.2117815 0.3092596\nx3 0.6833432 0.8604151 1.0000000 0.1380259 0.2793357\nx4 0.5592287 0.2117815 0.1380259 1.0000000 0.9731614\nx5 0.6102284 0.3092596 0.2793357 0.9731614 1.0000000\n\n\nResult! 상대적으로 표준편차가 큰 변수 x1은 상대적으로 다른 변수들과 0.5 이상의 강한 상관성을 보인다. 그리고, 변수 x4와 x5 사이에는 매우 강한 양의 상관성을 가지고 있다(\\(r=0.973\\)).\n\n\n8.3.2.3 산점도행렬\n\nggpairs(student[,-1]) +\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\n\n8.3.3 공분산행렬을 이용한 주성분분석\n\nstudent.prcomp &lt;- prcomp(student[,c(\"x1\", \"x2\", \"x3\", \"x4\", \"x5\")]) \nstudent.prcomp\n\nStandard deviations (1, .., p=5):\n[1] 46.259833 27.802085 10.689902  5.935039  2.997379\n\nRotation (n x k) = (5 x 5):\n         PC1        PC2         PC3         PC4         PC5\nx1 0.6155240  0.4184625  0.66098180 -0.08517714  0.04321101\nx2 0.3149575  0.5395460 -0.57224849  0.52551269  0.07784525\nx3 0.1533269  0.2865461 -0.39464213 -0.75500570 -0.41061682\nx4 0.5208733 -0.5438504 -0.06785537  0.26119676 -0.60007473\nx5 0.4765646 -0.3948383 -0.27438652 -0.27986409  0.68071806\n\n\nCaution! 주성분분석은 함수 prcomp()를 통해 수행할 수 있다. 자세한 옵션은 ?prcomp를 통해 확인하거나 여기를 참고한다.\nResult! 함수 prcomp()는 5개의 결과를 리스트로 반환한다.\n\nsdev : 데이터셋을 주성분에 투영했을 때의 표준편차인 주성분의 표준편차(= 공분산행렬의 고유값의 제곱근)\n\n출력 결과의 “Standard deviations”와 동일\n\nrotation : 주축의 계수(= 공분산행렬의 단위 고유벡터)\n\n출력 결과의 “Rotation”과 동일\n\ncenter : 변수의 평균\nscale : 표준편차로 나누어 주는 작업 진행 여부\nx : 주성분 점수\n\n\nstudent.prcomp$sdev        # 주성분의 표준편차\n\n[1] 46.259833 27.802085 10.689902  5.935039  2.997379\n\nstudent.prcomp$sdev^2      # 주성분의 분산 = 주성분에 의해 설명되는 분산의 양 = 공분산행렬의 고유값\n\n[1] 2139.972189  772.955942  114.274008   35.224690    8.984282\n\n\nCaution! 주성분의 분산은 함수 eigen(cov(student[,c(\"x1\", \"x2\", \"x3\", \"x4\", \"x5\")]))를 통해 얻어진 공분산행렬의 고유값과 동일하며, 공분산행렬의 대각성분 합이 주성분 분산의 합(공분산행렬의 고유값의 합)과 같음을 알 수 있다.\n\nstudent.prcomp$rotation   # 주축의 계수 \n\n         PC1        PC2         PC3         PC4         PC5\nx1 0.6155240  0.4184625  0.66098180 -0.08517714  0.04321101\nx2 0.3149575  0.5395460 -0.57224849  0.52551269  0.07784525\nx3 0.1533269  0.2865461 -0.39464213 -0.75500570 -0.41061682\nx4 0.5208733 -0.5438504 -0.06785537  0.26119676 -0.60007473\nx5 0.4765646 -0.3948383 -0.27438652 -0.27986409  0.68071806\n\n\nCaution! 주축의 계수는 함수 eigen(cov(student[,c(\"x1\", \"x2\", \"x3\", \"x4\", \"x5\")]))를 통해 얻어진 공분산행렬의 단위 고유벡터와 동일하다.\nResult! 첫 번째 주성분은 \\(Y_1=0.616C_{1}+0.315C_{2}+0.153C_{3}+0.521C_{4}+0.477C_{5}\\)이며, 두 번째 주성분은 \\(Y_2=0.418C_1+0.540C_2+0.287C_3-0.544C_4-0.395C_{5}\\)이 된다. 여기서 확률변수 \\(C_{i}\\)는 \\(X_i-\\mu_i\\)이며, \\(\\mu_i\\)는 \\(X_i\\)의 평균을 의미한다. 또한, 변수 x1-x5는 \\(X_1\\)-\\(X_5\\)로 표현한다.\n주성분의 의미를 해석해보면, 첫 번째 주성분은 계수가 서로 비슷하므로 전반적인 평점을 나타낸다고 할 수 있으며, 두 번째 주성분은 변수 x1-x3와 변수 x4-x5의 부호가 반대이므로 국어, 영어, 제2외국어의 “인문계열”과 수학, 과학의 “이과계열”의 점수 차이를 나타낸다고 할 수 있다.\n\n# 요약\nsummary(student.prcomp)    \n\nImportance of components:\n                           PC1     PC2      PC3     PC4     PC5\nStandard deviation     46.2598 27.8021 10.68990 5.93504 2.99738\nProportion of Variance  0.6967  0.2517  0.03721 0.01147 0.00293\nCumulative Proportion   0.6967  0.9484  0.98561 0.99707 1.00000\n\n\nResult! 처음 2개의 고유값은 2139.972(= \\(46.2598^2\\)), 772.956(= \\(27.8021^2\\))로서 각각 전체 변동의 69.7%(= 2139.972/3071.411)와 25.2%(= 772.956/3071.411)를 차지한다. 따라서, 처음 2개의 주성분에 의해 데이터 변동의 약 94.8%가 설명될 수 있음을 알 수 있다. 이는 2개의 주성분만으로 데이터 변동을 충분히 설명할 수 있음을 의미한다. 만약 처음 2개의 주성분을 새로운 변수로 고려할 경우, 이는 원래 다섯 개의 예측변수들이 가지고 있는 정보를 2차원으로 축소한다는 의미이다.\n\n# 변수 적재 Ver.1\n1:5 %&gt;%                                                # 첫 번째 변수부터 다섯 번째 변수에 function을 적용\n  map_df(function(x) student.prcomp$rotation[,x]*student.prcomp$sdev[x]) \n\n# A tibble: 5 × 5\n      x1     x2    x3      x4     x5\n   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1 28.5   14.6    7.09  24.1    22.0 \n2 11.6   15.0    7.97 -15.1   -11.0 \n3  7.07  -6.12  -4.22  -0.725  -2.93\n4 -0.506  3.12  -4.48   1.55   -1.66\n5  0.130  0.233 -1.23  -1.80    2.04\n\n\nCaution! 주성분의 변수 적재(Variable Loading)는 단위 고유벡터(= 주축의 계수)와 고유값의 제곱근(= 주성분의 표준편차)을 곱함으로써 계산될 수 있다. 변수 적재를 계산하기 위해 함수 map_df()를 이용한다.\nResult! 변수 적재는 각 변수가 특정 주성분에 얼마나 기여하는지를 설명한다. 결과값의 부호는 양/음의 상관관계를 나타내며, 값의 절대값이 클수록 주성분과 변수는 강한 관계를 가지고 있다. 출력 결과는 주성분과 변수 사이의 공분산처럼 해석할 수 있다. 예를 들어, 변수 x1은 첫 번째 주성분과 양의 상관성(28.5)을 가지고 있으며, 변수 x4는 두 번째 주성분과 음의 상관성(-15.1)을 가지고 있다.\n\n# 변수 적재 Ver.2\npcaDat &lt;- get_pca(student.prcomp)                      # 주성분 결과에서 변수에 대한 정보(좌표, 제곱 코사인, 기여) 추출\nround(pcaDat$coord,3)                                  # 변수 적재\n\n    Dim.1   Dim.2  Dim.3  Dim.4  Dim.5\nx1 28.474  11.634  7.066 -0.506  0.130\nx2 14.570  15.001 -6.117  3.119  0.233\nx3  7.093   7.967 -4.219 -4.481 -1.231\nx4 24.096 -15.120 -0.725  1.550 -1.799\nx5 22.046 -10.977 -2.933 -1.661  2.040\n\n\nCaution! 변수 적재는 package \"factoextra\"에서 제공하는 함수 get_pca()를 이용하여 계산할 수 있다.\n\n# 변수 적재 그래프\nfviz_pca_var(student.prcomp)\n\n\n\n\n\n\n\n\nResult! 그래프의 x축과 y축은 각각 첫 번째 주성분과 두 번째 주성분에 대한 변수 적재값을 의미하며, 특정 주축을 기준으로 화살표의 길이가 길수록 해당 변수와 해당 주성분은 강한 상관성을 가진다.\n\n# 주성분 점수\nstudent.score &lt;- student.prcomp$x           \nstudent.score\n\n              PC1        PC2        PC3        PC4         PC5\n [1,] -61.5413668   5.231022   8.666472 -9.6242324  0.99649177\n [2,] -50.4028345 -14.434976  12.356007  2.3543318 -0.04415861\n [3,]  -0.3514567  29.018103 -13.563126  0.4473432 -0.54559251\n [4,]  -1.7036742  27.544653 -10.714355  5.7983024 -0.04340246\n [5,]  -4.3952811 -39.552990   4.649289 11.0995753  0.67528203\n [6,] -55.6467471  17.373233  -3.000589  0.2628541 -2.60147547\n [7,]  34.9998806  26.089071   5.141256  1.8678545  4.63436503\n [8,]  16.7871502 -43.299075 -15.166696 -6.4591254  3.72326437\n [9,]  40.7164010 -22.241609  -2.763239 -2.7306959 -6.03517460\n[10,]  81.5379285  14.272568  14.394982 -3.0162076 -0.75959955\n\n\nCaution! 주성분 점수는 각 case의 관측값을 주성분에 대입함으로써 얻을 수 있으며, 고차원의 원본 데이터셋 대신 차원이 축소된 데이터셋으로 유용하게 사용될 수 있다. 함수 prcomp()를 이용한 결과 student.prcomp에는 주성분 점수가 포함되어 있다.\nResult! 첫 번째 주성분과 두 번째 주성분에 의해 얻어지는 \\(i\\)번째 case의 주성분 점수는 다음의 식을 이용하여 얻을 수 있다. \\[\n\\begin{align}\n\\begin{cases}\ny_{i1}=0.616c_{i1}+0.315c_{i2}+0.153c_{i3}+0.521c_{i4}+0.477c_{i5},\\\\\ny_{i2}=0.418c_{i1}+0.540c_{i2}+0.287c_{i3}-0.544c_{i4}-0.395c_{i5},\n\\end{cases}\n\\end{align}\n\\] 여기서 \\(c_{ij}=x_{ij}-\\bar{x}_{j}\\)는 \\(i\\)번째 case의 \\(j\\)번째 변수 관찰값 \\(x_{ij}\\)에서 \\(j\\)번째 변수의 평균값 \\(\\bar{x}_j\\)을 뺀 것을 의미한다.\n\n# 주성분 점수 그래프 Ver.1\nplot(student.score[,1:2],                              # 첫 번째와 두 번째 주성분 점수\n     main = \"Case별 주성분 점수\")\nabline(v = 0, h = 0, lty = 2)\ntext(student.score[,1:2],  labels = student$ID, pos = 4, col = \"red\")\n\n\n\n\n\n\n\n# 주성분 점수 그래프 Ver.2\nstudentPca &lt;- student %&gt;%\n  mutate(PCA1 = student.score[, 1], PCA2 = student.score[, 2])\n\nggplot(studentPca, aes(PCA1, PCA2)) +\n  geom_point() +\n  geom_hline(yintercept=0, linetype='dashed', color='black') + \n  geom_vline(xintercept=0, linetype='dashed', color='black') + \n  geom_text(aes(label = ID), hjust=0, vjust=0) +\n  theme_bw()\n\n\n\n\n\n\n\n\nResult! 그래프의 수직선을 중심으로 오른쪽에 위치하는 점들은 첫 번째 주성분 점수가 높다는 것을 의미하고 왼쪽에 위치하는 점들은 첫 번째 주성분 점수가 낮다는 것을 의미한다. 그래프를 살펴보면, 그래프의 오른쪽에 위치하는 “10”, “9”, “7”번 case는 첫 번째 주성분 값이 높으며, 이는 “10”, “9”, “7”번 case의 전반적인 평점이 높다고 해석할 수 있다. 반면, 왼쪽에 위치하는 “1”, “2”, “6”번 case는 전반적인 평점이 낮다고 해석할 수 있다. 마찬가지로 수평선을 중심으로 위쪽에 위치하는 점들은 두 번째 주성분 점수가 높다는 것을 의미하고 아래쪽에 위치하는 점들은 두 번째 주성분 점수가 낮다는 것을 의미한다. 두 번째 주성분 점수가 높다는 것은 국어, 영어, 제2외국어 등 인문계열 과목에 대해서는 점수가 높으나 수학, 과학 등 이과계열 과목에 대해서는 점수가 낮다고 해석할 수 있다.\n\n# 주성분 점수 예측\npredict(student.prcomp, newdata = tail(student[,c(\"x1\", \"x2\", \"x3\", \"x4\", \"x5\")], 2))\n\n        PC1       PC2       PC3       PC4        PC5\n9  40.71640 -22.24161 -2.763239 -2.730696 -6.0351746\n10 81.53793  14.27257 14.394982 -3.016208 -0.7595996\n\n\nCaution! 함수 predict()를 이용하여 새로운 case에 대한 주성분 점수를 예측할 수 있다. 여기서는 설명의 편의상 마지막 2개의 case를 새로운 자료로 취급하여 예측을 수행하였다.\n\n# Biplot\nfviz_pca_biplot(student.prcomp, label = \"var\")\n\n\n\n\n\n\n\n\nCaution! 주성분 점수와 변수 적재를 하나의 그래프에 함께 표현한 것을 행렬도(Biplot)라고 한다. 위 Biplot에서는 주성분 점수를 점으로 표현하고, 변수 적재를 화살표로 표현한다. Biplot는 다음을 기준으로 해석할 수 있다.\n1. 점은 각 case(데이터셋에서 하나의 행)에 대한 주성분 점수를 나타낸다.\n2. 화살표는 변수 적재값을 의미하며, 정확한 변수 적재값은 알 수 없다.\n3. 화살표의 길이는 상관성의 정도를 표현한다. 즉, 주축을 기준으로 화살표의 길이가 길수록 변수와 해당 주성분은 강한 상관성을 가진다.\n4. 화살표와 주축이 평행에 가까울수록 해당 변수는 해당 주성분에만 큰 영향을 미친다.\n5. 화살표들 간의 각도가 작을수록 해당 변수들은 강한 양의 상관관계를 나타내며, 180도는 강한 음의 상관관계를 나타낸다. 또한, 직각은 상관성이 없음을 의미한다.\nBiplot을 통해서 군집성, 변수들의 상관구조 등을 시각적으로 파악할 수 있다.\nResult! Biplot의 x축과 y축은 각각 첫 번째와 두 번째 주성분 점수를 의미한다. 변수 x1과 x4는 첫 번째 주축(x축, 수평 점선)을 기준으로 화살표의 길이가 길며, 이는 두 변수가 첫 번째 주성분과 강한 상관성을 가진다고 할 수 있다. 또한, 변수 x1, x2, x3의 화살표들 간의 각도가 작기 때문에(즉, 서로 가까이 위치해있기 때문에) 강한 양의 상관관계를 가지며, 변수 x4와 x5 또한 강한 양의 상관관계를 가진다.\n\n# ggbiplot을 이용한 Biplot\nggbiplot(student.prcomp,                               # 함수 prcomp에 의한 객체\n         obs.scale = 1,                                # 관찰값에 적용할 스케일\n         var.scale = 1,                                # 변수에 적용할 스케일\n         labels = student$ID,                          # 점에 대한 라벨\n         circle = TRUE) +\n  theme_bw()\n\n\n\n\n\n\n\n\nCaution! Package \"ggbiplot\"에서 제공하는 함수 ggbiplot()를 이용하여 Biplot을 만들 수 있으며, 함수에 대한 자세한 옵션은 여기를 참고한다.\n\n# 스크리 그래프 Ver.1 (y축 : 고유값)\npar(mfrow = c(1, 2))\nscreeplot(student.prcomp, type = \"b\", main = \"\")        # 막대그래프\nscreeplot(student.prcomp, type = \"l\", main = \"\")        # 선 그래프\n\n\n\n\n\n\n\n# 스크리 그래프 Ver.2\nfviz_screeplot(student.prcomp, \n               addlabels = TRUE,                       # 막대 높이 표시 여부\n               # geom = \"line\",                        # 그래프 유형(bar / line)\n               choice = \"eigenvalue\",                  # y축 (variance / eigenvalue)\n               linecolor = \"#FC4E07\",                  # 선 색깔\n               barcolor = \"#00AFBB\",                   # 막대의 윤곽선 색깔\n               barfill = \"#00AFBB\")                    # 막대의 색깔\n\n\n\n\n\n\n\nfviz_screeplot(student.prcomp, \n               addlabels = TRUE,                       # 막대 높이 표시 여부\n               choice = \"variance\",                    # y축(variance / eigenvalue)\n               linecolor = \"#FC4E07\",                  # 선 색깔\n               barcolor = \"#00AFBB\",                   # 막대의 윤곽선 색깔\n               barfill = \"#00AFBB\")                    # 막대의 색깔\n\n\n\n\n\n\n\n\nResult! 스크리 그래프를 보면 첫 번째 주성분과 두 번째 주성분의 분산(고유값)이 크며 가파른 경사를 형성한다. 그러므로, 2개의 주성분 개수를 고려할 수 있다.\n\n\n8.3.4 상관행렬을 이용한 주성분분석\n\nstudent.cor.prcomp &lt;- prcomp(student[,c(\"x1\", \"x2\", \"x3\", \"x4\", \"x5\")], center = TRUE, scale = TRUE) \nstudent.cor.prcomp\n\nStandard deviations (1, .., p=5):\n[1] 1.7852209 1.2132058 0.4662250 0.3308475 0.1195505\n\nRotation (n x k) = (5 x 5):\n         PC1         PC2         PC3        PC4         PC5\nx1 0.5175853  0.09386107 -0.71009530  0.4642922  0.05910103\nx2 0.4516210  0.43816660 -0.11258435 -0.7683317  0.03224429\nx3 0.4206036  0.47398415  0.62887267  0.4183725 -0.16707843\nx4 0.3980188 -0.57412032  0.06907097 -0.1329413 -0.69965898\nx5 0.4391100 -0.49489900  0.28781556 -0.0372845  0.69139676\n\n\nCaution! 상관행렬에 기초하여 주성분분석을 수행한다는 것은 표준화된 변수를 이용하여 주성분분석을 수행한다는 것을 의미한다. 함수 prcomp()의 옵션 center = TRUE와 scale = TRUE를 지정하여 변수를 표준화한 후, 상관행렬에 기초한 주성분분석을 수행할 수 있다.\nResult! 상관행렬을 이용한 주성분분석 결과는 위에서 공분산행렬에 기초하여 수행한 주성분분석 결과와는 다른 것을 확인할 수 있다.\n\nstudent.cor.prcomp$sdev        # 주성분의 표준편차\n\n[1] 1.7852209 1.2132058 0.4662250 0.3308475 0.1195505\n\nstudent.cor.prcomp$sdev^2      # 주성분의 분산 = 주성분에 의해 설명되는 분산의 양 = 상관행렬의 고유값\n\n[1] 3.18701362 1.47186824 0.21736574 0.10946007 0.01429233\n\n\nCaution! 주성분의 분산은 함수 eigen(cor(student[,c(\"x1\", \"x2\", \"x3\", \"x4\", \"x5\")]))를 통해 얻어진 상관행렬의 고유값과 동일하며, 상관행렬의 대각성분 합이 주성분 분산의 합(상관행렬의 고유값의 합)인 변수 개수 “5”와 같음을 알 수 있다.\n\nstudent.cor.prcomp$rotation    # 주축의 계수\n\n         PC1         PC2         PC3        PC4         PC5\nx1 0.5175853  0.09386107 -0.71009530  0.4642922  0.05910103\nx2 0.4516210  0.43816660 -0.11258435 -0.7683317  0.03224429\nx3 0.4206036  0.47398415  0.62887267  0.4183725 -0.16707843\nx4 0.3980188 -0.57412032  0.06907097 -0.1329413 -0.69965898\nx5 0.4391100 -0.49489900  0.28781556 -0.0372845  0.69139676\n\n\nCaution! 주축의 계수는 함수 eigen(cor(student[,c(\"x1\", \"x2\", \"x3\", \"x4\", \"x5\")]))를 통해 얻어진 상관행렬의 단위 고유벡터와 동일하다.\nResult! 첫 번째 주성분은 \\(Y_1=0.518Z_{1}+0.452Z_{2}+0.421Z_{3}+0.398Z_{4}+0.439Z_{5}\\)이며, 두 번째 주성분은 \\(Y_2=0.094Z_{1}+0.438Z_{2}+0.474Z_{3}-0.574Z_{4}-0.495Z_{5}\\)이 된다. 여기서 확률변수 \\(Z_{i}\\)는 \\((X_i-\\mu_i)/\\sigma_{i}\\)이며, \\(\\mu_i\\)와 \\(\\sigma_{i}\\)는 각각 \\(X_i\\)의 평균과 표준편차를 의미한다. 또한, 변수 x1-x5는 \\(X_1\\)-\\(X_5\\)로 표현한다.\n주성분의 의미를 해석해보면, 첫 번째 주성분은 계수가 서로 비슷하므로 전반적인 평점을 나타낸다고 할 수 있으며, 두 번째 주성분은 변수 x1-x3와 변수 x4-x5의 부호가 반대이므로 국어, 영어, 제2외국어의 “인문계열”과 수학, 과학의 “이과계열”의 점수 차이를 나타낸다고 할 수 있다.\n\n# 요약\nsummary(student.cor.prcomp)    \n\nImportance of components:\n                          PC1    PC2     PC3     PC4     PC5\nStandard deviation     1.7852 1.2132 0.46622 0.33085 0.11955\nProportion of Variance 0.6374 0.2944 0.04347 0.02189 0.00286\nCumulative Proportion  0.6374 0.9318 0.97525 0.99714 1.00000\n\n\nResult! 처음 2개의 고유값은 3.187(= \\(1.7852^2\\)), 1.472(= \\(1.2132^2\\))로서 각각 전체 변동의 63.7%(= 3.187/5)와 29.4%(= 1.472/5)를 차지한다. 따라서, 처음 2개의 주성분에 의해 데이터 변동의 약 93.2%가 설명될 수 있음을 알 수 있다. 이는 2개의 주성분만으로 데이터 변동을 충분히 설명할 수 있음을 의미한다. 만약 처음 2개의 주성분을 새로운 변수로 고려할 경우, 이는 원래 다섯 개의 예측변수들이 가지고 있는 정보를 2차원으로 축소한다는 의미를 가진다.\n\n# 변수 적재 Ver.1\n1:5 %&gt;%                                                # 첫 번째 변수부터 다섯 번째 변수에 function을 적용\n  map_df(function(x) student.cor.prcomp$rotation[,x]*student.cor.prcomp$sdev[x]) \n\n# A tibble: 5 × 5\n        x1       x2      x3      x4      x5\n     &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1  0.924    0.806    0.751   0.711   0.784 \n2  0.114    0.532    0.575  -0.697  -0.600 \n3 -0.331   -0.0525   0.293   0.0322  0.134 \n4  0.154   -0.254    0.138  -0.0440 -0.0123\n5  0.00707  0.00385 -0.0200 -0.0836  0.0827\n\n\nCaution! 주성분의 변수 적재(Variable Loading)는 단위 고유벡터(= 주축의 계수)와 고유값의 제곱근(= 주성분의 표준편차)을 곱함으로써 계산될 수 있다. 변수 적재를 계산하기 위해 함수 map_df()를 이용한다.\nResult! 변수 적재는 각 변수가 특정 주성분에 얼마나 기여하는지를 설명한다. 결과값의 부호는 양/음의 상관관계를 나타내며, 값의 절대값이 클수록 주성분과 변수는 강한 관계를 가지고 있다. 출력 결과는 피어슨 상관계수처럼 해석할 수 있다. 예를 들어, 변수 x1은 첫 번째 주성분과 강한 양의 상관성(\\(r=0.924\\))을 가지고 있으며, 변수 x4는 두 번째 주성분과 강한 음의 상관성(\\(r=-0.697\\))을 가지고 있다.\n\n# 변수 적재 Ver.2\npcaDat &lt;- get_pca(student.cor.prcomp)                  # 주성분 결과에서 변수에 대한 정보(좌표, 제곱 코사인, 기여) 추출\nround(pcaDat$coord,3)                                  # 변수 적재\n\n   Dim.1  Dim.2  Dim.3  Dim.4  Dim.5\nx1 0.924  0.114 -0.331  0.154  0.007\nx2 0.806  0.532 -0.052 -0.254  0.004\nx3 0.751  0.575  0.293  0.138 -0.020\nx4 0.711 -0.697  0.032 -0.044 -0.084\nx5 0.784 -0.600  0.134 -0.012  0.083\n\n\nCaution! 변수 적재는 package \"factoextra\"에서 제공하는 함수 get_pca()를 이용하여 계산할 수 있다.\n\n# 변수 적재 그래프\nfviz_pca_var(student.cor.prcomp)\n\n\n\n\n\n\n\n\nResult! 그래프의 x축과 y축은 각각 첫 번째 주성분과 두 번째 주성분에 대한 변수 적재값을 의미하며, 특정 주축을 기준으로 화살표의 길이가 길수록 해당 변수와 해당 주성분은 강한 상관성을 가진다.\n\n# 주성분 점수\nstudent.cor.score &lt;- student.cor.prcomp$x           \nstudent.cor.score\n\n             PC1         PC2         PC3         PC4         PC5\n [1,] -2.2470840  0.59291807  0.11734892  0.57000378  0.07050020\n [2,] -2.3648070 -0.56384142 -0.43800069  0.09637971 -0.01316672\n [3,]  0.6371219  1.45367994  0.36829470 -0.24073999 -0.01752385\n [4,]  0.4119368  1.24346894  0.04275167 -0.44523585 -0.01646831\n [5,] -0.9778549 -1.92149789 -0.49632909 -0.44545382 -0.01505308\n [6,] -1.7773223  1.14510117  0.12617138 -0.03003567 -0.10059295\n [7,]  1.4790506  0.68283716 -0.45563359 -0.05657281  0.17677268\n [8,]  0.4475007 -1.57666392  0.88207761 -0.01920990  0.16749550\n [9,]  1.3831919 -0.97790554  0.34768523  0.16519787 -0.22970590\n[10,]  3.0082663 -0.07809652 -0.49436614  0.40566668 -0.02225757\n\n\nCaution! 주성분 점수는 각 case의 관측값을 주성분에 대입함으로써 얻을 수 있으며, 고차원의 원본 데이터셋 대신 차원이 축소된 데이터셋으로 유용하게 사용될 수 있다. 함수 prcomp()를 이용한 결과 student.cor.prcomp에는 주성분 점수가 포함되어 있다.\nResult! 첫 번째 주성분과 두 번째 주성분에 의해 얻어지는 \\(i\\)번째 case의 주성분 점수는 다음의 식을 이용하여 얻을 수 있다. \\[\n\\begin{align}\n\\begin{cases}\ny_{i1}=0.518z_{i1}+0.452z_{i2}+0.421z_{i3}+0.398z_{i4}+0.439z_{i5},\\\\\ny_{i2}=0.094z_{i1}+0.438z_{i2}+0.474z_{i3}-0.574z_{i4}-0.495z_{i5},\n\\end{cases}\n\\end{align}\n\\] 여기서 \\(z_{ij}=(x_{ij}-\\bar{x}_{j})/s_{j}\\)는 \\(i\\)번째 case의 \\(j\\)번째 변수 관찰값 \\(x_{ij}\\)에서 \\(j\\)번째 변수의 평균값 \\(\\bar{x}_j\\)을 뺀 후 \\(j\\)번째 변수의 표준편차 값 \\(s_j\\)로 나눈 것을 의미한다.\n\n# 주성분 점수 그래프 Ver.1\nplot(student.cor.score[,1:2], \n     main = \"Case별 주성분 점수\")\nabline(v = 0, h = 0, lty = 2)\ntext(student.cor.score[,1:2],  labels = student$ID, pos = 4, col = \"red\")\n\n\n\n\n\n\n\n# 주성분 점수 그래프 Ver.2\nstudentPca &lt;- student %&gt;%\n  mutate(PCA1 = student.cor.score[, 1], PCA2 = student.cor.score[, 2])\nggplot(studentPca, aes(PCA1, PCA2)) +\n  geom_point() +\n  geom_hline(yintercept=0, linetype='dashed', color='black') + \n  geom_vline(xintercept=0, linetype='dashed', color='black') + \n  geom_text(aes(label = ID), hjust=0, vjust=0) +\n  theme_bw()\n\n\n\n\n\n\n\n\nResult! 그래프의 수직선을 중심으로 오른쪽에 위치하는 점들은 첫 번째 주성분 점수가 높다는 것을 의미하고 왼쪽에 위치하는 점들은 첫 번째 주성분 점수가 낮다는 것을 의미한다. 그래프를 살펴보면, 그래프의 오른쪽에 위치하는 “10”, “9”, “7”번 case는 첫 번째 주성분 값이 높으며, 이는 “10”, “9”, “7”번 case의 전반적인 평점이 높다고 해석할 수 있다. 반면, 왼쪽에 위치하는 “1”, “2”, “6”번 case는 전반적인 평점이 낮다고 해석할 수 있다. 마찬가지로 수평선을 중심으로 위쪽에 위치하는 점들은 두 번째 주성분 점수가 높다는 것을 의미하고 아래쪽에 위치하는 점들은 두 번째 주성분 점수가 낮다는 것을 의미한다. 두 번째 주성분 점수가 높다는 것은 국어, 영어, 제2외국어 등 인문계열 과목에 대해서는 점수가 높으나 수학, 과학 등 이과계열 과목에 대해서는 점수가 낮다고 해석할 수 있다.\n\n# 주성분 점수 예측\npredict(student.cor.prcomp, newdata = tail(student[,c(\"x1\", \"x2\", \"x3\", \"x4\", \"x5\")], 2))\n\n        PC1         PC2        PC3       PC4         PC5\n9  1.383192 -0.97790554  0.3476852 0.1651979 -0.22970590\n10 3.008266 -0.07809652 -0.4943661 0.4056667 -0.02225757\n\n\nCaution! 함수 predict()를 이용하여 새로운 case에 대한 주성분 점수를 예측할 수 있다. 여기서는 설명의 편의상 마지막 2개의 case를 새로운 자료로 취급하여 예측을 수행하였다.\n\n# Biplot\nfviz_pca_biplot(student.cor.prcomp, label = \"var\")\n\n\n\n\n\n\n\n\nCaution! 주성분 점수와 변수 적재를 하나의 그래프에 함께 표현한 것을 행렬도(Biplot)라고 한다. 위 Biplot에서는 주성분 점수를 점으로 표현하고, 변수 적재를 화살표로 표현한다. Biplot는 다음을 기준으로 해석할 수 있다.\n1. 점은 각 case(데이터셋에서 하나의 행)에 대한 주성분 점수를 나타낸다.\n2. 화살표는 변수 적재값을 의미하며, 정확한 변수 적재값은 알 수 없다.\n3. 화살표의 길이는 상관성의 정도를 표현한다. 즉, 주축을 기준으로 화살표의 길이가 길수록 변수와 해당 주성분은 강한 상관성을 가진다.\n4. 화살표와 주축이 평행에 가까울수록 해당 변수는 해당 주성분에만 큰 영향을 미친다.\n5. 화살표들 간의 각도가 작을수록 해당 변수들은 강한 양의 상관관계를 나타내며, 180도는 강한 음의 상관관계를 나타낸다. 또한, 직각은 상관성이 없음을 의미한다.\nBiplot을 통해서 군집성, 변수들의 상관구조 등을 시각적으로 파악할 수 있다.\nResult! Biplot의 x축과 y축은 각각 첫 번째와 두 번째 주성분 점수를 의미한다. 변수 x1과 x5는 첫 번째 주축(x축, 수평 점선)을 기준으로 화살표의 길이가 길며 이는 두 변수가 첫 번째 주성분과 강한 상관성을 가진다고 할 수 있다. 또한, 변수 x1, x2, x3의 화살표들 간의 각도가 작기 때문에(즉, 서로 가까이 위치해있기 때문에) 강한 양의 상관관계를 가지며, 변수 x4와 x5 또한 강한 양의 상관관계를 가진다.\n\n# ggbiplot을 이용한 Biplot\nggbiplot(student.cor.prcomp,                           # 함수 prcomp에 의한 객체\n         obs.scale = 1,                                # 관찰값에 적용할 스케일\n         var.scale = 1,                                # 변수에 적용할 스케일\n         labels = student$ID,                          # 점에 대한 라벨\n         circle = TRUE) +\n  theme_bw()\n\n\n\n\n\n\n\n\nCaution! Package \"ggbiplot\"에서 제공하는 함수 ggbiplot()를 이용하여 Biplot을 만들 수 있으며, 함수에 대한 자세한 옵션은 여기를 참고한다.\n\n# 스크리 그래프 Ver.1 (y축 : 고유값)\npar(mfrow = c(1, 2))\nscreeplot(student.cor.prcomp, type = \"b\", main = \"\")   # 막대그래프\nscreeplot(student.cor.prcomp, type = \"l\", main = \"\")   # 선 그래프\n\n\n\n\n\n\n\n# 스크리 그래프 Ver.2\nfviz_screeplot(student.cor.prcomp, \n               addlabels = TRUE,                       # 막대 높이 표시 여부\n               # geom = \"line\",                        # 그래프 유형(bar / line)\n               choice = \"eigenvalue\",                  # y축 (variance / eigenvalue)\n               linecolor = \"#FC4E07\",                  # 선 색깔\n               barcolor = \"#00AFBB\",                   # 막대의 윤곽선 색깔\n               barfill = \"#00AFBB\")                    # 막대의 색깔\n\n\n\n\n\n\n\nfviz_screeplot(student.cor.prcomp, \n               addlabels = TRUE,                       # 막대 높이 표시 여부\n               choice = \"variance\",                    # y축(variance / eigenvalue)\n               linecolor = \"#FC4E07\",                  # 선 색깔\n               barcolor = \"#00AFBB\",                   # 막대의 윤곽선 색깔\n               barfill = \"#00AFBB\")                    # 막대의 색깔\n\n\n\n\n\n\n\n\nResult! 스크리 그래프를 보면 첫 번째 주성분과 두 번째 주성분의 분산(고유값)이 크며 가파른 경사를 형성한다. 그러므로, 2개의 주성분 개수를 고려할 수 있다.",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Principal Component Analysis</span>"
    ]
  },
  {
    "objectID": "Principal.html#예제-3",
    "href": "Principal.html#예제-3",
    "title": "8  Principal Component Analysis",
    "section": "8.4 예제 3",
    "text": "8.4 예제 3\n\nPackage \"mclust\"에서 제공하는 데이터 banknote는 100개의 진품과 100개의 위조 옛날 스위스 1000프랑 지폐에 대해 측정된 6개의 변수값을 제공한다.\n\nStatus : 지폐의 상태\n\ngenuine : 진품\ncounterfeit : 위조\n\nLength : 지폐의 길이\nLeft : 왼쪽 가장자리 너비\nRight : 오른쪽 가장자리 너비\nBottom : 하단 여백 너비\nTop : 상단 여백 너비\nDiagonal : 대각선 길이\n\n\n\n8.4.1 데이터 불러오기\n\n# 데이터 불러오기\ndata(banknote, package = \"mclust\")\n\nswissTib &lt;- as_tibble(banknote)\nswissTib\n\n# A tibble: 200 × 7\n   Status  Length  Left Right Bottom   Top Diagonal\n   &lt;fct&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n 1 genuine   215.  131   131.    9     9.7     141 \n 2 genuine   215.  130.  130.    8.1   9.5     142.\n 3 genuine   215.  130.  130.    8.7   9.6     142.\n 4 genuine   215.  130.  130.    7.5  10.4     142 \n 5 genuine   215   130.  130.   10.4   7.7     142.\n 6 genuine   216.  131.  130.    9    10.1     141.\n 7 genuine   216.  130.  130.    7.9   9.6     142.\n 8 genuine   214.  130.  129.    7.2  10.7     142.\n 9 genuine   215.  129.  130.    8.2  11       142.\n10 genuine   215.  130.  130.    9.2  10       141.\n# ℹ 190 more rows\n\n\n\n\n8.4.2 데이터 탐색\n\n\n8.4.2.1 기술통계량\n\ndescribe(swissTib[,-1])\n\n         vars   n   mean   sd median trimmed  mad   min   max range  skew kurtosis   se\nLength      1 200 214.90 0.38 214.90  214.89 0.30 213.8 216.3   2.5  0.19     0.71 0.03\nLeft        2 200 130.12 0.36 130.20  130.13 0.44 129.0 131.0   2.0 -0.19    -0.59 0.03\nRight       3 200 129.96 0.40 130.00  129.96 0.44 129.0 131.1   2.1  0.04    -0.19 0.03\nBottom      4 200   9.42 1.44   9.10    9.35 1.63   7.2  12.7   5.5  0.37    -1.05 0.10\nTop         5 200  10.65 0.80  10.60   10.66 0.89   7.7  12.3   4.6 -0.23     0.15 0.06\nDiagonal    6 200 140.48 1.15 140.45  140.52 1.56 137.8 142.4   4.6 -0.19    -1.15 0.08\n\n\nResult! 변수 Bottom의 표준편차는 다른 변수들에 비해 상대적으로 큰 반면, 변수 Left의 표준편차는 다른 변수들에 비해 상대적으로 작다.\n\n\n8.4.2.2 상관행렬\n\ncor(swissTib[,-1])\n\n              Length       Left      Right     Bottom         Top   Diagonal\nLength    1.00000000  0.2312926  0.1517628 -0.1898009 -0.06132141  0.1943015\nLeft      0.23129257  1.0000000  0.7432628  0.4137810  0.36234960 -0.5032290\nRight     0.15176280  0.7432628  1.0000000  0.4867577  0.40067021 -0.5164755\nBottom   -0.18980092  0.4137810  0.4867577  1.0000000  0.14185134 -0.6229827\nTop      -0.06132141  0.3623496  0.4006702  0.1418513  1.00000000 -0.5940446\nDiagonal  0.19430146 -0.5032290 -0.5164755 -0.6229827 -0.59404464  1.0000000\n\n\nResult! 변수 Left와 Right 사이의 상관계수는 0.74로 가장 강한 양의 상관성을 보인다. 게다가, 변수 Bottom과 Diagonal 사이의 상관계수는 -0.62로 강한 음의 상관성을 보인다.\n\n\n8.4.2.3 산점도행렬\n\nggpairs(swissTib,\n  mapping = aes(col = Status), alpha = 0.8) +               # 변수 Status의 범주에 따라 색깔을 다르게 표현\n  scale_colour_manual(values = c(\"#00798c\", \"#d1495b\")) +   # 특정 색깔 지정\n  scale_fill_manual(values = c(\"#00798c\", \"#d1495b\")) +     # 특정 색깔 지정\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\n\n8.4.3 공분산행렬을 이용한 주성분분석\n\nswissTib.prcomp &lt;- select(swissTib, -Status) %&gt;%\n  prcomp()\nswissTib.prcomp\n\nStandard deviations (1, .., p=6):\n[1] 1.7321388 0.9672748 0.4933697 0.4412015 0.2919107 0.1884534\n\nRotation (n x k) = (6 x 6):\n                 PC1         PC2       PC3        PC4         PC5         PC6\nLength    0.04377427 -0.01070966 0.3263165 -0.5616918 -0.75257278  0.09809807\nLeft     -0.11216159 -0.07144697 0.2589614 -0.4554588  0.34680082 -0.76651197\nRight    -0.13919062 -0.06628208 0.3447327 -0.4153296  0.53465173  0.63169678\nBottom   -0.76830499  0.56307225 0.2180222  0.1861082 -0.09996771 -0.02221711\nTop      -0.20176610 -0.65928988 0.5566857  0.4506985 -0.10190229 -0.03485874\nDiagonal  0.57890193  0.48854255 0.5917628  0.2584483  0.08445895 -0.04567946\n\n\nCaution! 주성분분석은 함수 prcomp()를 통해 수행할 수 있다. 자세한 옵션은 ?prcomp를 통해 확인하거나 여기를 참고한다.\nResult! 함수 prcomp()는 5개의 결과를 리스트로 반환한다.\n\nsdev : 데이터셋을 주성분에 투영했을 때의 표준편차인 주성분의 표준편차(= 공분산행렬의 고유값의 제곱근)\n\n출력 결과의 “Standard deviations”와 동일\n\nrotation : 주축의 계수(= 공분산행렬의 단위 고유벡터)\n\n출력 결과의 “Rotation”과 동일\n\ncenter : 변수의 평균\nscale : 표준편차로 나누어 주는 작업 진행 여부\nx : 주성분 점수\n\n\nswissTib.prcomp$sdev                # 주성분의 표준편차\n\n[1] 1.7321388 0.9672748 0.4933697 0.4412015 0.2919107 0.1884534\n\nswissTib.prcomp$sdev^2              # 주성분의 분산 = 주성분에 의해 설명되는 분산의 양 = 공분산행렬의 고유값\n\n[1] 3.00030487 0.93562052 0.24341371 0.19465874 0.08521185 0.03551468\n\n\nCaution! 주성분의 분산은 함수 eigen(cov(swissTib[,-1]))를 통해 얻어진 공분산행렬의 고유값과 동일하며, 공분산행렬의 대각성분 합이 주성분 분산의 합(공분산행렬의 고유값의 합)과 같음을 알 수 있다.\n\nswissTib.prcomp$rotation            # 주축의 계수\n\n                 PC1         PC2       PC3        PC4         PC5         PC6\nLength    0.04377427 -0.01070966 0.3263165 -0.5616918 -0.75257278  0.09809807\nLeft     -0.11216159 -0.07144697 0.2589614 -0.4554588  0.34680082 -0.76651197\nRight    -0.13919062 -0.06628208 0.3447327 -0.4153296  0.53465173  0.63169678\nBottom   -0.76830499  0.56307225 0.2180222  0.1861082 -0.09996771 -0.02221711\nTop      -0.20176610 -0.65928988 0.5566857  0.4506985 -0.10190229 -0.03485874\nDiagonal  0.57890193  0.48854255 0.5917628  0.2584483  0.08445895 -0.04567946\n\n\nCaution! 주축의 계수는 함수 eigen(cov(swissTib[,-1]))를 통해 얻어진 공분산행렬의 단위 고유벡터와 동일하다.\nResult! 첫 번째 주성분은 \\(Y_1=0.044C_{\\text{Length}}-0.112C_{\\text{Left}}-0.139C_{\\text{Right}}-768C_{\\text{Bottom}}-0.202C_{\\text{Top}}+0.579C_{\\text{Diagonal}}\\)이며, 두 번째 주성분은 \\(Y_2=-0.011C_{\\text{Length}}-0.071C_{\\text{Left}}-0.066C_{\\text{Right}}+0.563C_{\\text{Bottom}}-0.659C_{\\text{Top}}+0.489C_{\\text{Diagonal}}\\)가 된다. 여기서 확률변수 \\(C_{i}\\)는 \\(X_i-\\mu_i\\)이며, \\(\\mu_i\\)는 \\(X_i\\)의 평균을 의미한다. 또한, 변수 Left의 확률변수를 \\(X_{\\text{Left}}\\)로 나타내며, 다른 변수들도 동일한 방식으로 나타낸다.\n\n# 요약\nsummary(swissTib.prcomp)       \n\nImportance of components:\n                          PC1    PC2     PC3     PC4     PC5    PC6\nStandard deviation     1.7321 0.9673 0.49337 0.44120 0.29191 0.1885\nProportion of Variance 0.6675 0.2082 0.05416 0.04331 0.01896 0.0079\nCumulative Proportion  0.6675 0.8757 0.92983 0.97314 0.99210 1.0000\n\n\nResult! 처음 2개의 고유값은 3.000(= \\(1.7321^2\\)), 0.936(= \\(0.9673^2\\))로서 각각 전체 변동의 66.8%(= 3.000/4.4947)와 20.8%(= 0.936/4.4947)를 차지한다. 따라서, 처음 2개의 주성분에 의해 데이터 변동의 약 87.6%가 설명될 수 있음을 알 수 있다. 이는 2개의 주성분만으로 데이터 변동을 충분히 설명할 수 있음을 의미한다. 만약 처음 2개의 주성분을 새로운 변수로 고려할 경우, 이는 원래 여섯 개의 예측변수들이 가지고 있는 정보를 2차원으로 축소한다는 의미이다.\n\n# 변수 적재 Ver.1\n1:6 %&gt;%                                                # 첫 번째 변수부터 여섯 번째 변수에 function을 적용\n  map_df(function(x) swissTib.prcomp$rotation[,x]*swissTib.prcomp$sdev[x]) \n\n# A tibble: 6 × 6\n   Length    Left   Right   Bottom      Top Diagonal\n    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1  0.0758 -0.194  -0.241  -1.33    -0.349    1.00   \n2 -0.0104 -0.0691 -0.0641  0.545   -0.638    0.473  \n3  0.161   0.128   0.170   0.108    0.275    0.292  \n4 -0.248  -0.201  -0.183   0.0821   0.199    0.114  \n5 -0.220   0.101   0.156  -0.0292  -0.0297   0.0247 \n6  0.0185 -0.144   0.119  -0.00419 -0.00657 -0.00861\n\n\nCaution! 주성분의 변수 적재(Variable Loading)는 단위 고유벡터(= 주축의 계수)와 고유값의 제곱근(= 주성분의 표준편차)을 곱함으로써 계산될 수 있다. 변수 적재를 계산하기 위해 함수 map_df()를 이용한다.\nResult! 변수 적재는 각 변수가 특정 주성분에 얼마나 기여하는지를 설명한다. 결과값의 부호는 양/음의 상관관계를 나타내며, 값의 절대값이 클수록 주성분과 변수는 강한 관계를 가지고 있다. 출력 결과는 주성분과 변수 사이의 공분산처럼 해석할 수 있다. 예를 들어, 변수 Bottom은 첫 번째 주성분과 음의 상관성(-1.33)을 가지고 있으며, 변수 Diagonal은 첫 번째 주성분과 양의 상관성(1.00)을 가지고 있다.\n\n# 변수 적재 Ver.2\npcaDat &lt;- get_pca(swissTib.prcomp)                     # 주성분 결과에서 변수에 대한 정보(좌표, 제곱 코사인, 기여) 추출\nround(pcaDat$coord,3)                                  # 변수 적재\n\n          Dim.1  Dim.2 Dim.3  Dim.4  Dim.5  Dim.6\nLength    0.076 -0.010 0.161 -0.248 -0.220  0.018\nLeft     -0.194 -0.069 0.128 -0.201  0.101 -0.144\nRight    -0.241 -0.064 0.170 -0.183  0.156  0.119\nBottom   -1.331  0.545 0.108  0.082 -0.029 -0.004\nTop      -0.349 -0.638 0.275  0.199 -0.030 -0.007\nDiagonal  1.003  0.473 0.292  0.114  0.025 -0.009\n\n\nCaution! 변수 적재는 package \"factoextra\"에서 제공하는 함수 get_pca()를 이용하여 계산할 수 있다.\n\n# 변수 적재 그래프\nfviz_pca_var(swissTib.prcomp)\n\n\n\n\n\n\n\n\nResult! 그래프의 x축과 y축은 각각 첫 번째 주성분과 두 번째 주성분에 대한 변수 적재값을 의미하며, 특정 주축을 기준으로 화살표의 길이가 길수록 해당 변수와 해당 주성분은 강한 상관성을 가진다.\n\n# 주성분 점수\nswissTib.score &lt;- swissTib.prcomp$x           \nswissTib.score\n\n               PC1          PC2          PC3           PC4          PC5           PC6\n  [1,]  0.54964810  0.506373006  0.275864575 -1.1937281200  1.170503449  0.0583625153\n  [2,]  2.01862924  0.661263637 -0.501997459  0.0154448639  0.291137175  0.1458244963\n  [3,]  1.83567546  1.175307339  0.045629151  0.1890654554  0.112681238  0.1257882398\n  [4,]  2.49436724 -0.118891563  0.076525211  0.3161376917  0.080763695  0.0705279928\n  [5,]  0.70132282  3.194766676 -0.838773875 -0.5210495315 -0.082627733  0.2687933598\n  [6,]  0.84584597  0.482494017  0.770296914 -1.0753024458  0.096059409 -0.1112801721\n  [7,]  2.15605260  0.438516644 -0.307217041 -0.4169825947 -0.454181069  0.3929406516\n  [8,]  2.54441845 -0.595292540 -0.261088782  0.6981655399  0.032076696 -0.1250175937\n  [9,]  1.80171073 -0.155434257  0.493392385  0.7299232166 -0.184633318  0.3415617957\n [10,]  0.35794585  0.366247704  0.008309448 -0.7179691519  0.157770550  0.0509543013\n [11,]  1.65490951 -0.950213178  1.354817025  0.0344015973  0.132142242 -0.0198609195\n [12,]  2.47187462  0.036578902  0.340253464  0.3727030793 -0.227660283  0.2361946209\n [13,]  1.65312961 -0.533379672  0.446734754 -0.3098899888  0.029792115 -0.7288186081\n [14,]  2.04785612 -0.488042059  0.222785259  0.5158103065  0.113203777  0.1157189104\n [15,]  2.12100032 -0.391832074  0.408611849  0.1808168227 -0.099829048  0.0005736733\n [16,]  1.21102652  1.934684021 -0.828495022 -0.2686782727  0.428034852  0.1352993260\n [17,]  1.80316035  0.478981674 -0.123504166 -0.0879583708  0.533790574  0.2325214800\n [18,]  1.53889558  1.576808851 -0.283448877 -0.3064857901  0.037340223  0.0200594112\n [19,]  2.08852993 -1.141828097  0.475826274  0.4849402367 -0.399270717  0.1731352480\n [20,]  1.56983259  0.660812466  0.234767930  0.0185733945  0.412167442 -0.1389561442\n [21,]  1.56433776  0.361917180 -0.291351040  0.0694554716 -0.260671607 -0.2313080432\n [22,]  1.71161398 -0.002774378  0.521080211 -0.7004988527 -0.113567156 -0.2030970200\n [23,]  1.29800080 -0.216283697  0.733654611 -0.3222003143  0.057497407 -0.3287041959\n [24,]  1.34918672  0.553219058  0.439831066 -0.6435750104 -0.322274617  0.0337937361\n [25,]  1.94085465 -0.901700553 -0.053874530 -0.0479036365 -0.091389813  0.3188561808\n [26,]  1.99484719 -0.194759972  1.317293970 -0.1747853359  0.289171720  0.0426484337\n [27,]  1.67632658  1.184039245  0.814718624 -0.4189290182 -0.050340816  0.0433285541\n [28,]  0.69936696  1.628202711  0.512367561 -0.4198004286  0.290669000  0.0670794392\n [29,]  2.35904830 -0.389996104  0.305515445 -0.1803699626  0.155807553  0.1305542642\n [30,]  2.20395298  1.274456689 -0.631836800 -0.0413547510 -0.016942787 -0.0879524907\n [31,]  1.95554198 -0.235277204  0.515444918 -0.0158252813 -0.062064302 -0.0807067836\n [32,]  2.07127921  1.497499308 -0.195339622 -0.0290497874  0.182075048  0.1408713745\n [33,]  1.54306350 -0.730887434 -0.450541775 -0.1865296237 -0.105691015 -0.0883519764\n [34,]  1.13107842 -0.126461743  0.240006298 -0.7957224630 -0.175447744 -0.0425335990\n [35,]  0.94500822  0.156119745  0.816149915 -0.5910540390 -0.501455713 -0.1161118168\n [36,]  0.91169363  1.241389316  0.253791873 -0.0620241229  0.589970865  0.0379949634\n [37,]  1.73601743  0.674790092  0.286404111 -0.7161348899 -0.059627191 -0.0544902140\n [38,]  2.29504463  0.363665479  0.087063794 -0.0785701389 -0.332319045 -0.1550080674\n [39,]  1.89089003  1.136889758  0.232270889 -0.7294635823  0.200454366 -0.0129222050\n [40,]  1.74620974  0.345014679 -0.941723111  0.4128449365  0.597598359 -0.8136390458\n [41,]  1.82112732  1.498914224 -0.239924093  0.5487878718  0.189897375 -0.3079901961\n [42,]  0.91479705  0.376771710 -0.465743357 -0.1337475440  0.047572305 -0.1972822565\n [43,]  1.26365194  1.690411695 -0.550134670  0.0150627141 -0.198720366  0.0531649223\n [44,]  0.73812255  0.526181884 -0.333014151 -0.3759355271  0.120017132 -0.3552139106\n [45,]  1.52124882 -0.026850433 -0.724014015  0.4421278740 -0.424658300  0.0217324317\n [46,]  1.83267939  0.398616340 -0.262643806  0.7781984711  0.204274076  0.0467759486\n [47,]  1.59427412  0.198235336 -0.070010043  0.1130356860  0.101765850 -0.0075669306\n [48,]  2.51079381 -0.582068554  0.397529158  0.3716405792  0.172631429 -0.0325906724\n [49,]  1.64961714 -0.278536451 -0.420837792  0.1421800681  0.232398692  0.2129582819\n [50,]  2.45031623  0.498829813 -0.471247441  0.5888797395  0.094926019  0.5919070628\n [51,]  2.40820093 -0.357823417 -0.734103424  0.0489703966  0.170657952 -0.0994979211\n [52,]  0.44324726  0.932897624  0.124419645 -0.7166289554  0.025841868 -0.2965266152\n [53,]  1.41252740 -0.868890349 -0.087081730  0.1332184197  0.485270251  0.0133254006\n [54,]  1.97176231 -0.669564823  0.672075357 -0.3572237943  0.028679983  0.1237696225\n [55,]  1.95484578  0.108202955 -0.624054523  0.4019107152  0.099128575  0.2403468157\n [56,]  1.43536270  1.506593687 -0.047942678  0.0402123815 -0.395238578 -0.0194824773\n [57,]  0.75871371  0.429680850  0.276179378 -0.1333312922 -0.836954168 -0.1987022011\n [58,]  1.30484070  1.114679077 -0.981571828 -0.2892295672 -0.274669156  0.1014909625\n [59,]  1.58726469 -0.682892683  0.388410821  0.0047963234 -0.006142010 -0.0149648033\n [60,]  1.58103488  0.010159066  0.062944381 -0.1419364900 -0.044500081  0.0116847555\n [61,]  1.81515116  0.489610577 -0.295526018  0.1379329241 -0.402890340  0.0050270479\n [62,]  2.23446492 -0.421190240 -0.069475945  0.0342034223 -0.454872742  0.0125915323\n [63,]  1.82329709 -0.213798767  0.153731508  0.0706123280 -0.555624021 -0.0688442859\n [64,]  1.64930545 -0.405789904 -0.001526942  0.5078050669  0.215690463 -0.2496690709\n [65,]  1.26669582  0.087526222  0.343703598  0.1497303596 -0.031354679 -0.0220374640\n [66,]  0.62142325 -0.200105638  0.262660711 -0.4626413756  0.054026798 -0.3084534737\n [67,]  2.02500521 -0.239383753 -0.604721580  0.4969376221 -0.120867180 -0.0174498615\n [68,]  1.19897497  1.150998273 -0.474957628  0.2036569183 -0.190097571 -0.1003158159\n [69,]  1.65102134  0.789028710  0.004931014 -0.0072796083 -0.138472768  0.3085602855\n [70,]  0.42421948 -1.613853150 -0.420394007 -0.3836217149  0.165490711  0.1467350481\n [71,]  0.98379298 -0.600833086 -0.323407605  1.0725097420  0.560344001 -0.1615400619\n [72,]  1.63838565  0.036117420 -0.033739929 -0.0279608998 -0.314832961 -0.0913632733\n [73,]  1.12644279  0.394910567 -0.111725893 -0.1635607520  0.069592607  0.5696434087\n [74,]  2.31846822 -0.292534589 -0.064893116  0.4431028265  0.424070951 -0.1163636125\n [75,]  2.72355404 -0.396018424  0.398424119  0.0189883305 -0.079384330  0.0147599439\n [76,]  2.20566769 -0.372407984 -0.269933228  0.9557525733  0.346583897 -0.1099739890\n [77,]  1.02550545  0.437482875 -0.079340187 -0.1838854280  0.185428185  0.2644886210\n [78,]  1.95980970 -0.787345660 -0.534016433  0.2790766477  0.064185353 -0.1111527479\n [79,]  1.34931238 -0.835402258  0.197780036 -0.3404725871 -0.019737485 -0.3531718029\n [80,]  2.14862225  0.273453732 -0.259710324  0.2629244341  0.177590110 -0.2145408264\n [81,]  0.85815888 -0.127383774 -0.435418704 -0.0960812590 -0.309559739  0.2061253972\n [82,]  1.92880318 -0.549720784 -0.512378419 -0.0890955373 -0.034082217  0.0528519412\n [83,]  1.51236086  1.167222642 -0.087137522  0.2369543443 -0.574657138 -0.2104377647\n [84,]  1.63199534 -0.552105673  0.309705335 -0.1415125545 -0.061018830  0.0018167522\n [85,]  0.56814054 -0.244262154  0.981419113 -0.3376413072  0.007961563 -0.2792902782\n [86,]  1.16034248  0.539493994  0.124224951  0.0977260515 -0.237451782 -0.0546374513\n [87,]  1.50358830  0.929537541 -0.182778253 -0.3268418541 -0.159472848  0.0426186276\n [88,]  1.97678343  0.600101284  0.122058405  0.5186795986 -0.379436221 -0.1034715024\n [89,]  2.01565718 -1.010725734  0.495618401  0.0748181732  0.260227894 -0.1928858992\n [90,]  2.06244161  0.073656039  0.392733725  0.2092985788 -0.007099607 -0.0145795374\n [91,]  1.61646362  0.853458383 -0.501755524  0.2376866669 -0.066600774 -0.1070708894\n [92,]  1.47081626  0.564813562 -0.073292143 -0.5665636198 -0.185655680  0.1185339672\n [93,]  1.81993080  0.387624008 -0.424613547  0.2138414564 -0.213254725  0.2718388404\n [94,]  2.27227416 -0.579870111 -0.327259775  0.6877104365  0.013976457  0.0194957524\n [95,]  1.98118749  0.610126057 -0.064732361  0.4279928856  0.028662467  0.0703695141\n [96,]  1.32065858  1.129773190  0.141277838 -0.5529071875 -0.375116030  0.1969641338\n [97,]  0.61722905  0.375641454  0.269286204 -0.4307225904  0.331684997  0.0083128636\n [98,]  1.66367916 -0.151348417 -0.508542409  0.4235729638  0.220966851 -0.0029600236\n [99,]  0.96762720  0.631707331  0.262672076  0.0063358915 -0.115834896 -0.0093927147\n[100,]  1.87127286 -0.084194683 -0.578042467 -0.0124704376  0.096334317 -0.2517528269\n[101,] -0.89159170 -0.882695441  0.192358026  0.4946599805  0.356557732  0.1731725382\n[102,] -2.03276398 -0.192711717  0.419190415  0.1474300332 -0.069388751 -0.1557595453\n[103,]  0.13556700 -1.256738478  0.357044941  0.1230593704  0.076452446 -0.0534748517\n[104,] -0.64352995 -0.046122324  0.463393480 -0.2977046045  0.273207592  0.1921906630\n[105,] -2.39959336  0.767976332  0.269470902  0.2850302004  0.028609728  0.1117497738\n[106,] -1.29444242  0.325271430  0.078281373 -0.1037242705 -0.093393781  0.1025059040\n[107,] -0.38861272 -1.186894946  0.841059130  0.1903269988 -0.325318206 -0.0415093835\n[108,] -0.86658814 -0.656588058  0.326999269  0.1827662641  0.127823376  0.2757635365\n[109,] -1.32327254 -1.028106424  0.216189620  0.3208237297 -0.358320895 -0.0926636207\n[110,] -1.12972786  0.007939095  0.925412403 -0.3559369788  0.218429005  0.1632810625\n[111,]  0.10890978 -2.031187632 -0.305932947 -0.6529237434 -0.001810051  0.0938459172\n[112,] -1.38326503 -0.133585228  0.786775819  0.0741844217 -0.075775683 -0.0914910877\n[113,] -0.58352194 -0.664393894  1.478916384 -0.4207422545  0.297163757  0.2766914059\n[114,] -1.95466880  0.584608459  0.335445636  0.2700481650 -0.219716714 -0.2783466403\n[115,] -1.40940003  0.166674685  0.005178609 -0.1289932152 -0.267983342 -0.0850248226\n[116,]  0.07066808 -1.704114494 -0.434859084 -0.7948202933 -0.377400259 -0.0602194935\n[117,] -2.27802324  1.065224167  0.140610914  0.0314780387  0.109606518 -0.3118188208\n[118,] -2.40801561  1.363218477  0.157733017  0.1591772454  0.028892166 -0.1662636313\n[119,] -1.64680739  0.382275462  0.404097351  0.1074741183  0.099049143 -0.1709797145\n[120,] -1.56232459 -1.129010900 -0.020482061  0.6698297987  0.056143983 -0.1480941573\n[121,] -1.41424219 -1.044092469  0.600680753  0.3403915790  0.080714169  0.1085846043\n[122,] -2.72775470  1.429298466  0.163736887 -0.3701096988 -0.120797203 -0.1377552749\n[123,] -2.04833645  0.995100482  0.981695095 -0.7007308710  0.305661639  0.2081201691\n[124,] -1.51381685 -0.208440108  0.447528304 -0.3156400022  0.053833533 -0.1506726857\n[125,] -0.64868005  0.254439504 -0.095442583 -0.4553187587  0.524443917  0.0529915029\n[126,] -1.29789145 -0.499290997  0.153272964  0.1655148706 -0.090713695  0.3073577331\n[127,] -0.43066579 -0.824759203  0.615939521 -0.0180486685  0.136483603  0.0571266898\n[128,] -1.19928567 -0.624028603  0.989715230 -0.2066626131 -0.306474129 -0.2025570848\n[129,] -0.79541139 -0.157492569  0.572618470  0.1208508742 -0.146025000  0.0842372357\n[130,] -1.03983436 -1.069350199  0.657958411  0.4930810935  0.434064264  0.2751070283\n[131,] -1.39161376  0.485335554 -0.367797924  0.2751521809  0.328414609 -0.0831841198\n[132,] -3.07288619  0.642737189  0.011976609  0.7040728683 -0.210985596 -0.2224446743\n[133,] -1.49388121 -0.222523597  0.568686675  0.1763660733  0.004381910 -0.1651444875\n[134,] -1.60068286 -0.562935722  0.488900778  0.4633543811  0.195578141  0.1626190190\n[135,] -1.94679534  0.048295493 -0.105717520  0.6331341148  0.314582472  0.1692854110\n[136,] -2.58912576  0.614047217  0.222046652  0.4145336868 -0.235526995  0.0718138568\n[137,] -1.71407541 -0.093545919 -0.207234706  0.3728020166 -0.024072155  0.3765459882\n[138,] -1.39714937 -1.559316230 -0.742302896 -0.7469262040  0.152601642 -0.1428501980\n[139,] -1.97810287  0.581376816  0.217601418  0.0962955268  0.295312320  0.0218337318\n[140,] -2.34473155  1.167961043 -0.201433521 -0.0390699074  0.292585063 -0.1720240456\n[141,] -1.44559383 -1.101331577  0.229643132  0.2411854007 -0.002391541  0.1449634220\n[142,] -1.33222908 -0.369196263 -0.681629213  0.3679911561 -0.414408363 -0.2485736999\n[143,] -1.80077325  0.654142228  0.147514642  0.1495514447  0.254585052  0.1762757647\n[144,] -1.43663547  0.026864973  0.447590602 -0.1431484309  0.076815895 -0.0150518283\n[145,] -2.03653755  1.004553063 -0.896674443  0.2037656106 -0.129006344  0.1414180546\n[146,] -2.38785607  1.099504837  0.331096256 -0.1868483804  0.109490712 -0.1049118835\n[147,] -1.97057301  0.741038723  0.399334090 -0.1745412556  0.037602643 -0.0188820190\n[148,] -1.50438050 -1.720092895 -0.700356436 -0.9326768458 -0.210189568 -0.0213097524\n[149,] -1.72046694 -0.050638476 -0.161160352  0.1309124351 -0.003884051  0.0200672030\n[150,] -1.31179649 -1.332252752  0.341214885  0.6337661616 -0.364402833  0.1789280559\n[151,] -2.30478889  1.088150977  0.136710043  0.2025239207 -0.272065629 -0.1942925548\n[152,] -2.60745691  1.072009980 -0.885469119  0.2041729820 -0.308560480  0.0105163978\n[153,] -1.38480977 -0.178594295 -0.723641822  0.6653974096 -0.508204150 -0.1006109616\n[154,] -2.65239635  1.208452214 -0.336768684  0.2338592246  0.043327233  0.0703959516\n[155,] -2.00000324 -0.160882044  0.167924994  0.5462644238  0.055349850 -0.1680357361\n[156,] -2.12528390  0.929083363  0.081926517 -0.0660557951 -0.281025088  0.3226783159\n[157,] -1.33217222 -0.416509721 -0.431523978  0.9788334736 -0.060651874  0.0288011639\n[158,] -2.22469755  0.404269129 -0.473969666  0.3112645242  0.087440800  0.0103825500\n[159,] -3.04719021  1.524825796 -0.127792063 -0.3655618513  0.171059220  0.1918588963\n[160,] -0.86241165 -3.000166826 -0.932355198 -0.3708874095  0.231228659 -0.2084083290\n[161,]  0.10020751 -3.164448462 -0.674478027 -0.4946996746 -0.806588579  0.0094933900\n[162,] -1.72187620 -0.632345702 -1.407266646 -0.9634917575  0.001341007 -0.0852227910\n[163,] -2.17575650  0.727233398 -0.243241640  0.2686124612 -0.047539385  0.0153407779\n[164,] -2.56813830  0.376009259 -0.189560658  0.1798184042 -0.090217352  0.1570823935\n[165,] -1.94064341  0.872341430 -0.189286248  0.3598820571  0.293117294 -0.1753872931\n[166,] -1.50454223 -0.833164090  0.814634407  0.1068147496 -0.039484736  0.2588278881\n[167,] -1.37620426 -0.217297249 -0.414843807 -1.8110960811 -0.763190479  0.0576096900\n[168,] -1.36184169 -1.216638049 -0.417580792 -0.7870399153 -0.589822523  0.0090637181\n[169,] -0.88153408 -1.191351572  0.125576895  0.6336489097 -0.318623114  0.0507657549\n[170,] -2.00540794  0.581407725  0.057839952  0.3554721667 -0.365138600  0.0408799154\n[171,] -1.35775957 -2.341764569 -1.259361885 -0.3739799041  0.999285232 -0.0888965415\n[172,] -2.55057911  1.263387279 -0.160881345  0.0380474630  0.639973783 -0.1562087312\n[173,] -2.52182855  0.862624464 -0.020412164 -0.1655905131  0.072815927 -0.0807466749\n[174,] -1.64122205 -0.664417166 -0.168126619  0.5524484684 -0.388729841  0.4215002971\n[175,] -2.01210434  0.783567484 -0.196272843  0.1184382671 -0.169421046  0.0361000312\n[176,] -2.84106039  0.604358632 -0.151715710 -0.1293096537 -0.154747412 -0.0483770214\n[177,] -2.14368135  0.943762811 -0.222177093  0.4208176651  0.248782869  0.0412093038\n[178,] -1.20907678 -1.068196898  0.291515836  0.5471935855  0.157489161 -0.2422454305\n[179,] -1.78903691 -1.239717703  0.343920547  0.1802194442  0.044382915 -0.0872694467\n[180,] -0.93787249 -2.785161762 -1.169531340 -0.3995771655  0.340289152  0.2906995435\n[181,] -2.38072122  0.377234005 -0.203392148 -0.2111551467 -0.225040114 -0.0951962838\n[182,] -0.24206379 -2.239420068 -0.632797442 -0.8182316943  0.496935500  0.1171389326\n[183,] -2.11007127 -0.218933997  0.243327653  0.0360343039 -0.204812763 -0.1964976488\n[184,] -1.47786367 -0.741299778  0.020000898 -0.0313852766  0.346582806 -0.0262324473\n[185,] -1.68275336 -0.067713210 -0.046315499  0.2018271179 -0.005628386  0.0120133825\n[186,] -2.28309435  0.589945100 -0.136429297  0.0950306652 -0.037392542 -0.2037209340\n[187,] -0.42644265 -2.807288944 -0.662328338 -0.0005654899  0.234142510 -0.1567572615\n[188,] -2.21086838  0.549250797 -0.506625374  0.2302735557 -0.408470455 -0.0619718933\n[189,] -1.03281411 -1.249643924  0.089448854  0.3707575443 -0.111463981  0.3160662329\n[190,] -3.01901435  2.217746342 -0.873433550 -0.4357976113  0.136305624  0.0277091587\n[191,] -1.47881365 -0.975863721  0.313621003  0.3884790105 -0.517227117 -0.1539527869\n[192,] -0.79641081 -1.573381673 -0.570336478 -1.1669385327 -0.036947394  0.2533867300\n[193,] -1.95838966 -0.171741653 -0.141672723  0.0558246016  0.047182415  0.0100139915\n[194,] -1.44469751 -1.147609643 -0.689041426 -0.6946211924  0.015266135  0.0114327265\n[195,] -2.15781177  0.879460057  0.278143028 -0.1025063214  0.078715724  0.1913906445\n[196,] -1.24912344 -1.159365339  0.613762475  0.1868186645 -0.068591937 -0.0071732341\n[197,] -1.30622574 -0.457121697  0.294978650  0.1721962348 -0.362789805 -0.1659304862\n[198,] -1.36506781  0.092150553  0.389711315  0.0861265133  0.166416182  0.1140630049\n[199,] -2.29848688  0.016918735  0.429981485 -0.2043538867  0.473408258  0.0609186590\n[200,] -1.27744022 -0.525136661 -0.150637600  0.7592775113  0.102098968  0.0689855007\n\n\nCaution! 주성분 점수는 각 case의 관측값을 주성분에 대입함으로써 얻을 수 있으며, 고차원의 원본 데이터셋 대신 차원이 축소된 데이터셋으로 유용하게 사용될 수 있다. 함수 prcomp()를 이용한 결과 swissTib.prcomp에는 주성분 점수가 포함되어 있다.\nResult! 첫 번째 주성분과 두 번째 주성분에 의해 얻어지는 \\(i\\)번째 case의 주성분 점수는 다음의 식을 이용하여 얻을 수 있다. \\[\n\\begin{align}\n\\begin{cases}\ny_{i1}=0.044c_{i1}-0.112c_{i2}-0.139c_{i3}-0.768c_{i4}-0.202c_{i5}+0.579c_{i6},\\\\\ny_{i2}=-0.011c_{i1}-0.071c_{i2}-0.066c_{i3}+0.563c_{i4}-0.659c_{i5}+0.489c_{i6},\n\\end{cases}\n\\end{align}\n\\] 여기서 \\(c_{ij}=x_{ij}-\\bar{x}_{j}\\)는 \\(i\\)번째 case의 \\(j\\)번째 변수 관찰값 \\(x_{ij}\\)에서 \\(j\\)번째 변수의 평균값 \\(\\bar{x}_j\\)을 뺀 것을 의미한다.\n\n# 지폐의 상태에 따른 주성분 점수 그래프 Ver.1\nplot(swissTib.score[,1:2],                             # 첫 번째와 두 번째 주성분 점수\n     main = \"지폐의 상태별 주성분 점수\")\nabline(v = 0, h = 0, lty = 2)\ntext(swissTib.score[,1:2],  labels = swissTib$Status, pos = 4, col = \"red\")\n\n\n\n\n\n\n\n# 지폐의 상태에 따른 주성분 점수 그래프 Ver.2\nswissTibPca &lt;- swissTib %&gt;%\n  mutate(PCA1 = swissTib.score[, 1], PCA2 = swissTib.score[, 2])\nggplot(swissTibPca, aes(PCA1, PCA2, \n                        col = Status)) +               # 변수 Status의 범주에 따라 색깔을 다르게 표현\n  geom_point() +\n  geom_hline(yintercept=0, linetype='dashed', color='black') + \n  geom_vline(xintercept=0, linetype='dashed', color='black') + \n  theme_bw()\n\n\n\n\n\n\n\n\nResult! 그래프의 수직선을 중심으로 오른쪽에 위치하는 점들은 첫 번째 주성분 점수가 높다는 것을 의미하고 왼쪽에 위치하는 점들은 첫 번째 주성분 점수가 낮다는 것을 의미한다. 오른쪽에 위치하는 점들은 대부분 “진품”(genuine)이므로, 전반적으로 진품인 지폐가 위조 지폐보다 첫 번째 주성분 점수가 높다고 해석할 수 있다. 마찬가지로 수평선을 중심으로 위쪽에 위치하는 점들은 두 번째 주성분 점수가 높다는 것을 의미하고 아래쪽에 위치하는 점들은 두 번째 주성분 점수가 낮다는 것을 의미한다.\n\n# 주성분 점수 예측\npredict(swissTib.prcomp, newdata = tail(swissTib[,-1], 2))\n\n           PC1         PC2        PC3        PC4       PC5        PC6\n[1,] -2.298487  0.01691873  0.4299815 -0.2043539 0.4734083 0.06091866\n[2,] -1.277440 -0.52513666 -0.1506376  0.7592775 0.1020990 0.06898550\n\n\nCaution! 함수 predict()를 이용하여 새로운 case에 대한 주성분 점수를 예측할 수 있다. 여기서는 설명의 편의상 마지막 2개의 case를 새로운 자료로 취급하여 예측을 수행하였다.\n\n# Biplot\nfviz_pca_biplot(swissTib.prcomp, label = \"var\")\n\n\n\n\n\n\n\n\nCaution! 주성분 점수와 변수 적재를 하나의 그래프에 함께 표현한 것을 행렬도(Biplot)라고 한다. 위 Biplot에서는 주성분 점수를 점으로 표현하고, 변수 적재를 화살표로 표현한다. Biplot는 다음을 기준으로 해석할 수 있다.\n1. 점은 각 case(데이터셋에서 하나의 행)에 대한 주성분 점수를 나타낸다.\n2. 화살표는 변수 적재값을 의미하며, 정확한 변수 적재값은 알 수 없다.\n3. 화살표의 길이는 상관성의 정도를 표현한다. 즉, 주축을 기준으로 화살표의 길이가 길수록 변수와 해당 주성분은 강한 상관성을 가진다.\n4. 화살표와 주축이 평행에 가까울수록 해당 변수는 해당 주성분에만 큰 영향을 미친다.\n5. 화살표들 간의 각도가 작을수록 해당 변수들은 강한 양의 상관관계를 나타내며, 180도는 강한 음의 상관관계를 나타낸다. 또한, 직각은 상관성이 없음을 의미한다.\nBiplot을 통해서 군집성, 변수들의 상관구조 등을 시각적으로 파악할 수 있다.\nResult! Biplot의 x축과 y축은 각각 첫 번째와 두 번째 주성분 점수를 의미한다. 변수 Bottom과 Diagonal은 첫 번째 주축(x축, 수평 점선)을 기준으로 화살표의 길이가 길며 이는 두 변수가 첫 번째 주성분과 강한 상관성을 가진다고 할 수 있다. 또한, 변수 Right와 Left의 화살표들 간의 각도가 작기 때문에(즉, 서로 가까이 위치해있기 때문에) 강한 양의 상관관계를 가지며, 변수 Right와 Diagonal은 화살표들 간의 각도가 180도를 이루므로 강한 음의 상관관계를 가진다.\n\n# ggbiplot을 이용한 Biplot\nggbiplot(swissTib.prcomp,                              # 함수 prcomp에 의한 객체\n         obs.scale = 1,                                # 관찰값에 적용할 스케일\n         var.scale = 1,                                # 변수에 적용할 스케일\n         circle = TRUE) +\n  theme_bw()\n\n\n\n\n\n\n\n\nCaution! Package \"ggbiplot\"에서 제공하는 함수 ggbiplot()를 이용하여 Biplot을 만들 수 있으며, 함수에 대한 자세한 옵션은 여기를 참고한다.\n\n# 스크리 그래프 Ver.1 (y축 : 고유값)\npar(mfrow = c(1, 2))\nscreeplot(swissTib.prcomp, type = \"b\", main = \"\")      # 막대그래프\nscreeplot(swissTib.prcomp, type = \"l\", main = \"\")      # 선 그래프\n\n\n\n\n\n\n\n# 스크리 그래프 Ver.2\nfviz_screeplot(swissTib.prcomp, \n               addlabels = TRUE,                       # 막대 높이 표시 여부\n               # geom = \"line\",                        # 그래프 유형(bar / line)\n               choice = \"eigenvalue\",                  # y축 (variance / eigenvalue)\n               linecolor = \"#FC4E07\",                  # 선 색깔\n               barcolor = \"#00AFBB\",                   # 막대의 윤곽선 색깔\n               barfill = \"#00AFBB\")                    # 막대의 색깔\n\n\n\n\n\n\n\nfviz_screeplot(swissTib.prcomp, \n               addlabels = TRUE,                       # 막대 높이 표시 여부\n               choice = \"variance\",                    # y축(variance / eigenvalue)\n               linecolor = \"#FC4E07\",                  # 선 색깔\n               barcolor = \"#00AFBB\",                   # 막대의 윤곽선 색깔\n               barfill = \"#00AFBB\")                    # 막대의 색깔\n\n\n\n\n\n\n\n\nResult! 스크리 그래프를 보면 첫 번째 주성분과 두 번째 주성분의 분산(고유값)이 크며 가파른 경사를 형성한다. 그러므로, 2개의 주성분 개수를 고려할 수 있다.\n\n\n8.4.4 상관행렬을 이용한 주성분분석\n\nswissTib.cor.prcomp &lt;- select(swissTib, -Status) %&gt;%\n  prcomp(center = TRUE, scale = TRUE)\nswissTib.cor.prcomp\n\nStandard deviations (1, .., p=6):\n[1] 1.7162629 1.1305237 0.9322192 0.6706480 0.5183405 0.4346031\n\nRotation (n x k) = (6 x 6):\n                  PC1         PC2         PC3        PC4        PC5         PC6\nLength    0.006987029 -0.81549497  0.01768066  0.5746173 -0.0587961  0.03105698\nLeft     -0.467758161 -0.34196711 -0.10338286 -0.3949225  0.6394961 -0.29774768\nRight    -0.486678705 -0.25245860 -0.12347472 -0.4302783 -0.6140972  0.34915294\nBottom   -0.406758327  0.26622878 -0.58353831  0.4036735 -0.2154756 -0.46235361\nTop      -0.367891118  0.09148667  0.78757147  0.1102267 -0.2198494 -0.41896754\nDiagonal  0.493458317 -0.27394074 -0.11387536 -0.3919305 -0.3401601 -0.63179849\n\n\nCaution! 상관행렬에 기초하여 주성분분석을 수행한다는 것은 표준화된 변수를 이용하여 주성분분석을 수행한다는 것을 의미한다. 함수 prcomp()의 옵션 center = TRUE와 scale = TRUE를 지정하여 변수를 표준화한 후, 상관행렬에 기초한 주성분분석을 수행할 수 있다.\nResult! 상관행렬을 이용한 주성분분석 결과는 위에서 공분산행렬에 기초하여 수행한 주성분분석 결과와는 다른 것을 확인할 수 있다.\n\nswissTib.cor.prcomp$sdev        # 주성분의 표준편차\n\n[1] 1.7162629 1.1305237 0.9322192 0.6706480 0.5183405 0.4346031\n\nswissTib.cor.prcomp$sdev^2      # 주성분의 분산 = 주성분에 의해 설명되는 분산의 양 = 상관행렬의 고유값\n\n[1] 2.9455582 1.2780838 0.8690326 0.4497687 0.2686769 0.1888799\n\n\nCaution! 주성분의 분산은 함수 eigen(cor(swissTib[,-1]))를 통해 얻어진 상관행렬의 고유값과 동일하며, 상관행렬의 대각성분 합이 주성분 분산의 합(상관행렬의 고유값의 합)인 변수 개수 “6”과 같음을 알 수 있다.\n\nswissTib.cor.prcomp$rotation    # 주축의 계수\n\n                  PC1         PC2         PC3        PC4        PC5         PC6\nLength    0.006987029 -0.81549497  0.01768066  0.5746173 -0.0587961  0.03105698\nLeft     -0.467758161 -0.34196711 -0.10338286 -0.3949225  0.6394961 -0.29774768\nRight    -0.486678705 -0.25245860 -0.12347472 -0.4302783 -0.6140972  0.34915294\nBottom   -0.406758327  0.26622878 -0.58353831  0.4036735 -0.2154756 -0.46235361\nTop      -0.367891118  0.09148667  0.78757147  0.1102267 -0.2198494 -0.41896754\nDiagonal  0.493458317 -0.27394074 -0.11387536 -0.3919305 -0.3401601 -0.63179849\n\n\nCaution! 주축의 계수는 함수 eigen(cor(swissTib[,-1]))를 통해 얻어진 상관행렬의 단위 고유벡터와 동일하다.\nResult! 첫 번째 주성분은 \\(Y_1=0.007Z_{\\text{Length}}-0.468Z_{\\text{Left}}-0.487Z_{\\text{Right}}-0.407Z_{\\text{Bottom}}-0.368Z_{\\text{Top}}+0.493Z_{\\text{Diagonal}}\\)이며, 두 번째 주성분은 \\(Y_2=-0.815Z_{\\text{Length}}-0.342Z_{\\text{Left}}-0.252Z_{\\text{Right}}+0.266Z_{\\text{Bottom}}+0.091Z_{\\text{Top}}-0.274Z_{\\text{Diagonal}}\\)가 된다. 여기서 확률변수 \\(Z_{i}\\)는 \\((X_i-\\mu_i)/\\sigma_{i}\\)이며, \\(\\mu_i\\)와 \\(\\sigma_{i}\\)는 각각 \\(X_i\\)의 평균과 표준편차를 의미한다. 또한, 변수 Left의 확률변수를 \\(X_{\\text{Left}}\\)로 나타내며, 다른 변수들도 동일한 방식으로 나타낸다.\n\n# 요약\nsummary(swissTib.cor.prcomp)  \n\nImportance of components:\n                          PC1    PC2    PC3     PC4     PC5     PC6\nStandard deviation     1.7163 1.1305 0.9322 0.67065 0.51834 0.43460\nProportion of Variance 0.4909 0.2130 0.1448 0.07496 0.04478 0.03148\nCumulative Proportion  0.4909 0.7039 0.8488 0.92374 0.96852 1.00000\n\n\nResult! 처음 3개의 고유값은 2.9456(= \\(1.7163^2\\)), 1.2781(= \\(1.1305^2\\)), 0.8690(= \\(0.9322^2\\))로서 각각 전체 변동의 49.1%(= 2.9456/6), 21.3%(= 1.2781/6) 그리고 14.5%(= 0.8690/6)를 차지한다. 따라서, 처음 3개의 주성분에 의해 데이터 변동의 약 84.9%가 설명될 수 있음을 알 수 있다. 이는 3개의 주성분만으로 데이터 변동을 충분히 설명할 수 있음을 의미한다. 만약 처음 3개의 주성분을 새로운 변수로 고려할 경우, 이는 원래 여섯 개의 예측변수들이 가지고 있는 정보를 3차원으로 축소한다는 의미를 가진다.\n\n# 변수 적재 Ver.1\n1:6 %&gt;%                                                # 첫 번째 변수부터 여섯 번째 변수에 function을 적용\n  map_df(function(x) swissTib.cor.prcomp$rotation[,x]*swissTib.cor.prcomp$sdev[x]) \n\n# A tibble: 6 × 6\n   Length    Left  Right Bottom     Top Diagonal\n    &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1  0.0120 -0.803  -0.835 -0.698 -0.631     0.847\n2 -0.922  -0.387  -0.285  0.301  0.103    -0.310\n3  0.0165 -0.0964 -0.115 -0.544  0.734    -0.106\n4  0.385  -0.265  -0.289  0.271  0.0739   -0.263\n5 -0.0305  0.331  -0.318 -0.112 -0.114    -0.176\n6  0.0135 -0.129   0.152 -0.201 -0.182    -0.275\n\n\nCaution! 주성분의 변수 적재(Variable Loading)는 단위 고유벡터(= 주축의 계수)와 고유값의 제곱근(= 주성분의 표준편차)을 곱함으로써 계산될 수 있다. 변수 적재를 계산하기 위해 함수 map_df()를 이용한다.\nResult! 변수 적재는 각 변수가 특정 주성분에 얼마나 기여하는지를 설명한다. 결과값의 부호는 양/음의 상관관계를 나타내며, 값의 절대값이 클수록 주성분과 변수는 강한 관계를 가지고 있다. 출력 결과는 피어슨 상관계수처럼 해석할 수 있다. 예를 들어, 변수 Length는 첫 번째 주성분과 상관관계(\\(r=0.0120\\))가 매우 작지만 두 번째 주성분과는 매우 강한 음의 상관관계(\\(r=-0.922)\\)를 가지고 있음을 알 수 있다.\n\n# 변수 적재 Ver.2\npcaDat &lt;- get_pca(swissTib.cor.prcomp)                 # 주성분 결과에서 변수에 대한 정보(좌표, 제곱 코사인, 기여) 추출\nround(pcaDat$coord,3)                                  # 변수 적재\n\n          Dim.1  Dim.2  Dim.3  Dim.4  Dim.5  Dim.6\nLength    0.012 -0.922  0.016  0.385 -0.030  0.013\nLeft     -0.803 -0.387 -0.096 -0.265  0.331 -0.129\nRight    -0.835 -0.285 -0.115 -0.289 -0.318  0.152\nBottom   -0.698  0.301 -0.544  0.271 -0.112 -0.201\nTop      -0.631  0.103  0.734  0.074 -0.114 -0.182\nDiagonal  0.847 -0.310 -0.106 -0.263 -0.176 -0.275\n\n\nCaution! 변수 적재는 package \"factoextra\"에서 제공하는 함수 get_pca()를 이용하여 계산할 수 있다.\n\n# 변수 적재 그래프\nfviz_pca_var(swissTib.cor.prcomp)\n\n\n\n\n\n\n\n\nResult! 그래프의 x축과 y축은 각각 첫 번째 주성분과 두 번째 주성분에 대한 변수 적재값을 의미하며, 특정 주축을 기준으로 화살표의 길이가 길수록 해당 변수와 해당 주성분은 강한 상관성을 가진다.\n\n# 주성분 점수\nswissTib.cor.score &lt;- swissTib.cor.prcomp$x           \nswissTib.cor.score\n\n               PC1          PC2          PC3         PC4           PC5           PC6\n  [1,] -1.74302723 -1.646696046 -1.420197269 -2.74796911  0.0032937589  0.6020220037\n  [2,]  2.26862482  0.537444608 -0.531315146 -0.65735578 -0.1581717423  0.4565426787\n  [3,]  2.27170086  0.107407538 -0.715619112 -0.34083839 -0.4538808889 -0.0453290484\n  [4,]  2.27783852  0.087434897  0.604117608 -0.39182554 -0.2829134846 -0.0554387538\n  [5,]  2.62553969 -0.039097788 -3.188383676  0.42401683 -0.2775028948  0.7202643316\n  [6,] -0.75650894 -3.081013588 -0.784511718 -0.59803217  0.1927570170 -0.1052939323\n  [7,]  2.51212347 -1.223914242 -0.243028293  0.92666684 -0.6209939573  0.7623806863\n  [8,]  2.70215331  1.131990218  1.185984540 -0.25489648  0.2458745002 -0.2393701002\n  [9,]  2.03311114  0.313693202  0.979796097  0.29444051 -1.2210768567 -0.1956448226\n [10,] -0.31691634 -1.302449879 -0.742024634 -0.43024244  0.0704451956  0.3825258001\n [11,] -0.25684271 -1.826416610  1.346535045 -0.78169056 -0.5414585644 -0.6833334095\n [12,]  2.52605080 -0.372122462  0.673006474  0.28633636 -0.8002767382 -0.0916020731\n [13,]  0.30721041 -1.558830894  0.597963961 -0.61394121  1.6110356758 -0.9373997188\n [14,]  1.74166195  0.406674107  1.008149839 -0.42434228 -0.4974469349 -0.1376898240\n [15,]  1.57859924 -0.684207226  0.861691722 -0.08046661 -0.2077781876 -0.2722968073\n [16,]  2.09422804  0.727798602 -2.050905233 -0.79377044  0.0069318902  0.6447823719\n [17,]  1.36211305  0.150698829 -0.456956263 -1.23294931 -0.5088709819  0.4486898066\n [18,]  2.07824378 -0.456923492 -1.443545924 -0.15091308  0.0772541813  0.1877694996\n [19,]  1.72486230 -0.458341595  1.820279740  0.62109053 -0.6611664945 -0.2077811017\n [20,]  1.09755099 -0.176118481 -0.462225954 -1.12434457  0.1374025300 -0.3053397375\n [21,]  2.05665920 -0.084775033 -0.048684085  0.41471507  0.6484600011 -0.2134641156\n [22,]  0.47997337 -2.458512773 -0.010557251 -0.18210027  0.4572981592 -0.2241356583\n [23,] -0.01154140 -1.767499290  0.325846098 -0.56280252  0.5291457489 -0.6334309723\n [24,]  0.83903036 -2.314523925 -0.456575884  0.42514390 -0.0970701595 -0.0039669750\n [25,]  1.38153551 -0.508591370  1.048210521  0.07960705 -0.6146044238  0.5452994474\n [26,]  0.12940523 -2.069093575  0.539573332 -1.12639649 -0.6642942613 -0.5378339795\n [27,]  1.09279715 -2.119988984 -0.852545180 -0.23021905 -0.4290578166 -0.3323551552\n [28,]  0.38483795 -1.222844289 -1.569468922 -0.78259656 -0.3979192770 -0.1323605219\n [29,]  1.30962894 -1.055833340  0.568310663 -0.63432640 -0.3596878615  0.1570092793\n [30,]  3.05535927  0.262790255 -1.000556641 -0.04100923  0.4370154053  0.1597932702\n [31,]  1.19038715 -1.127231208  0.599683840 -0.21097213 -0.0235547092 -0.3544184137\n [32,]  2.57177114  0.008234914 -1.175533236 -0.47143473 -0.3315843299  0.1927393140\n [33,]  1.23400097 -0.272548354  0.673372688  0.09700056  0.5438181773  0.3102510874\n [34,]  0.14767195 -2.228338214 -0.074365675  0.10871734  0.2605659065  0.1777147834\n [35,]  0.16674388 -2.784331855  0.023030759  0.71784506  0.0908959286 -0.4198388237\n [36,]  0.60373577 -0.009960454 -1.166121838 -1.38002108 -0.3105800812 -0.0990390053\n [37,]  1.01332986 -2.113126677 -0.687440354 -0.18248475  0.1791382904  0.0399559684\n [38,]  2.33951794 -1.031747713  0.077519897  0.42222494  0.3470937235 -0.2712703806\n [39,]  1.17276379 -1.840938197 -1.189771912 -0.72317731  0.0644320729  0.1220857255\n [40,]  2.05842348  2.040327774 -0.286393637 -1.47297233  2.1410908327 -0.5859214668\n [41,]  2.81507908  1.181647553 -0.897090265 -0.53377750  0.5410031413 -0.6073202143\n [42,]  1.15155397  0.152676082 -0.417268403 -0.16060157  0.6933449254  0.0626321516\n [43,]  2.65628881  0.334079096 -1.372078468  0.49597047  0.0316946314  0.1813594149\n [44,]  0.63377815 -0.385068927 -0.707912169 -0.40049617  1.0547016072 -0.1019621997\n [45,]  2.73503274  1.027948734  0.462709764  0.97705790  0.1911319352  0.1885645650\n [46,]  2.54930393  1.656867408  0.199467885 -0.45894990 -0.2606788895 -0.1465741008\n [47,]  1.55052072  0.079030544  0.046376648 -0.35092684  0.0024140200 -0.0115079206\n [48,]  1.72549354 -0.144374856  1.087502727 -0.70433751 -0.1876940869 -0.3308582222\n [49,]  1.58100415  0.671903074  0.362893604 -0.50582285 -0.3222338706  0.5185182750\n [50,]  3.36965253  1.387109976  0.080788625 -0.08243455 -1.3564689130  0.7141831758\n [51,]  2.35341742  0.616362387  0.425227815 -0.49408573  0.5903184605  0.3613244550\n [52,]  0.01142424 -1.595014250 -1.157897691 -0.27037330  0.7843382774 -0.1922022204\n [53,]  0.48760780  0.482111720  0.831210215 -1.18649830  0.0076347166  0.1817918585\n [54,]  0.48994608 -1.889954092  0.795327169 -0.42945304 -0.4365297552  0.0265598383\n [55,]  2.59509858  1.254565995  0.211875040 -0.15402281 -0.3885096078  0.4905063286\n [56,]  2.50565335 -0.454521438 -0.983541426  0.76930386 -0.0211832493 -0.2175726194\n [57,]  1.32546313 -1.517392252  0.013941238  1.61351995  0.3945096517 -0.5068921818\n [58,]  2.54197955  0.168009836 -1.106114831  0.71293494  0.2677857661  0.6786208271\n [59,]  0.71650994 -0.820089939  0.908099975 -0.25880374 -0.0944537434 -0.1586388791\n [60,]  1.24559439 -0.711133841  0.149631564 -0.08920674 -0.0022161679  0.0518287936\n [61,]  2.60683072 -0.094551035 -0.035537300  0.78578207  0.0847004174  0.0167241898\n [62,]  2.26806043 -0.740182653  0.836208573  0.76793725  0.0631941919  0.0349585349\n [63,]  1.95374910 -0.947931648  0.708381380  0.96459262  0.1227532887 -0.2514731825\n [64,]  1.42301809  0.795819960  0.784346581 -0.67259155  0.4403310994 -0.4537657255\n [65,]  1.03648264 -0.410441711  0.267731425 -0.12286195 -0.1579274927 -0.2958084339\n [66,] -0.33416537 -1.333583736  0.032582076 -0.39298541  0.7465038653 -0.2815266784\n [67,]  2.70475739  1.151810323  0.664534295  0.22795377  0.2061527256  0.1193613091\n [68,]  2.38688911  0.586063649 -0.783872162  0.42124763  0.3283914122 -0.0829902732\n [69,]  2.05160923 -0.410598644 -0.427359073  0.25542936 -0.7515948802  0.2952673183\n [70,] -0.62591369 -0.223734665  1.102182918 -0.35921185  0.0901564338  0.7973822768\n [71,]  1.20495042  2.728005687  0.990842309 -1.19897845  0.2011647398 -0.3569577274\n [72,]  1.73834439 -0.645544753  0.274635660  0.49223791  0.2609679487 -0.1166766172\n [73,]  1.19123675 -0.260083839 -0.339212551 -0.06362926 -1.2364400900  0.8252768312\n [74,]  1.87982128  0.823206215  0.645914923 -1.13924364  0.1654715580 -0.1958917789\n [75,]  1.94135064 -1.087031066  0.842540444 -0.19708279 -0.1826151888 -0.1641566339\n [76,]  2.46165926  2.009499702  0.975067917 -0.86000331  0.0966906957 -0.3139745378\n [77,]  0.89297654 -0.246771261 -0.439652347 -0.40996627 -0.5523649425  0.4511967216\n [78,]  1.89372232  0.792906265  0.962598191 -0.25379026  0.4847676228  0.1487337035\n [79,]  0.19507158 -1.269360736  0.770255219 -0.31494781  0.8959062403 -0.2951881543\n [80,]  2.24087922  0.531775283  0.064417675 -0.57793940  0.5154354420 -0.2193422107\n [81,]  1.29950041 -0.100582579  0.183581226  0.72933152 -0.2051343987  0.5234638614\n [82,]  1.76769749  0.002493116  0.580919302 -0.02220452  0.2011955567  0.4708246446\n [83,]  2.74302037 -0.245988252 -0.506941672  1.10807065  0.4119601329 -0.5144925759\n [84,]  0.81000071 -1.059445501  0.716625056 -0.13366041 -0.0553073438 -0.0460336963\n [85,] -0.81500738 -1.987666332  0.322327825 -0.42167747  0.3036368360 -0.7189156334\n [86,]  1.50758827 -0.397619120 -0.151345803  0.38101671  0.0180530199 -0.2652069724\n [87,]  1.80886284 -0.817055135 -0.792898086  0.24113458  0.0424346934  0.2038807660\n [88,]  2.77393403  0.118235751  0.194772338  0.63872614  0.0076300948 -0.5406287923\n [89,]  0.58847178 -0.693302786  1.219814117 -0.96306971  0.2518180915 -0.3940712718\n [90,]  1.71537540 -0.494081586  0.421792307 -0.25844594 -0.2138126274 -0.3296869219\n [91,]  2.52282651  0.698105255 -0.498393284  0.10864483  0.3616838905 -0.0382197728\n [92,]  1.32115183 -1.436391560 -0.576533908  0.26356835 -0.0815018768  0.3800362123\n [93,]  2.60669203  0.408414313  0.001505584  0.49246170 -0.4978549842  0.4248280928\n [94,]  2.56930917  1.248639201  1.123039546 -0.12807804 -0.0540257525 -0.0248379622\n [95,]  2.48400403  0.563060512 -0.056879843 -0.15991239 -0.3022611867 -0.1149519472\n [96,]  1.53375149 -1.776770211 -0.966297607  0.68837574 -0.3982453905  0.2588410046\n [97,] -0.21280535 -0.960052064 -0.554381669 -0.87198381 -0.0562549518  0.0743546318\n [98,]  1.95329181  1.287129729  0.394898559 -0.49763426  0.1204893240  0.1559605222\n [99,]  1.08082317 -0.580439010 -0.321885643  0.11454362 -0.1385999696 -0.2388736538\n[100,]  1.88437784  0.344701792  0.140167952 -0.35858976  0.8689961574  0.0674241336\n[101,] -1.24817986  1.214064407  0.860740287 -0.64365111 -0.6103966783  0.0103746574\n[102,] -2.03959577  0.102933919  0.108582386  0.22612493  0.1214588721 -0.5119086614\n[103,] -0.80427139 -0.212647903  1.252473411 -0.30195497  0.0008279999 -0.1854177252\n[104,] -1.46271664 -0.730104545 -0.203551509 -0.59968638 -0.5870082397  0.1509323381\n[105,] -1.63976014  0.789276237 -0.776889671  0.21576289 -0.5447766670 -0.2472112629\n[106,] -0.99857947 -0.089434931 -0.463449253  0.34923901 -0.2649326658  0.0698856980\n[107,] -1.14906242 -0.922768562  1.421229342  0.53101300 -0.2606457469 -0.5531754850\n[108,] -1.25489817  0.257181831  0.602516809 -0.17326706 -0.8145071082  0.1472949461\n[109,] -1.23224288  0.243022630  1.097025281  0.83583715  0.0995353114 -0.3492968059\n[110,] -2.23725861 -1.351311926 -0.220264116 -0.54533679 -0.7246452251 -0.1412647186\n[111,] -1.30867123 -0.996080863  1.362226088 -0.04944002  0.2815458210  0.8063760776\n[112,] -1.78674965 -0.609041732  0.189696615  0.10897948 -0.1792090589 -0.6099681889\n[113,] -2.67377298 -2.198567983  0.510441232 -0.88426478 -1.1831056436 -0.2015426136\n[114,] -1.26094137  0.306741926 -0.462643076  0.56205046  0.3594113422 -0.7751142087\n[115,] -1.01686823 -0.216824472 -0.308423914  0.68717550  0.2322022938 -0.1196733984\n[116,] -0.86063524 -1.455671660  1.092940875  0.74251709  0.7429438030  0.6644183755\n[117,] -1.69103233  0.465999831 -1.232541330 -0.09774733  0.5477108554 -0.5960354362\n[118,] -1.42773350  0.675561522 -1.404420556  0.15711984  0.1465560810 -0.5297589094\n[119,] -1.59823792  0.143661947 -0.435952430 -0.16518233  0.1263698719 -0.5334174459\n[120,] -1.40300081  1.619800861  1.146309226  0.02994303  0.2099665460 -0.3733052856\n[121,] -2.00187783  0.262712853  1.042221048 -0.12380619 -0.5807074449 -0.2622468759\n[122,] -2.01348013 -0.419716163 -1.751336841  0.46623933  0.2479028672 -0.2840571942\n[123,] -2.96166576 -1.768196414 -1.427873929 -0.64400281 -0.8271125790 -0.0549001839\n[124,] -2.17201089 -0.818476837 -0.112462910 -0.14935554  0.2382209463 -0.2806393493\n[125,] -1.28814766 -0.133458461 -0.784461379 -1.07472539  0.0122688196  0.3800423810\n[126,] -1.19832125  0.331458872  0.436391263  0.39529463 -0.7989977406  0.2402561010\n[127,] -1.44459242 -0.593762123  0.756014350 -0.39632472 -0.3706156350 -0.1722772657\n[128,] -2.10610456 -1.680516209  0.616922050  0.46401980  0.1196439602 -0.7156059090\n[129,] -0.95954404 -0.424881937  0.292197948  0.30843114 -0.4883332509 -0.2942351041\n[130,] -1.90582139  0.755570228  1.087190464 -0.87105724 -1.0587674852 -0.1001761223\n[131,] -0.75002782  1.570912698 -0.661883665 -0.47148010  0.2176872040 -0.0334824079\n[132,] -1.53361686  1.780003113 -0.491795112  0.79396358  0.2372221670 -0.7381589889\n[133,] -1.75566719 -0.065879254  0.230628924 -0.02170491  0.0630385891 -0.6032102227\n[134,] -1.80837560  0.806330643  0.595750498 -0.28303785 -0.7336557651 -0.2225865371\n[135,] -1.26731287  2.058332264 -0.075361340 -0.33630512 -0.5727664014 -0.0007424578\n[136,] -1.47289617  0.881151815 -0.506901781  0.81414889 -0.4442043459 -0.3560092010\n[137,] -0.91329946  1.338595631  0.033672655  0.42932400 -0.8878407977  0.4002202229\n[138,] -2.31694378 -0.211175617  0.531794642 -0.20719585  1.0137111796  0.7681572393\n[139,] -1.79175853  0.626609426 -0.775410474 -0.44955920 -0.2544343208 -0.1766201386\n[140,] -1.63382043  0.944744477 -1.518343810 -0.37319709  0.3910118964 -0.1774512486\n[141,] -1.76055329  0.450017862  0.975286811  0.13871105 -0.4476239707  0.0346732516\n[142,] -0.10606970  1.376423117  0.349209306  1.12961144  0.8276306900 -0.1258778884\n[143,] -1.41583130  0.762454321 -0.785712223 -0.30646626 -0.5959254724  0.0176787113\n[144,] -1.81142833 -0.452979809 -0.218131516 -0.13698827 -0.1470087408 -0.2134303138\n[145,] -0.16931148  1.832523942 -1.200606811  0.78128066 -0.0380245605  0.4510962529\n[146,] -2.07680914 -0.136142521 -1.355217757 -0.08406270  0.0456348730 -0.3523198160\n[147,] -1.85341461 -0.351121681 -0.933627075  0.03164911 -0.1568146825 -0.2607599578\n[148,] -2.31142569 -0.923783854  0.697062685  0.59434432  0.8057825942  0.9411039029\n[149,] -1.26343765  0.794228457 -0.143703039  0.23712433 -0.0155647197  0.0443470633\n[150,] -1.12096421  0.708421176  1.580414915  0.93188751 -0.6628326354 -0.2004270620\n[151,] -1.13171767  0.471807579 -1.018436909  0.79026014  0.2467408906 -0.5891233945\n[152,] -0.49165437  1.758575860 -1.268228190  1.18646330  0.2620746563  0.2427488362\n[153,]  0.38772039  1.952716962  0.370307710  1.43353860  0.4044697350 -0.0919580807\n[154,] -1.21106095  1.500336868 -1.376575151  0.33643107 -0.1786298166  0.0274975677\n[155,] -1.54700322  1.283604553  0.208187834  0.04747871  0.1336038557 -0.5527711237\n[156,] -1.13362590  0.030013110 -1.012388234  0.93413834 -0.8221469676  0.2234511175\n[157,] -0.05049575  2.611150466  0.672822851  0.46262615 -0.1426521792 -0.1520943339\n[158,] -1.13613669  1.725073388 -0.615451899  0.18970818  0.0578095209  0.0898328596\n[159,] -2.21440405  0.317386438 -2.047134891  0.03823744 -0.4019605854  0.3202103405\n[160,] -2.19783308  0.634696942  2.014489322 -0.41834941  1.2380269548  0.7868518127\n[161,] -0.68427763 -1.043942695  2.658285084  1.72858039  0.7335533102  0.8337633639\n[162,] -1.61334556  0.147408420 -0.553270634  0.32296485  1.2067489324  1.1997014671\n[163,] -1.01444709  1.246079978 -0.814583224  0.43502358 -0.0644333982 -0.0699971012\n[164,] -1.59038890  1.052262062 -0.577611033  0.57983382 -0.3629750098  0.1418498575\n[165,] -1.07669124  1.605196064 -0.973280132 -0.38526426  0.2904090676 -0.3399942181\n[166,] -2.20486996 -0.510257459  0.806435360  0.12916476 -0.9634770449 -0.1313499877\n[167,] -1.89039067 -3.420802466 -0.844138509  1.69723275  0.6923018210  1.0458057315\n[168,] -1.63037296 -1.334064768  0.560853892  1.38392365  0.5436555389  0.6399823656\n[169,] -0.57435829  0.912928882  1.443996931  0.79921795 -0.2754172596 -0.2386009170\n[170,] -0.78251892  0.721780357 -0.426419222  1.05390682 -0.2626991926 -0.2833825366\n[171,] -2.75902164  1.872022293  1.009760921 -1.90256428  1.0208586589  1.1681497352\n[172,] -2.06615208  1.411628076 -1.702969804 -1.09746681  0.2812016636 -0.1758609753\n[173,] -1.97180043  0.314292144 -1.220794341  0.08732511  0.1690929239 -0.1131739003\n[174,] -0.63984073  1.269089208  0.792824745  1.21910705 -1.0024932873  0.3536287829\n[175,] -0.89393628  0.759347159 -0.872765972  0.66453609 -0.0828866475 -0.0241483775\n[176,] -2.01103013  0.391237281 -0.961598591  0.64725335  0.1767300072 -0.0259012836\n[177,] -1.03714661  1.792791981 -1.017471976 -0.18307063 -0.2161453649 -0.0978203064\n[178,] -1.55310195  1.019357572  1.104433033 -0.33466455  0.3083894155 -0.5989072039\n[179,] -2.38284402  0.273049099  1.024526193 -0.03808574  0.0582251291 -0.2714517033\n[180,] -1.97629369  1.050734684  1.707897557 -0.43207450  0.1859228698  1.5470825897\n[181,] -1.70512049  0.121227992 -0.734256487  0.73260609  0.3581514977  0.0011347184\n[182,] -2.10485911 -0.399210884  1.145828476 -1.04172866  0.4173228725  1.1939993044\n[183,] -1.95712913 -0.015000958  0.065515697  0.53950939  0.3442440894 -0.4282288993\n[184,] -2.07246806  0.497971678  0.318610653 -0.64183485  0.0850126772  0.0860564380\n[185,] -1.26643023  0.781848229 -0.055500622  0.21683821 -0.0724660221 -0.0626626583\n[186,] -1.48992543  0.780517027 -0.787827605  0.30719688  0.4534926102 -0.3065154334\n[187,] -1.58082782  0.953505558  2.176806427 -0.46398374  0.8617617123  0.5079820118\n[188,] -0.62015961  1.147994321 -0.614841171  1.24316524  0.2866153011 -0.0337563362\n[189,] -1.09596509  0.699168683  1.243446813  0.42757572 -0.7969037438  0.2688742257\n[190,] -1.29355762  1.053245343 -2.859331709  0.23472206  0.3061555772  0.5009818363\n[191,] -1.21207560  0.137185695  1.149574688  1.16453649  0.1786861126 -0.5436476487\n[192,] -2.04897360 -1.478264612  0.497023843  0.18590496  0.1662191904  1.3334594669\n[193,] -1.67306977  0.714400053 -0.125440280  0.13094882  0.0263370142  0.0737605418\n[194,] -1.96314676 -0.253349716  0.256642915  0.15252852  0.5948015026  0.8400292274\n[195,] -1.76990787  0.041648199 -1.080599456  0.06751608 -0.6203745368  0.0253450228\n[196,] -1.95097274 -0.239523601  1.134322280  0.12260092 -0.2529937438 -0.3506217082\n[197,] -1.13267674 -0.129876377  0.529912864  0.80592482  0.2372649200 -0.4753165224\n[198,] -1.51318687  0.145823810 -0.180133252 -0.25742175 -0.4995676196 -0.1198111587\n[199,] -2.98678212 -0.001793364 -0.506587263 -0.88804668 -0.3230792182 -0.0275417785\n[200,] -0.64393392  1.986895264  0.657170427  0.02876048 -0.3019169936 -0.1245704452\n\n\nCaution! 주성분 점수는 각 case의 관측값을 주성분에 대입함으로써 얻을 수 있으며, 고차원의 원본 데이터셋 대신 차원이 축소된 데이터셋으로 유용하게 사용될 수 있다. 함수 prcomp()를 이용한 결과 swissTib.cor.prcomp에는 주성분 점수가 포함되어 있다.\nResult! 첫 번째 주성분과 두 번째 주성분에 의해 얻어지는 \\(i\\)번째 case의 주성분 점수는 다음의 식을 이용하여 얻을 수 있다. \\[\n\\begin{align}\n\\begin{cases}\ny_{i1}=0.007z_{i1}-0.468z_{i2}-0.487z_{i3}-0.407z_{i4}-0.368z_{i5}+0.493z_{i6},\\\\\ny_{i2}=-0.815z_{i1}-0.342z_{i2}-0.252z_{i3}+0.266z_{i4}+0.091z_{i5}-0.274z_{i6},\n\\end{cases}\n\\end{align}\n\\] 여기서 \\(z_{ij}=(x_{ij}-\\bar{x}_{j})/s_{j}\\)는 \\(i\\)번째 case의 \\(j\\)번째 변수 관찰값 \\(x_{ij}\\)에서 \\(j\\)번째 변수의 평균값 \\(\\bar{x}_j\\)을 뺀 후 \\(j\\)번째 변수의 표준편차 값 \\(s_j\\)로 나눈 것을 의미한다.\n\n# 지폐의 상태에 따른 주성분 점수 그래프 Ver.1\nplot(swissTib.cor.score[,1:2],                         # 첫 번째와 두 번째 주성분 점수\n     main = \"지폐의 상태별 주성분 점수\")\nabline(v = 0, h = 0, lty = 2)\ntext(swissTib.cor.score[,1:2],  labels = swissTib$Status, pos = 4, col = \"red\")\n\n\n\n\n\n\n\n# 지폐의 상태에 따른 주성분 점수 그래프 Ver.2\nswissTibPca &lt;- swissTib %&gt;%\n  mutate(PCA1 = swissTib.cor.score[, 1], PCA2 = swissTib.cor.score[, 2])\nggplot(swissTibPca, aes(PCA1, PCA2, \n                        col = Status)) +               # 변수 Status의 범주에 따라 색깔을 다르게 표현\n  geom_point() +\n  geom_hline(yintercept=0, linetype='dashed', color='black') + \n  geom_vline(xintercept=0, linetype='dashed', color='black') + \n  theme_bw()\n\n\n\n\n\n\n\n\nResult! 그래프의 수직선을 중심으로 오른쪽에 위치하는 점들은 첫 번째 주성분 점수가 높다는 것을 의미하고 왼쪽에 위치하는 점들은 첫 번째 주성분 점수가 낮다는 것을 의미한다. 오른쪽에 위치하는 점들은 대부분 “진품”(genuine)이므로, 전반적으로 진품인 지폐가 위조 지폐보다 첫 번째 주성분 점수가 높다고 해석할 수 있다. 마찬가지로 수평선을 중심으로 위쪽에 위치하는 점들은 두 번째 주성분 점수가 높다는 것을 의미하고 아래쪽에 위치하는 점들은 두 번째 주성분 점수가 낮다는 것을 의미한다.\n\n# 주성분 점수 예측\npredict(swissTib.cor.prcomp, newdata = tail(swissTib[,-1], 2))\n\n            PC1          PC2        PC3         PC4        PC5         PC6\n[1,] -2.9867821 -0.001793364 -0.5065873 -0.88804668 -0.3230792 -0.02754178\n[2,] -0.6439339  1.986895264  0.6571704  0.02876048 -0.3019170 -0.12457045\n\n\nCaution! 함수 predict()를 이용하여 새로운 case에 대한 주성분 점수를 예측할 수 있다. 여기서는 설명의 편의상 마지막 2개의 case를 새로운 자료로 취급하여 예측을 수행하였다.\n\n# Biplot\nfviz_pca_biplot(swissTib.cor.prcomp, label = \"var\")\n\n\n\n\n\n\n\n\nCaution! 주성분 점수와 변수 적재를 하나의 그래프에 함께 표현한 것을 행렬도(Biplot)라고 한다. 위 Biplot에서는 주성분 점수를 점으로 표현하고, 변수 적재를 화살표로 표현한다. Biplot는 다음을 기준으로 해석할 수 있다.\n1. 점은 각 case(데이터셋에서 하나의 행)에 대한 주성분 점수를 나타낸다.\n2. 화살표는 변수 적재값을 의미하며, 정확한 변수 적재값은 알 수 없다.\n3. 화살표의 길이는 상관성의 정도를 표현한다. 즉, 주축을 기준으로 화살표의 길이가 길수록 변수와 해당 주성분은 강한 상관성을 가진다.\n4. 화살표와 주축이 평행에 가까울수록 해당 변수는 해당 주성분에만 큰 영향을 미친다.\n5. 화살표들 간의 각도가 작을수록 해당 변수들은 강한 양의 상관관계를 나타내며, 180도는 강한 음의 상관관계를 나타낸다. 또한, 직각은 상관성이 없음을 의미한다.\nBiplot을 통해서 군집성, 변수들의 상관구조 등을 시각적으로 파악할 수 있다.\nResult! Biplot의 x축과 y축은 각각 첫 번째와 두 번째 주성분 점수를 의미한다. 변수 Right와 Diagonal은 첫 번째 주축(x축, 수평 점선)을 기준으로 화살표의 길이가 길며 이는 두 변수가 첫 번째 주성분과 강한 상관성을 가진다고 할 수 있다. 또한, 변수 Right와 Left의 화살표들 간의 각도가 작기 때문에(즉, 서로 가까이 위치해있기 때문에) 강한 양의 상관관계를 가지며, 변수 Bottom과 Diagonal은 화살표들 간의 각도가 180도를 이루므로 강한 음의 상관관계를 가진다.\n\n# ggbiplot을 이용한 Biplot\nggbiplot(swissTib.cor.prcomp,                          # 함수 prcomp에 의한 객체\n         obs.scale = 1,                                # 관찰값에 적용할 스케일\n         var.scale = 1,                                # 변수에 적용할 스케일\n         circle = TRUE) +\n  theme_bw()\n\n\n\n\n\n\n\n\nCaution! Package \"ggbiplot\"에서 제공하는 함수 ggbiplot()를 이용하여 Biplot을 만들 수 있으며, 함수에 대한 자세한 옵션은 여기를 참고한다.\n\n# 스크리 그래프 Ver.1 (y축 : 고유값)\npar(mfrow = c(1, 2))\nscreeplot(swissTib.cor.prcomp, type = \"b\", main = \"\")  # 막대그래프\nscreeplot(swissTib.cor.prcomp, type = \"l\", main = \"\")  # 선 그래프\n\n\n\n\n\n\n\n# 스크리 그래프 Ver.2\nfviz_screeplot(swissTib.cor.prcomp, \n               addlabels = TRUE,                       # 막대 높이 표시 여부\n               # geom = \"line\",                        # 그래프 유형(bar / line)\n               choice = \"eigenvalue\",                  # y축 (variance / eigenvalue)\n               linecolor = \"#FC4E07\",                  # 선 색깔\n               barcolor = \"#00AFBB\",                   # 막대의 윤곽선 색깔\n               barfill = \"#00AFBB\")                    # 막대의 색깔\n\n\n\n\n\n\n\nfviz_screeplot(swissTib.cor.prcomp, \n               addlabels = TRUE,                       # 막대 높이 표시 여부\n               choice = \"variance\",                    # y축(variance / eigenvalue)\n               linecolor = \"#FC4E07\",                  # 선 색깔\n               barcolor = \"#00AFBB\",                   # 막대의 윤곽선 색깔\n               barfill = \"#00AFBB\")                    # 막대의 색깔\n\n\n\n\n\n\n\n\nResult! 스크리 그래프를 보면 첫 번째 주성분, 두 번째 주성분 그리고 세 번째 주성분의 분산(고유값)이 크며 가파른 경사를 형성한다. 그러므로, 3개의 주성분 개수를 고려할 수 있다.",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Principal Component Analysis</span>"
    ]
  },
  {
    "objectID": "Logistic.html",
    "href": "Logistic.html",
    "title": "9  Logistic Regression",
    "section": "",
    "text": "9.1 데이터 불러오기\npacman::p_load(\"data.table\",\n               \"tidyverse\", \n               \"dplyr\", \"tidyr\",\n               \"ggplot2\", \"GGally\",\n               \"caret\")                      \n\ntitanic &lt;- fread(\"../Titanic.csv\")                         # 데이터 불러오기\n\ntitanic %&gt;%\n  as_tibble\n# A tibble: 891 × 11\n   Survived Pclass Name                                                Sex      Age SibSp Parch Ticket            Fare Cabin  Embarked\n      &lt;int&gt;  &lt;int&gt; &lt;chr&gt;                                               &lt;chr&gt;  &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;   \n 1        0      3 Braund, Mr. Owen Harris                             male      22     1     0 A/5 21171         7.25 \"\"     S       \n 2        1      1 Cumings, Mrs. John Bradley (Florence Briggs Thayer) female    38     1     0 PC 17599         71.3  \"C85\"  C       \n 3        1      3 Heikkinen, Miss. Laina                              female    26     0     0 STON/O2. 3101282  7.92 \"\"     S       \n 4        1      1 Futrelle, Mrs. Jacques Heath (Lily May Peel)        female    35     1     0 113803           53.1  \"C123\" S       \n 5        0      3 Allen, Mr. William Henry                            male      35     0     0 373450            8.05 \"\"     S       \n 6        0      3 Moran, Mr. James                                    male      NA     0     0 330877            8.46 \"\"     Q       \n 7        0      1 McCarthy, Mr. Timothy J                             male      54     0     0 17463            51.9  \"E46\"  S       \n 8        0      3 Palsson, Master. Gosta Leonard                      male       2     3     1 349909           21.1  \"\"     S       \n 9        1      3 Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)   female    27     0     2 347742           11.1  \"\"     S       \n10        1      2 Nasser, Mrs. Nicholas (Adele Achem)                 female    14     1     0 237736           30.1  \"\"     C       \n# ℹ 881 more rows",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "Logistic.html#데이터-전처리-i",
    "href": "Logistic.html#데이터-전처리-i",
    "title": "9  Logistic Regression",
    "section": "9.2 데이터 전처리 I",
    "text": "9.2 데이터 전처리 I\n\ntitanic %&lt;&gt;%\n  data.frame() %&gt;%                                                      # Data Frame 형태로 변환 \n  mutate(Survived = ifelse(Survived == 1, \"yes\", \"no\"))                 # Target을 문자형 변수로 변환\n\n# 1. Convert to Factor\nfac.col &lt;- c(\"Pclass\", \"Sex\",\n             # Target\n             \"Survived\")\n\ntitanic &lt;- titanic %&gt;% \n  mutate_at(fac.col, as.factor)                                         # 범주형으로 변환\n\nglimpse(titanic)                                                        # 데이터 구조 확인\n\nRows: 891\nColumns: 11\n$ Survived &lt;fct&gt; no, yes, yes, yes, no, no, no, no, yes, yes, yes, yes, no, no, no, yes, no, yes, no, yes, no, yes, yes, yes, no, yes, no, no, yes, no, no, yes, yes, no, no, no, yes, no, no, yes, no…\n$ Pclass   &lt;fct&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3, 2, 2, 3, 1, 3, 3, 3, 1, 3, 3, 1, 1, 3, 2, 1, 1, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 1, 1, 2, 3, 2, 3, 3…\n$ Name     &lt;chr&gt; \"Braund, Mr. Owen Harris\", \"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\", \"Heikkinen, Miss. Laina\", \"Futrelle, Mrs. Jacques Heath (Lily May Peel)\", \"Allen, Mr. William Henry…\n$ Sex      &lt;fct&gt; male, female, female, female, male, male, male, male, female, female, female, female, male, male, female, female, male, male, female, female, male, male, female, male, female, femal…\n$ Age      &lt;dbl&gt; 22.0, 38.0, 26.0, 35.0, 35.0, NA, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, NA, 31.0, NA, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, NA, 19.0, NA, NA, 40.0, NA, NA, 66.…\n$ SibSp    &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0, 0, 0, 0, 0, 3, 1, 0, 3, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 1, 0, 0, 1, 0, 2, 1, 4, 0, 1, 1, 0, 0, 0, 0, 1, 5, 0…\n$ Parch    &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 5, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 2, 2, 0…\n$ Ticket   &lt;chr&gt; \"A/5 21171\", \"PC 17599\", \"STON/O2. 3101282\", \"113803\", \"373450\", \"330877\", \"17463\", \"349909\", \"347742\", \"237736\", \"PP 9549\", \"113783\", \"A/5. 2151\", \"347082\", \"350406\", \"248706\", \"38…\n$ Fare     &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625, 21.0750, 11.1333, 30.0708, 16.7000, 26.5500, 8.0500, 31.2750, 7.8542, 16.0000, 29.1250, 13.0000, 18.0000, 7.2250, 26.0000,…\n$ Cabin    &lt;chr&gt; \"\", \"C85\", \"\", \"C123\", \"\", \"\", \"E46\", \"\", \"\", \"\", \"G6\", \"C103\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"D56\", \"\", \"A6\", \"\", \"\", \"\", \"C23 C25 C27\", \"\", \"\", \"\", \"B78\", \"\", \"\", \"\", \"\", \"\"…\n$ Embarked &lt;chr&gt; \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"C\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"Q\", \"S\", \"C\", \"C\", \"Q\", \"S\", \"C\", \"S\", \"…\n\n# 2. Generate New Variable\ntitanic &lt;- titanic %&gt;%\n  mutate(FamSize = SibSp + Parch)                                       # \"FamSize = 형제 및 배우자 수 + 부모님 및 자녀 수\"로 가족 수를 의미하는 새로운 변수\n\nglimpse(titanic)                                                        # 데이터 구조 확인\n\nRows: 891\nColumns: 12\n$ Survived &lt;fct&gt; no, yes, yes, yes, no, no, no, no, yes, yes, yes, yes, no, no, no, yes, no, yes, no, yes, no, yes, yes, yes, no, yes, no, no, yes, no, no, yes, yes, no, no, no, yes, no, no, yes, no…\n$ Pclass   &lt;fct&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3, 2, 2, 3, 1, 3, 3, 3, 1, 3, 3, 1, 1, 3, 2, 1, 1, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 1, 1, 2, 3, 2, 3, 3…\n$ Name     &lt;chr&gt; \"Braund, Mr. Owen Harris\", \"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\", \"Heikkinen, Miss. Laina\", \"Futrelle, Mrs. Jacques Heath (Lily May Peel)\", \"Allen, Mr. William Henry…\n$ Sex      &lt;fct&gt; male, female, female, female, male, male, male, male, female, female, female, female, male, male, female, female, male, male, female, female, male, male, female, male, female, femal…\n$ Age      &lt;dbl&gt; 22.0, 38.0, 26.0, 35.0, 35.0, NA, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, NA, 31.0, NA, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, NA, 19.0, NA, NA, 40.0, NA, NA, 66.…\n$ SibSp    &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0, 0, 0, 0, 0, 3, 1, 0, 3, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 1, 0, 0, 1, 0, 2, 1, 4, 0, 1, 1, 0, 0, 0, 0, 1, 5, 0…\n$ Parch    &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 5, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 2, 2, 0…\n$ Ticket   &lt;chr&gt; \"A/5 21171\", \"PC 17599\", \"STON/O2. 3101282\", \"113803\", \"373450\", \"330877\", \"17463\", \"349909\", \"347742\", \"237736\", \"PP 9549\", \"113783\", \"A/5. 2151\", \"347082\", \"350406\", \"248706\", \"38…\n$ Fare     &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625, 21.0750, 11.1333, 30.0708, 16.7000, 26.5500, 8.0500, 31.2750, 7.8542, 16.0000, 29.1250, 13.0000, 18.0000, 7.2250, 26.0000,…\n$ Cabin    &lt;chr&gt; \"\", \"C85\", \"\", \"C123\", \"\", \"\", \"E46\", \"\", \"\", \"\", \"G6\", \"C103\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"D56\", \"\", \"A6\", \"\", \"\", \"\", \"C23 C25 C27\", \"\", \"\", \"\", \"B78\", \"\", \"\", \"\", \"\", \"\"…\n$ Embarked &lt;chr&gt; \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"C\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"Q\", \"S\", \"C\", \"C\", \"Q\", \"S\", \"C\", \"S\", \"…\n$ FamSize  &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 4, 2, 1, 2, 0, 0, 6, 0, 0, 5, 0, 1, 0, 0, 0, 0, 0, 4, 6, 0, 5, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 3, 0, 0, 1, 0, 2, 1, 5, 0, 1, 1, 1, 0, 0, 0, 3, 7, 0…\n\n# 3. Select Variables used for Analysis\ntitanic1 &lt;- titanic %&gt;% \n  select(Survived, Pclass, Sex, Age, Fare, FamSize)                     # 분석에 사용할 변수 선택\n\ntitanic1 %&gt;%\n  as_tibble\n\n# A tibble: 891 × 6\n   Survived Pclass Sex      Age  Fare FamSize\n   &lt;fct&gt;    &lt;fct&gt;  &lt;fct&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;int&gt;\n 1 no       3      male      22  7.25       1\n 2 yes      1      female    38 71.3        1\n 3 yes      3      female    26  7.92       0\n 4 yes      1      female    35 53.1        1\n 5 no       3      male      35  8.05       0\n 6 no       3      male      NA  8.46       0\n 7 no       1      male      54 51.9        0\n 8 no       3      male       2 21.1        4\n 9 yes      3      female    27 11.1        2\n10 yes      2      female    14 30.1        1\n# ℹ 881 more rows",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "Logistic.html#데이터-탐색",
    "href": "Logistic.html#데이터-탐색",
    "title": "9  Logistic Regression",
    "section": "9.3 데이터 탐색",
    "text": "9.3 데이터 탐색\n\nggpairs(titanic1,                                        \n        aes(colour = Survived)) +                         # Target의 범주에 따라 색깔을 다르게 표현\n  theme_bw()\n\n\n\n\n\n\n\nggpairs(titanic1,                                     \n        aes(colour = Survived, alpha = 0.8)) +            # Target의 범주에 따라 색깔을 다르게 표현\n  scale_colour_manual(values = c(\"purple\", \"cyan4\")) +    # 특정 색깔 지정\n  scale_fill_manual(values = c(\"purple\", \"cyan4\")) +      # 특정 색깔 지정\n  theme_bw()",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "Logistic.html#데이터-분할",
    "href": "Logistic.html#데이터-분할",
    "title": "9  Logistic Regression",
    "section": "9.4 데이터 분할",
    "text": "9.4 데이터 분할\n\n# Partition (Training Dataset : Test Dataset = 7:3)\ny      &lt;- titanic1$Survived                             # Target\n\nset.seed(200)\nind    &lt;- createDataPartition(y, p = 0.7, list  =T)     # Index를 이용하여 7:3으로 분할\ntitanic.trd &lt;- titanic1[ind$Resample1,]                 # Training Dataset\ntitanic.ted &lt;- titanic1[-ind$Resample1,]                # Test Dataset",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "Logistic.html#데이터-전처리-ii",
    "href": "Logistic.html#데이터-전처리-ii",
    "title": "9  Logistic Regression",
    "section": "9.5 데이터 전처리 II",
    "text": "9.5 데이터 전처리 II\n\n# 1. Imputation\ntitanic.trd.Imp &lt;- titanic.trd %&gt;% \n  mutate(Age = replace_na(Age, mean(Age, na.rm = TRUE)))                 # 평균으로 결측값 대체\n\ntitanic.ted.Imp &lt;- titanic.ted %&gt;% \n  mutate(Age = replace_na(Age, mean(titanic.trd$Age, na.rm = TRUE)))     # Training Dataset을 이용하여 결측값 대체\n\n# 2. Standardization\npreProcValues &lt;- preProcess(titanic.trd.Imp, \n                            method = c(\"center\", \"scale\"))               # Standardization 정의 -&gt; Training Dataset에 대한 평균과 표준편차 계산 \n\ntitanic.trd.Imp &lt;- predict(preProcValues, titanic.trd.Imp)               # Standardization for Training Dataset\ntitanic.ted.Imp &lt;- predict(preProcValues, titanic.ted.Imp)               # Standardization for Test Dataset\n\nglimpse(titanic.trd.Imp)                                                 # 데이터 구조 확인\n\nRows: 625\nColumns: 6\n$ Survived &lt;fct&gt; no, yes, yes, no, no, no, yes, yes, yes, yes, no, no, yes, no, yes, no, yes, no, no, no, yes, no, no, yes, yes, no, no, no, no, no, yes, no, no, no, yes, no, yes, no, no, no, yes, n…\n$ Pclass   &lt;fct&gt; 3, 3, 1, 3, 3, 3, 3, 2, 3, 1, 3, 3, 2, 3, 3, 2, 1, 3, 3, 1, 3, 3, 1, 1, 3, 2, 1, 1, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3, 1, 3, 1, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 1, 2, 3…\n$ Sex      &lt;fct&gt; male, female, female, male, male, male, female, female, female, female, male, female, male, female, female, male, male, female, male, male, female, male, male, female, female, male,…\n$ Age      &lt;dbl&gt; -0.61306970, -0.30411628, 0.39102893, 0.39102893, 0.00000000, -2.15783684, -0.22687792, -1.23097656, -2.00336012, 2.16751113, 0.69998236, -1.23097656, 0.00000000, 0.08207551, 0.0000…\n$ Fare     &lt;dbl&gt; -0.51776394, -0.50463325, 0.37414970, -0.50220165, -0.49425904, -0.24882814, -0.44222264, -0.07383411, -0.33393441, -0.14232374, -0.05040897, -0.50601052, -0.40590999, -0.30864569, …\n$ FamSize  &lt;dbl&gt; 0.04506631, -0.55421976, 0.04506631, -0.55421976, -0.55421976, 1.84292454, 0.64435239, 0.04506631, 0.64435239, -0.55421976, 3.04149669, -0.55421976, -0.55421976, 0.04506631, -0.5542…\n\nglimpse(titanic.ted.Imp)                                                 # 데이터 구조 확인\n\nRows: 266\nColumns: 6\n$ Survived &lt;fct&gt; yes, no, no, yes, no, yes, yes, yes, yes, yes, no, no, yes, yes, no, yes, no, yes, yes, no, yes, no, no, no, no, no, no, yes, yes, no, no, no, no, no, no, no, no, no, no, yes, no, n…\n$ Pclass   &lt;fct&gt; 1, 1, 3, 2, 3, 2, 3, 3, 3, 2, 3, 3, 2, 2, 3, 2, 1, 3, 2, 3, 3, 2, 2, 3, 3, 3, 3, 1, 2, 2, 3, 3, 3, 3, 3, 2, 3, 2, 2, 2, 3, 3, 2, 1, 3, 1, 3, 2, 1, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 1, 3…\n$ Sex      &lt;fct&gt; female, male, male, female, male, male, female, female, male, female, male, male, female, female, male, female, male, male, female, male, female, male, male, male, male, male, male,…\n$ Age      &lt;dbl&gt; 0.62274400, 1.85855771, -0.76754642, 1.93579607, -2.15783684, 0.31379058, -1.15373820, 0.62274400, 0.00000000, -2.08059848, 0.00000000, -0.69030806, -0.07240121, -0.69030806, -0.111…\n$ Fare     &lt;dbl&gt; 0.727866891, 0.350076786, -0.502201647, -0.347551409, -0.092232621, -0.405909990, -0.502606266, -0.048220525, -0.518168555, 0.150037190, -0.502201647, -0.507064862, -0.153022808, -0…\n$ FamSize  &lt;dbl&gt; 0.04506631, -0.55421976, -0.55421976, -0.55421976, 2.44221062, -0.55421976, -0.55421976, 3.04149669, -0.55421976, 1.24363847, -0.55421976, -0.55421976, 0.04506631, -0.55421976, -0.5…",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "Logistic.html#모형-훈련",
    "href": "Logistic.html#모형-훈련",
    "title": "9  Logistic Regression",
    "section": "9.6 모형 훈련",
    "text": "9.6 모형 훈련\nCaution! 함수 glm()에서 Logistic Regression은 Target이 2개의 클래스를 가질 때 “두 번째 클래스”에 속할 확률을 모델링하며, 범주형 예측 변수의 경우 더미 변환을 자동적으로 수행한다. 여기서, “두 번째 클래스”란 “Factor” 변환하였을 때 두 번째 수준(Level)을 의미한다. 예를 들어, “a”와 “b” 2개의 클래스를 가진 Target을 “Factor” 변환하였을 때 수준이 “a” “b”라면, 첫 번째 클래스는 “a”, 두 번째 클래스는 “b”가 된다.\n\nlogis.fit &lt;- glm(Survived ~ . , data = titanic.trd.Imp,\n                 family = \"binomial\")                  # For Logit Transformation\n\nlogis.fit                                              # Fitted Logistic Regression\n\n\nCall:  glm(formula = Survived ~ ., family = \"binomial\", data = titanic.trd.Imp)\n\nCoefficients:\n(Intercept)      Pclass2      Pclass3      Sexmale          Age         Fare      FamSize  \n     2.5729      -1.0518      -2.3731      -2.7202      -0.5296       0.1226      -0.3978  \n\nDegrees of Freedom: 624 Total (i.e. Null);  618 Residual\nNull Deviance:      832.5 \nResidual Deviance: 555.1    AIC: 569.1\n\nsummary(logis.fit)                                     # Summary for Fitted Logistic Regression\n\n\nCall:\nglm(formula = Survived ~ ., family = \"binomial\", data = titanic.trd.Imp)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.6575  -0.6298  -0.4076   0.6127   2.4606  \n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   2.5729     0.3141   8.192 2.58e-16 ***\nPclass2      -1.0518     0.3546  -2.966  0.00302 ** \nPclass3      -2.3731     0.3477  -6.826 8.76e-12 ***\nSexmale      -2.7202     0.2390 -11.381  &lt; 2e-16 ***\nAge          -0.5296     0.1207  -4.386 1.15e-05 ***\nFare          0.1226     0.1499   0.818  0.41351    \nFamSize      -0.3978     0.1356  -2.934  0.00335 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 832.49  on 624  degrees of freedom\nResidual deviance: 555.06  on 618  degrees of freedom\nAIC: 569.06\n\nNumber of Fisher Scoring iterations: 5\n\n\nResult! 데이터 “titanic.trd.Imp”의 Target “Survived”은 “no”와 “yes” 2개의 클래스를 가지며, “Factor” 변환하면 알파벳순으로 수준을 부여하기 때문에 “yes”가 두 번째 클래스가 된다. 즉, “yes”에 속할 확률(= 탑승객이 생존할 확률)을 \\(p\\)라고 할 때, 추정된 회귀계수를 이용하여 다음과 같은 모형식을 얻을 수 있다. \\[\n\\begin{align*}\n\\log{\\frac{p}{1-p}} = &\\;2.573 - 1.052X_{\\text{Pclass2}} - 2.373 X_{\\text{Pclass3}} -2.720  X_{\\text{Sexmale}} \\\\\n                      &-0.530 Z_{\\text{Age}} +0.123 Z_{\\text{Fare}} - 0.398 Z_{\\text{FamSize}}\n\\end{align*}\n\\] 여기서, \\(Z_{\\text{예측 변수}}\\)는 표준화한 예측 변수, \\(X_{\\text{예측 변수}}\\)는 더미 변수를 의미한다.\n범주형 예측 변수(“Pclass”, “Sex”)는 더미 변환이 수행되었는데, 예를 들어, \\(X_{\\text{Pclass2}}\\)는 탑승객의 티켓 등급이 2등급인 경우 “1”값을 가지고 2등급이 아니면 “0”값을 가진다.\n\nOR &lt;- exp(coef(logis.fit))                             # Odds Ratio\nCI &lt;- exp(confint(logis.fit))                          # 95% Confidence Interval\n\ncbind(\"Odds Ratio\" = round(OR, 3),                     # round : 반올림\n      round(CI, 3))\n\n            Odds Ratio 2.5 % 97.5 %\n(Intercept)     13.104 7.159 24.579\nPclass2          0.349 0.173  0.698\nPclass3          0.093 0.047  0.184\nSexmale          0.066 0.041  0.104\nAge              0.589 0.462  0.743\nFare             1.130 0.858  1.571\nFamSize          0.672 0.507  0.865\n\n\nResult! 오즈비를 살펴보면, 나이(“Age”)를 표준화한 값이 1 증가할 경우, 탑승객의 생존 가능성은 1.700(=1/0.589)배 감소한다. 반면, 티켓 요금(“Fare”)을 표준화한 값이 1 증가할 경우, 탑승객의 생존 가능성은 1.130배 증가한다.",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "Logistic.html#모형-평가",
    "href": "Logistic.html#모형-평가",
    "title": "9  Logistic Regression",
    "section": "9.7 모형 평가",
    "text": "9.7 모형 평가\nCaution! 모형 평가를 위해 Test Dataset에 대한 예측 class/확률 이 필요하며, 함수 predict()를 이용하여 생성한다.\n\n# 예측 확률 생성\ntest.logis.prob &lt;- predict(logis.fit, \n                           newdata = titanic.ted.Imp,                      # Test Dataset including Only 예측 변수                        \n                           type = \"response\")                              # 예측 확률 생성 \n\ntest.logis.prob %&gt;%                                                        # \"Survived = yes\"에 대한 예측 확률\n  as_tibble\n\n# A tibble: 266 × 1\n    value\n    &lt;dbl&gt;\n 1 0.910 \n 2 0.296 \n 3 0.124 \n 4 0.662 \n 5 0.0862\n 6 0.232 \n 7 0.725 \n 8 0.207 \n 9 0.0860\n10 0.895 \n# ℹ 256 more rows\n\n# 예측 class 생성\nlogis.pred &lt;- ifelse(test.logis.prob &gt; 0.5, \"yes\", \"no\") %&gt;%               # \"Survived = yes\"에 대한 예측 확률이 0.5 초과하면 \"yes\", 0.5를 넘기지 못하면 \"no\"로 분류\n  factor                                                                   # 범주형으로 변환\n\nlogis.pred %&gt;%                                      \n  as_tibble\n\n# A tibble: 266 × 1\n   value\n   &lt;fct&gt;\n 1 yes  \n 2 no   \n 3 no   \n 4 yes  \n 5 no   \n 6 no   \n 7 yes  \n 8 no   \n 9 no   \n10 yes  \n# ℹ 256 more rows\n\n\n\n\n9.7.1 ConfusionMatrix\n\nCM   &lt;- caret::confusionMatrix(logis.pred, titanic.ted.Imp$Survived, \n                               positive = \"yes\")        # confusionMatrix(예측 class, 실제 class, positive = \"관심 class\")\nCM\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  no yes\n       no  148  32\n       yes  16  70\n                                         \n               Accuracy : 0.8195         \n                 95% CI : (0.768, 0.8638)\n    No Information Rate : 0.6165         \n    P-Value [Acc &gt; NIR] : 5.675e-13      \n                                         \n                  Kappa : 0.6067         \n                                         \n Mcnemar's Test P-Value : 0.03038        \n                                         \n            Sensitivity : 0.6863         \n            Specificity : 0.9024         \n         Pos Pred Value : 0.8140         \n         Neg Pred Value : 0.8222         \n             Prevalence : 0.3835         \n         Detection Rate : 0.2632         \n   Detection Prevalence : 0.3233         \n      Balanced Accuracy : 0.7944         \n                                         \n       'Positive' Class : yes            \n                                         \n\n\n\n\n\n9.7.2 ROC 곡선\n\nac  &lt;- titanic.ted.Imp$Survived                           # Test Dataset의 실제 class \npp  &lt;- as.numeric(test.logis.prob)                        # 예측 확률을 수치형으로 변환\n\n\n9.7.2.1 Package “pROC”\n\npacman::p_load(\"pROC\")\n\nlogis.roc  &lt;- roc(ac, pp, plot = T, col = \"gray\")         # roc(실제 class, 예측 확률)\nauc        &lt;- round(auc(logis.roc), 3)\nlegend(\"bottomright\", legend = auc, bty = \"n\")\n\n\n\n\n\n\n\n\nCaution! Package \"pROC\"를 통해 출력한 ROC 곡선은 다양한 함수를 이용해서 그래프를 수정할 수 있다.\n\n# 함수 plot.roc() 이용\nplot.roc(logis.roc,   \n         col=\"gray\",                                      # Line Color\n         print.auc = TRUE,                                # AUC 출력 여부\n         print.auc.col = \"red\",                           # AUC 글씨 색깔\n         print.thres = TRUE,                              # Cutoff Value 출력 여부\n         print.thres.pch = 19,                            # Cutoff Value를 표시하는 도형 모양\n         print.thres.col = \"red\",                         # Cutoff Value를 표시하는 도형의 색깔\n         auc.polygon = TRUE,                              # 곡선 아래 면적에 대한 여부\n         auc.polygon.col = \"gray90\")                      # 곡선 아래 면적의 색깔\n\n\n\n\n\n\n\n\n\n# 함수 ggroc() 이용\nggroc(logis.roc) +\nannotate(geom = \"text\", x = 0.9, y = 1.0,\nlabel = paste(\"AUC = \", auc),\nsize = 5,\ncolor=\"red\") +\ntheme_bw()\n\n\n\n\n\n\n\n\n\n\n9.7.2.2 Package “Epi”\n\npacman::p_load(\"Epi\")       \n# install_version(\"etm\", version = \"1.1\", repos = \"http://cran.us.r-project.org\")\n\nROC(pp, ac, plot = \"ROC\")                                  # ROC(예측 확률, 실제 class)  \n\n\n\n\n\n\n\n\n\n\n9.7.2.3 Package “ROCR”\n\npacman::p_load(\"ROCR\")\n\nlogis.pred &lt;- prediction(pp, ac)                          # prediction(예측 확률, 실제 class)    \n\nlogis.perf &lt;- performance(logis.pred, \"tpr\", \"fpr\")       # performance(, \"민감도\", \"1-특이도\")                      \nplot(logis.perf, col = \"gray\")                            # ROC Curve\n\nperf.auc   &lt;- performance(logis.pred, \"auc\")              # AUC\nauc        &lt;- attributes(perf.auc)$y.values \nlegend(\"bottomright\", legend = auc, bty = \"n\")\n\n\n\n\n\n\n\n\n\n\n\n\n9.7.3 향상 차트\n\n9.7.3.1 Package “ROCR”\n\nlogis.pred &lt;- performance(logis.pred, \"lift\", \"rpp\")      # Lift Chart\nplot(logis.pred, main = \"lift curve\", \n     colorize = T,                                        # Coloring according to cutoff\n     lwd = 2)",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Logistic Regression</span>"
    ]
  },
  {
    "objectID": "LASSO.html",
    "href": "LASSO.html",
    "title": "10  LASSO Regression",
    "section": "",
    "text": "10.1 데이터 불러오기\npacman::p_load(\"data.table\", \n               \"tidyverse\", \n               \"dplyr\", \"tidyr\",\n               \"ggplot2\", \"GGally\",\n               \"caret\",\n               \"glmnet\")                                                # For glmnet\n\ntitanic &lt;- fread(\"../Titanic.csv\")                                      # 데이터 불러오기\n\ntitanic %&gt;%\n  as_tibble\n# A tibble: 891 × 11\n   Survived Pclass Name                                                Sex      Age SibSp Parch Ticket            Fare Cabin  Embarked\n      &lt;int&gt;  &lt;int&gt; &lt;chr&gt;                                               &lt;chr&gt;  &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;   \n 1        0      3 Braund, Mr. Owen Harris                             male      22     1     0 A/5 21171         7.25 \"\"     S       \n 2        1      1 Cumings, Mrs. John Bradley (Florence Briggs Thayer) female    38     1     0 PC 17599         71.3  \"C85\"  C       \n 3        1      3 Heikkinen, Miss. Laina                              female    26     0     0 STON/O2. 3101282  7.92 \"\"     S       \n 4        1      1 Futrelle, Mrs. Jacques Heath (Lily May Peel)        female    35     1     0 113803           53.1  \"C123\" S       \n 5        0      3 Allen, Mr. William Henry                            male      35     0     0 373450            8.05 \"\"     S       \n 6        0      3 Moran, Mr. James                                    male      NA     0     0 330877            8.46 \"\"     Q       \n 7        0      1 McCarthy, Mr. Timothy J                             male      54     0     0 17463            51.9  \"E46\"  S       \n 8        0      3 Palsson, Master. Gosta Leonard                      male       2     3     1 349909           21.1  \"\"     S       \n 9        1      3 Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)   female    27     0     2 347742           11.1  \"\"     S       \n10        1      2 Nasser, Mrs. Nicholas (Adele Achem)                 female    14     1     0 237736           30.1  \"\"     C       \n# ℹ 881 more rows",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>LASSO Regression</span>"
    ]
  },
  {
    "objectID": "LASSO.html#데이터-전처리-i",
    "href": "LASSO.html#데이터-전처리-i",
    "title": "10  LASSO Regression",
    "section": "10.2 데이터 전처리 I",
    "text": "10.2 데이터 전처리 I\n\ntitanic %&lt;&gt;%\n  data.frame() %&gt;%                                                      # Data Frame 형태로 변환 \n  mutate(Survived = ifelse(Survived == 1, \"yes\", \"no\"))                 # Target을 문자형 변수로 변환\n\n# 1. Convert to Factor\nfac.col &lt;- c(\"Pclass\", \"Sex\",\n             # Target\n             \"Survived\")\n\ntitanic &lt;- titanic %&gt;% \n  mutate_at(fac.col, as.factor)                                         # 범주형으로 변환\n\nglimpse(titanic)                                                        # 데이터 구조 확인\n\nRows: 891\nColumns: 11\n$ Survived &lt;fct&gt; no, yes, yes, yes, no, no, no, no, yes, yes, yes, yes, no, no, no, yes, no, yes, no, yes, no, yes, yes, yes, no, yes, no, no, yes, no, no, yes, yes, no, no, no, yes, no, no, yes, no…\n$ Pclass   &lt;fct&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3, 2, 2, 3, 1, 3, 3, 3, 1, 3, 3, 1, 1, 3, 2, 1, 1, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 1, 1, 2, 3, 2, 3, 3…\n$ Name     &lt;chr&gt; \"Braund, Mr. Owen Harris\", \"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\", \"Heikkinen, Miss. Laina\", \"Futrelle, Mrs. Jacques Heath (Lily May Peel)\", \"Allen, Mr. William Henry…\n$ Sex      &lt;fct&gt; male, female, female, female, male, male, male, male, female, female, female, female, male, male, female, female, male, male, female, female, male, male, female, male, female, femal…\n$ Age      &lt;dbl&gt; 22.0, 38.0, 26.0, 35.0, 35.0, NA, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, NA, 31.0, NA, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, NA, 19.0, NA, NA, 40.0, NA, NA, 66.…\n$ SibSp    &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0, 0, 0, 0, 0, 3, 1, 0, 3, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 1, 0, 0, 1, 0, 2, 1, 4, 0, 1, 1, 0, 0, 0, 0, 1, 5, 0…\n$ Parch    &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 5, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 2, 2, 0…\n$ Ticket   &lt;chr&gt; \"A/5 21171\", \"PC 17599\", \"STON/O2. 3101282\", \"113803\", \"373450\", \"330877\", \"17463\", \"349909\", \"347742\", \"237736\", \"PP 9549\", \"113783\", \"A/5. 2151\", \"347082\", \"350406\", \"248706\", \"38…\n$ Fare     &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625, 21.0750, 11.1333, 30.0708, 16.7000, 26.5500, 8.0500, 31.2750, 7.8542, 16.0000, 29.1250, 13.0000, 18.0000, 7.2250, 26.0000,…\n$ Cabin    &lt;chr&gt; \"\", \"C85\", \"\", \"C123\", \"\", \"\", \"E46\", \"\", \"\", \"\", \"G6\", \"C103\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"D56\", \"\", \"A6\", \"\", \"\", \"\", \"C23 C25 C27\", \"\", \"\", \"\", \"B78\", \"\", \"\", \"\", \"\", \"\"…\n$ Embarked &lt;chr&gt; \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"C\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"Q\", \"S\", \"C\", \"C\", \"Q\", \"S\", \"C\", \"S\", \"…\n\n# 2. Generate New Variable\ntitanic &lt;- titanic %&gt;%\n  mutate(FamSize = SibSp + Parch)                                       # \"FamSize = 형제 및 배우자 수 + 부모님 및 자녀 수\"로 가족 수를 의미하는 새로운 변수\n\nglimpse(titanic)                                                        # 데이터 구조 확인\n\nRows: 891\nColumns: 12\n$ Survived &lt;fct&gt; no, yes, yes, yes, no, no, no, no, yes, yes, yes, yes, no, no, no, yes, no, yes, no, yes, no, yes, yes, yes, no, yes, no, no, yes, no, no, yes, yes, no, no, no, yes, no, no, yes, no…\n$ Pclass   &lt;fct&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3, 2, 2, 3, 1, 3, 3, 3, 1, 3, 3, 1, 1, 3, 2, 1, 1, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 1, 1, 2, 3, 2, 3, 3…\n$ Name     &lt;chr&gt; \"Braund, Mr. Owen Harris\", \"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\", \"Heikkinen, Miss. Laina\", \"Futrelle, Mrs. Jacques Heath (Lily May Peel)\", \"Allen, Mr. William Henry…\n$ Sex      &lt;fct&gt; male, female, female, female, male, male, male, male, female, female, female, female, male, male, female, female, male, male, female, female, male, male, female, male, female, femal…\n$ Age      &lt;dbl&gt; 22.0, 38.0, 26.0, 35.0, 35.0, NA, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, NA, 31.0, NA, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, NA, 19.0, NA, NA, 40.0, NA, NA, 66.…\n$ SibSp    &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0, 0, 0, 0, 0, 3, 1, 0, 3, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 1, 0, 0, 1, 0, 2, 1, 4, 0, 1, 1, 0, 0, 0, 0, 1, 5, 0…\n$ Parch    &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 5, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 2, 2, 0…\n$ Ticket   &lt;chr&gt; \"A/5 21171\", \"PC 17599\", \"STON/O2. 3101282\", \"113803\", \"373450\", \"330877\", \"17463\", \"349909\", \"347742\", \"237736\", \"PP 9549\", \"113783\", \"A/5. 2151\", \"347082\", \"350406\", \"248706\", \"38…\n$ Fare     &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625, 21.0750, 11.1333, 30.0708, 16.7000, 26.5500, 8.0500, 31.2750, 7.8542, 16.0000, 29.1250, 13.0000, 18.0000, 7.2250, 26.0000,…\n$ Cabin    &lt;chr&gt; \"\", \"C85\", \"\", \"C123\", \"\", \"\", \"E46\", \"\", \"\", \"\", \"G6\", \"C103\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"D56\", \"\", \"A6\", \"\", \"\", \"\", \"C23 C25 C27\", \"\", \"\", \"\", \"B78\", \"\", \"\", \"\", \"\", \"\"…\n$ Embarked &lt;chr&gt; \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"C\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"Q\", \"S\", \"C\", \"C\", \"Q\", \"S\", \"C\", \"S\", \"…\n$ FamSize  &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 4, 2, 1, 2, 0, 0, 6, 0, 0, 5, 0, 1, 0, 0, 0, 0, 0, 4, 6, 0, 5, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 3, 0, 0, 1, 0, 2, 1, 5, 0, 1, 1, 1, 0, 0, 0, 3, 7, 0…\n\n# 3. Select Variables used for Analysis\ntitanic1 &lt;- titanic %&gt;% \n  select(Survived, Pclass, Sex, Age, Fare, FamSize)                     # 분석에 사용할 변수 선택\n\ntitanic1 %&gt;%\n  as_tibble\n\n# A tibble: 891 × 6\n   Survived Pclass Sex      Age  Fare FamSize\n   &lt;fct&gt;    &lt;fct&gt;  &lt;fct&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;int&gt;\n 1 no       3      male      22  7.25       1\n 2 yes      1      female    38 71.3        1\n 3 yes      3      female    26  7.92       0\n 4 yes      1      female    35 53.1        1\n 5 no       3      male      35  8.05       0\n 6 no       3      male      NA  8.46       0\n 7 no       1      male      54 51.9        0\n 8 no       3      male       2 21.1        4\n 9 yes      3      female    27 11.1        2\n10 yes      2      female    14 30.1        1\n# ℹ 881 more rows",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>LASSO Regression</span>"
    ]
  },
  {
    "objectID": "LASSO.html#데이터-탐색",
    "href": "LASSO.html#데이터-탐색",
    "title": "10  LASSO Regression",
    "section": "10.3 데이터 탐색",
    "text": "10.3 데이터 탐색\n\nggpairs(titanic1,                                        \n        aes(colour = Survived)) +                         # Target의 범주에 따라 색깔을 다르게 표현\n  theme_bw()\n\n\n\n\n\n\n\nggpairs(titanic1,                                     \n        aes(colour = Survived, alpha = 0.8)) +            # Target의 범주에 따라 색깔을 다르게 표현\n  scale_colour_manual(values = c(\"#E69F00\", \"#56B4E9\")) + # 특정 색깔 지정\n  scale_fill_manual(values = c(\"#E69F00\", \"#56B4E9\")) +   # 특정 색깔 지정\n  theme_bw()",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>LASSO Regression</span>"
    ]
  },
  {
    "objectID": "LASSO.html#데이터-분할",
    "href": "LASSO.html#데이터-분할",
    "title": "10  LASSO Regression",
    "section": "10.4 데이터 분할",
    "text": "10.4 데이터 분할\n\n# Partition (Training Dataset : Test Dataset = 7:3)\ny      &lt;- titanic1$Survived                             # Target\n\nset.seed(200)\nind    &lt;- createDataPartition(y, p = 0.7, list  =T)     # Index를 이용하여 7:3으로 분할\ntitanic.trd &lt;- titanic1[ind$Resample1,]                 # Training Dataset\ntitanic.ted &lt;- titanic1[-ind$Resample1,]                # Test Dataset",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>LASSO Regression</span>"
    ]
  },
  {
    "objectID": "LASSO.html#데이터-전처리-ii",
    "href": "LASSO.html#데이터-전처리-ii",
    "title": "10  LASSO Regression",
    "section": "10.5 데이터 전처리 II",
    "text": "10.5 데이터 전처리 II\n\n# 1. Imputation\ntitanic.trd.Imp &lt;- titanic.trd %&gt;% \n  mutate(Age = replace_na(Age, mean(Age, na.rm = TRUE)))                 # 평균으로 결측값 대체\n\ntitanic.ted.Imp &lt;- titanic.ted %&gt;% \n  mutate(Age = replace_na(Age, mean(titanic.trd$Age, na.rm = TRUE)))     # Training Dataset을 이용하여 결측값 대체\n\n# 2. Standardization\npreProcValues &lt;- preProcess(titanic.trd.Imp, \n                            method = c(\"center\", \"scale\"))               # Standardization 정의 -&gt; Training Dataset에 대한 평균과 표준편차 계산 \n\ntitanic.trd.Imp &lt;- predict(preProcValues, titanic.trd.Imp)               # Standardization for Training Dataset\ntitanic.ted.Imp &lt;- predict(preProcValues, titanic.ted.Imp)               # Standardization for Test Dataset\n\n# 3. Convert Factor Var. into Dummy Var. \ntrain.x &lt;- model.matrix(Survived ~.,                                     # Survived는 Target으로 제외  \n                        titanic.trd.Imp)[,-1]                            # [,-1] : 절편 제거\n\ntrain.x\n\n    Pclass2 Pclass3 Sexmale         Age         Fare     FamSize\n1         0       1       1 -0.61306970 -0.517763935  0.04506631\n3         0       1       0 -0.30411628 -0.504633254 -0.55421976\n4         0       0       0  0.39102893  0.374149700  0.04506631\n5         0       1       1  0.39102893 -0.502201647 -0.55421976\n6         0       1       1  0.00000000 -0.494259044 -0.55421976\n8         0       1       1 -2.15783684 -0.248828144  1.84292454\n9         0       1       0 -0.22687792 -0.442222643  0.64435239\n10        1       0       0 -1.23097656 -0.073834105  0.04506631\n11        0       1       0 -2.00336012 -0.333934407  0.64435239\n12        0       0       0  2.16751113 -0.142323735 -0.55421976\n14        0       1       1  0.69998236 -0.050408971  3.04149669\n15        0       1       0 -1.23097656 -0.506010517 -0.55421976\n18        1       0       1  0.00000000 -0.405909990 -0.55421976\n19        0       1       0  0.08207551 -0.308645689  0.04506631\n20        0       1       0  0.00000000 -0.518250257 -0.55421976\n21        1       0       1  0.39102893 -0.153022808 -0.55421976\n24        0       0       1 -0.14963956  0.031779363 -0.55421976\n25        0       1       0 -1.69440670 -0.248828144  1.84292454\n27        0       1       1  0.00000000 -0.518250257 -0.55421976\n28        0       0       1 -0.84478477  4.457305033  2.44221062\n29        0       1       0  0.00000000 -0.505524195 -0.55421976\n30        0       1       1  0.00000000 -0.505201278 -0.55421976\n31        0       0       1  0.77722072 -0.119548327 -0.55421976\n32        0       0       0  0.00000000  2.191451452  0.04506631\n33        0       1       0  0.00000000 -0.508037505 -0.55421976\n34        1       0       1  2.78541799 -0.454542140 -0.55421976\n35        0       0       1 -0.14963956  0.939659905  0.04506631\n36        0       0       1  0.93169743  0.352751554  0.04506631\n38        0       1       1 -0.69030806 -0.502201647 -0.55421976\n39        0       1       0 -0.92202313 -0.308645689  0.64435239\n40        0       1       0 -1.23097656 -0.440113953  0.04506631\n41        0       1       0  0.77722072 -0.474481321  0.04506631\n42        1       0       0 -0.22687792 -0.250287109  0.04506631\n43        0       1       1  0.00000000 -0.505201278 -0.55421976\n45        0       1       0 -0.84478477 -0.505524195 -0.55421976\n47        0       1       1  0.00000000 -0.357277839  0.04506631\n48        0       1       0  0.00000000 -0.508037505 -0.55421976\n49        0       1       1  0.00000000 -0.237074726  0.64435239\n50        0       1       0 -0.92202313 -0.312536261  0.04506631\n51        0       1       1 -1.77164505  0.113238214  2.44221062\n53        0       0       0  1.47236593  0.833805222  0.04506631\n55        0       0       1  2.70817963  0.546875535  0.04506631\n56        0       0       1  0.00000000  0.031779363 -0.55421976\n60        0       1       1 -1.46269163  0.253541968  3.64078277\n61        0       1       1 -0.61306970 -0.518168555 -0.55421976\n62        0       0       0  0.62274400  0.897431637 -0.55421976\n64        0       1       1 -2.00336012 -0.116062374  2.44221062\n65        0       0       1  0.00000000 -0.119548327 -0.55421976\n70        0       1       1 -0.30411628 -0.490286770  0.64435239\n72        0       1       0 -1.07649984  0.253541968  3.64078277\n74        0       1       1 -0.30411628 -0.377621640  0.04506631\n75        0       1       1  0.15931386  0.440207722 -0.55421976\n76        0       1       1 -0.38135463 -0.509982791 -0.55421976\n77        0       1       1  0.00000000 -0.505201278 -0.55421976\n79        1       0       1 -2.24820571 -0.094664228  0.64435239\n80        0       1       0  0.00483715 -0.416122741 -0.55421976\n82        0       1       1 -0.07240121 -0.473995000 -0.55421976\n83        0       1       0  0.00000000 -0.507308023 -0.55421976\n84        0       0       1 -0.14963956  0.257432540 -0.55421976\n85        1       0       0 -0.99926149 -0.454542140 -0.55421976\n86        0       1       0  0.23655222 -0.350469338  1.24363847\n88        0       1       1  0.00000000 -0.502201647 -0.55421976\n89        0       0       0 -0.53583135  4.457305033  2.44221062\n91        0       1       1 -0.07240121 -0.502201647 -0.55421976\n92        0       1       1 -0.76754642 -0.506010517 -0.55421976\n93        0       0       1  1.24065086  0.531231545  0.04506631\n94        0       1       1 -0.30411628 -0.258554574  1.24363847\n95        0       1       1  2.24474949 -0.517763935 -0.55421976\n96        0       1       1  0.00000000 -0.502201647 -0.55421976\n97        0       0       1  3.17160977  0.015326133 -0.55421976\n103       0       0       1 -0.69030806  0.844665754  0.04506631\n105       0       1       1  0.54550565 -0.504633254  0.64435239\n107       0       1       0 -0.69030806 -0.509982791 -0.55421976\n108       0       1       1  0.00000000 -0.507551184 -0.55421976\n110       0       1       0  0.00000000 -0.189010600  0.04506631\n111       0       0       1  1.31788921  0.352751554 -0.55421976\n112       0       1       0 -1.19235738 -0.377621640  0.04506631\n113       0       1       1 -0.61306970 -0.502201647 -0.55421976\n114       0       1       0 -0.76754642 -0.467672820  0.04506631\n115       0       1       0 -0.99926149 -0.377541884 -0.55421976\n116       0       1       1 -0.69030806 -0.504633254 -0.55421976\n117       0       1       1  3.13299059 -0.508037505 -0.55421976\n119       0       0       1 -0.45859299  4.156190321  0.04506631\n122       0       1       1  0.00000000 -0.502201647 -0.55421976\n125       0       0       1  1.85855771  0.844665754  0.04506631\n126       0       1       1 -1.38545327 -0.440113953  0.04506631\n128       0       1       1 -0.45859299 -0.519870680 -0.55421976\n129       0       1       0  0.00000000 -0.223864289  0.64435239\n130       0       1       1  1.16341250 -0.523113472 -0.55421976\n131       0       1       1  0.23655222 -0.505201278 -0.55421976\n132       0       1       1 -0.76754642 -0.521654507 -0.55421976\n134       1       0       0 -0.07240121 -0.153022808  0.04506631\n136       1       0       1 -0.53583135 -0.366113328 -0.55421976\n138       0       0       1  0.54550565  0.374149700  0.04506631\n141       0       1       0  0.00000000 -0.362222756  0.64435239\n142       0       1       0 -0.61306970 -0.508037505 -0.55421976\n143       0       1       0 -0.45859299 -0.350469338  0.04506631\n146       1       0       1 -0.84478477  0.056095438  0.64435239\n147       0       1       1 -0.22687792 -0.507146564 -0.55421976\n148       0       1       0 -1.61716834  0.009894895  1.84292454\n149       1       0       1  0.50688647 -0.153022808  0.64435239\n150       1       0       1  0.93169743 -0.405909990 -0.55421976\n151       1       0       1  1.62684264 -0.415150098 -0.55421976\n153       0       1       1  1.97441524 -0.502201647 -0.55421976\n154       0       1       1  0.81583989 -0.376730699  0.64435239\n156       0       0       1  1.62684264  0.535203819  0.04506631\n157       0       1       0 -1.07649984 -0.508362368 -0.55421976\n158       0       1       1  0.00483715 -0.502201647 -0.55421976\n160       0       1       1  0.00000000  0.694149249  5.43864100\n162       1       0       0  0.77722072 -0.352414624 -0.55421976\n163       0       1       1 -0.30411628 -0.507551184 -0.55421976\n164       0       1       1 -0.99926149 -0.490286770 -0.55421976\n167       0       0       0  0.00000000  0.411110134  0.04506631\n169       0       0       1  0.00000000 -0.154481773 -0.55421976\n171       0       0       1  2.39922620 -0.007126358 -0.55421976\n173       0       1       0 -2.23507519 -0.442222643  0.64435239\n174       0       1       1 -0.69030806 -0.504633254 -0.55421976\n176       0       1       1 -0.92202313 -0.506010517  0.64435239\n179       1       0       1  0.00483715 -0.405909990 -0.55421976\n180       0       1       1  0.46826729 -0.658797171 -0.55421976\n181       0       1       0  0.00000000  0.694149249  5.43864100\n182       1       0       1  0.00000000 -0.366031626 -0.55421976\n184       1       0       1 -2.23507519  0.099864373  1.24363847\n185       0       1       0 -2.00336012 -0.230347927  0.64435239\n188       0       0       1  1.16341250 -0.142323735 -0.55421976\n189       0       1       1  0.77722072 -0.357277839  0.64435239\n190       0       1       1  0.46826729 -0.505201278 -0.55421976\n191       1       0       0  0.15931386 -0.405909990 -0.55421976\n192       1       0       1 -0.84478477 -0.405909990 -0.55421976\n194       1       0       1 -2.08059848 -0.153022808  0.64435239\n196       0       0       0  2.16751113  2.191451452 -0.55421976\n197       0       1       1  0.00000000 -0.508037505 -0.55421976\n198       0       1       1  0.93169743 -0.495311444  0.04506631\n199       0       1       0  0.00000000 -0.508037505 -0.55421976\n200       1       0       0 -0.45859299 -0.405909990 -0.55421976\n202       0       1       1  0.00000000  0.694149249  5.43864100\n203       0       1       1  0.31379058 -0.532435282 -0.55421976\n204       0       1       1  1.20203168 -0.518250257 -0.55421976\n205       0       1       1 -0.92202313 -0.502201647 -0.55421976\n206       0       1       0 -2.15783684 -0.455271622  0.04506631\n207       0       1       1  0.15931386 -0.350469338  0.04506631\n209       0       1       0 -1.07649984 -0.508037505 -0.55421976\n211       0       1       1 -0.45859299 -0.521654507 -0.55421976\n212       1       0       0  0.39102893 -0.250287109 -0.55421976\n213       0       1       1 -0.61306970 -0.517763935 -0.55421976\n214       1       0       1  0.00483715 -0.405909990 -0.55421976\n216       0       0       0  0.08207551  1.544725556  0.04506631\n217       0       1       0 -0.22687792 -0.504633254 -0.55421976\n218       1       0       1  0.93169743 -0.133569948  0.04506631\n219       0       0       0  0.15931386  0.825294596 -0.55421976\n220       1       0       1  0.00483715 -0.454542140 -0.55421976\n223       0       1       1  1.62684264 -0.502201647 -0.55421976\n224       0       1       1  0.00000000 -0.505201278 -0.55421976\n226       0       1       1 -0.61306970 -0.476912929 -0.55421976\n227       1       0       1 -0.84478477 -0.454542140 -0.55421976\n229       1       0       1 -0.92202313 -0.405909990 -0.55421976\n230       0       1       0  0.00000000 -0.163397019  1.84292454\n232       0       1       1 -0.07240121 -0.507551184 -0.55421976\n233       1       0       1  2.24474949 -0.396183559 -0.55421976\n235       1       0       1 -0.45859299 -0.454542140 -0.55421976\n236       0       1       0  0.00000000 -0.511928077 -0.55421976\n237       1       0       1  1.08617414 -0.153022808  0.04506631\n238       1       0       0 -1.69440670 -0.148159593  0.64435239\n240       1       0       1  0.23655222 -0.420013313 -0.55421976\n242       0       1       0  0.00000000 -0.357277839  0.04506631\n243       1       0       1 -0.07240121 -0.454542140 -0.55421976\n244       0       1       1 -0.61306970 -0.520195543 -0.55421976\n245       0       1       1  0.00483715 -0.518250257 -0.55421976\n246       0       0       1  1.08617414  1.091960238  0.64435239\n247       0       1       0 -0.38135463 -0.507551184 -0.55421976\n248       1       0       0 -0.45859299 -0.376730699  0.64435239\n249       0       0       1  0.54550565  0.363532329  0.64435239\n252       0       1       0 -0.07240121 -0.455271622  0.64435239\n253       0       0       1  2.47646456 -0.142323735 -0.55421976\n254       0       1       1  0.00483715 -0.345606123  0.04506631\n255       0       1       0  0.85445907 -0.265606236  0.64435239\n257       0       0       0  0.00000000  0.881869349 -0.55421976\n258       0       0       0  0.00483715  1.023875227 -0.55421976\n259       0       0       0  0.39102893  9.307471078 -0.55421976\n262       0       1       1 -2.08059848 -0.048220525  3.04149669\n264       0       0       1  0.77722072 -0.658797171 -0.55421976\n265       0       1       0  0.00000000 -0.508037505 -0.55421976\n266       1       0       1  0.46826729 -0.454542140 -0.55421976\n267       0       1       1 -1.07649984  0.113238214  2.44221062\n269       0       0       0  2.16751113  2.326487371  0.04506631\n270       0       0       0  0.39102893  1.979658438 -0.55421976\n273       1       0       0  0.85445907 -0.279466399  0.04506631\n275       0       1       0  0.00000000 -0.508037505 -0.55421976\n276       0       0       0  2.55370292  0.857714732  0.04506631\n278       1       0       1  0.00000000 -0.658797171 -0.55421976\n280       0       1       0  0.39102893 -0.264876754  0.64435239\n281       0       1       1  2.70817963 -0.508037505 -0.55421976\n285       0       0       1  0.00000000 -0.153022808 -0.55421976\n286       0       1       1  0.23655222 -0.490286770 -0.55421976\n287       0       1       1  0.00483715 -0.473995000 -0.55421976\n288       0       1       1 -0.61306970 -0.505201278 -0.55421976\n289       1       0       1  0.93169743 -0.405909990 -0.55421976\n290       0       1       0 -0.61306970 -0.508037505 -0.55421976\n291       0       0       0 -0.30411628  0.875060848 -0.55421976\n292       0       0       0 -0.84478477  1.112953764  0.04506631\n293       1       0       1  0.46826729 -0.408341597 -0.55421976\n294       0       1       0 -0.45859299 -0.486639359 -0.55421976\n296       0       0       1  0.00000000 -0.119548327 -0.55421976\n297       0       1       1 -0.49721217 -0.518168555 -0.55421976\n298       0       0       0 -2.15783684  2.289283776  1.24363847\n299       0       0       1  0.00000000 -0.065484938 -0.55421976\n300       0       0       0  1.54960428  4.156190321  0.04506631\n302       0       1       1  0.00000000 -0.206518174  0.64435239\n303       0       1       1 -0.84478477 -0.658797171 -0.55421976\n304       1       0       0  0.00000000 -0.418554349 -0.55421976\n305       0       1       1  0.00000000 -0.502201647 -0.55421976\n306       0       0       1 -2.24125426  2.289283776  1.24363847\n307       0       0       0  0.00000000  1.498200151 -0.55421976\n309       1       0       1  0.00483715 -0.191928529  0.04506631\n311       0       0       0 -0.45859299  0.958869605 -0.55421976\n315       1       0       1  1.00893579 -0.148159593  0.64435239\n316       0       1       0 -0.30411628 -0.506010517 -0.55421976\n317       1       0       0 -0.45859299 -0.153022808  0.04506631\n319       0       0       0  0.08207551  2.548331678  0.64435239\n320       0       0       0  0.77722072  1.957612512  0.64435239\n322       0       1       1 -0.22687792 -0.505201278 -0.55421976\n323       1       0       0  0.00483715 -0.418554349 -0.55421976\n324       1       0       0 -0.61306970 -0.094664228  0.64435239\n325       0       1       1  0.00000000  0.694149249  5.43864100\n327       0       1       1  2.39922620 -0.537459956 -0.55421976\n329       0       1       0  0.08207551 -0.259527217  0.64435239\n330       0       0       0 -1.07649984  0.469064095  0.04506631\n331       0       1       0  0.00000000 -0.206518174  0.64435239\n332       0       0       1  1.20203168 -0.104390658 -0.55421976\n335       0       0       0  0.00000000  1.941077581  0.04506631\n336       0       1       1  0.00000000 -0.505201278 -0.55421976\n337       0       0       1 -0.07240121  0.636763311  0.04506631\n339       0       1       1  1.16341250 -0.502201647 -0.55421976\n340       0       0       1  1.16341250  0.031779363 -0.55421976\n341       1       0       1 -2.15783684 -0.153022808  0.64435239\n342       0       0       0 -0.45859299  4.457305033  2.44221062\n343       1       0       1 -0.14963956 -0.405909990 -0.55421976\n345       1       0       1  0.46826729 -0.405909990 -0.55421976\n346       1       0       0 -0.45859299 -0.405909990 -0.55421976\n348       0       1       0  0.00000000 -0.345606123  0.04506631\n349       0       1       1 -2.08059848 -0.349496695  0.64435239\n350       0       1       1  0.93169743 -0.490286770 -0.55421976\n352       0       0       1  0.00000000  0.022052932 -0.55421976\n353       0       1       1 -1.15373820 -0.518168555  0.64435239\n354       0       1       1 -0.38135463 -0.312536261  0.04506631\n355       0       1       1  0.00000000 -0.518250257 -0.55421976\n356       0       1       1 -0.14963956 -0.473995000 -0.55421976\n357       0       0       0 -0.61306970  0.411110134  0.04506631\n360       0       1       0  0.00000000 -0.505524195 -0.55421976\n361       0       1       1  0.77722072 -0.116062374  2.44221062\n362       1       0       1 -0.07240121 -0.119548327  0.04506631\n363       0       1       0  1.16341250 -0.377621640  0.04506631\n365       0       1       1  0.00000000 -0.357277839  0.04506631\n366       0       1       1  0.00483715 -0.517763935 -0.55421976\n367       0       0       0  2.32198785  0.805030551  0.04506631\n368       0       1       0  0.00000000 -0.518168555 -0.55421976\n370       0       0       0 -0.45859299  0.689286034 -0.55421976\n371       0       0       1 -0.38135463  0.419702463  0.04506631\n372       0       1       1 -0.92202313 -0.532435282  0.04506631\n373       0       1       1 -0.84478477 -0.502201647 -0.55421976\n374       0       0       1 -0.61306970  1.979658438 -0.55421976\n376       0       0       0  0.00000000  0.939659905  0.04506631\n377       0       1       0 -0.61306970 -0.517763935 -0.55421976\n379       0       1       1 -0.76754642 -0.580742570 -0.55421976\n381       0       0       0  0.93169743  3.767214822 -0.55421976\n382       0       1       0 -2.23507519 -0.352576083  0.64435239\n383       0       1       1  0.15931386 -0.504633254 -0.55421976\n384       0       0       0  0.39102893  0.352751554  0.04506631\n385       0       1       1  0.00000000 -0.505201278 -0.55421976\n386       1       0       1 -0.92202313  0.770988046 -0.55421976\n387       0       1       1 -2.23507519  0.253541968  3.64078277\n388       1       0       0  0.46826729 -0.405909990 -0.55421976\n389       0       1       1  0.00000000 -0.508442125 -0.55421976\n390       1       0       0 -0.99926149 -0.425362850 -0.55421976\n391       0       0       1  0.46826729  1.675546040  1.24363847\n392       0       1       1 -0.69030806 -0.507146564 -0.55421976\n393       0       1       1 -0.14963956 -0.504633254  0.64435239\n394       0       0       0 -0.53583135  1.544725556  0.04506631\n395       0       1       0 -0.45859299 -0.333934407  0.64435239\n396       0       1       1 -0.61306970 -0.507146564 -0.55421976\n397       0       1       0  0.08207551 -0.506010517 -0.55421976\n398       1       0       1  1.24065086 -0.153022808 -0.55421976\n399       1       0       1 -0.53583135 -0.454542140 -0.55421976\n401       0       1       1  0.69998236 -0.504633254 -0.55421976\n402       0       1       1 -0.30411628 -0.502201647 -0.55421976\n404       0       1       1 -0.14963956 -0.350469338  0.04506631\n405       0       1       0 -0.76754642 -0.490286770 -0.55421976\n406       1       0       1  0.31379058 -0.250287109  0.04506631\n407       0       1       1  1.62684264 -0.508037505 -0.55421976\n408       1       0       1 -2.08059848 -0.294056044  0.64435239\n410       0       1       0  0.00000000 -0.163397019  1.84292454\n411       0       1       1  0.00000000 -0.505201278 -0.55421976\n414       1       0       1  0.00000000 -0.658797171 -0.55421976\n417       1       0       0  0.31379058 -0.026579218  0.64435239\n421       0       1       1  0.00000000 -0.505201278 -0.55421976\n422       0       1       1 -0.69030806 -0.508362368 -0.55421976\n423       0       1       1 -0.07240121 -0.505605898 -0.55421976\n425       0       1       1 -0.92202313 -0.265606236  0.64435239\n426       0       1       1  0.00000000 -0.517763935 -0.55421976\n428       1       0       0 -0.84478477 -0.153022808 -0.55421976\n429       0       1       1  0.00000000 -0.508037505 -0.55421976\n431       0       0       1 -0.14963956 -0.142323735 -0.55421976\n432       0       1       0  0.00000000 -0.345606123  0.04506631\n433       1       0       0  0.93169743 -0.153022808  0.04506631\n434       0       1       1 -0.99926149 -0.520195543 -0.55421976\n435       0       0       1  1.54960428  0.428617708  0.04506631\n437       0       1       0 -0.69030806  0.009894895  1.84292454\n438       1       0       0 -0.45859299 -0.294056044  2.44221062\n439       0       0       1  2.63094127  4.457305033  2.44221062\n443       0       1       1 -0.38135463 -0.507551184  0.04506631\n444       1       0       0 -0.14963956 -0.405909990 -0.55421976\n446       0       0       1 -2.00336012  0.933580887  0.64435239\n449       0       1       0 -1.92612177 -0.284168155  1.24363847\n451       1       0       1  0.46826729 -0.118980303  1.24363847\n453       0       0       1  0.00483715 -0.118980303 -0.55421976\n454       0       0       1  1.47236593  1.074534365  0.04506631\n456       0       1       1 -0.07240121 -0.505201278 -0.55421976\n459       1       0       0  1.54960428 -0.454542140 -0.55421976\n460       0       1       1  0.00000000 -0.508037505 -0.55421976\n461       0       0       1  1.39512757 -0.142323735 -0.55421976\n463       0       0       1  1.31788921  0.090137943 -0.55421976\n464       1       0       1  1.39512757 -0.405909990 -0.55421976\n465       0       1       1  0.00000000 -0.502201647 -0.55421976\n466       0       1       1  0.62274400 -0.521654507 -0.55421976\n468       0       0       1  2.01303442 -0.142323735 -0.55421976\n470       0       1       0 -2.25438478 -0.284168155  1.24363847\n471       0       1       1  0.00000000 -0.517763935 -0.55421976\n472       0       1       1  0.62274400 -0.490286770 -0.55421976\n474       1       0       0 -0.53583135 -0.390509160 -0.55421976\n475       0       1       0 -0.61306970 -0.467429660 -0.55421976\n479       0       1       1 -0.61306970 -0.512496101 -0.55421976\n480       0       1       0 -2.15783684 -0.419770152  0.04506631\n481       0       1       1 -1.61716834  0.253541968  3.64078277\n484       0       1       0  2.55370292 -0.472292875 -0.55421976\n485       0       0       1 -0.38135463  1.112953764  0.04506631\n486       0       1       0  0.00000000 -0.163397019  1.84292454\n487       0       0       0  0.39102893  1.091960238  0.04506631\n489       0       1       1  0.00483715 -0.502201647 -0.55421976\n491       0       1       1  0.00000000 -0.270387749  0.04506631\n493       0       0       1  1.93579607 -0.065484938 -0.55421976\n494       0       0       1  3.17160977  0.304201106 -0.55421976\n497       0       0       0  1.85855771  0.863713994  0.04506631\n498       0       1       1  0.00000000 -0.365058983 -0.55421976\n499       0       0       0 -0.38135463  2.289283776  1.24363847\n500       0       1       1 -0.45859299 -0.507146564 -0.55421976\n501       0       1       1 -0.99926149 -0.490286770 -0.55421976\n502       0       1       0 -0.69030806 -0.508037505 -0.55421976\n503       0       1       0  0.00000000 -0.510387411 -0.55421976\n504       0       1       0  0.54550565 -0.472292875 -0.55421976\n505       0       0       0 -1.07649984  1.023875227 -0.55421976\n506       0       0       1 -0.92202313  1.459619293  0.04506631\n507       1       0       0  0.23655222 -0.153022808  0.64435239\n508       0       0       1  0.00000000 -0.142323735 -0.55421976\n509       0       1       1 -0.14963956 -0.220621497 -0.55421976\n511       0       1       1 -0.07240121 -0.508037505 -0.55421976\n512       0       1       1  0.00000000 -0.502201647 -0.55421976\n513       0       0       1  0.46826729 -0.147430111 -0.55421976\n514       0       0       0  1.85855771  0.496702719  0.04506631\n516       0       0       1  1.31788921  0.003004692 -0.55421976\n517       1       0       0  0.31379058 -0.454542140 -0.55421976\n518       0       1       1  0.00000000 -0.189010600 -0.55421976\n519       1       0       0  0.46826729 -0.153022808  0.04506631\n521       0       0       0  0.00483715  1.160045248 -0.55421976\n522       0       1       1 -0.61306970 -0.505201278 -0.55421976\n524       0       0       0  1.08617414  0.469064095  0.04506631\n526       0       1       1  0.81583989 -0.508037505 -0.55421976\n528       0       0       1  0.00000000  3.655442578 -0.55421976\n530       1       0       1 -0.53583135 -0.435089280  1.24363847\n532       0       1       1  0.00000000 -0.518168555 -0.55421976\n533       0       1       1 -0.99926149 -0.518168555  0.64435239\n535       0       1       0  0.00483715 -0.490286770 -0.55421976\n536       1       0       0 -1.77164505 -0.148159593  0.64435239\n537       0       0       1  1.16341250 -0.142323735 -0.55421976\n538       0       0       0  0.00483715  1.411473465 -0.55421976\n541       0       0       0  0.46826729  0.722355896  0.64435239\n542       0       1       0 -1.61716834 -0.050408971  3.04149669\n543       0       1       0 -1.46269163 -0.050408971  3.04149669\n544       1       0       1  0.15931386 -0.153022808  0.04506631\n545       0       0       1  1.54960428  1.411473465  0.04506631\n546       0       0       1  2.63094127 -0.153022808 -0.55421976\n547       1       0       0 -0.84478477 -0.153022808  0.04506631\n548       1       0       1  0.00000000 -0.389131898 -0.55421976\n549       0       1       1  0.23655222 -0.259527217  0.64435239\n552       1       0       1 -0.22687792 -0.153022808 -0.55421976\n553       0       1       1  0.00000000 -0.506496838 -0.55421976\n555       0       1       0 -0.61306970 -0.507551184 -0.55421976\n556       0       0       1  2.47646456 -0.142323735 -0.55421976\n557       0       0       0  1.39512757  0.111536089  0.04506631\n558       0       0       1  0.00000000  3.767214822 -0.55421976\n559       0       0       0  0.69998236  0.890623136  0.64435239\n560       0       1       0  0.46826729 -0.320317405  0.04506631\n561       0       1       1  0.00000000 -0.508037505 -0.55421976\n563       1       0       1 -0.14963956 -0.396183559 -0.55421976\n564       0       1       1  0.00000000 -0.502201647 -0.55421976\n565       0       1       0  0.00000000 -0.502201647 -0.55421976\n567       0       1       1 -0.84478477 -0.505201278 -0.55421976\n568       0       1       0 -0.07240121 -0.248828144  1.84292454\n569       0       1       1  0.00000000 -0.518168555 -0.55421976\n570       0       1       1  0.15931386 -0.506010517 -0.55421976\n573       0       0       1  0.46826729 -0.145484825 -0.55421976\n575       0       1       1 -1.07649984 -0.502201647 -0.55421976\n576       0       1       1 -0.84478477 -0.376730699 -0.55421976\n577       1       0       0  0.31379058 -0.405909990 -0.55421976\n578       0       0       0  0.69998236  0.428617708  0.04506631\n579       0       1       0  0.00000000 -0.377541884  0.04506631\n580       0       1       1  0.15931386 -0.504633254 -0.55421976\n581       1       0       0 -0.38135463 -0.075211368  0.64435239\n584       0       0       1  0.46826729  0.121748840 -0.55421976\n585       0       1       1  0.00000000 -0.489314127 -0.55421976\n587       1       0       1  1.31788921 -0.367004269 -0.55421976\n588       0       0       1  2.32198785  0.881869349  0.64435239\n590       0       1       1  0.00000000 -0.502201647 -0.55421976\n591       0       1       1  0.39102893 -0.520195543 -0.55421976\n592       0       0       0  1.70408100  0.863713994  0.04506631\n593       0       1       1  1.31788921 -0.517763935 -0.55421976\n594       0       1       0  0.00000000 -0.508037505  0.64435239\n595       1       0       1  0.54550565 -0.153022808  0.04506631\n596       0       1       1  0.46826729 -0.189010600  0.64435239\n597       1       0       0  0.00000000 -0.016852788 -0.55421976\n598       0       1       1  1.47236593 -0.658797171 -0.55421976\n600       0       0       1  1.47236593  0.448638592  0.04506631\n601       1       0       0 -0.45859299 -0.133569948  1.24363847\n603       0       0       1  0.00000000  0.166004097 -0.55421976\n605       0       0       1  0.39102893 -0.142323735 -0.55421976\n606       0       1       1  0.46826729 -0.356305196  0.04506631\n608       0       0       1 -0.22687792 -0.065484938 -0.55421976\n609       1       0       0 -0.61306970  0.150037190  1.24363847\n610       0       0       0  0.77722072  2.326487371 -0.55421976\n611       0       1       0  0.69998236 -0.050408971  3.04149669\n612       0       1       1  0.00000000 -0.521654507 -0.55421976\n613       0       1       0  0.00000000 -0.357277839  0.04506631\n614       0       1       1  0.00000000 -0.508037505 -0.55421976\n615       0       1       1  0.39102893 -0.502201647 -0.55421976\n616       1       0       0 -0.45859299  0.605638735  1.24363847\n617       0       1       1  0.31379058 -0.378675985  0.64435239\n618       0       1       0 -0.30411628 -0.345606123  0.04506631\n619       1       0       0 -2.00336012  0.099864373  1.24363847\n621       0       1       1 -0.22687792 -0.377621640  0.04506631\n622       0       0       1  0.93169743  0.363532329  0.04506631\n623       0       1       1 -0.76754642 -0.352576083  0.64435239\n624       0       1       1 -0.69030806 -0.506010517 -0.55421976\n625       0       1       1 -0.69030806 -0.345606123 -0.55421976\n626       0       0       1  2.39922620 -0.030065170 -0.55421976\n627       1       0       1  2.09027278 -0.418554349 -0.55421976\n631       0       0       1  3.86675498 -0.075211368 -0.55421976\n633       0       0       1  0.15931386 -0.065484938 -0.55421976\n634       0       0       1  0.00000000 -0.658797171 -0.55421976\n635       0       1       0 -1.61716834 -0.116062374  2.44221062\n637       0       1       1  0.15931386 -0.504633254 -0.55421976\n638       1       0       1  0.08207551 -0.148159593  0.64435239\n639       0       1       0  0.85445907  0.113238214  2.44221062\n640       0       1       1  0.00000000 -0.345606123  0.04506631\n641       0       1       1 -0.76754642 -0.506010517 -0.55421976\n642       0       0       0 -0.45859299  0.689286034 -0.55421976\n644       0       1       1  0.00000000  0.440207722 -0.55421976\n645       0       1       0 -2.25438478 -0.284168155  1.24363847\n646       0       0       1  1.39512757  0.833805222  0.04506631\n647       0       1       1 -0.84478477 -0.505201278 -0.55421976\n648       0       0       1  2.01303442  0.031779363 -0.55421976\n649       0       1       1  0.00000000 -0.511928077 -0.55421976\n650       0       1       0 -0.53583135 -0.511928077 -0.55421976\n651       0       1       1  0.00000000 -0.505201278 -0.55421976\n654       0       1       0  0.00000000 -0.506496838 -0.55421976\n655       0       1       0 -0.92202313 -0.527490365 -0.55421976\n656       1       0       1 -0.45859299  0.770988046  0.64435239\n658       0       1       0  0.15931386 -0.357277839  0.64435239\n659       1       0       1 -0.53583135 -0.405909990 -0.55421976\n661       0       0       1  1.54960428  1.941077581  0.64435239\n662       0       1       1  0.77722072 -0.518250257 -0.55421976\n663       0       0       1  1.31788921 -0.161047113 -0.55421976\n667       1       0       1 -0.38135463 -0.405909990 -0.55421976\n668       0       1       1  0.00000000 -0.507551184 -0.55421976\n670       0       0       0  0.00000000  0.352751554  0.04506631\n671       1       0       0  0.77722072  0.099864373  0.64435239\n674       1       0       1  0.08207551 -0.405909990 -0.55421976\n677       0       1       1 -0.41997381 -0.502201647 -0.55421976\n678       0       1       0 -0.92202313 -0.467347958 -0.55421976\n679       0       1       0  1.00893579  0.253541968  3.64078277\n681       0       1       0  0.00000000 -0.500499522 -0.55421976\n682       0       0       1 -0.22687792  0.833805222 -0.55421976\n683       0       1       1 -0.76754642 -0.479344536 -0.55421976\n687       0       1       1 -1.23097656  0.113238214  2.44221062\n689       0       1       1 -0.92202313 -0.507146564 -0.55421976\n690       0       0       0 -1.15373820  3.452321649  0.04506631\n691       0       0       1  0.08207551  0.450015854  0.04506631\n692       0       1       0 -2.00336012 -0.397803983  0.04506631\n693       0       1       1  0.00000000  0.440207722 -0.55421976\n694       0       1       1 -0.38135463 -0.518250257 -0.55421976\n695       0       0       1  2.32198785 -0.142323735 -0.55421976\n699       0       0       1  1.47236593  1.498200151  0.64435239\n701       0       0       0 -0.92202313  3.767214822  0.04506631\n702       0       0       1  0.39102893 -0.147430111 -0.55421976\n703       0       1       0 -0.92202313 -0.377621640  0.04506631\n704       0       1       1 -0.38135463 -0.508198964 -0.55421976\n705       0       1       1 -0.30411628 -0.506010517  0.04506631\n708       0       0       1  0.93169743 -0.147430111 -0.55421976\n709       0       0       0 -0.61306970  2.289283776 -0.55421976\n710       0       1       1  0.00000000 -0.362222756  0.64435239\n712       0       0       1  0.00000000 -0.142323735 -0.55421976\n713       0       0       1  1.39512757  0.352751554  0.04506631\n714       0       1       1 -0.07240121 -0.474319863 -0.55421976\n716       0       1       1 -0.84478477 -0.509982791 -0.55421976\n717       0       0       0  0.62274400  3.767214822 -0.55421976\n718       1       0       0 -0.22687792 -0.454542140 -0.55421976\n719       0       1       1  0.00000000 -0.357277839 -0.55421976\n720       0       1       1  0.23655222 -0.507551184 -0.55421976\n721       1       0       0 -1.84888341 -0.016852788  0.04506631\n723       1       0       1  0.31379058 -0.405909990 -0.55421976\n725       0       0       1 -0.22687792  0.374149700  0.04506631\n726       0       1       1 -0.76754642 -0.490286770 -0.55421976\n728       0       1       0  0.00000000 -0.508280666 -0.55421976\n729       1       0       1 -0.38135463 -0.153022808  0.04506631\n730       0       1       0 -0.38135463 -0.504633254  0.04506631\n732       0       1       1 -1.46269163 -0.293326562 -0.55421976\n735       1       0       1 -0.53583135 -0.405909990 -0.55421976\n736       0       1       1 -0.11102039 -0.345606123 -0.55421976\n737       0       1       0  1.39512757  0.009894895  1.84292454\n738       0       0       1  0.39102893  9.307471078 -0.55421976\n739       0       1       1  0.00000000 -0.505201278 -0.55421976\n740       0       1       1  0.00000000 -0.505201278 -0.55421976\n742       0       0       1  0.46826729  0.875060848  0.04506631\n743       0       0       0 -0.69030806  4.445146996  1.84292454\n744       0       1       1 -0.45859299 -0.345606123  0.04506631\n745       0       1       1  0.08207551 -0.504633254 -0.55421976\n749       0       0       1 -0.84478477  0.374149700  0.04506631\n750       0       1       1  0.08207551 -0.508037505 -0.55421976\n752       0       1       1 -1.84888341 -0.416122741  0.04506631\n753       0       1       1  0.23655222 -0.473995000 -0.55421976\n754       0       1       1 -0.53583135 -0.505201278 -0.55421976\n755       1       0       0  1.39512757  0.605638735  1.24363847\n757       0       1       1 -0.14963956 -0.507146564 -0.55421976\n759       0       1       1  0.31379058 -0.502201647 -0.55421976\n760       0       0       0  0.23655222  1.023875227 -0.55421976\n762       0       1       1  0.85445907 -0.520195543 -0.55421976\n763       0       1       1 -0.76754642 -0.518168555 -0.55421976\n764       0       0       0  0.46826729  1.675546040  1.24363847\n766       0       0       0  1.62684264  0.857714732  0.04506631\n767       0       0       1  0.00000000  0.111536089 -0.55421976\n768       0       1       0  0.04345633 -0.508037505 -0.55421976\n769       0       1       1  0.00000000 -0.189010600  0.04506631\n770       0       1       1  0.15931386 -0.496122628 -0.55421976\n771       0       1       1 -0.45859299 -0.473995000 -0.55421976\n773       1       0       0  2.09027278 -0.454542140 -0.55421976\n774       0       1       1  0.00000000 -0.518250257 -0.55421976\n777       0       1       1  0.00000000 -0.508037505 -0.55421976\n778       0       1       0 -1.92612177 -0.416122741 -0.55421976\n780       0       0       0  1.00893579  3.452321649  0.04506631\n781       0       1       0 -1.30821491 -0.518168555 -0.55421976\n782       0       0       0 -0.99926149  0.450015854  0.04506631\n783       0       0       1 -0.07240121 -0.075211368 -0.55421976\n784       0       1       1  0.00000000 -0.202627602  1.24363847\n786       0       1       1 -0.38135463 -0.517763935 -0.55421976\n789       0       1       1 -2.23507519 -0.258554574  1.24363847\n790       0       0       1  1.24065086  0.881869349 -0.55421976\n791       0       1       1  0.00000000 -0.508037505 -0.55421976\n792       1       0       1 -1.07649984 -0.153022808 -0.55421976\n793       0       1       0  0.00000000  0.694149249  5.43864100\n794       0       0       1  0.00000000 -0.061676068 -0.55421976\n795       0       1       1 -0.38135463 -0.505201278 -0.55421976\n796       1       0       1  0.69998236 -0.405909990 -0.55421976\n797       0       0       0  1.47236593 -0.154400071 -0.55421976\n799       0       1       1  0.00483715 -0.518168555 -0.55421976\n800       0       1       0  0.00483715 -0.189010600  0.64435239\n801       1       0       1  0.31379058 -0.405909990 -0.55421976\n803       0       0       1 -1.46269163  1.675546040  1.24363847\n804       0       1       1 -2.27987344 -0.493122997  0.04506631\n806       0       1       1  0.08207551 -0.507551184 -0.55421976\n808       0       1       0 -0.92202313 -0.507551184 -0.55421976\n811       0       1       1 -0.30411628 -0.505362737 -0.55421976\n812       0       1       1  0.69998236 -0.189010600 -0.55421976\n813       1       0       1  0.39102893 -0.454542140 -0.55421976\n815       0       1       1  0.04345633 -0.502201647 -0.55421976\n816       0       0       1  0.00000000 -0.658797171 -0.55421976\n817       0       1       0 -0.53583135 -0.504633254 -0.55421976\n819       0       1       1  1.00893579 -0.533326223 -0.55421976\n822       0       1       1 -0.22687792 -0.490286770 -0.55421976\n823       0       0       1  0.62274400 -0.658797171 -0.55421976\n824       0       1       0 -0.22687792 -0.416122741  0.04506631\n825       0       1       1 -2.15783684  0.113238214  2.44221062\n826       0       1       1  0.00000000 -0.523599793 -0.55421976\n827       0       1       1  0.00000000  0.440207722 -0.55421976\n828       1       0       1 -2.23507519  0.061040355  0.64435239\n831       0       1       0 -1.15373820 -0.377621640  0.04506631\n832       1       0       1 -2.24820571 -0.294056044  0.64435239\n833       0       1       1  0.00000000 -0.518168555 -0.55421976\n835       0       1       1 -0.92202313 -0.497338432 -0.55421976\n836       0       0       0  0.69998236  0.958869605  0.64435239\n838       0       1       1  0.00000000 -0.502201647 -0.55421976\n840       0       0       1  0.00000000 -0.081047226 -0.55421976\n843       0       0       0  0.00483715 -0.055758508 -0.55421976\n845       0       1       1 -0.99926149 -0.490286770 -0.55421976\n846       0       1       1  0.93169743 -0.511928077 -0.55421976\n847       0       1       1  0.00000000  0.694149249  5.43864100\n849       1       0       1 -0.14963956 -0.016852788  0.04506631\n850       0       0       0  0.00000000  1.074534365  0.04506631\n851       0       1       1 -2.00336012 -0.050408971  3.04149669\n852       0       1       1  3.40332484 -0.507551184 -0.55421976\n853       0       1       0 -1.61716834 -0.362222756  0.64435239\n855       1       0       0  1.08617414 -0.153022808  0.04506631\n856       0       1       0 -0.92202313 -0.476912929  0.04506631\n857       0       0       0  1.16341250  2.548331678  0.64435239\n858       0       0       1  1.62684264 -0.142323735 -0.55421976\n859       0       1       0 -0.45859299 -0.284168155  1.24363847\n860       0       1       1  0.00000000 -0.518168555 -0.55421976\n861       0       1       1  0.85445907 -0.384350385  0.64435239\n862       1       0       1 -0.69030806 -0.435089280  0.04506631\n864       0       1       0  0.00000000  0.694149249  5.43864100\n865       1       0       1 -0.45859299 -0.405909990 -0.55421976\n867       1       0       0 -0.22687792 -0.389213600  0.04506631\n868       0       0       1  0.08207551  0.323490562 -0.55421976\n871       0       1       1 -0.30411628 -0.505201278 -0.55421976\n872       0       0       0  1.31788921  0.363532329  0.64435239\n874       0       1       1  1.31788921 -0.483721430 -0.55421976\n877       0       1       1 -0.76754642 -0.467268201 -0.55421976\n878       0       1       1 -0.84478477 -0.505201278 -0.55421976\n879       0       1       1  0.00000000 -0.505201278 -0.55421976\n880       0       0       0  2.01303442  0.958869605  0.04506631\n881       1       0       0 -0.38135463 -0.153022808  0.04506631\n882       0       1       1  0.23655222 -0.505201278 -0.55421976\n883       0       1       0 -0.61306970 -0.454217277 -0.55421976\n885       0       1       1 -0.38135463 -0.521654507 -0.55421976\n886       0       1       0  0.69998236 -0.092232621  2.44221062\n887       1       0       1 -0.22687792 -0.405909990 -0.55421976\n888       0       0       0 -0.84478477 -0.075211368 -0.55421976\n889       0       1       0  0.00000000 -0.202627602  1.24363847\n\ntest.x &lt;- model.matrix(Survived ~.,                                      # Survived는 Target으로 제외  \n                       titanic.ted.Imp)[,-1]                             # [,-1] : 절편 제거\n\ntest.x\n\n    Pclass2 Pclass3 Sexmale         Age         Fare     FamSize\n2         0       0       0  0.62274400  0.727866891  0.04506631\n7         0       0       1  1.85855771  0.350076786 -0.55421976\n13        0       1       1 -0.76754642 -0.502201647 -0.55421976\n16        1       0       0  1.93579607 -0.347551409 -0.55421976\n17        0       1       1 -2.15783684 -0.092232621  2.44221062\n22        1       0       1  0.31379058 -0.405909990 -0.55421976\n23        0       1       0 -1.15373820 -0.502606266 -0.55421976\n26        0       1       0  0.62274400 -0.048220525  3.04149669\n37        0       1       1  0.00000000 -0.518168555 -0.55421976\n44        1       0       0 -2.08059848  0.150037190  1.24363847\n46        0       1       1  0.00000000 -0.502201647 -0.55421976\n52        0       1       1 -0.69030806 -0.507064862 -0.55421976\n54        1       0       0 -0.07240121 -0.153022808  0.04506631\n57        1       0       0 -0.69030806 -0.454542140 -0.55421976\n58        0       1       1 -0.11102039 -0.518168555 -0.55421976\n59        1       0       0 -1.92612177 -0.118980303  1.24363847\n63        0       0       1  1.16341250  0.965030325  0.04506631\n66        0       1       1  0.00000000 -0.362222756  0.64435239\n67        1       0       0 -0.07240121 -0.454542140 -0.55421976\n68        0       1       1 -0.84478477 -0.500094902 -0.55421976\n69        0       1       0 -0.99926149 -0.504633254  3.04149669\n71        1       0       1  0.15931386 -0.454542140 -0.55421976\n73        1       0       1 -0.69030806  0.770988046 -0.55421976\n78        0       1       1  0.00000000 -0.502201647 -0.55421976\n81        0       1       1 -0.61306970 -0.483721430 -0.55421976\n87        0       1       1 -1.07649984  0.009894895  1.84292454\n90        0       1       1 -0.45859299 -0.502201647 -0.55421976\n98        0       0       1 -0.53583135  0.573702975  0.04506631\n99        1       0       0  0.31379058 -0.211381389  0.04506631\n100       1       0       1  0.31379058 -0.153022808  0.04506631\n101       0       1       0 -0.14963956 -0.505201278 -0.55421976\n102       0       1       1  0.00000000 -0.505201278 -0.55421976\n104       0       1       1  0.23655222 -0.490448229 -0.55421976\n106       0       1       1 -0.14963956 -0.505201278 -0.55421976\n109       0       1       1  0.62274400 -0.505201278 -0.55421976\n118       1       0       1 -0.07240121 -0.250287109  0.04506631\n120       0       1       0 -2.15783684 -0.050408971  3.04149669\n121       1       0       1 -0.69030806  0.770988046  0.64435239\n123       1       0       1  0.19793304 -0.073834105  0.04506631\n124       1       0       0  0.19793304 -0.405909990 -0.55421976\n127       0       1       1  0.00000000 -0.508037505 -0.55421976\n133       0       1       0  1.31788921 -0.376730699  0.04506631\n135       1       0       1 -0.38135463 -0.405909990 -0.55421976\n137       0       0       0 -0.84478477 -0.147511813  0.64435239\n139       0       1       1 -1.07649984 -0.479505995 -0.55421976\n140       0       0       1 -0.45859299  0.881869349 -0.55421976\n144       0       1       1 -0.84478477 -0.527490365 -0.55421976\n145       1       0       1 -0.92202313 -0.435089280 -0.55421976\n152       0       0       0 -0.61306970  0.636763311  0.04506631\n155       0       1       1  0.00000000 -0.516548131 -0.55421976\n159       0       1       1  0.00000000 -0.490286770 -0.55421976\n161       0       1       1  1.08617414 -0.345606123  0.04506631\n165       0       1       1 -2.23507519  0.113238214  2.44221062\n166       0       1       1 -1.61716834 -0.259527217  0.64435239\n168       0       1       0  1.16341250 -0.116062374  2.44221062\n170       0       1       1 -0.14963956  0.440207722 -0.55421976\n172       0       1       1 -2.00336012 -0.092232621  2.44221062\n175       0       0       1  2.01303442 -0.061676068 -0.55421976\n177       0       1       1  0.00000000 -0.163397019  1.84292454\n178       0       0       0  1.54960428 -0.100256925 -0.55421976\n183       0       1       1 -1.61716834 -0.048220525  3.04149669\n186       0       0       1  0.00000000  0.313845834 -0.55421976\n187       0       1       0  0.00000000 -0.357277839  0.04506631\n193       0       1       0 -0.84478477 -0.506010517  0.04506631\n195       0       0       0  1.08617414 -0.119548327 -0.55421976\n201       0       1       1 -0.14963956 -0.473995000 -0.55421976\n208       0       1       1 -0.30411628 -0.293326562 -0.55421976\n210       0       0       1  0.77722072 -0.055758508 -0.55421976\n215       0       1       1  0.00000000 -0.508037505  0.04506631\n221       0       1       1 -1.07649984 -0.502201647 -0.55421976\n222       1       0       1 -0.22687792 -0.405909990 -0.55421976\n225       0       0       1  0.62274400  1.091960238  0.04506631\n228       0       1       1 -0.72892724 -0.517763935 -0.55421976\n231       0       0       0  0.39102893  0.965030325  0.04506631\n234       0       1       0 -1.92612177 -0.048220525  3.04149669\n239       1       0       1 -0.84478477 -0.454542140 -0.55421976\n241       0       1       0  0.00000000 -0.377621640  0.04506631\n250       1       0       1  1.85855771 -0.153022808  0.04506631\n251       0       1       1  0.00000000 -0.517763935 -0.55421976\n256       0       1       0 -0.07240121 -0.362222756  0.64435239\n260       1       0       0  1.54960428 -0.153022808  0.04506631\n261       0       1       1  0.00000000 -0.508037505 -0.55421976\n263       0       0       1  1.70408100  0.890623136  0.64435239\n268       0       1       1 -0.38135463 -0.507551184  0.04506631\n271       0       0       1  0.00000000 -0.055758508 -0.55421976\n272       0       1       1 -0.38135463 -0.658797171 -0.55421976\n274       0       0       1  0.54550565 -0.081047226  0.04506631\n277       0       1       0  1.16341250 -0.508037505 -0.55421976\n279       0       1       1 -1.77164505 -0.092232621  2.44221062\n282       0       1       1 -0.14963956 -0.506010517 -0.55421976\n283       0       1       1 -1.07649984 -0.473995000 -0.55421976\n284       0       1       1 -0.84478477 -0.502201647 -0.55421976\n295       0       1       1 -0.45859299 -0.505201278 -0.55421976\n301       0       1       0  0.00000000 -0.508037505 -0.55421976\n308       0       0       0 -0.99926149  1.459619293  0.04506631\n310       0       0       0  0.00483715  0.448638592 -0.55421976\n312       0       0       0 -0.92202313  4.445146996  1.84292454\n313       1       0       0 -0.30411628 -0.153022808  0.64435239\n314       0       1       1 -0.14963956 -0.505201278 -0.55421976\n318       1       0       1  1.85855771 -0.386457129 -0.55421976\n321       0       1       1 -0.61306970 -0.517763935 -0.55421976\n326       0       0       0  0.46826729  1.979658438 -0.55421976\n328       1       0       0  0.46826729 -0.405909990 -0.55421976\n333       0       0       1  0.62274400  2.326487371  0.04506631\n334       0       1       1 -1.07649984 -0.308645689  0.64435239\n338       0       0       0  0.85445907  1.957612512 -0.55421976\n344       1       0       1 -0.38135463 -0.405909990 -0.55421976\n347       1       0       0  0.77722072 -0.405909990 -0.55421976\n351       0       1       1 -0.53583135 -0.479344536 -0.55421976\n358       1       0       0  0.62274400 -0.405909990 -0.55421976\n359       0       1       0  0.00000000 -0.505524195 -0.55421976\n364       0       1       1  0.39102893 -0.521654507 -0.55421976\n369       0       1       0  0.00000000 -0.508037505 -0.55421976\n375       0       1       0 -2.08059848 -0.248828144  1.84292454\n378       0       0       1 -0.22687792  3.455482739  0.64435239\n380       0       1       1 -0.84478477 -0.507551184 -0.55421976\n400       1       0       0 -0.14963956 -0.412718491 -0.55421976\n403       0       1       0 -0.69030806 -0.467672820  0.04506631\n409       0       1       1 -0.69030806 -0.507551184 -0.55421976\n412       0       1       1  0.00000000 -0.525383620 -0.55421976\n413       0       0       0  0.23655222  1.091960238  0.04506631\n415       0       1       1  1.08617414 -0.504633254 -0.55421976\n416       0       1       0  0.00000000 -0.502201647 -0.55421976\n418       1       0       0 -0.92202313 -0.405909990  0.64435239\n419       1       0       1  0.00483715 -0.405909990 -0.55421976\n420       0       1       0 -1.53992998 -0.189010600  0.64435239\n424       0       1       0 -0.14963956 -0.378675985  0.64435239\n427       1       0       0 -0.14963956 -0.153022808  0.04506631\n430       0       1       1  0.15931386 -0.502201647 -0.55421976\n436       0       0       0 -1.23097656  1.675546040  1.24363847\n440       1       0       1  0.08207551 -0.454542140 -0.55421976\n441       1       0       0  1.16341250 -0.148159593  0.64435239\n442       0       1       1 -0.76754642 -0.473995000 -0.55421976\n445       0       1       1  0.00000000 -0.500985843 -0.55421976\n447       1       0       0 -1.30821491 -0.279466399  0.04506631\n448       0       0       1  0.31379058 -0.142323735 -0.55421976\n450       0       0       1  1.70408100 -0.065484938 -0.55421976\n452       0       1       1  0.00000000 -0.270387749  0.04506631\n455       0       1       1  0.00000000 -0.502201647 -0.55421976\n457       0       0       1  2.70817963 -0.142323735 -0.55421976\n458       0       0       0  0.00000000  0.350076786  0.04506631\n462       0       1       1  0.31379058 -0.502201647 -0.55421976\n467       1       0       1  0.00000000 -0.658797171 -0.55421976\n469       0       1       1  0.00000000 -0.508523827 -0.55421976\n473       1       0       0  0.23655222 -0.118980303  1.24363847\n476       0       0       1  0.00000000  0.352751554 -0.55421976\n477       1       0       1  0.31379058 -0.250287109  0.04506631\n478       0       1       1 -0.07240121 -0.521736209  0.04506631\n482       1       0       1  0.00000000 -0.658797171 -0.55421976\n483       0       1       1  1.54960428 -0.502201647 -0.55421976\n488       0       0       1  2.16751113 -0.081047226 -0.55421976\n490       0       1       1 -1.61716834 -0.349496695  0.64435239\n492       0       1       1 -0.69030806 -0.517763935 -0.55421976\n495       0       1       1 -0.69030806 -0.502201647 -0.55421976\n496       0       1       1  0.00000000 -0.377541884 -0.55421976\n510       0       1       1 -0.30411628  0.440207722 -0.55421976\n515       0       1       1 -0.45859299 -0.512982422 -0.55421976\n520       0       1       1  0.15931386 -0.505201278 -0.55421976\n523       0       1       1  0.00000000 -0.518250257 -0.55421976\n525       0       1       1  0.00000000 -0.518168555 -0.55421976\n527       1       0       0  1.54960428 -0.454542140 -0.55421976\n529       0       1       1  0.69998236 -0.504633254 -0.55421976\n531       1       0       0 -2.15783684 -0.153022808  0.64435239\n534       0       1       0  0.00000000 -0.223864289  0.64435239\n539       0       1       1  0.00000000 -0.376730699 -0.55421976\n540       0       0       0 -0.61306970  0.304119404  0.64435239\n550       1       0       1 -1.69440670  0.056095438  0.64435239\n551       0       0       1 -0.99926149  1.498200151  0.64435239\n554       0       1       1 -0.61306970 -0.518250257 -0.55421976\n562       0       1       1  0.77722072 -0.505201278 -0.55421976\n566       0       1       1 -0.45859299 -0.189010600  0.64435239\n571       1       0       1  2.47646456 -0.454542140 -0.55421976\n572       0       0       0  1.78131935  0.342620505  0.64435239\n574       0       1       0  0.00000000 -0.508037505 -0.55421976\n582       0       0       0  0.69998236  1.498200151  0.64435239\n583       1       0       1  1.85855771 -0.153022808 -0.55421976\n586       0       0       0 -0.92202313  0.890623136  0.64435239\n589       0       1       1 -0.61306970 -0.502201647 -0.55421976\n599       0       1       1  0.00000000 -0.518250257 -0.55421976\n602       0       1       1  0.00000000 -0.505201278 -0.55421976\n604       0       1       1  1.08617414 -0.502201647 -0.55421976\n607       0       1       1  0.00483715 -0.505201278 -0.55421976\n620       1       0       1 -0.30411628 -0.454542140 -0.55421976\n628       0       0       0 -0.69030806  0.857714732 -0.55421976\n629       0       1       1 -0.30411628 -0.505201278 -0.55421976\n630       0       1       1  0.00000000 -0.508362368 -0.55421976\n632       0       1       1  1.62684264 -0.521572805 -0.55421976\n636       1       0       0 -0.14963956 -0.405909990 -0.55421976\n643       0       1       0 -2.15783684 -0.116062374  2.44221062\n652       1       0       0 -0.92202313 -0.211381389  0.04506631\n653       0       1       1 -0.69030806 -0.494745366 -0.55421976\n657       0       1       1  0.00000000 -0.505201278 -0.55421976\n660       0       0       1  2.16751113  1.544725556  0.64435239\n664       0       1       1  0.46826729 -0.512982422 -0.55421976\n665       0       1       1 -0.76754642 -0.504633254  0.04506631\n666       1       0       1  0.15931386  0.770988046  0.64435239\n669       0       1       1  1.00893579 -0.502201647 -0.55421976\n672       0       0       1  0.08207551  0.352751554  0.04506631\n673       1       0       1  3.09437141 -0.454542140 -0.55421976\n675       1       0       1  0.00000000 -0.658797171 -0.55421976\n676       0       1       1 -0.92202313 -0.507551184 -0.55421976\n680       0       0       1  0.46826729  9.307471078  0.04506631\n684       0       1       1 -1.23097656  0.253541968  3.64078277\n685       1       0       1  2.32198785  0.099864373  0.64435239\n686       1       0       1 -0.38135463  0.150037190  1.24363847\n688       0       1       1 -0.84478477 -0.460946021 -0.55421976\n696       1       0       1  1.70408100 -0.396183559 -0.55421976\n697       0       1       1  1.08617414 -0.502201647 -0.55421976\n698       0       1       0  0.00000000 -0.508362368 -0.55421976\n700       0       1       1  0.93169743 -0.509982791 -0.55421976\n706       1       0       1  0.69998236 -0.153022808 -0.55421976\n707       1       0       0  1.16341250 -0.396183559 -0.55421976\n711       0       0       0 -0.45859299  0.304201106 -0.55421976\n715       1       0       1  1.70408100 -0.405909990 -0.55421976\n722       0       1       1 -0.99926149 -0.521572805  0.04506631\n724       1       0       1  1.54960428 -0.405909990 -0.55421976\n727       1       0       0  0.00483715 -0.250287109  1.24363847\n731       0       0       0 -0.07240121  3.452321649 -0.55421976\n733       1       0       1  0.00000000 -0.658797171 -0.55421976\n734       1       0       1 -0.53583135 -0.405909990 -0.55421976\n741       0       0       1  0.00000000 -0.075211368 -0.55421976\n746       0       0       1  3.09437141  0.722355896  0.64435239\n747       0       1       1 -1.07649984 -0.264876754  0.64435239\n748       1       0       0  0.00483715 -0.405909990 -0.55421976\n751       1       0       0 -2.00336012 -0.211381389  0.64435239\n756       1       0       1 -2.26056385 -0.376730699  0.64435239\n758       1       0       1 -0.92202313 -0.435089280 -0.55421976\n761       0       1       1  0.00000000 -0.376730699 -0.55421976\n765       0       1       1 -1.07649984 -0.507551184 -0.55421976\n772       0       1       1  1.39512757 -0.506010517 -0.55421976\n775       1       0       0  1.85855771 -0.211381389  1.84292454\n776       0       1       1 -0.92202313 -0.508037505 -0.55421976\n779       0       1       1  0.00000000 -0.508280666 -0.55421976\n785       0       1       1 -0.38135463 -0.521654507 -0.55421976\n787       0       1       0 -0.92202313 -0.512982422 -0.55421976\n788       0       1       1 -1.69440670 -0.092232621  2.44221062\n798       0       1       0  0.08207551 -0.489882151 -0.55421976\n802       1       0       0  0.08207551 -0.148159593  0.64435239\n805       0       1       1 -0.22687792 -0.523113472 -0.55421976\n807       0       0       1  0.69998236 -0.658797171 -0.55421976\n809       1       0       1  0.69998236 -0.405909990 -0.55421976\n810       0       0       0  0.23655222  0.374149700  0.04506631\n814       0       1       0 -1.84888341 -0.050408971  3.04149669\n818       1       0       1  0.08207551  0.061040355  0.64435239\n820       0       1       1 -1.53992998 -0.116062374  2.44221062\n821       0       0       0  1.70408100  1.160045248  0.64435239\n829       0       1       1  0.00000000 -0.508037505 -0.55421976\n830       0       0       0  2.47646456  0.897431637 -0.55421976\n834       0       1       1 -0.53583135 -0.506010517 -0.55421976\n837       0       1       1 -0.69030806 -0.490286770 -0.55421976\n839       0       1       1  0.15931386  0.440207722 -0.55421976\n841       0       1       1 -0.76754642 -0.504633254 -0.55421976\n842       1       0       1 -1.07649984 -0.454542140 -0.55421976\n844       0       1       1  0.35240975 -0.533569384 -0.55421976\n848       0       1       1  0.39102893 -0.505201278 -0.55421976\n854       0       0       0 -1.07649984  0.107645517  0.04506631\n863       0       0       0  1.39512757 -0.154400071 -0.55421976\n866       1       0       0  0.93169743 -0.405909990 -0.55421976\n869       0       1       1  0.00000000 -0.473995000 -0.55421976\n870       0       1       1 -2.00336012 -0.442222643  0.64435239\n873       0       0       1  0.23655222 -0.561532870 -0.55421976\n875       1       0       0 -0.14963956 -0.191928529  0.04506631\n876       0       1       0 -1.15373820 -0.518250257 -0.55421976\n884       1       0       1 -0.14963956 -0.454542140 -0.55421976\n890       0       0       1 -0.30411628 -0.075211368 -0.55421976\n891       0       1       1  0.15931386 -0.508037505 -0.55421976",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>LASSO Regression</span>"
    ]
  },
  {
    "objectID": "LASSO.html#모형-훈련",
    "href": "LASSO.html#모형-훈련",
    "title": "10  LASSO Regression",
    "section": "10.6 모형 훈련",
    "text": "10.6 모형 훈련\nPackage \"glmnet\"에서 제공하는 함수 glmnet()을 이용하여 LASSO Regression을 수행할 수 있다. 함수 glmnet()는 Target이 2개의 클래스를 가질 때 “두 번째 클래스”에 속할 확률을 모델링하며, “두 번째 클래스”란 “Factor” 변환하였을 때 두 번째 수준(Level)을 의미한다. 예를 들어, “a”와 “b” 2개의 클래스를 가진 Target을 “Factor” 변환하였을 때 수준이 “a” “b”라면, 첫 번째 클래스는 “a”, 두 번째 클래스는 “b”가 된다. 함수 glmnet()에 대한 자세한 옵션은 여기를 참고한다.\n\nglmnet(x, y, family, alpha, lambda, ...)\n\n\nx : 예측 변수를 포함하는 행렬\ny : Target을 포함하는 변수\nfamily : Target의 분포\n\n\"gaussian\" : 수치형인 Target\n\"binomial\" : 2개의 클래스를 가지는 Target\n\"multinomial\" : 3개 이상 클래스를 가지는 Target\n\"poisson\" : Count Data인 Target\n\nalpha : Elasticnet Mixing Parameter\n\n0 : Ridge Regression\n1 : Lasso Regression\n0 &lt; alpha &lt; 1 : Elastic Net Regression\n\nlambda : Regularization Parameter\n\n직접 값을 지정하면 해당 값에 대한 결과만 보여준다.\n값을 지정하지 않으면 100개의 lambda 값에 대한 결과를 보여준다.\n\n\n\n10.6.1 람다 값 직접 지정\n\nlasso.fit &lt;- glmnet(x = train.x,                 # 예측 변수를 포함하는 행렬\n                    y = titanic.trd.Imp$Survived,# Target\n                    family = \"binomial\",         # Binary Classification\n                    alpha = 1,                   # 0 : Ridge / 1 : Lasso / 0 &lt; alpha &lt; 1 : Elastic Net\n                    lambda = 0.1)\n\nround(coef(lasso.fit), 3)                        # 회귀계수 추정치\n\n7 x 1 sparse Matrix of class \"dgCMatrix\"\n                s0\n(Intercept)  0.571\nPclass2      .    \nPclass3     -0.459\nSexmale     -1.308\nAge          .    \nFare         .    \nFamSize      .    \n\n\nResult! 데이터 “titanic.trd.Imp”의 Target “Survived”은 “no”와 “yes” 2개의 클래스를 가지며, “Factor” 변환하면 알파벳순으로 수준을 부여하기 때문에 “yes”가 두 번째 클래스가 된다. 즉, “yes”에 속할 확률(= 탑승객이 생존할 확률)을 \\(p\\)라고 할 때, 추정된 회귀계수를 이용하여 다음과 같은 모형식을 얻을 수 있다. \\[\n\\begin{align*}\n\\log{\\frac{p}{1-p}} = &\\;0.571 -0.459 X_{\\text{Pclass3}} -1.308 X_{\\text{Sexmale}}\n\\end{align*}\n\\] 여기서, \\(X_{\\text{예측 변수}}\\)는 더미 변수를 의미한다.\n\n\n10.6.2 교차 검증을 통한 최적의 람다 값\n\n# 100개의 람다 값에 따른 결과\nlasso.fit &lt;- glmnet(x = train.x,                 # 예측 변수를 포함하는 행렬\n                    y = titanic.trd.Imp$Survived,# Target\n                    family = \"binomial\",         # Binary Classification\n                    alpha = 1)                   # 0 : Ridge / 1 : Lasso / 0 &lt; alpha &lt; 1 : Elastic Net\n\nplot(lasso.fit, xvar = \"lambda\")                 # 람다 값에 따른 회귀계수 추정치 확인\n\n\n\n\n\n\n\n\nResult! 100개의 \\(\\lambda\\) 값에 대한 회귀계수 추정치의 변화를 보여준다. 해당 그림을 통해 \\(\\lambda\\) 값이 클수록 회귀계수 추정치는 작아진다는 것을 알 수 있다.\n\nlasso.fit$lambda                                 # 100개의 람다 값\n\n [1] 0.2507754711 0.2284972694 0.2081982018 0.1897024473 0.1728498048 0.1574943045 0.1435029446 0.1307545385 0.1191386657 0.1085547150 0.0989110133 0.0901240315 0.0821176609 0.0748225542 0.0681755247\n[16] 0.0621189990 0.0566005184 0.0515722843 0.0469907447 0.0428162165 0.0390125418 0.0355467751 0.0323888976 0.0295115572 0.0268898318 0.0245010132 0.0223244107 0.0203411716 0.0185341180 0.0168875980\n[31] 0.0153873504 0.0140203806 0.0127748486 0.0116399663 0.0106059037 0.0096637045 0.0088052076 0.0080229772 0.0073102381 0.0066608167 0.0060690881 0.0055299270 0.0050386635 0.0045910425 0.0041831870\n[46] 0.0038115642 0.0034729553 0.0031644275 0.0028833085 0.0026271633 0.0023937734 0.0021811172 0.0019873527 0.0018108018 0.0016499351 0.0015033595 0.0013698051 0.0012481154 0.0011372363 0.0010362074\n[61] 0.0009441536 0.0008602776 0.0007838529\n\n\nCaution! \\(\\lambda\\)는 모형이 Training Dataset에 과적합 되는 것을 방지하기 위해 사용하는 모수이며, 교차 검증(Cross Validation)을 통해 최적의 값을 찾을 수 있다. 이러한 방법은 package \"glmnet\"에서 제공하는 함수 cv.glmnet()을 통해 수행할 수 있으며, 함수에 대한 자세한 옵션은 여기를 참고한다.\n\nset.seed(200)                                          # Seed 고정 -&gt; 동일한 결과를 출력하기 위해\ncv.lasso.fit &lt;- cv.glmnet(x = train.x,                 # 예측 변수를 포함하는 행렬\n                          y = titanic.trd.Imp$Survived,# Target\n                          family = \"binomial\",         # Binary Classification\n                          alpha = 1,                   # 0 : Ridge / 1 : Lasso / 0 &lt; alpha &lt; 1 : Elastic Net\n                          nfolds = 5,                  # 5-Fold Cross Validation\n                          type.measure = \"auc\")        # AUC에 기반하여 최적의 람다 값 찾기\n\nplot(cv.lasso.fit)                                     # Plot\n\n\n\n\n\n\n\n\nResult! 100개의 \\(\\lambda\\) 값에 대한 AUC의 변화를 보여준다.\nCaution! 만약 \\(\\lambda\\) 값에 대해 직접 후보 값을 지정하고 싶으면 함수 cv.glmnet()의 옵션 lambda = 후보 값을 이용하면 된다.\n\ncv.lasso.fit$lambda.min                                   # 최적의 람다 값\n\n[1] 0.0007838529\n\nmax(cv.lasso.fit$cvm)                                     # 최적의 람다 값에 대한 AUC\n\n[1] 0.850222\n\nround(coef(cv.lasso.fit, s = cv.lasso.fit$lambda.min), 3) # 최적의 람다 값에 대한 회귀계수 추정치\n\n7 x 1 sparse Matrix of class \"dgCMatrix\"\n                s1\n(Intercept)  2.529\nPclass2     -1.011\nPclass3     -2.330\nSexmale     -2.694\nAge         -0.515\nFare         0.122\nFamSize     -0.385\n\n\nResult! 최적의 \\(\\lambda\\) 값에 대해 추정된 회귀계수를 이용하여 다음과 같은 모형식을 얻을 수 있다. \\[\n\\begin{align*}\n\\log{\\frac{p}{1-p}} = &\\;2.529 - 1.011 X_{\\text{Pclass2}} - 2.330 X_{\\text{Pclass3}} -2.694 X_{\\text{Sexmale}} \\\\\n                      &-0.515 Z_{\\text{Age}} +0.122 Z_{\\text{Fare}} - 0.385 Z_{\\text{FamSize}}\n\\end{align*}\n\\]\n여기서, \\(Z_{\\text{예측 변수}}\\)는 표준화한 예측 변수, \\(X_{\\text{예측 변수}}\\)는 더미 변수를 의미한다.",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>LASSO Regression</span>"
    ]
  },
  {
    "objectID": "LASSO.html#모형-평가",
    "href": "LASSO.html#모형-평가",
    "title": "10  LASSO Regression",
    "section": "10.7 모형 평가",
    "text": "10.7 모형 평가\nCaution! 모형 평가를 위해 Test Dataset에 대한 예측 class/확률 이 필요하며, 함수 predict()를 이용하여 생성한다.\n\n# 예측 class 생성\ntest.lasso.class &lt;- predict(cv.lasso.fit, \n                            newx = test.x,                # Test Dataset including Only 예측 변수 \n                            s = \"lambda.min\",             # 최적의 람다 값 기반\n                            type = \"class\")               # 예측 class 생성\n\ntest.lasso.class %&gt;%                                      \n  as_tibble\n\n# A tibble: 266 × 1\n   lambda.min\n   &lt;chr&gt;     \n 1 yes       \n 2 no        \n 3 no        \n 4 yes       \n 5 no        \n 6 no        \n 7 yes       \n 8 no        \n 9 no        \n10 yes       \n# ℹ 256 more rows\n\n\n\n\n10.7.1 ConfusionMatrix\n\nCM   &lt;- caret::confusionMatrix(as.factor(test.lasso.class), titanic.ted.Imp$Survived, \n                               positive = \"yes\")       # confusionMatrix(예측 class, 실제 class, positive = \"관심 class\")\nCM\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  no yes\n       no  148  32\n       yes  16  70\n                                         \n               Accuracy : 0.8195         \n                 95% CI : (0.768, 0.8638)\n    No Information Rate : 0.6165         \n    P-Value [Acc &gt; NIR] : 5.675e-13      \n                                         \n                  Kappa : 0.6067         \n                                         \n Mcnemar's Test P-Value : 0.03038        \n                                         \n            Sensitivity : 0.6863         \n            Specificity : 0.9024         \n         Pos Pred Value : 0.8140         \n         Neg Pred Value : 0.8222         \n             Prevalence : 0.3835         \n         Detection Rate : 0.2632         \n   Detection Prevalence : 0.3233         \n      Balanced Accuracy : 0.7944         \n                                         \n       'Positive' Class : yes            \n                                         \n\n\n\n\n\n10.7.2 ROC 곡선\n\n# 예측 확률 생성\ntest.lasso.prob &lt;- predict(cv.lasso.fit, \n                           newx = test.x,              # Test Dataset including Only 예측 변수 \n                           s = \"lambda.min\",           # 최적의 람다 값 기반\n                           type = \"response\")          # 예측 확률 생성\n\ntest.lasso.prob %&gt;%                                    # \"Survived = yes\"에 대한 예측 확률                           \n  as_tibble\n\n# A tibble: 266 × 1\n   lambda.min\n        &lt;dbl&gt;\n 1     0.907 \n 2     0.296 \n 3     0.125 \n 4     0.666 \n 5     0.0882\n 6     0.236 \n 7     0.720 \n 8     0.214 \n 9     0.0875\n10     0.894 \n# ℹ 256 more rows\n\n\n\nac  &lt;- titanic.ted.Imp$Survived                        # Test Dataset의 실제 class \npp  &lt;- as.numeric(test.lasso.prob)                     # 예측 확률을 수치형으로 변환\n\n\n10.7.2.1 Package “pROC”\n\npacman::p_load(\"pROC\")\n\nlasso.roc  &lt;- roc(ac, pp, plot = T, col = \"gray\")      # roc(실제 class, 예측 확률)\nauc        &lt;- round(auc(lasso.roc), 3)\nlegend(\"bottomright\", legend = auc, bty = \"n\")\n\n\n\n\n\n\n\n\nCaution! Package \"pROC\"를 통해 출력한 ROC 곡선은 다양한 함수를 이용해서 그래프를 수정할 수 있다.\n\n# 함수 plot.roc() 이용\nplot.roc(lasso.roc,   \n         col=\"gray\",                                   # Line Color\n         print.auc = TRUE,                             # AUC 출력 여부\n         print.auc.col = \"red\",                        # AUC 글씨 색깔\n         print.thres = TRUE,                           # Cutoff Value 출력 여부\n         print.thres.pch = 19,                         # Cutoff Value를 표시하는 도형 모양\n         print.thres.col = \"red\",                      # Cutoff Value를 표시하는 도형의 색깔\n         auc.polygon = TRUE,                           # 곡선 아래 면적에 대한 여부\n         auc.polygon.col = \"gray90\")                   # 곡선 아래 면적의 색깔\n\n\n\n\n\n\n\n\n\n# 함수 ggroc() 이용\nggroc(lasso.roc) +\nannotate(geom = \"text\", x = 0.9, y = 1.0,\nlabel = paste(\"AUC = \", auc),\nsize = 5,\ncolor=\"red\") +\ntheme_bw()\n\n\n\n\n\n\n\n\n\n\n10.7.2.2 Package “Epi”\n\npacman::p_load(\"Epi\")       \n# install_version(\"etm\", version = \"1.1\", repos = \"http://cran.us.r-project.org\")\n\nROC(pp, ac, plot = \"ROC\")                              # ROC(예측 확률, 실제 class)  \n\n\n\n\n\n\n\n\n\n\n10.7.2.3 Package “ROCR”\n\npacman::p_load(\"ROCR\")\n\nlasso.pred &lt;- prediction(pp, ac)                       # prediction(예측 확률, 실제 class) \n\nlasso.perf &lt;- performance(lasso.pred, \"tpr\", \"fpr\")    # performance(, \"민감도\", \"1-특이도\")                      \nplot(lasso.perf, col = \"gray\")                         # ROC Curve\n\nperf.auc   &lt;- performance(lasso.pred, \"auc\")           # AUC\nauc        &lt;- attributes(perf.auc)$y.values\nlegend(\"bottomright\", legend = auc, bty = \"n\")\n\n\n\n\n\n\n\n\n\n\n\n\n10.7.3 향상 차트\n\n10.7.3.1 Package “ROCR”\n\nlasso.perf &lt;- performance(lasso.pred, \"lift\", \"rpp\")   # Lift Chart                      \nplot(lasso.perf, main = \"lift curve\",\n     colorize = T,                                     # Coloring according to cutoff \n     lwd = 2)",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>LASSO Regression</span>"
    ]
  },
  {
    "objectID": "Ridge.html",
    "href": "Ridge.html",
    "title": "11  Ridge Regression",
    "section": "",
    "text": "11.1 데이터 불러오기\npacman::p_load(\"data.table\", \n               \"tidyverse\", \n               \"dplyr\", \"tidyr\",\n               \"ggplot2\", \"GGally\",\n               \"caret\",\n               \"glmnet\")                                                # For glmnet\n\ntitanic &lt;- fread(\"../Titanic.csv\")                                      # 데이터 불러오기\n\ntitanic %&gt;%\n  as_tibble\n# A tibble: 891 × 11\n   Survived Pclass Name                                                Sex      Age SibSp Parch Ticket            Fare Cabin  Embarked\n      &lt;int&gt;  &lt;int&gt; &lt;chr&gt;                                               &lt;chr&gt;  &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;   \n 1        0      3 Braund, Mr. Owen Harris                             male      22     1     0 A/5 21171         7.25 \"\"     S       \n 2        1      1 Cumings, Mrs. John Bradley (Florence Briggs Thayer) female    38     1     0 PC 17599         71.3  \"C85\"  C       \n 3        1      3 Heikkinen, Miss. Laina                              female    26     0     0 STON/O2. 3101282  7.92 \"\"     S       \n 4        1      1 Futrelle, Mrs. Jacques Heath (Lily May Peel)        female    35     1     0 113803           53.1  \"C123\" S       \n 5        0      3 Allen, Mr. William Henry                            male      35     0     0 373450            8.05 \"\"     S       \n 6        0      3 Moran, Mr. James                                    male      NA     0     0 330877            8.46 \"\"     Q       \n 7        0      1 McCarthy, Mr. Timothy J                             male      54     0     0 17463            51.9  \"E46\"  S       \n 8        0      3 Palsson, Master. Gosta Leonard                      male       2     3     1 349909           21.1  \"\"     S       \n 9        1      3 Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)   female    27     0     2 347742           11.1  \"\"     S       \n10        1      2 Nasser, Mrs. Nicholas (Adele Achem)                 female    14     1     0 237736           30.1  \"\"     C       \n# ℹ 881 more rows",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Ridge Regression</span>"
    ]
  },
  {
    "objectID": "Ridge.html#데이터-전처리-i",
    "href": "Ridge.html#데이터-전처리-i",
    "title": "11  Ridge Regression",
    "section": "11.2 데이터 전처리 I",
    "text": "11.2 데이터 전처리 I\n\ntitanic %&lt;&gt;%\n  data.frame() %&gt;%                                                      # Data Frame 형태로 변환 \n  mutate(Survived = ifelse(Survived == 1, \"yes\", \"no\"))                 # Target을 문자형 변수로 변환\n\n# 1. Convert to Factor\nfac.col &lt;- c(\"Pclass\", \"Sex\",\n             # Target\n             \"Survived\")\n\ntitanic &lt;- titanic %&gt;% \n  mutate_at(fac.col, as.factor)                                         # 범주형으로 변환\n\nglimpse(titanic)                                                        # 데이터 구조 확인\n\nRows: 891\nColumns: 11\n$ Survived &lt;fct&gt; no, yes, yes, yes, no, no, no, no, yes, yes, yes, yes, no, no, no, yes, no, yes, no, yes, no, yes, yes, yes, no, yes, no, no, yes, no, no, yes, yes, no, no, no, yes, no, no, yes, no…\n$ Pclass   &lt;fct&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3, 2, 2, 3, 1, 3, 3, 3, 1, 3, 3, 1, 1, 3, 2, 1, 1, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 1, 1, 2, 3, 2, 3, 3…\n$ Name     &lt;chr&gt; \"Braund, Mr. Owen Harris\", \"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\", \"Heikkinen, Miss. Laina\", \"Futrelle, Mrs. Jacques Heath (Lily May Peel)\", \"Allen, Mr. William Henry…\n$ Sex      &lt;fct&gt; male, female, female, female, male, male, male, male, female, female, female, female, male, male, female, female, male, male, female, female, male, male, female, male, female, femal…\n$ Age      &lt;dbl&gt; 22.0, 38.0, 26.0, 35.0, 35.0, NA, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, NA, 31.0, NA, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, NA, 19.0, NA, NA, 40.0, NA, NA, 66.…\n$ SibSp    &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0, 0, 0, 0, 0, 3, 1, 0, 3, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 1, 0, 0, 1, 0, 2, 1, 4, 0, 1, 1, 0, 0, 0, 0, 1, 5, 0…\n$ Parch    &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 5, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 2, 2, 0…\n$ Ticket   &lt;chr&gt; \"A/5 21171\", \"PC 17599\", \"STON/O2. 3101282\", \"113803\", \"373450\", \"330877\", \"17463\", \"349909\", \"347742\", \"237736\", \"PP 9549\", \"113783\", \"A/5. 2151\", \"347082\", \"350406\", \"248706\", \"38…\n$ Fare     &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625, 21.0750, 11.1333, 30.0708, 16.7000, 26.5500, 8.0500, 31.2750, 7.8542, 16.0000, 29.1250, 13.0000, 18.0000, 7.2250, 26.0000,…\n$ Cabin    &lt;chr&gt; \"\", \"C85\", \"\", \"C123\", \"\", \"\", \"E46\", \"\", \"\", \"\", \"G6\", \"C103\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"D56\", \"\", \"A6\", \"\", \"\", \"\", \"C23 C25 C27\", \"\", \"\", \"\", \"B78\", \"\", \"\", \"\", \"\", \"\"…\n$ Embarked &lt;chr&gt; \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"C\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"Q\", \"S\", \"C\", \"C\", \"Q\", \"S\", \"C\", \"S\", \"…\n\n# 2. Generate New Variable\ntitanic &lt;- titanic %&gt;%\n  mutate(FamSize = SibSp + Parch)                                       # \"FamSize = 형제 및 배우자 수 + 부모님 및 자녀 수\"로 가족 수를 의미하는 새로운 변수\n\nglimpse(titanic)                                                        # 데이터 구조 확인\n\nRows: 891\nColumns: 12\n$ Survived &lt;fct&gt; no, yes, yes, yes, no, no, no, no, yes, yes, yes, yes, no, no, no, yes, no, yes, no, yes, no, yes, yes, yes, no, yes, no, no, yes, no, no, yes, yes, no, no, no, yes, no, no, yes, no…\n$ Pclass   &lt;fct&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3, 2, 2, 3, 1, 3, 3, 3, 1, 3, 3, 1, 1, 3, 2, 1, 1, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 1, 1, 2, 3, 2, 3, 3…\n$ Name     &lt;chr&gt; \"Braund, Mr. Owen Harris\", \"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\", \"Heikkinen, Miss. Laina\", \"Futrelle, Mrs. Jacques Heath (Lily May Peel)\", \"Allen, Mr. William Henry…\n$ Sex      &lt;fct&gt; male, female, female, female, male, male, male, male, female, female, female, female, male, male, female, female, male, male, female, female, male, male, female, male, female, femal…\n$ Age      &lt;dbl&gt; 22.0, 38.0, 26.0, 35.0, 35.0, NA, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, NA, 31.0, NA, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, NA, 19.0, NA, NA, 40.0, NA, NA, 66.…\n$ SibSp    &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0, 0, 0, 0, 0, 3, 1, 0, 3, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 1, 0, 0, 1, 0, 2, 1, 4, 0, 1, 1, 0, 0, 0, 0, 1, 5, 0…\n$ Parch    &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 5, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 2, 2, 0…\n$ Ticket   &lt;chr&gt; \"A/5 21171\", \"PC 17599\", \"STON/O2. 3101282\", \"113803\", \"373450\", \"330877\", \"17463\", \"349909\", \"347742\", \"237736\", \"PP 9549\", \"113783\", \"A/5. 2151\", \"347082\", \"350406\", \"248706\", \"38…\n$ Fare     &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625, 21.0750, 11.1333, 30.0708, 16.7000, 26.5500, 8.0500, 31.2750, 7.8542, 16.0000, 29.1250, 13.0000, 18.0000, 7.2250, 26.0000,…\n$ Cabin    &lt;chr&gt; \"\", \"C85\", \"\", \"C123\", \"\", \"\", \"E46\", \"\", \"\", \"\", \"G6\", \"C103\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"D56\", \"\", \"A6\", \"\", \"\", \"\", \"C23 C25 C27\", \"\", \"\", \"\", \"B78\", \"\", \"\", \"\", \"\", \"\"…\n$ Embarked &lt;chr&gt; \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"C\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"Q\", \"S\", \"C\", \"C\", \"Q\", \"S\", \"C\", \"S\", \"…\n$ FamSize  &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 4, 2, 1, 2, 0, 0, 6, 0, 0, 5, 0, 1, 0, 0, 0, 0, 0, 4, 6, 0, 5, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 3, 0, 0, 1, 0, 2, 1, 5, 0, 1, 1, 1, 0, 0, 0, 3, 7, 0…\n\n# 3. Select Variables used for Analysis\ntitanic1 &lt;- titanic %&gt;% \n  select(Survived, Pclass, Sex, Age, Fare, FamSize)                     # 분석에 사용할 변수 선택\n\ntitanic1 %&gt;%\n  as_tibble\n\n# A tibble: 891 × 6\n   Survived Pclass Sex      Age  Fare FamSize\n   &lt;fct&gt;    &lt;fct&gt;  &lt;fct&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;int&gt;\n 1 no       3      male      22  7.25       1\n 2 yes      1      female    38 71.3        1\n 3 yes      3      female    26  7.92       0\n 4 yes      1      female    35 53.1        1\n 5 no       3      male      35  8.05       0\n 6 no       3      male      NA  8.46       0\n 7 no       1      male      54 51.9        0\n 8 no       3      male       2 21.1        4\n 9 yes      3      female    27 11.1        2\n10 yes      2      female    14 30.1        1\n# ℹ 881 more rows",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Ridge Regression</span>"
    ]
  },
  {
    "objectID": "Ridge.html#데이터-탐색",
    "href": "Ridge.html#데이터-탐색",
    "title": "11  Ridge Regression",
    "section": "11.3 데이터 탐색",
    "text": "11.3 데이터 탐색\n\nggpairs(titanic1,                                        \n        aes(colour = Survived)) +                         # Target의 범주에 따라 색깔을 다르게 표현\n  theme_bw()\n\n\n\n\n\n\n\nggpairs(titanic1,                                     \n        aes(colour = Survived, alpha = 0.8)) +            # Target의 범주에 따라 색깔을 다르게 표현\n  scale_colour_manual(values = c(\"#E69F00\", \"#56B4E9\")) + # 특정 색깔 지정\n  scale_fill_manual(values = c(\"#E69F00\", \"#56B4E9\")) +   # 특정 색깔 지정\n  theme_bw()",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Ridge Regression</span>"
    ]
  },
  {
    "objectID": "Ridge.html#데이터-분할",
    "href": "Ridge.html#데이터-분할",
    "title": "11  Ridge Regression",
    "section": "11.4 데이터 분할",
    "text": "11.4 데이터 분할\n\n# Partition (Training Dataset : Test Dataset = 7:3)\ny      &lt;- titanic1$Survived                             # Target\n\nset.seed(200)\nind    &lt;- createDataPartition(y, p = 0.7, list  =T)     # Index를 이용하여 7:3으로 분할\ntitanic.trd &lt;- titanic1[ind$Resample1,]                 # Training Dataset\ntitanic.ted &lt;- titanic1[-ind$Resample1,]                # Test Dataset",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Ridge Regression</span>"
    ]
  },
  {
    "objectID": "Ridge.html#데이터-전처리-ii",
    "href": "Ridge.html#데이터-전처리-ii",
    "title": "11  Ridge Regression",
    "section": "11.5 데이터 전처리 II",
    "text": "11.5 데이터 전처리 II\n\n# 1. Imputation\ntitanic.trd.Imp &lt;- titanic.trd %&gt;% \n  mutate(Age = replace_na(Age, mean(Age, na.rm = TRUE)))                 # 평균으로 결측값 대체\n\ntitanic.ted.Imp &lt;- titanic.ted %&gt;% \n  mutate(Age = replace_na(Age, mean(titanic.trd$Age, na.rm = TRUE)))     # Training Dataset을 이용하여 결측값 대체\n\n# 2. Standardization\npreProcValues &lt;- preProcess(titanic.trd.Imp, \n                            method = c(\"center\", \"scale\"))               # Standardization 정의 -&gt; Training Dataset에 대한 평균과 표준편차 계산 \n\ntitanic.trd.Imp &lt;- predict(preProcValues, titanic.trd.Imp)               # Standardization for Training Dataset\ntitanic.ted.Imp &lt;- predict(preProcValues, titanic.ted.Imp)               # Standardization for Test Dataset\n\n# 3. Convert Factor Var. into Dummy Var. \ntrain.x &lt;- model.matrix(Survived ~.,                                     # Survived는 Target으로 제외  \n                        titanic.trd.Imp)[,-1]                            # [,-1] : 절편 제거\n\ntrain.x\n\n    Pclass2 Pclass3 Sexmale         Age         Fare     FamSize\n1         0       1       1 -0.61306970 -0.517763935  0.04506631\n3         0       1       0 -0.30411628 -0.504633254 -0.55421976\n4         0       0       0  0.39102893  0.374149700  0.04506631\n5         0       1       1  0.39102893 -0.502201647 -0.55421976\n6         0       1       1  0.00000000 -0.494259044 -0.55421976\n8         0       1       1 -2.15783684 -0.248828144  1.84292454\n9         0       1       0 -0.22687792 -0.442222643  0.64435239\n10        1       0       0 -1.23097656 -0.073834105  0.04506631\n11        0       1       0 -2.00336012 -0.333934407  0.64435239\n12        0       0       0  2.16751113 -0.142323735 -0.55421976\n14        0       1       1  0.69998236 -0.050408971  3.04149669\n15        0       1       0 -1.23097656 -0.506010517 -0.55421976\n18        1       0       1  0.00000000 -0.405909990 -0.55421976\n19        0       1       0  0.08207551 -0.308645689  0.04506631\n20        0       1       0  0.00000000 -0.518250257 -0.55421976\n21        1       0       1  0.39102893 -0.153022808 -0.55421976\n24        0       0       1 -0.14963956  0.031779363 -0.55421976\n25        0       1       0 -1.69440670 -0.248828144  1.84292454\n27        0       1       1  0.00000000 -0.518250257 -0.55421976\n28        0       0       1 -0.84478477  4.457305033  2.44221062\n29        0       1       0  0.00000000 -0.505524195 -0.55421976\n30        0       1       1  0.00000000 -0.505201278 -0.55421976\n31        0       0       1  0.77722072 -0.119548327 -0.55421976\n32        0       0       0  0.00000000  2.191451452  0.04506631\n33        0       1       0  0.00000000 -0.508037505 -0.55421976\n34        1       0       1  2.78541799 -0.454542140 -0.55421976\n35        0       0       1 -0.14963956  0.939659905  0.04506631\n36        0       0       1  0.93169743  0.352751554  0.04506631\n38        0       1       1 -0.69030806 -0.502201647 -0.55421976\n39        0       1       0 -0.92202313 -0.308645689  0.64435239\n40        0       1       0 -1.23097656 -0.440113953  0.04506631\n41        0       1       0  0.77722072 -0.474481321  0.04506631\n42        1       0       0 -0.22687792 -0.250287109  0.04506631\n43        0       1       1  0.00000000 -0.505201278 -0.55421976\n45        0       1       0 -0.84478477 -0.505524195 -0.55421976\n47        0       1       1  0.00000000 -0.357277839  0.04506631\n48        0       1       0  0.00000000 -0.508037505 -0.55421976\n49        0       1       1  0.00000000 -0.237074726  0.64435239\n50        0       1       0 -0.92202313 -0.312536261  0.04506631\n51        0       1       1 -1.77164505  0.113238214  2.44221062\n53        0       0       0  1.47236593  0.833805222  0.04506631\n55        0       0       1  2.70817963  0.546875535  0.04506631\n56        0       0       1  0.00000000  0.031779363 -0.55421976\n60        0       1       1 -1.46269163  0.253541968  3.64078277\n61        0       1       1 -0.61306970 -0.518168555 -0.55421976\n62        0       0       0  0.62274400  0.897431637 -0.55421976\n64        0       1       1 -2.00336012 -0.116062374  2.44221062\n65        0       0       1  0.00000000 -0.119548327 -0.55421976\n70        0       1       1 -0.30411628 -0.490286770  0.64435239\n72        0       1       0 -1.07649984  0.253541968  3.64078277\n74        0       1       1 -0.30411628 -0.377621640  0.04506631\n75        0       1       1  0.15931386  0.440207722 -0.55421976\n76        0       1       1 -0.38135463 -0.509982791 -0.55421976\n77        0       1       1  0.00000000 -0.505201278 -0.55421976\n79        1       0       1 -2.24820571 -0.094664228  0.64435239\n80        0       1       0  0.00483715 -0.416122741 -0.55421976\n82        0       1       1 -0.07240121 -0.473995000 -0.55421976\n83        0       1       0  0.00000000 -0.507308023 -0.55421976\n84        0       0       1 -0.14963956  0.257432540 -0.55421976\n85        1       0       0 -0.99926149 -0.454542140 -0.55421976\n86        0       1       0  0.23655222 -0.350469338  1.24363847\n88        0       1       1  0.00000000 -0.502201647 -0.55421976\n89        0       0       0 -0.53583135  4.457305033  2.44221062\n91        0       1       1 -0.07240121 -0.502201647 -0.55421976\n92        0       1       1 -0.76754642 -0.506010517 -0.55421976\n93        0       0       1  1.24065086  0.531231545  0.04506631\n94        0       1       1 -0.30411628 -0.258554574  1.24363847\n95        0       1       1  2.24474949 -0.517763935 -0.55421976\n96        0       1       1  0.00000000 -0.502201647 -0.55421976\n97        0       0       1  3.17160977  0.015326133 -0.55421976\n103       0       0       1 -0.69030806  0.844665754  0.04506631\n105       0       1       1  0.54550565 -0.504633254  0.64435239\n107       0       1       0 -0.69030806 -0.509982791 -0.55421976\n108       0       1       1  0.00000000 -0.507551184 -0.55421976\n110       0       1       0  0.00000000 -0.189010600  0.04506631\n111       0       0       1  1.31788921  0.352751554 -0.55421976\n112       0       1       0 -1.19235738 -0.377621640  0.04506631\n113       0       1       1 -0.61306970 -0.502201647 -0.55421976\n114       0       1       0 -0.76754642 -0.467672820  0.04506631\n115       0       1       0 -0.99926149 -0.377541884 -0.55421976\n116       0       1       1 -0.69030806 -0.504633254 -0.55421976\n117       0       1       1  3.13299059 -0.508037505 -0.55421976\n119       0       0       1 -0.45859299  4.156190321  0.04506631\n122       0       1       1  0.00000000 -0.502201647 -0.55421976\n125       0       0       1  1.85855771  0.844665754  0.04506631\n126       0       1       1 -1.38545327 -0.440113953  0.04506631\n128       0       1       1 -0.45859299 -0.519870680 -0.55421976\n129       0       1       0  0.00000000 -0.223864289  0.64435239\n130       0       1       1  1.16341250 -0.523113472 -0.55421976\n131       0       1       1  0.23655222 -0.505201278 -0.55421976\n132       0       1       1 -0.76754642 -0.521654507 -0.55421976\n134       1       0       0 -0.07240121 -0.153022808  0.04506631\n136       1       0       1 -0.53583135 -0.366113328 -0.55421976\n138       0       0       1  0.54550565  0.374149700  0.04506631\n141       0       1       0  0.00000000 -0.362222756  0.64435239\n142       0       1       0 -0.61306970 -0.508037505 -0.55421976\n143       0       1       0 -0.45859299 -0.350469338  0.04506631\n146       1       0       1 -0.84478477  0.056095438  0.64435239\n147       0       1       1 -0.22687792 -0.507146564 -0.55421976\n148       0       1       0 -1.61716834  0.009894895  1.84292454\n149       1       0       1  0.50688647 -0.153022808  0.64435239\n150       1       0       1  0.93169743 -0.405909990 -0.55421976\n151       1       0       1  1.62684264 -0.415150098 -0.55421976\n153       0       1       1  1.97441524 -0.502201647 -0.55421976\n154       0       1       1  0.81583989 -0.376730699  0.64435239\n156       0       0       1  1.62684264  0.535203819  0.04506631\n157       0       1       0 -1.07649984 -0.508362368 -0.55421976\n158       0       1       1  0.00483715 -0.502201647 -0.55421976\n160       0       1       1  0.00000000  0.694149249  5.43864100\n162       1       0       0  0.77722072 -0.352414624 -0.55421976\n163       0       1       1 -0.30411628 -0.507551184 -0.55421976\n164       0       1       1 -0.99926149 -0.490286770 -0.55421976\n167       0       0       0  0.00000000  0.411110134  0.04506631\n169       0       0       1  0.00000000 -0.154481773 -0.55421976\n171       0       0       1  2.39922620 -0.007126358 -0.55421976\n173       0       1       0 -2.23507519 -0.442222643  0.64435239\n174       0       1       1 -0.69030806 -0.504633254 -0.55421976\n176       0       1       1 -0.92202313 -0.506010517  0.64435239\n179       1       0       1  0.00483715 -0.405909990 -0.55421976\n180       0       1       1  0.46826729 -0.658797171 -0.55421976\n181       0       1       0  0.00000000  0.694149249  5.43864100\n182       1       0       1  0.00000000 -0.366031626 -0.55421976\n184       1       0       1 -2.23507519  0.099864373  1.24363847\n185       0       1       0 -2.00336012 -0.230347927  0.64435239\n188       0       0       1  1.16341250 -0.142323735 -0.55421976\n189       0       1       1  0.77722072 -0.357277839  0.64435239\n190       0       1       1  0.46826729 -0.505201278 -0.55421976\n191       1       0       0  0.15931386 -0.405909990 -0.55421976\n192       1       0       1 -0.84478477 -0.405909990 -0.55421976\n194       1       0       1 -2.08059848 -0.153022808  0.64435239\n196       0       0       0  2.16751113  2.191451452 -0.55421976\n197       0       1       1  0.00000000 -0.508037505 -0.55421976\n198       0       1       1  0.93169743 -0.495311444  0.04506631\n199       0       1       0  0.00000000 -0.508037505 -0.55421976\n200       1       0       0 -0.45859299 -0.405909990 -0.55421976\n202       0       1       1  0.00000000  0.694149249  5.43864100\n203       0       1       1  0.31379058 -0.532435282 -0.55421976\n204       0       1       1  1.20203168 -0.518250257 -0.55421976\n205       0       1       1 -0.92202313 -0.502201647 -0.55421976\n206       0       1       0 -2.15783684 -0.455271622  0.04506631\n207       0       1       1  0.15931386 -0.350469338  0.04506631\n209       0       1       0 -1.07649984 -0.508037505 -0.55421976\n211       0       1       1 -0.45859299 -0.521654507 -0.55421976\n212       1       0       0  0.39102893 -0.250287109 -0.55421976\n213       0       1       1 -0.61306970 -0.517763935 -0.55421976\n214       1       0       1  0.00483715 -0.405909990 -0.55421976\n216       0       0       0  0.08207551  1.544725556  0.04506631\n217       0       1       0 -0.22687792 -0.504633254 -0.55421976\n218       1       0       1  0.93169743 -0.133569948  0.04506631\n219       0       0       0  0.15931386  0.825294596 -0.55421976\n220       1       0       1  0.00483715 -0.454542140 -0.55421976\n223       0       1       1  1.62684264 -0.502201647 -0.55421976\n224       0       1       1  0.00000000 -0.505201278 -0.55421976\n226       0       1       1 -0.61306970 -0.476912929 -0.55421976\n227       1       0       1 -0.84478477 -0.454542140 -0.55421976\n229       1       0       1 -0.92202313 -0.405909990 -0.55421976\n230       0       1       0  0.00000000 -0.163397019  1.84292454\n232       0       1       1 -0.07240121 -0.507551184 -0.55421976\n233       1       0       1  2.24474949 -0.396183559 -0.55421976\n235       1       0       1 -0.45859299 -0.454542140 -0.55421976\n236       0       1       0  0.00000000 -0.511928077 -0.55421976\n237       1       0       1  1.08617414 -0.153022808  0.04506631\n238       1       0       0 -1.69440670 -0.148159593  0.64435239\n240       1       0       1  0.23655222 -0.420013313 -0.55421976\n242       0       1       0  0.00000000 -0.357277839  0.04506631\n243       1       0       1 -0.07240121 -0.454542140 -0.55421976\n244       0       1       1 -0.61306970 -0.520195543 -0.55421976\n245       0       1       1  0.00483715 -0.518250257 -0.55421976\n246       0       0       1  1.08617414  1.091960238  0.64435239\n247       0       1       0 -0.38135463 -0.507551184 -0.55421976\n248       1       0       0 -0.45859299 -0.376730699  0.64435239\n249       0       0       1  0.54550565  0.363532329  0.64435239\n252       0       1       0 -0.07240121 -0.455271622  0.64435239\n253       0       0       1  2.47646456 -0.142323735 -0.55421976\n254       0       1       1  0.00483715 -0.345606123  0.04506631\n255       0       1       0  0.85445907 -0.265606236  0.64435239\n257       0       0       0  0.00000000  0.881869349 -0.55421976\n258       0       0       0  0.00483715  1.023875227 -0.55421976\n259       0       0       0  0.39102893  9.307471078 -0.55421976\n262       0       1       1 -2.08059848 -0.048220525  3.04149669\n264       0       0       1  0.77722072 -0.658797171 -0.55421976\n265       0       1       0  0.00000000 -0.508037505 -0.55421976\n266       1       0       1  0.46826729 -0.454542140 -0.55421976\n267       0       1       1 -1.07649984  0.113238214  2.44221062\n269       0       0       0  2.16751113  2.326487371  0.04506631\n270       0       0       0  0.39102893  1.979658438 -0.55421976\n273       1       0       0  0.85445907 -0.279466399  0.04506631\n275       0       1       0  0.00000000 -0.508037505 -0.55421976\n276       0       0       0  2.55370292  0.857714732  0.04506631\n278       1       0       1  0.00000000 -0.658797171 -0.55421976\n280       0       1       0  0.39102893 -0.264876754  0.64435239\n281       0       1       1  2.70817963 -0.508037505 -0.55421976\n285       0       0       1  0.00000000 -0.153022808 -0.55421976\n286       0       1       1  0.23655222 -0.490286770 -0.55421976\n287       0       1       1  0.00483715 -0.473995000 -0.55421976\n288       0       1       1 -0.61306970 -0.505201278 -0.55421976\n289       1       0       1  0.93169743 -0.405909990 -0.55421976\n290       0       1       0 -0.61306970 -0.508037505 -0.55421976\n291       0       0       0 -0.30411628  0.875060848 -0.55421976\n292       0       0       0 -0.84478477  1.112953764  0.04506631\n293       1       0       1  0.46826729 -0.408341597 -0.55421976\n294       0       1       0 -0.45859299 -0.486639359 -0.55421976\n296       0       0       1  0.00000000 -0.119548327 -0.55421976\n297       0       1       1 -0.49721217 -0.518168555 -0.55421976\n298       0       0       0 -2.15783684  2.289283776  1.24363847\n299       0       0       1  0.00000000 -0.065484938 -0.55421976\n300       0       0       0  1.54960428  4.156190321  0.04506631\n302       0       1       1  0.00000000 -0.206518174  0.64435239\n303       0       1       1 -0.84478477 -0.658797171 -0.55421976\n304       1       0       0  0.00000000 -0.418554349 -0.55421976\n305       0       1       1  0.00000000 -0.502201647 -0.55421976\n306       0       0       1 -2.24125426  2.289283776  1.24363847\n307       0       0       0  0.00000000  1.498200151 -0.55421976\n309       1       0       1  0.00483715 -0.191928529  0.04506631\n311       0       0       0 -0.45859299  0.958869605 -0.55421976\n315       1       0       1  1.00893579 -0.148159593  0.64435239\n316       0       1       0 -0.30411628 -0.506010517 -0.55421976\n317       1       0       0 -0.45859299 -0.153022808  0.04506631\n319       0       0       0  0.08207551  2.548331678  0.64435239\n320       0       0       0  0.77722072  1.957612512  0.64435239\n322       0       1       1 -0.22687792 -0.505201278 -0.55421976\n323       1       0       0  0.00483715 -0.418554349 -0.55421976\n324       1       0       0 -0.61306970 -0.094664228  0.64435239\n325       0       1       1  0.00000000  0.694149249  5.43864100\n327       0       1       1  2.39922620 -0.537459956 -0.55421976\n329       0       1       0  0.08207551 -0.259527217  0.64435239\n330       0       0       0 -1.07649984  0.469064095  0.04506631\n331       0       1       0  0.00000000 -0.206518174  0.64435239\n332       0       0       1  1.20203168 -0.104390658 -0.55421976\n335       0       0       0  0.00000000  1.941077581  0.04506631\n336       0       1       1  0.00000000 -0.505201278 -0.55421976\n337       0       0       1 -0.07240121  0.636763311  0.04506631\n339       0       1       1  1.16341250 -0.502201647 -0.55421976\n340       0       0       1  1.16341250  0.031779363 -0.55421976\n341       1       0       1 -2.15783684 -0.153022808  0.64435239\n342       0       0       0 -0.45859299  4.457305033  2.44221062\n343       1       0       1 -0.14963956 -0.405909990 -0.55421976\n345       1       0       1  0.46826729 -0.405909990 -0.55421976\n346       1       0       0 -0.45859299 -0.405909990 -0.55421976\n348       0       1       0  0.00000000 -0.345606123  0.04506631\n349       0       1       1 -2.08059848 -0.349496695  0.64435239\n350       0       1       1  0.93169743 -0.490286770 -0.55421976\n352       0       0       1  0.00000000  0.022052932 -0.55421976\n353       0       1       1 -1.15373820 -0.518168555  0.64435239\n354       0       1       1 -0.38135463 -0.312536261  0.04506631\n355       0       1       1  0.00000000 -0.518250257 -0.55421976\n356       0       1       1 -0.14963956 -0.473995000 -0.55421976\n357       0       0       0 -0.61306970  0.411110134  0.04506631\n360       0       1       0  0.00000000 -0.505524195 -0.55421976\n361       0       1       1  0.77722072 -0.116062374  2.44221062\n362       1       0       1 -0.07240121 -0.119548327  0.04506631\n363       0       1       0  1.16341250 -0.377621640  0.04506631\n365       0       1       1  0.00000000 -0.357277839  0.04506631\n366       0       1       1  0.00483715 -0.517763935 -0.55421976\n367       0       0       0  2.32198785  0.805030551  0.04506631\n368       0       1       0  0.00000000 -0.518168555 -0.55421976\n370       0       0       0 -0.45859299  0.689286034 -0.55421976\n371       0       0       1 -0.38135463  0.419702463  0.04506631\n372       0       1       1 -0.92202313 -0.532435282  0.04506631\n373       0       1       1 -0.84478477 -0.502201647 -0.55421976\n374       0       0       1 -0.61306970  1.979658438 -0.55421976\n376       0       0       0  0.00000000  0.939659905  0.04506631\n377       0       1       0 -0.61306970 -0.517763935 -0.55421976\n379       0       1       1 -0.76754642 -0.580742570 -0.55421976\n381       0       0       0  0.93169743  3.767214822 -0.55421976\n382       0       1       0 -2.23507519 -0.352576083  0.64435239\n383       0       1       1  0.15931386 -0.504633254 -0.55421976\n384       0       0       0  0.39102893  0.352751554  0.04506631\n385       0       1       1  0.00000000 -0.505201278 -0.55421976\n386       1       0       1 -0.92202313  0.770988046 -0.55421976\n387       0       1       1 -2.23507519  0.253541968  3.64078277\n388       1       0       0  0.46826729 -0.405909990 -0.55421976\n389       0       1       1  0.00000000 -0.508442125 -0.55421976\n390       1       0       0 -0.99926149 -0.425362850 -0.55421976\n391       0       0       1  0.46826729  1.675546040  1.24363847\n392       0       1       1 -0.69030806 -0.507146564 -0.55421976\n393       0       1       1 -0.14963956 -0.504633254  0.64435239\n394       0       0       0 -0.53583135  1.544725556  0.04506631\n395       0       1       0 -0.45859299 -0.333934407  0.64435239\n396       0       1       1 -0.61306970 -0.507146564 -0.55421976\n397       0       1       0  0.08207551 -0.506010517 -0.55421976\n398       1       0       1  1.24065086 -0.153022808 -0.55421976\n399       1       0       1 -0.53583135 -0.454542140 -0.55421976\n401       0       1       1  0.69998236 -0.504633254 -0.55421976\n402       0       1       1 -0.30411628 -0.502201647 -0.55421976\n404       0       1       1 -0.14963956 -0.350469338  0.04506631\n405       0       1       0 -0.76754642 -0.490286770 -0.55421976\n406       1       0       1  0.31379058 -0.250287109  0.04506631\n407       0       1       1  1.62684264 -0.508037505 -0.55421976\n408       1       0       1 -2.08059848 -0.294056044  0.64435239\n410       0       1       0  0.00000000 -0.163397019  1.84292454\n411       0       1       1  0.00000000 -0.505201278 -0.55421976\n414       1       0       1  0.00000000 -0.658797171 -0.55421976\n417       1       0       0  0.31379058 -0.026579218  0.64435239\n421       0       1       1  0.00000000 -0.505201278 -0.55421976\n422       0       1       1 -0.69030806 -0.508362368 -0.55421976\n423       0       1       1 -0.07240121 -0.505605898 -0.55421976\n425       0       1       1 -0.92202313 -0.265606236  0.64435239\n426       0       1       1  0.00000000 -0.517763935 -0.55421976\n428       1       0       0 -0.84478477 -0.153022808 -0.55421976\n429       0       1       1  0.00000000 -0.508037505 -0.55421976\n431       0       0       1 -0.14963956 -0.142323735 -0.55421976\n432       0       1       0  0.00000000 -0.345606123  0.04506631\n433       1       0       0  0.93169743 -0.153022808  0.04506631\n434       0       1       1 -0.99926149 -0.520195543 -0.55421976\n435       0       0       1  1.54960428  0.428617708  0.04506631\n437       0       1       0 -0.69030806  0.009894895  1.84292454\n438       1       0       0 -0.45859299 -0.294056044  2.44221062\n439       0       0       1  2.63094127  4.457305033  2.44221062\n443       0       1       1 -0.38135463 -0.507551184  0.04506631\n444       1       0       0 -0.14963956 -0.405909990 -0.55421976\n446       0       0       1 -2.00336012  0.933580887  0.64435239\n449       0       1       0 -1.92612177 -0.284168155  1.24363847\n451       1       0       1  0.46826729 -0.118980303  1.24363847\n453       0       0       1  0.00483715 -0.118980303 -0.55421976\n454       0       0       1  1.47236593  1.074534365  0.04506631\n456       0       1       1 -0.07240121 -0.505201278 -0.55421976\n459       1       0       0  1.54960428 -0.454542140 -0.55421976\n460       0       1       1  0.00000000 -0.508037505 -0.55421976\n461       0       0       1  1.39512757 -0.142323735 -0.55421976\n463       0       0       1  1.31788921  0.090137943 -0.55421976\n464       1       0       1  1.39512757 -0.405909990 -0.55421976\n465       0       1       1  0.00000000 -0.502201647 -0.55421976\n466       0       1       1  0.62274400 -0.521654507 -0.55421976\n468       0       0       1  2.01303442 -0.142323735 -0.55421976\n470       0       1       0 -2.25438478 -0.284168155  1.24363847\n471       0       1       1  0.00000000 -0.517763935 -0.55421976\n472       0       1       1  0.62274400 -0.490286770 -0.55421976\n474       1       0       0 -0.53583135 -0.390509160 -0.55421976\n475       0       1       0 -0.61306970 -0.467429660 -0.55421976\n479       0       1       1 -0.61306970 -0.512496101 -0.55421976\n480       0       1       0 -2.15783684 -0.419770152  0.04506631\n481       0       1       1 -1.61716834  0.253541968  3.64078277\n484       0       1       0  2.55370292 -0.472292875 -0.55421976\n485       0       0       1 -0.38135463  1.112953764  0.04506631\n486       0       1       0  0.00000000 -0.163397019  1.84292454\n487       0       0       0  0.39102893  1.091960238  0.04506631\n489       0       1       1  0.00483715 -0.502201647 -0.55421976\n491       0       1       1  0.00000000 -0.270387749  0.04506631\n493       0       0       1  1.93579607 -0.065484938 -0.55421976\n494       0       0       1  3.17160977  0.304201106 -0.55421976\n497       0       0       0  1.85855771  0.863713994  0.04506631\n498       0       1       1  0.00000000 -0.365058983 -0.55421976\n499       0       0       0 -0.38135463  2.289283776  1.24363847\n500       0       1       1 -0.45859299 -0.507146564 -0.55421976\n501       0       1       1 -0.99926149 -0.490286770 -0.55421976\n502       0       1       0 -0.69030806 -0.508037505 -0.55421976\n503       0       1       0  0.00000000 -0.510387411 -0.55421976\n504       0       1       0  0.54550565 -0.472292875 -0.55421976\n505       0       0       0 -1.07649984  1.023875227 -0.55421976\n506       0       0       1 -0.92202313  1.459619293  0.04506631\n507       1       0       0  0.23655222 -0.153022808  0.64435239\n508       0       0       1  0.00000000 -0.142323735 -0.55421976\n509       0       1       1 -0.14963956 -0.220621497 -0.55421976\n511       0       1       1 -0.07240121 -0.508037505 -0.55421976\n512       0       1       1  0.00000000 -0.502201647 -0.55421976\n513       0       0       1  0.46826729 -0.147430111 -0.55421976\n514       0       0       0  1.85855771  0.496702719  0.04506631\n516       0       0       1  1.31788921  0.003004692 -0.55421976\n517       1       0       0  0.31379058 -0.454542140 -0.55421976\n518       0       1       1  0.00000000 -0.189010600 -0.55421976\n519       1       0       0  0.46826729 -0.153022808  0.04506631\n521       0       0       0  0.00483715  1.160045248 -0.55421976\n522       0       1       1 -0.61306970 -0.505201278 -0.55421976\n524       0       0       0  1.08617414  0.469064095  0.04506631\n526       0       1       1  0.81583989 -0.508037505 -0.55421976\n528       0       0       1  0.00000000  3.655442578 -0.55421976\n530       1       0       1 -0.53583135 -0.435089280  1.24363847\n532       0       1       1  0.00000000 -0.518168555 -0.55421976\n533       0       1       1 -0.99926149 -0.518168555  0.64435239\n535       0       1       0  0.00483715 -0.490286770 -0.55421976\n536       1       0       0 -1.77164505 -0.148159593  0.64435239\n537       0       0       1  1.16341250 -0.142323735 -0.55421976\n538       0       0       0  0.00483715  1.411473465 -0.55421976\n541       0       0       0  0.46826729  0.722355896  0.64435239\n542       0       1       0 -1.61716834 -0.050408971  3.04149669\n543       0       1       0 -1.46269163 -0.050408971  3.04149669\n544       1       0       1  0.15931386 -0.153022808  0.04506631\n545       0       0       1  1.54960428  1.411473465  0.04506631\n546       0       0       1  2.63094127 -0.153022808 -0.55421976\n547       1       0       0 -0.84478477 -0.153022808  0.04506631\n548       1       0       1  0.00000000 -0.389131898 -0.55421976\n549       0       1       1  0.23655222 -0.259527217  0.64435239\n552       1       0       1 -0.22687792 -0.153022808 -0.55421976\n553       0       1       1  0.00000000 -0.506496838 -0.55421976\n555       0       1       0 -0.61306970 -0.507551184 -0.55421976\n556       0       0       1  2.47646456 -0.142323735 -0.55421976\n557       0       0       0  1.39512757  0.111536089  0.04506631\n558       0       0       1  0.00000000  3.767214822 -0.55421976\n559       0       0       0  0.69998236  0.890623136  0.64435239\n560       0       1       0  0.46826729 -0.320317405  0.04506631\n561       0       1       1  0.00000000 -0.508037505 -0.55421976\n563       1       0       1 -0.14963956 -0.396183559 -0.55421976\n564       0       1       1  0.00000000 -0.502201647 -0.55421976\n565       0       1       0  0.00000000 -0.502201647 -0.55421976\n567       0       1       1 -0.84478477 -0.505201278 -0.55421976\n568       0       1       0 -0.07240121 -0.248828144  1.84292454\n569       0       1       1  0.00000000 -0.518168555 -0.55421976\n570       0       1       1  0.15931386 -0.506010517 -0.55421976\n573       0       0       1  0.46826729 -0.145484825 -0.55421976\n575       0       1       1 -1.07649984 -0.502201647 -0.55421976\n576       0       1       1 -0.84478477 -0.376730699 -0.55421976\n577       1       0       0  0.31379058 -0.405909990 -0.55421976\n578       0       0       0  0.69998236  0.428617708  0.04506631\n579       0       1       0  0.00000000 -0.377541884  0.04506631\n580       0       1       1  0.15931386 -0.504633254 -0.55421976\n581       1       0       0 -0.38135463 -0.075211368  0.64435239\n584       0       0       1  0.46826729  0.121748840 -0.55421976\n585       0       1       1  0.00000000 -0.489314127 -0.55421976\n587       1       0       1  1.31788921 -0.367004269 -0.55421976\n588       0       0       1  2.32198785  0.881869349  0.64435239\n590       0       1       1  0.00000000 -0.502201647 -0.55421976\n591       0       1       1  0.39102893 -0.520195543 -0.55421976\n592       0       0       0  1.70408100  0.863713994  0.04506631\n593       0       1       1  1.31788921 -0.517763935 -0.55421976\n594       0       1       0  0.00000000 -0.508037505  0.64435239\n595       1       0       1  0.54550565 -0.153022808  0.04506631\n596       0       1       1  0.46826729 -0.189010600  0.64435239\n597       1       0       0  0.00000000 -0.016852788 -0.55421976\n598       0       1       1  1.47236593 -0.658797171 -0.55421976\n600       0       0       1  1.47236593  0.448638592  0.04506631\n601       1       0       0 -0.45859299 -0.133569948  1.24363847\n603       0       0       1  0.00000000  0.166004097 -0.55421976\n605       0       0       1  0.39102893 -0.142323735 -0.55421976\n606       0       1       1  0.46826729 -0.356305196  0.04506631\n608       0       0       1 -0.22687792 -0.065484938 -0.55421976\n609       1       0       0 -0.61306970  0.150037190  1.24363847\n610       0       0       0  0.77722072  2.326487371 -0.55421976\n611       0       1       0  0.69998236 -0.050408971  3.04149669\n612       0       1       1  0.00000000 -0.521654507 -0.55421976\n613       0       1       0  0.00000000 -0.357277839  0.04506631\n614       0       1       1  0.00000000 -0.508037505 -0.55421976\n615       0       1       1  0.39102893 -0.502201647 -0.55421976\n616       1       0       0 -0.45859299  0.605638735  1.24363847\n617       0       1       1  0.31379058 -0.378675985  0.64435239\n618       0       1       0 -0.30411628 -0.345606123  0.04506631\n619       1       0       0 -2.00336012  0.099864373  1.24363847\n621       0       1       1 -0.22687792 -0.377621640  0.04506631\n622       0       0       1  0.93169743  0.363532329  0.04506631\n623       0       1       1 -0.76754642 -0.352576083  0.64435239\n624       0       1       1 -0.69030806 -0.506010517 -0.55421976\n625       0       1       1 -0.69030806 -0.345606123 -0.55421976\n626       0       0       1  2.39922620 -0.030065170 -0.55421976\n627       1       0       1  2.09027278 -0.418554349 -0.55421976\n631       0       0       1  3.86675498 -0.075211368 -0.55421976\n633       0       0       1  0.15931386 -0.065484938 -0.55421976\n634       0       0       1  0.00000000 -0.658797171 -0.55421976\n635       0       1       0 -1.61716834 -0.116062374  2.44221062\n637       0       1       1  0.15931386 -0.504633254 -0.55421976\n638       1       0       1  0.08207551 -0.148159593  0.64435239\n639       0       1       0  0.85445907  0.113238214  2.44221062\n640       0       1       1  0.00000000 -0.345606123  0.04506631\n641       0       1       1 -0.76754642 -0.506010517 -0.55421976\n642       0       0       0 -0.45859299  0.689286034 -0.55421976\n644       0       1       1  0.00000000  0.440207722 -0.55421976\n645       0       1       0 -2.25438478 -0.284168155  1.24363847\n646       0       0       1  1.39512757  0.833805222  0.04506631\n647       0       1       1 -0.84478477 -0.505201278 -0.55421976\n648       0       0       1  2.01303442  0.031779363 -0.55421976\n649       0       1       1  0.00000000 -0.511928077 -0.55421976\n650       0       1       0 -0.53583135 -0.511928077 -0.55421976\n651       0       1       1  0.00000000 -0.505201278 -0.55421976\n654       0       1       0  0.00000000 -0.506496838 -0.55421976\n655       0       1       0 -0.92202313 -0.527490365 -0.55421976\n656       1       0       1 -0.45859299  0.770988046  0.64435239\n658       0       1       0  0.15931386 -0.357277839  0.64435239\n659       1       0       1 -0.53583135 -0.405909990 -0.55421976\n661       0       0       1  1.54960428  1.941077581  0.64435239\n662       0       1       1  0.77722072 -0.518250257 -0.55421976\n663       0       0       1  1.31788921 -0.161047113 -0.55421976\n667       1       0       1 -0.38135463 -0.405909990 -0.55421976\n668       0       1       1  0.00000000 -0.507551184 -0.55421976\n670       0       0       0  0.00000000  0.352751554  0.04506631\n671       1       0       0  0.77722072  0.099864373  0.64435239\n674       1       0       1  0.08207551 -0.405909990 -0.55421976\n677       0       1       1 -0.41997381 -0.502201647 -0.55421976\n678       0       1       0 -0.92202313 -0.467347958 -0.55421976\n679       0       1       0  1.00893579  0.253541968  3.64078277\n681       0       1       0  0.00000000 -0.500499522 -0.55421976\n682       0       0       1 -0.22687792  0.833805222 -0.55421976\n683       0       1       1 -0.76754642 -0.479344536 -0.55421976\n687       0       1       1 -1.23097656  0.113238214  2.44221062\n689       0       1       1 -0.92202313 -0.507146564 -0.55421976\n690       0       0       0 -1.15373820  3.452321649  0.04506631\n691       0       0       1  0.08207551  0.450015854  0.04506631\n692       0       1       0 -2.00336012 -0.397803983  0.04506631\n693       0       1       1  0.00000000  0.440207722 -0.55421976\n694       0       1       1 -0.38135463 -0.518250257 -0.55421976\n695       0       0       1  2.32198785 -0.142323735 -0.55421976\n699       0       0       1  1.47236593  1.498200151  0.64435239\n701       0       0       0 -0.92202313  3.767214822  0.04506631\n702       0       0       1  0.39102893 -0.147430111 -0.55421976\n703       0       1       0 -0.92202313 -0.377621640  0.04506631\n704       0       1       1 -0.38135463 -0.508198964 -0.55421976\n705       0       1       1 -0.30411628 -0.506010517  0.04506631\n708       0       0       1  0.93169743 -0.147430111 -0.55421976\n709       0       0       0 -0.61306970  2.289283776 -0.55421976\n710       0       1       1  0.00000000 -0.362222756  0.64435239\n712       0       0       1  0.00000000 -0.142323735 -0.55421976\n713       0       0       1  1.39512757  0.352751554  0.04506631\n714       0       1       1 -0.07240121 -0.474319863 -0.55421976\n716       0       1       1 -0.84478477 -0.509982791 -0.55421976\n717       0       0       0  0.62274400  3.767214822 -0.55421976\n718       1       0       0 -0.22687792 -0.454542140 -0.55421976\n719       0       1       1  0.00000000 -0.357277839 -0.55421976\n720       0       1       1  0.23655222 -0.507551184 -0.55421976\n721       1       0       0 -1.84888341 -0.016852788  0.04506631\n723       1       0       1  0.31379058 -0.405909990 -0.55421976\n725       0       0       1 -0.22687792  0.374149700  0.04506631\n726       0       1       1 -0.76754642 -0.490286770 -0.55421976\n728       0       1       0  0.00000000 -0.508280666 -0.55421976\n729       1       0       1 -0.38135463 -0.153022808  0.04506631\n730       0       1       0 -0.38135463 -0.504633254  0.04506631\n732       0       1       1 -1.46269163 -0.293326562 -0.55421976\n735       1       0       1 -0.53583135 -0.405909990 -0.55421976\n736       0       1       1 -0.11102039 -0.345606123 -0.55421976\n737       0       1       0  1.39512757  0.009894895  1.84292454\n738       0       0       1  0.39102893  9.307471078 -0.55421976\n739       0       1       1  0.00000000 -0.505201278 -0.55421976\n740       0       1       1  0.00000000 -0.505201278 -0.55421976\n742       0       0       1  0.46826729  0.875060848  0.04506631\n743       0       0       0 -0.69030806  4.445146996  1.84292454\n744       0       1       1 -0.45859299 -0.345606123  0.04506631\n745       0       1       1  0.08207551 -0.504633254 -0.55421976\n749       0       0       1 -0.84478477  0.374149700  0.04506631\n750       0       1       1  0.08207551 -0.508037505 -0.55421976\n752       0       1       1 -1.84888341 -0.416122741  0.04506631\n753       0       1       1  0.23655222 -0.473995000 -0.55421976\n754       0       1       1 -0.53583135 -0.505201278 -0.55421976\n755       1       0       0  1.39512757  0.605638735  1.24363847\n757       0       1       1 -0.14963956 -0.507146564 -0.55421976\n759       0       1       1  0.31379058 -0.502201647 -0.55421976\n760       0       0       0  0.23655222  1.023875227 -0.55421976\n762       0       1       1  0.85445907 -0.520195543 -0.55421976\n763       0       1       1 -0.76754642 -0.518168555 -0.55421976\n764       0       0       0  0.46826729  1.675546040  1.24363847\n766       0       0       0  1.62684264  0.857714732  0.04506631\n767       0       0       1  0.00000000  0.111536089 -0.55421976\n768       0       1       0  0.04345633 -0.508037505 -0.55421976\n769       0       1       1  0.00000000 -0.189010600  0.04506631\n770       0       1       1  0.15931386 -0.496122628 -0.55421976\n771       0       1       1 -0.45859299 -0.473995000 -0.55421976\n773       1       0       0  2.09027278 -0.454542140 -0.55421976\n774       0       1       1  0.00000000 -0.518250257 -0.55421976\n777       0       1       1  0.00000000 -0.508037505 -0.55421976\n778       0       1       0 -1.92612177 -0.416122741 -0.55421976\n780       0       0       0  1.00893579  3.452321649  0.04506631\n781       0       1       0 -1.30821491 -0.518168555 -0.55421976\n782       0       0       0 -0.99926149  0.450015854  0.04506631\n783       0       0       1 -0.07240121 -0.075211368 -0.55421976\n784       0       1       1  0.00000000 -0.202627602  1.24363847\n786       0       1       1 -0.38135463 -0.517763935 -0.55421976\n789       0       1       1 -2.23507519 -0.258554574  1.24363847\n790       0       0       1  1.24065086  0.881869349 -0.55421976\n791       0       1       1  0.00000000 -0.508037505 -0.55421976\n792       1       0       1 -1.07649984 -0.153022808 -0.55421976\n793       0       1       0  0.00000000  0.694149249  5.43864100\n794       0       0       1  0.00000000 -0.061676068 -0.55421976\n795       0       1       1 -0.38135463 -0.505201278 -0.55421976\n796       1       0       1  0.69998236 -0.405909990 -0.55421976\n797       0       0       0  1.47236593 -0.154400071 -0.55421976\n799       0       1       1  0.00483715 -0.518168555 -0.55421976\n800       0       1       0  0.00483715 -0.189010600  0.64435239\n801       1       0       1  0.31379058 -0.405909990 -0.55421976\n803       0       0       1 -1.46269163  1.675546040  1.24363847\n804       0       1       1 -2.27987344 -0.493122997  0.04506631\n806       0       1       1  0.08207551 -0.507551184 -0.55421976\n808       0       1       0 -0.92202313 -0.507551184 -0.55421976\n811       0       1       1 -0.30411628 -0.505362737 -0.55421976\n812       0       1       1  0.69998236 -0.189010600 -0.55421976\n813       1       0       1  0.39102893 -0.454542140 -0.55421976\n815       0       1       1  0.04345633 -0.502201647 -0.55421976\n816       0       0       1  0.00000000 -0.658797171 -0.55421976\n817       0       1       0 -0.53583135 -0.504633254 -0.55421976\n819       0       1       1  1.00893579 -0.533326223 -0.55421976\n822       0       1       1 -0.22687792 -0.490286770 -0.55421976\n823       0       0       1  0.62274400 -0.658797171 -0.55421976\n824       0       1       0 -0.22687792 -0.416122741  0.04506631\n825       0       1       1 -2.15783684  0.113238214  2.44221062\n826       0       1       1  0.00000000 -0.523599793 -0.55421976\n827       0       1       1  0.00000000  0.440207722 -0.55421976\n828       1       0       1 -2.23507519  0.061040355  0.64435239\n831       0       1       0 -1.15373820 -0.377621640  0.04506631\n832       1       0       1 -2.24820571 -0.294056044  0.64435239\n833       0       1       1  0.00000000 -0.518168555 -0.55421976\n835       0       1       1 -0.92202313 -0.497338432 -0.55421976\n836       0       0       0  0.69998236  0.958869605  0.64435239\n838       0       1       1  0.00000000 -0.502201647 -0.55421976\n840       0       0       1  0.00000000 -0.081047226 -0.55421976\n843       0       0       0  0.00483715 -0.055758508 -0.55421976\n845       0       1       1 -0.99926149 -0.490286770 -0.55421976\n846       0       1       1  0.93169743 -0.511928077 -0.55421976\n847       0       1       1  0.00000000  0.694149249  5.43864100\n849       1       0       1 -0.14963956 -0.016852788  0.04506631\n850       0       0       0  0.00000000  1.074534365  0.04506631\n851       0       1       1 -2.00336012 -0.050408971  3.04149669\n852       0       1       1  3.40332484 -0.507551184 -0.55421976\n853       0       1       0 -1.61716834 -0.362222756  0.64435239\n855       1       0       0  1.08617414 -0.153022808  0.04506631\n856       0       1       0 -0.92202313 -0.476912929  0.04506631\n857       0       0       0  1.16341250  2.548331678  0.64435239\n858       0       0       1  1.62684264 -0.142323735 -0.55421976\n859       0       1       0 -0.45859299 -0.284168155  1.24363847\n860       0       1       1  0.00000000 -0.518168555 -0.55421976\n861       0       1       1  0.85445907 -0.384350385  0.64435239\n862       1       0       1 -0.69030806 -0.435089280  0.04506631\n864       0       1       0  0.00000000  0.694149249  5.43864100\n865       1       0       1 -0.45859299 -0.405909990 -0.55421976\n867       1       0       0 -0.22687792 -0.389213600  0.04506631\n868       0       0       1  0.08207551  0.323490562 -0.55421976\n871       0       1       1 -0.30411628 -0.505201278 -0.55421976\n872       0       0       0  1.31788921  0.363532329  0.64435239\n874       0       1       1  1.31788921 -0.483721430 -0.55421976\n877       0       1       1 -0.76754642 -0.467268201 -0.55421976\n878       0       1       1 -0.84478477 -0.505201278 -0.55421976\n879       0       1       1  0.00000000 -0.505201278 -0.55421976\n880       0       0       0  2.01303442  0.958869605  0.04506631\n881       1       0       0 -0.38135463 -0.153022808  0.04506631\n882       0       1       1  0.23655222 -0.505201278 -0.55421976\n883       0       1       0 -0.61306970 -0.454217277 -0.55421976\n885       0       1       1 -0.38135463 -0.521654507 -0.55421976\n886       0       1       0  0.69998236 -0.092232621  2.44221062\n887       1       0       1 -0.22687792 -0.405909990 -0.55421976\n888       0       0       0 -0.84478477 -0.075211368 -0.55421976\n889       0       1       0  0.00000000 -0.202627602  1.24363847\n\ntest.x &lt;- model.matrix(Survived ~.,                                      # Survived는 Target으로 제외  \n                       titanic.ted.Imp)[,-1]                             # [,-1] : 절편 제거\n\ntest.x\n\n    Pclass2 Pclass3 Sexmale         Age         Fare     FamSize\n2         0       0       0  0.62274400  0.727866891  0.04506631\n7         0       0       1  1.85855771  0.350076786 -0.55421976\n13        0       1       1 -0.76754642 -0.502201647 -0.55421976\n16        1       0       0  1.93579607 -0.347551409 -0.55421976\n17        0       1       1 -2.15783684 -0.092232621  2.44221062\n22        1       0       1  0.31379058 -0.405909990 -0.55421976\n23        0       1       0 -1.15373820 -0.502606266 -0.55421976\n26        0       1       0  0.62274400 -0.048220525  3.04149669\n37        0       1       1  0.00000000 -0.518168555 -0.55421976\n44        1       0       0 -2.08059848  0.150037190  1.24363847\n46        0       1       1  0.00000000 -0.502201647 -0.55421976\n52        0       1       1 -0.69030806 -0.507064862 -0.55421976\n54        1       0       0 -0.07240121 -0.153022808  0.04506631\n57        1       0       0 -0.69030806 -0.454542140 -0.55421976\n58        0       1       1 -0.11102039 -0.518168555 -0.55421976\n59        1       0       0 -1.92612177 -0.118980303  1.24363847\n63        0       0       1  1.16341250  0.965030325  0.04506631\n66        0       1       1  0.00000000 -0.362222756  0.64435239\n67        1       0       0 -0.07240121 -0.454542140 -0.55421976\n68        0       1       1 -0.84478477 -0.500094902 -0.55421976\n69        0       1       0 -0.99926149 -0.504633254  3.04149669\n71        1       0       1  0.15931386 -0.454542140 -0.55421976\n73        1       0       1 -0.69030806  0.770988046 -0.55421976\n78        0       1       1  0.00000000 -0.502201647 -0.55421976\n81        0       1       1 -0.61306970 -0.483721430 -0.55421976\n87        0       1       1 -1.07649984  0.009894895  1.84292454\n90        0       1       1 -0.45859299 -0.502201647 -0.55421976\n98        0       0       1 -0.53583135  0.573702975  0.04506631\n99        1       0       0  0.31379058 -0.211381389  0.04506631\n100       1       0       1  0.31379058 -0.153022808  0.04506631\n101       0       1       0 -0.14963956 -0.505201278 -0.55421976\n102       0       1       1  0.00000000 -0.505201278 -0.55421976\n104       0       1       1  0.23655222 -0.490448229 -0.55421976\n106       0       1       1 -0.14963956 -0.505201278 -0.55421976\n109       0       1       1  0.62274400 -0.505201278 -0.55421976\n118       1       0       1 -0.07240121 -0.250287109  0.04506631\n120       0       1       0 -2.15783684 -0.050408971  3.04149669\n121       1       0       1 -0.69030806  0.770988046  0.64435239\n123       1       0       1  0.19793304 -0.073834105  0.04506631\n124       1       0       0  0.19793304 -0.405909990 -0.55421976\n127       0       1       1  0.00000000 -0.508037505 -0.55421976\n133       0       1       0  1.31788921 -0.376730699  0.04506631\n135       1       0       1 -0.38135463 -0.405909990 -0.55421976\n137       0       0       0 -0.84478477 -0.147511813  0.64435239\n139       0       1       1 -1.07649984 -0.479505995 -0.55421976\n140       0       0       1 -0.45859299  0.881869349 -0.55421976\n144       0       1       1 -0.84478477 -0.527490365 -0.55421976\n145       1       0       1 -0.92202313 -0.435089280 -0.55421976\n152       0       0       0 -0.61306970  0.636763311  0.04506631\n155       0       1       1  0.00000000 -0.516548131 -0.55421976\n159       0       1       1  0.00000000 -0.490286770 -0.55421976\n161       0       1       1  1.08617414 -0.345606123  0.04506631\n165       0       1       1 -2.23507519  0.113238214  2.44221062\n166       0       1       1 -1.61716834 -0.259527217  0.64435239\n168       0       1       0  1.16341250 -0.116062374  2.44221062\n170       0       1       1 -0.14963956  0.440207722 -0.55421976\n172       0       1       1 -2.00336012 -0.092232621  2.44221062\n175       0       0       1  2.01303442 -0.061676068 -0.55421976\n177       0       1       1  0.00000000 -0.163397019  1.84292454\n178       0       0       0  1.54960428 -0.100256925 -0.55421976\n183       0       1       1 -1.61716834 -0.048220525  3.04149669\n186       0       0       1  0.00000000  0.313845834 -0.55421976\n187       0       1       0  0.00000000 -0.357277839  0.04506631\n193       0       1       0 -0.84478477 -0.506010517  0.04506631\n195       0       0       0  1.08617414 -0.119548327 -0.55421976\n201       0       1       1 -0.14963956 -0.473995000 -0.55421976\n208       0       1       1 -0.30411628 -0.293326562 -0.55421976\n210       0       0       1  0.77722072 -0.055758508 -0.55421976\n215       0       1       1  0.00000000 -0.508037505  0.04506631\n221       0       1       1 -1.07649984 -0.502201647 -0.55421976\n222       1       0       1 -0.22687792 -0.405909990 -0.55421976\n225       0       0       1  0.62274400  1.091960238  0.04506631\n228       0       1       1 -0.72892724 -0.517763935 -0.55421976\n231       0       0       0  0.39102893  0.965030325  0.04506631\n234       0       1       0 -1.92612177 -0.048220525  3.04149669\n239       1       0       1 -0.84478477 -0.454542140 -0.55421976\n241       0       1       0  0.00000000 -0.377621640  0.04506631\n250       1       0       1  1.85855771 -0.153022808  0.04506631\n251       0       1       1  0.00000000 -0.517763935 -0.55421976\n256       0       1       0 -0.07240121 -0.362222756  0.64435239\n260       1       0       0  1.54960428 -0.153022808  0.04506631\n261       0       1       1  0.00000000 -0.508037505 -0.55421976\n263       0       0       1  1.70408100  0.890623136  0.64435239\n268       0       1       1 -0.38135463 -0.507551184  0.04506631\n271       0       0       1  0.00000000 -0.055758508 -0.55421976\n272       0       1       1 -0.38135463 -0.658797171 -0.55421976\n274       0       0       1  0.54550565 -0.081047226  0.04506631\n277       0       1       0  1.16341250 -0.508037505 -0.55421976\n279       0       1       1 -1.77164505 -0.092232621  2.44221062\n282       0       1       1 -0.14963956 -0.506010517 -0.55421976\n283       0       1       1 -1.07649984 -0.473995000 -0.55421976\n284       0       1       1 -0.84478477 -0.502201647 -0.55421976\n295       0       1       1 -0.45859299 -0.505201278 -0.55421976\n301       0       1       0  0.00000000 -0.508037505 -0.55421976\n308       0       0       0 -0.99926149  1.459619293  0.04506631\n310       0       0       0  0.00483715  0.448638592 -0.55421976\n312       0       0       0 -0.92202313  4.445146996  1.84292454\n313       1       0       0 -0.30411628 -0.153022808  0.64435239\n314       0       1       1 -0.14963956 -0.505201278 -0.55421976\n318       1       0       1  1.85855771 -0.386457129 -0.55421976\n321       0       1       1 -0.61306970 -0.517763935 -0.55421976\n326       0       0       0  0.46826729  1.979658438 -0.55421976\n328       1       0       0  0.46826729 -0.405909990 -0.55421976\n333       0       0       1  0.62274400  2.326487371  0.04506631\n334       0       1       1 -1.07649984 -0.308645689  0.64435239\n338       0       0       0  0.85445907  1.957612512 -0.55421976\n344       1       0       1 -0.38135463 -0.405909990 -0.55421976\n347       1       0       0  0.77722072 -0.405909990 -0.55421976\n351       0       1       1 -0.53583135 -0.479344536 -0.55421976\n358       1       0       0  0.62274400 -0.405909990 -0.55421976\n359       0       1       0  0.00000000 -0.505524195 -0.55421976\n364       0       1       1  0.39102893 -0.521654507 -0.55421976\n369       0       1       0  0.00000000 -0.508037505 -0.55421976\n375       0       1       0 -2.08059848 -0.248828144  1.84292454\n378       0       0       1 -0.22687792  3.455482739  0.64435239\n380       0       1       1 -0.84478477 -0.507551184 -0.55421976\n400       1       0       0 -0.14963956 -0.412718491 -0.55421976\n403       0       1       0 -0.69030806 -0.467672820  0.04506631\n409       0       1       1 -0.69030806 -0.507551184 -0.55421976\n412       0       1       1  0.00000000 -0.525383620 -0.55421976\n413       0       0       0  0.23655222  1.091960238  0.04506631\n415       0       1       1  1.08617414 -0.504633254 -0.55421976\n416       0       1       0  0.00000000 -0.502201647 -0.55421976\n418       1       0       0 -0.92202313 -0.405909990  0.64435239\n419       1       0       1  0.00483715 -0.405909990 -0.55421976\n420       0       1       0 -1.53992998 -0.189010600  0.64435239\n424       0       1       0 -0.14963956 -0.378675985  0.64435239\n427       1       0       0 -0.14963956 -0.153022808  0.04506631\n430       0       1       1  0.15931386 -0.502201647 -0.55421976\n436       0       0       0 -1.23097656  1.675546040  1.24363847\n440       1       0       1  0.08207551 -0.454542140 -0.55421976\n441       1       0       0  1.16341250 -0.148159593  0.64435239\n442       0       1       1 -0.76754642 -0.473995000 -0.55421976\n445       0       1       1  0.00000000 -0.500985843 -0.55421976\n447       1       0       0 -1.30821491 -0.279466399  0.04506631\n448       0       0       1  0.31379058 -0.142323735 -0.55421976\n450       0       0       1  1.70408100 -0.065484938 -0.55421976\n452       0       1       1  0.00000000 -0.270387749  0.04506631\n455       0       1       1  0.00000000 -0.502201647 -0.55421976\n457       0       0       1  2.70817963 -0.142323735 -0.55421976\n458       0       0       0  0.00000000  0.350076786  0.04506631\n462       0       1       1  0.31379058 -0.502201647 -0.55421976\n467       1       0       1  0.00000000 -0.658797171 -0.55421976\n469       0       1       1  0.00000000 -0.508523827 -0.55421976\n473       1       0       0  0.23655222 -0.118980303  1.24363847\n476       0       0       1  0.00000000  0.352751554 -0.55421976\n477       1       0       1  0.31379058 -0.250287109  0.04506631\n478       0       1       1 -0.07240121 -0.521736209  0.04506631\n482       1       0       1  0.00000000 -0.658797171 -0.55421976\n483       0       1       1  1.54960428 -0.502201647 -0.55421976\n488       0       0       1  2.16751113 -0.081047226 -0.55421976\n490       0       1       1 -1.61716834 -0.349496695  0.64435239\n492       0       1       1 -0.69030806 -0.517763935 -0.55421976\n495       0       1       1 -0.69030806 -0.502201647 -0.55421976\n496       0       1       1  0.00000000 -0.377541884 -0.55421976\n510       0       1       1 -0.30411628  0.440207722 -0.55421976\n515       0       1       1 -0.45859299 -0.512982422 -0.55421976\n520       0       1       1  0.15931386 -0.505201278 -0.55421976\n523       0       1       1  0.00000000 -0.518250257 -0.55421976\n525       0       1       1  0.00000000 -0.518168555 -0.55421976\n527       1       0       0  1.54960428 -0.454542140 -0.55421976\n529       0       1       1  0.69998236 -0.504633254 -0.55421976\n531       1       0       0 -2.15783684 -0.153022808  0.64435239\n534       0       1       0  0.00000000 -0.223864289  0.64435239\n539       0       1       1  0.00000000 -0.376730699 -0.55421976\n540       0       0       0 -0.61306970  0.304119404  0.64435239\n550       1       0       1 -1.69440670  0.056095438  0.64435239\n551       0       0       1 -0.99926149  1.498200151  0.64435239\n554       0       1       1 -0.61306970 -0.518250257 -0.55421976\n562       0       1       1  0.77722072 -0.505201278 -0.55421976\n566       0       1       1 -0.45859299 -0.189010600  0.64435239\n571       1       0       1  2.47646456 -0.454542140 -0.55421976\n572       0       0       0  1.78131935  0.342620505  0.64435239\n574       0       1       0  0.00000000 -0.508037505 -0.55421976\n582       0       0       0  0.69998236  1.498200151  0.64435239\n583       1       0       1  1.85855771 -0.153022808 -0.55421976\n586       0       0       0 -0.92202313  0.890623136  0.64435239\n589       0       1       1 -0.61306970 -0.502201647 -0.55421976\n599       0       1       1  0.00000000 -0.518250257 -0.55421976\n602       0       1       1  0.00000000 -0.505201278 -0.55421976\n604       0       1       1  1.08617414 -0.502201647 -0.55421976\n607       0       1       1  0.00483715 -0.505201278 -0.55421976\n620       1       0       1 -0.30411628 -0.454542140 -0.55421976\n628       0       0       0 -0.69030806  0.857714732 -0.55421976\n629       0       1       1 -0.30411628 -0.505201278 -0.55421976\n630       0       1       1  0.00000000 -0.508362368 -0.55421976\n632       0       1       1  1.62684264 -0.521572805 -0.55421976\n636       1       0       0 -0.14963956 -0.405909990 -0.55421976\n643       0       1       0 -2.15783684 -0.116062374  2.44221062\n652       1       0       0 -0.92202313 -0.211381389  0.04506631\n653       0       1       1 -0.69030806 -0.494745366 -0.55421976\n657       0       1       1  0.00000000 -0.505201278 -0.55421976\n660       0       0       1  2.16751113  1.544725556  0.64435239\n664       0       1       1  0.46826729 -0.512982422 -0.55421976\n665       0       1       1 -0.76754642 -0.504633254  0.04506631\n666       1       0       1  0.15931386  0.770988046  0.64435239\n669       0       1       1  1.00893579 -0.502201647 -0.55421976\n672       0       0       1  0.08207551  0.352751554  0.04506631\n673       1       0       1  3.09437141 -0.454542140 -0.55421976\n675       1       0       1  0.00000000 -0.658797171 -0.55421976\n676       0       1       1 -0.92202313 -0.507551184 -0.55421976\n680       0       0       1  0.46826729  9.307471078  0.04506631\n684       0       1       1 -1.23097656  0.253541968  3.64078277\n685       1       0       1  2.32198785  0.099864373  0.64435239\n686       1       0       1 -0.38135463  0.150037190  1.24363847\n688       0       1       1 -0.84478477 -0.460946021 -0.55421976\n696       1       0       1  1.70408100 -0.396183559 -0.55421976\n697       0       1       1  1.08617414 -0.502201647 -0.55421976\n698       0       1       0  0.00000000 -0.508362368 -0.55421976\n700       0       1       1  0.93169743 -0.509982791 -0.55421976\n706       1       0       1  0.69998236 -0.153022808 -0.55421976\n707       1       0       0  1.16341250 -0.396183559 -0.55421976\n711       0       0       0 -0.45859299  0.304201106 -0.55421976\n715       1       0       1  1.70408100 -0.405909990 -0.55421976\n722       0       1       1 -0.99926149 -0.521572805  0.04506631\n724       1       0       1  1.54960428 -0.405909990 -0.55421976\n727       1       0       0  0.00483715 -0.250287109  1.24363847\n731       0       0       0 -0.07240121  3.452321649 -0.55421976\n733       1       0       1  0.00000000 -0.658797171 -0.55421976\n734       1       0       1 -0.53583135 -0.405909990 -0.55421976\n741       0       0       1  0.00000000 -0.075211368 -0.55421976\n746       0       0       1  3.09437141  0.722355896  0.64435239\n747       0       1       1 -1.07649984 -0.264876754  0.64435239\n748       1       0       0  0.00483715 -0.405909990 -0.55421976\n751       1       0       0 -2.00336012 -0.211381389  0.64435239\n756       1       0       1 -2.26056385 -0.376730699  0.64435239\n758       1       0       1 -0.92202313 -0.435089280 -0.55421976\n761       0       1       1  0.00000000 -0.376730699 -0.55421976\n765       0       1       1 -1.07649984 -0.507551184 -0.55421976\n772       0       1       1  1.39512757 -0.506010517 -0.55421976\n775       1       0       0  1.85855771 -0.211381389  1.84292454\n776       0       1       1 -0.92202313 -0.508037505 -0.55421976\n779       0       1       1  0.00000000 -0.508280666 -0.55421976\n785       0       1       1 -0.38135463 -0.521654507 -0.55421976\n787       0       1       0 -0.92202313 -0.512982422 -0.55421976\n788       0       1       1 -1.69440670 -0.092232621  2.44221062\n798       0       1       0  0.08207551 -0.489882151 -0.55421976\n802       1       0       0  0.08207551 -0.148159593  0.64435239\n805       0       1       1 -0.22687792 -0.523113472 -0.55421976\n807       0       0       1  0.69998236 -0.658797171 -0.55421976\n809       1       0       1  0.69998236 -0.405909990 -0.55421976\n810       0       0       0  0.23655222  0.374149700  0.04506631\n814       0       1       0 -1.84888341 -0.050408971  3.04149669\n818       1       0       1  0.08207551  0.061040355  0.64435239\n820       0       1       1 -1.53992998 -0.116062374  2.44221062\n821       0       0       0  1.70408100  1.160045248  0.64435239\n829       0       1       1  0.00000000 -0.508037505 -0.55421976\n830       0       0       0  2.47646456  0.897431637 -0.55421976\n834       0       1       1 -0.53583135 -0.506010517 -0.55421976\n837       0       1       1 -0.69030806 -0.490286770 -0.55421976\n839       0       1       1  0.15931386  0.440207722 -0.55421976\n841       0       1       1 -0.76754642 -0.504633254 -0.55421976\n842       1       0       1 -1.07649984 -0.454542140 -0.55421976\n844       0       1       1  0.35240975 -0.533569384 -0.55421976\n848       0       1       1  0.39102893 -0.505201278 -0.55421976\n854       0       0       0 -1.07649984  0.107645517  0.04506631\n863       0       0       0  1.39512757 -0.154400071 -0.55421976\n866       1       0       0  0.93169743 -0.405909990 -0.55421976\n869       0       1       1  0.00000000 -0.473995000 -0.55421976\n870       0       1       1 -2.00336012 -0.442222643  0.64435239\n873       0       0       1  0.23655222 -0.561532870 -0.55421976\n875       1       0       0 -0.14963956 -0.191928529  0.04506631\n876       0       1       0 -1.15373820 -0.518250257 -0.55421976\n884       1       0       1 -0.14963956 -0.454542140 -0.55421976\n890       0       0       1 -0.30411628 -0.075211368 -0.55421976\n891       0       1       1  0.15931386 -0.508037505 -0.55421976",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Ridge Regression</span>"
    ]
  },
  {
    "objectID": "Ridge.html#모형-훈련",
    "href": "Ridge.html#모형-훈련",
    "title": "11  Ridge Regression",
    "section": "11.6 모형 훈련",
    "text": "11.6 모형 훈련\nPackage \"glmnet\"에서 제공하는 함수 glmnet()을 이용하여 Ridge Regression을 수행할 수 있다. 함수 glmnet()는 Target이 2개의 클래스를 가질 때 “두 번째 클래스”에 속할 확률을 모델링하며, “두 번째 클래스”란 “Factor” 변환하였을 때 두 번째 수준(Level)을 의미한다. 예를 들어, “a”와 “b” 2개의 클래스를 가진 Target을 “Factor” 변환하였을 때 수준이 “a” “b”라면, 첫 번째 클래스는 “a”, 두 번째 클래스는 “b”가 된다. 함수 glmnet()에 대한 자세한 옵션은 여기를 참고한다.\n\nglmnet(x, y, family, alpha, lambda, ...)\n\n\nx : 예측 변수를 포함하는 행렬\ny : Target을 포함하는 변수\nfamily : Target의 분포\n\n\"gaussian\" : 수치형인 Target\n\"binomial\" : 2개의 클래스를 가지는 Target\n\"multinomial\" : 3개 이상 클래스를 가지는 Target\n\"poisson\" : Count Data인 Target\n\nalpha : Elasticnet Mixing Parameter\n\n0 : Ridge Regression\n1 : Lasso Regression\n0 &lt; alpha &lt; 1 : Elastic Net Regression\n\nlambda : Regularization Parameter\n\n직접 값을 지정하면 해당 값에 대한 결과만 보여준다.\n값을 지정하지 않으면 100개의 lambda 값에 대한 결과를 보여준다.\n\n\n\n11.6.1 람다 값 직접 지정\n\nridge.fit &lt;- glmnet(x = train.x,                 # 예측 변수를 포함하는 행렬\n                    y = titanic.trd.Imp$Survived,# Target\n                    family = \"binomial\",         # Binary Classification\n                    alpha = 0,                   # 0 : Ridge / 1 : Lasso / 0 &lt; alpha &lt; 1 : Elastic Net\n                    lambda = 1)\n\nround(coef(ridge.fit), 3)                        # 회귀계수 추정치\n\n7 x 1 sparse Matrix of class \"dgCMatrix\"\n                s0\n(Intercept) -0.099\nPclass2      0.063\nPclass3     -0.240\nSexmale     -0.409\nAge         -0.036\nFare         0.090\nFamSize     -0.013\n\n\nResult! 데이터 “titanic.trd.Imp”의 Target “Survived”은 “no”와 “yes” 2개의 클래스를 가지며, “Factor” 변환하면 알파벳순으로 수준을 부여하기 때문에 “yes”가 두 번째 클래스가 된다. 즉, “yes”에 속할 확률(= 탑승객이 생존할 확률)을 \\(p\\)라고 할 때, 추정된 회귀계수를 이용하여 다음과 같은 모형식을 얻을 수 있다. \\[\n\\begin{align*}\n\\log{\\frac{p}{1-p}} = &-0.099 + 0.063 X_{\\text{Pclass2}} - 0.240 X_{\\text{Pclass3}} -0.409 X_{\\text{Sexmale}} \\\\\n                      &-0.036 Z_{\\text{Age}} +0.090 Z_{\\text{Fare}} - 0.013 Z_{\\text{FamSize}}\n\\end{align*}\n\\] 여기서, \\(Z_{\\text{예측 변수}}\\)는 표준화한 예측 변수, \\(X_{\\text{예측 변수}}\\)는 더미 변수를 의미한다.\n\n\n11.6.2 교차 검증을 통한 최적의 람다 값\n\n# 100개의 람다 값에 따른 결과\nridge.fit &lt;- glmnet(x = train.x,                 # 예측 변수를 포함하는 행렬\n                    y = titanic.trd.Imp$Survived,# Target\n                    family = \"binomial\",         # Binary Classification\n                    alpha = 0)                   # 0 : Ridge / 1 : Lasso / 0 &lt; alpha &lt; 1 : Elastic Net\n\nplot(ridge.fit, xvar = \"lambda\")                 # 람다 값에 따른 회귀계수 추정치 확인\n\n\n\n\n\n\n\n\nResult! 100개의 \\(\\lambda\\) 값에 대한 회귀계수 추정치의 변화를 보여준다. 해당 그림을 통해 \\(\\lambda\\) 값이 클수록 회귀계수 추정치는 작아진다는 것을 알 수 있다.\n\nridge.fit$lambda                                 # 100개의 람다 값\n\n  [1] 250.77547111 228.49726943 208.19820178 189.70244735 172.84980477 157.49430451 143.50294457 130.75453848 119.13866566 108.55471496  98.91101327  90.12403146  82.11766090  74.82255423  68.17552473\n [16]  62.11899902  56.60051835  51.57228430  46.99074470  42.81621645  39.01254179  35.54677510  32.38889757  29.51155718  26.88983178  24.50101323  22.32441074  20.34117162  18.53411800  16.88759804\n [31]  15.38735037  14.02038057  12.77484861  11.63996626  10.60590374   9.66370449   8.80520761   8.02297724   7.31023805   6.66081665   6.06908806   5.52992700   5.03866353   4.59104255   4.18318698\n [46]   3.81156418   3.47295532   3.16442754   2.88330852   2.62716334   2.39377339   2.18111716   1.98735272   1.81080178   1.64993514   1.50335945   1.36980514   1.24811543   1.13723629   1.03620736\n [61]   0.94415355   0.86027755   0.78385286   0.71421754   0.65076842   0.59295595   0.54027937   0.49228244   0.44854943   0.40870153   0.37239362   0.33931119   0.30916772   0.28170211   0.25667647\n [76]   0.23387404   0.21309732   0.19416634   0.17691714   0.16120031   0.14687972   0.13383133   0.12194212   0.11110912   0.10123849   0.09224474   0.08404997   0.07658321   0.06977976   0.06358072\n [91]   0.05793239   0.05278583   0.04809648   0.04382373   0.03993055   0.03638323   0.03315104   0.03020599   0.02752258   0.02507755\n\ncoef(ridge.fit)                                  # 100개의 람다 값에 따른 회귀계수 추정치\n\n7 x 100 sparse Matrix of class \"dgCMatrix\"\n\n\n                                                                                                                                                                                                 \n(Intercept) -4.726044e-01 -4.704569e-01 -4.702478e-01 -4.700184e-01 -4.697668e-01 -4.694907e-01 -4.691878e-01 -4.688555e-01 -4.684910e-01 -4.680912e-01 -4.676526e-01 -4.671715e-01 -4.666440e-01\nPclass2      1.157524e-37  5.000604e-04  5.487603e-04  6.020873e-04  6.605777e-04  7.247275e-04  7.950798e-04  8.722285e-04  9.568236e-04  1.049576e-03  1.151262e-03  1.262731e-03  1.384909e-03\nPclass3     -3.278078e-37 -1.417983e-03 -1.556055e-03 -1.707480e-03 -1.873610e-03 -2.055867e-03 -2.255809e-03 -2.475142e-03 -2.715736e-03 -2.979639e-03 -3.269094e-03 -3.586555e-03 -3.934709e-03\nSexmale     -5.262198e-37 -2.277161e-03 -2.498915e-03 -2.742203e-03 -3.009139e-03 -3.302014e-03 -3.623340e-03 -3.975869e-03 -4.362618e-03 -4.786891e-03 -5.252312e-03 -5.762846e-03 -6.322839e-03\nAge         -3.962343e-38 -1.716261e-04 -1.883474e-04 -2.067040e-04 -2.268490e-04 -2.489563e-04 -2.732169e-04 -2.998405e-04 -3.290567e-04 -3.611178e-04 -3.963005e-04 -4.349081e-04 -4.772734e-04\nFare         1.325639e-37  5.732668e-04  6.290431e-04  6.902341e-04  7.573627e-04  8.310019e-04  9.117794e-04  1.000383e-03  1.097565e-03  1.204150e-03  1.321040e-03  1.449223e-03  1.589777e-03\nFamSize     -3.833817e-39 -1.690088e-05 -1.857967e-05 -2.042846e-05 -2.246511e-05 -2.470948e-05 -2.718368e-05 -2.991237e-05 -3.292304e-05 -3.624643e-05 -3.991691e-05 -4.397301e-05 -4.845794e-05\n                                                                                                                                                                                                 \n(Intercept) -4.660653e-01 -4.654308e-01 -4.647351e-01 -4.639723e-01 -4.631359e-01 -0.4622191570 -4.612143e-01 -0.4601141058 -0.4589075318 -0.4575855856 -0.4561374736 -0.4545514404 -0.4528146926\nPclass2      1.518810e-03  1.665536e-03  1.826294e-03  2.002393e-03  2.195265e-03  0.0024064623  2.637677e-03  0.0028879564  0.0031643067  0.0034665479  0.0037969936  0.0041581416  0.0045526835\nPclass3     -4.316497e-03 -4.735133e-03 -5.194136e-03 -5.697349e-03 -6.248974e-03 -0.0068535974 -7.516230e-03 -0.0082405117 -0.0090356875 -0.0099067224 -0.0108606777 -0.0119052365 -0.0130487520\nSexmale     -6.937047e-03 -7.610680e-03 -8.349438e-03 -9.159557e-03 -1.004786e-02 -0.0110218069 -1.208955e-02 -0.0132592013 -0.0145419363 -0.0159477048 -0.0174880927 -0.0191757336 -0.0210243943\nAge         -5.237615e-04 -5.747729e-04 -6.307465e-04 -6.921638e-04 -7.595528e-04 -0.0008334922 -9.146167e-04 -0.0010038119 -0.0011014984 -0.0012086708 -0.0013262461 -0.0014552286 -0.0015967189\nFare         1.743884e-03  1.912834e-03  2.098037e-03  2.301035e-03  2.523507e-03  0.0027672890  3.034382e-03  0.0033269807  0.0036474327  0.0039983341  0.0043824938  0.0048029629  0.0052630518\nFamSize     -5.342027e-05 -5.891465e-05 -6.500269e-05 -7.175397e-05 -7.924718e-05 -0.0000875715 -9.682813e-05 -0.0001071327 -0.0001186154 -0.0001314263 -0.0001457363 -0.0001617414 -0.0001796661\n                                                                                                                                                                                               \n(Intercept) -0.4509133186 -0.4488322041 -0.446554945 -0.4440637571 -0.4413393811 -0.4383609899 -0.4351060925 -0.4315504395 -0.4276679311 -0.4234305300 -0.4188081803 -0.4137687371 -0.408277908\nPclass2      0.0049835144  0.0054537409  0.005966689  0.0065259094  0.0071351808  0.0077985105  0.0085201309  0.0093044918  0.0101562467  0.0110802319  0.0120814380  0.0131649707  0.014336000\nPclass3     -0.0143002968 -0.0156697153 -0.017167677 -0.0188057312 -0.0205963633 -0.0225530494 -0.0246903118 -0.0270237712 -0.0295701964 -0.0323475493 -0.0353750227 -0.0386730700 -0.042263424\nSexmale     -0.0230490668 -0.0252660640 -0.027693122 -0.0303495034 -0.0332561128 -0.0364356055 -0.0399125064 -0.0437133275 -0.0478666856 -0.0524034179 -0.0573566938 -0.0627621186 -0.068657827\nAge         -0.0017519219 -0.0019221572 -0.002108869 -0.0023136384 -0.0025381942 -0.0027844272 -0.0030544045 -0.0033503841 -0.0036748320 -0.0040304390 -0.0044201397 -0.0048471319 -0.005314897\nFare         0.0057663482  0.0063167352  0.006918410  0.0075759010  0.0082940872  0.0090782133  0.0099339054  0.0108671847  0.0118844766  0.0129926182  0.0141988591  0.0155108573  0.016936667\nFamSize     -0.0001997685 -0.0002223454 -0.000247739 -0.0002763438 -0.0003086157 -0.0003450817 -0.0003863519 -0.0004331326 -0.0004862427 -0.0005466314 -0.0006153993 -0.0006938227 -0.000783381\n                                                                                                                                                                                                 \n(Intercept) -0.4022992114 -0.395793956 -0.388721246 -0.381038012 -0.372699085 -0.363657302 -0.353863663 -0.343267537 -0.33181692 -0.319458756 -0.306139310 -0.291804612 -0.276400948 -0.259875415\nPclass2      0.0155996978  0.016961155  0.018425287  0.019996714  0.021679625  0.023477608  0.025393469  0.027429008  0.02958478  0.031859817  0.034251342  0.036754436  0.039361704  0.042062924\nPclass3     -0.0461691019 -0.050414393 -0.055024830 -0.060027130 -0.065449124 -0.071319637 -0.077668356 -0.084525653 -0.09192237 -0.099889595 -0.108458341 -0.117659279 -0.127522377 -0.138076555\nSexmale     -0.0750845646 -0.082085743 -0.089707480 -0.097998602 -0.107010614 -0.116797624 -0.127416212 -0.138925246 -0.15138563 -0.164859959 -0.179412132 -0.195106828 -0.212008923 -0.230182799\nAge         -0.0058272212 -0.006388218 -0.007002351 -0.007674454 -0.008409757 -0.009213906 -0.010092982 -0.011053521 -0.01210253 -0.013247488 -0.014496371 -0.015857633 -0.017340205 -0.018953478\nFare         0.0184847193  0.020163788  0.021982949  0.023951522  0.026078995  0.028374937  0.030848886  0.033510220  0.03636801  0.039430838  0.042706633  0.046202441  0.049924225  0.053876637\nFamSize     -0.0008857883 -0.001003029 -0.001137399 -0.001291548 -0.001468533 -0.001671872 -0.001905604 -0.002174354 -0.00248340 -0.002838749 -0.003247205 -0.003716445 -0.004255088 -0.004872758\n                                                                                                                                                                                                    \n(Intercept) -0.242176518 -0.223254813 -0.203063566 -0.181559439 -0.15870316 -0.13446019 -0.10880134 -0.08170331 -0.05314921 -0.02312896  0.008360434  0.04131468  0.07572214  0.11156388  0.14881382\nPclass2      0.044844684  0.047690037  0.050578167  0.053484086  0.05637838  0.05922705  0.06199135  0.06462784  0.06708843  0.06932063  0.071267854  0.07286990  0.07406349  0.07478294  0.07496086\nPclass3     -0.149349317 -0.161366396 -0.174151415 -0.187725583 -0.20210744 -0.21731267 -0.23335402 -0.25024124 -0.26798125 -0.28657828 -0.306034193 -0.32634889 -0.34752074 -0.36954712 -0.39242492\nSexmale     -0.249691564 -0.270596175 -0.292954488 -0.316820231 -0.34224192 -0.36926176 -0.39791451 -0.42822638 -0.46021398 -0.49388338 -0.529229220 -0.56623403 -0.60486771 -0.64508724 -0.68683655\nAge         -0.020707272 -0.022611796 -0.024677597 -0.026915496 -0.02933651 -0.03195174 -0.03477231 -0.03780923 -0.04107326 -0.04457484 -0.048323903 -0.05232981 -0.05660122 -0.06114596 -0.06597100\nFare         0.058062798  0.062484082  0.067139925  0.072027651  0.07714234  0.08247676  0.08802129  0.09376399  0.09969060  0.10578476  0.112028090  0.11840043  0.12488008  0.13144400  0.13806810\nFamSize     -0.005580138 -0.006389012 -0.007312285 -0.008363985 -0.00955923 -0.01091417 -0.01244590 -0.01417229 -0.01611186 -0.01828353 -0.020706366 -0.02339931 -0.02638086 -0.02966871 -0.03327942\n                                                                                                                                                                                                 \n(Intercept)  0.18743910  0.22740041  0.26865250  0.31114477  0.35482181  0.39962413  0.44548870  0.49234964  0.54013871  0.58878582  0.63821946  0.68836691  0.7391545215  0.79051795  0.84236586\nPclass2      0.07452897  0.07341891  0.07156304  0.06889525  0.06535171  0.06087163  0.05539787  0.04887762  0.04126293  0.03251127  0.02258603  0.01145705 -0.0008989611 -0.01451876 -0.02937769\nPclass3     -0.41615111 -0.44072319 -0.46613960 -0.49240001 -0.51950554 -0.54745873 -0.57626343 -0.60592448 -0.63644731 -0.66783729 -0.70009901 -0.73323550 -0.7672472489 -0.80214210 -0.83789634\nSexmale     -0.73004678 -0.77463660 -0.82051300 -0.86757212 -0.91570047 -0.96477620 -1.01467065 -1.06524992 -1.11637653 -1.16791112 -1.21971405 -1.27164697 -1.3235742450 -1.37536496 -1.42689128\nAge         -0.07108228 -0.07648476 -0.08218225 -0.08817745 -0.09447190 -0.10106590 -0.10795856 -0.11514768 -0.12262980 -0.13040007 -0.13845226 -0.14677867 -0.1553700522 -0.16421588 -0.17330330\nFare         0.14472741  0.15139633  0.15804881  0.16465846  0.17119870  0.17764284  0.18396413  0.19013578  0.19613103  0.20192314  0.20748541  0.21279129  0.2178144105  0.22252645  0.22690532\nFamSize     -0.03722809 -0.04152795 -0.04619008 -0.05122309 -0.05663286 -0.06242225 -0.06859098 -0.07513539 -0.08204839 -0.08931937 -0.09693417 -0.10487509 -0.1131210348 -0.12164724 -0.13042659\n                                                                                                                                                                                              \n(Intercept)  0.89462884  0.94722942  1.00008867  1.0531259  1.1062585  1.1594015  1.2125066  1.2654172  1.3180708  1.3703731  1.4222273  1.4735355  1.5241984  1.5741166  1.6231914  1.6714232\nPclass2     -0.04549014 -0.06284768 -0.08143274 -0.1012183 -0.1221676 -0.1442340 -0.1674321 -0.1915727 -0.2166347 -0.2425331 -0.2691743 -0.2964570 -0.3242730 -0.3525084 -0.3810453 -0.4099249\nPclass3     -0.87450473 -0.91194873 -0.95020275 -0.9892333 -1.0289986 -1.0694476 -1.1105657 -1.1522062 -1.1943246 -1.2368329 -1.2796346 -1.3226253 -1.3656935 -1.4087219 -1.4515887 -1.4942899\nSexmale     -1.47803314 -1.52867656 -1.57871476 -1.6280484 -1.6765859 -1.7242434 -1.7709464 -1.8166226 -1.8612118 -1.9046592 -1.9469167 -1.9879424 -2.0277005 -2.0661609 -2.1032991 -2.1391022\nAge         -0.18261831 -0.19214504 -0.20186588 -0.2117615 -0.2218109 -0.2319914 -0.2422812 -0.2526512 -0.2630766 -0.2735297 -0.2839825 -0.2944063 -0.3047723 -0.3150519 -0.3252167 -0.3352477\nFare         0.23092467  0.23456069  0.23779094  0.2405948  0.2429539  0.2448527  0.2462671  0.2472081  0.2476625  0.2476305  0.2471172  0.2461328  0.2446928  0.2428178  0.2405333  0.2378348\nFamSize     -0.13942843 -0.14861969 -0.15796506 -0.1674274 -0.1769682 -0.1865482 -0.1961253 -0.2056639 -0.2151237 -0.2244673 -0.2336593 -0.2426665 -0.2514588 -0.2600088 -0.2682928 -0.2762825\n                      \n(Intercept)  1.7185370\nPclass2     -0.4387237\nPclass3     -1.5364772\nSexmale     -2.1735447\nAge         -0.3451031\nFare         0.2348199\nFamSize     -0.2839760\n\ncoef(ridge.fit)[,100]                            # 100번째 람다 값에 대한 회귀계수 추정치\n\n(Intercept)     Pclass2     Pclass3     Sexmale         Age        Fare     FamSize \n  1.7185370  -0.4387237  -1.5364772  -2.1735447  -0.3451031   0.2348199  -0.2839760 \n\n\nCaution! \\(\\lambda\\)는 모형이 Training Dataset에 과적합 되는 것을 방지하기 위해 사용하는 모수이며, 교차 검증(Cross Validation)을 통해 최적의 값을 찾을 수 있다. 이러한 방법은 package \"glmnet\"에서 제공하는 함수 cv.glmnet()을 통해 수행할 수 있으며, 함수에 대한 자세한 옵션은 여기를 참고한다.\n\nset.seed(200)                                          # Seed 고정 -&gt; 동일한 결과를 출력하기 위해\ncv.ridge.fit &lt;- cv.glmnet(x = train.x,                 # 예측 변수를 포함하는 행렬\n                          y = titanic.trd.Imp$Survived,# Target\n                          family = \"binomial\",         # Binary Classification\n                          alpha = 0,                   # 0 : Ridge / 1 : Lasso / 0 &lt; alpha &lt; 1 : Elastic Net\n                          nfolds = 5,                  # 5-Fold Cross Validation\n                          type.measure = \"auc\")        # AUC에 기반하여 최적의 람다 값 찾기\n\nplot(cv.ridge.fit)                                     # Plot\n\n\n\n\n\n\n\n\nResult! 100개의 \\(\\lambda\\) 값에 대한 AUC의 변화를 보여준다.\nCaution! 만약 \\(\\lambda\\) 값에 대해 직접 후보 값을 지정하고 싶으면 함수 cv.glmnet()의 옵션 lambda = 후보 값을 이용하면 된다.\n\ncv.ridge.fit$lambda.min                                   # 최적의 람다 값\n\n[1] 0.03020599\n\nmax(cv.ridge.fit$cvm)                                     # 최적의 람다 값에 대한 AUC\n\n[1] 0.849817\n\nround(coef(cv.ridge.fit, s = cv.ridge.fit$lambda.min), 3) # 최적의 람다 값에 대한 회귀계수 추정치\n\n7 x 1 sparse Matrix of class \"dgCMatrix\"\n                s1\n(Intercept)  1.623\nPclass2     -0.381\nPclass3     -1.452\nSexmale     -2.103\nAge         -0.325\nFare         0.241\nFamSize     -0.268\n\n\nResult! 최적의 \\(\\lambda\\) 값에 대해 추정된 회귀계수를 이용하여 다음과 같은 모형식을 얻을 수 있다. \\[\n\\begin{align*}\n\\log{\\frac{p}{1-p}} =&\\; 1.623 - 0.381 X_{\\text{Pclass2}} - 1.452 X_{\\text{Pclass3}} -2.103 X_{\\text{Sexmale}} \\\\\n                      &-0.325 Z_{\\text{Age}} +0.241 Z_{\\text{Fare}} - 0.268 Z_{\\text{FamSize}}\n\\end{align*}\n\\]",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Ridge Regression</span>"
    ]
  },
  {
    "objectID": "Ridge.html#모형-평가",
    "href": "Ridge.html#모형-평가",
    "title": "11  Ridge Regression",
    "section": "11.7 모형 평가",
    "text": "11.7 모형 평가\nCaution! 모형 평가를 위해 Test Dataset에 대한 예측 class/확률 이 필요하며, 함수 predict()를 이용하여 생성한다.\n\n# 예측 class 생성\ntest.ridge.class &lt;- predict(cv.ridge.fit, \n                            newx = test.x,             # Test Dataset including Only 예측 변수 \n                            s = \"lambda.min\",          # 최적의 람다 값 기반\n                            type = \"class\")            # 예측 class 생성\n\ntest.ridge.class %&gt;%                                      \n  as_tibble\n\n# A tibble: 266 × 1\n   lambda.min\n   &lt;chr&gt;     \n 1 yes       \n 2 no        \n 3 no        \n 4 yes       \n 5 no        \n 6 no        \n 7 yes       \n 8 no        \n 9 no        \n10 yes       \n# ℹ 256 more rows\n\n\n\n\n11.7.1 ConfusionMatrix\n\nCM   &lt;- caret::confusionMatrix(as.factor(test.ridge.class), titanic.ted.Imp$Survived, \n                               positive = \"yes\")       # confusionMatrix(예측 class, 실제 class, positive = \"관심 class\")\nCM\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  no yes\n       no  151  35\n       yes  13  67\n                                         \n               Accuracy : 0.8195         \n                 95% CI : (0.768, 0.8638)\n    No Information Rate : 0.6165         \n    P-Value [Acc &gt; NIR] : 5.675e-13      \n                                         \n                  Kappa : 0.6021         \n                                         \n Mcnemar's Test P-Value : 0.002437       \n                                         \n            Sensitivity : 0.6569         \n            Specificity : 0.9207         \n         Pos Pred Value : 0.8375         \n         Neg Pred Value : 0.8118         \n             Prevalence : 0.3835         \n         Detection Rate : 0.2519         \n   Detection Prevalence : 0.3008         \n      Balanced Accuracy : 0.7888         \n                                         \n       'Positive' Class : yes            \n                                         \n\n\n\n\n\n11.7.2 ROC 곡선\n\n# 예측 확률 생성\ntest.ridge.prob &lt;- predict(cv.ridge.fit, \n                           newx = test.x,              # Test Dataset including Only 예측 변수 \n                           s = \"lambda.min\",           # 최적의 람다 값 기반\n                           type = \"response\")          # 예측 확률 생성\n\ntest.ridge.prob %&gt;%                                    # \"Survived = yes\"에 대한 예측 확률                           \n  as_tibble\n\n# A tibble: 266 × 1\n   lambda.min\n        &lt;dbl&gt;\n 1      0.830\n 2      0.299\n 3      0.161\n 4      0.663\n 5      0.129\n 6      0.287\n 7      0.640\n 8      0.298\n 9      0.129\n10      0.835\n# ℹ 256 more rows\n\n\n\nac  &lt;- titanic.ted.Imp$Survived                        # Test Dataset의 실제 class \npp  &lt;- as.numeric(test.ridge.prob)                     # 예측 확률을 수치형으로 변환\n\n\n11.7.2.1 Package “pROC”\n\npacman::p_load(\"pROC\")\n\nridge.roc  &lt;- roc(ac, pp, plot = T, col = \"gray\")      # roc(실제 class, 예측 확률)\nauc        &lt;- round(auc(ridge.roc), 3)\nlegend(\"bottomright\", legend = auc, bty = \"n\")\n\n\n\n\n\n\n\n\nCaution! Package \"pROC\"를 통해 출력한 ROC 곡선은 다양한 함수를 이용해서 그래프를 수정할 수 있다.\n\n# 함수 plot.roc() 이용\nplot.roc(ridge.roc,   \n         col=\"gray\",                                   # Line Color\n         print.auc = TRUE,                             # AUC 출력 여부\n         print.auc.col = \"red\",                        # AUC 글씨 색깔\n         print.thres = TRUE,                           # Cutoff Value 출력 여부\n         print.thres.pch = 19,                         # Cutoff Value를 표시하는 도형 모양\n         print.thres.col = \"red\",                      # Cutoff Value를 표시하는 도형의 색깔\n         auc.polygon = TRUE,                           # 곡선 아래 면적에 대한 여부\n         auc.polygon.col = \"gray90\")                   # 곡선 아래 면적의 색깔\n\n\n\n\n\n\n\n\n\n# 함수 ggroc() 이용\nggroc(ridge.roc) +\nannotate(geom = \"text\", x = 0.9, y = 1.0,\nlabel = paste(\"AUC = \", auc),\nsize = 5,\ncolor=\"red\") +\ntheme_bw()\n\n\n\n\n\n\n\n\n\n\n11.7.2.2 Package “Epi”\n\npacman::p_load(\"Epi\")       \n# install_version(\"etm\", version = \"1.1\", repos = \"http://cran.us.r-project.org\")\n\nROC(pp, ac, plot = \"ROC\")                              # ROC(예측 확률, 실제 class)  \n\n\n\n\n\n\n\n\n\n\n11.7.2.3 Package “ROCR”\n\npacman::p_load(\"ROCR\")\n\nridge.pred &lt;- prediction(pp, ac)                       # prediction(예측 확률, 실제 class) \n\nridge.perf &lt;- performance(ridge.pred, \"tpr\", \"fpr\")    # performance(, \"민감도\", \"1-특이도\")                      \nplot(ridge.perf, col = \"gray\")                         # ROC Curve\n\nperf.auc   &lt;- performance(ridge.pred, \"auc\")           # AUC\nauc        &lt;- attributes(perf.auc)$y.values\nlegend(\"bottomright\", legend = auc, bty = \"n\")\n\n\n\n\n\n\n\n\n\n\n\n\n11.7.3 향상 차트\n\n11.7.3.1 Package “ROCR”\n\nridge.perf &lt;- performance(ridge.pred, \"lift\", \"rpp\")   # Lift Chart                      \nplot(ridge.perf, main = \"lift curve\",\n     colorize = T,                                     # Coloring according to cutoff \n     lwd = 2)",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Ridge Regression</span>"
    ]
  },
  {
    "objectID": "Elasticnet.html",
    "href": "Elasticnet.html",
    "title": "12  Elastic Net Regression",
    "section": "",
    "text": "12.1 데이터 불러오기\npacman::p_load(\"data.table\", \n               \"tidyverse\", \n               \"dplyr\", \"tidyr\",\n               \"ggplot2\", \"GGally\",\n               \"caret\",\n               \"glmnet\")                                                # For glmnet\n\ntitanic &lt;- fread(\"../Titanic.csv\")                                      # 데이터 불러오기\n\ntitanic %&gt;%\n  as_tibble\n# A tibble: 891 × 11\n   Survived Pclass Name                                                Sex      Age SibSp Parch Ticket            Fare Cabin  Embarked\n      &lt;int&gt;  &lt;int&gt; &lt;chr&gt;                                               &lt;chr&gt;  &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;   \n 1        0      3 Braund, Mr. Owen Harris                             male      22     1     0 A/5 21171         7.25 \"\"     S       \n 2        1      1 Cumings, Mrs. John Bradley (Florence Briggs Thayer) female    38     1     0 PC 17599         71.3  \"C85\"  C       \n 3        1      3 Heikkinen, Miss. Laina                              female    26     0     0 STON/O2. 3101282  7.92 \"\"     S       \n 4        1      1 Futrelle, Mrs. Jacques Heath (Lily May Peel)        female    35     1     0 113803           53.1  \"C123\" S       \n 5        0      3 Allen, Mr. William Henry                            male      35     0     0 373450            8.05 \"\"     S       \n 6        0      3 Moran, Mr. James                                    male      NA     0     0 330877            8.46 \"\"     Q       \n 7        0      1 McCarthy, Mr. Timothy J                             male      54     0     0 17463            51.9  \"E46\"  S       \n 8        0      3 Palsson, Master. Gosta Leonard                      male       2     3     1 349909           21.1  \"\"     S       \n 9        1      3 Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)   female    27     0     2 347742           11.1  \"\"     S       \n10        1      2 Nasser, Mrs. Nicholas (Adele Achem)                 female    14     1     0 237736           30.1  \"\"     C       \n# ℹ 881 more rows",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Elastic Net Regression</span>"
    ]
  },
  {
    "objectID": "Elasticnet.html#데이터-전처리-i",
    "href": "Elasticnet.html#데이터-전처리-i",
    "title": "12  Elastic Net Regression",
    "section": "12.2 데이터 전처리 I",
    "text": "12.2 데이터 전처리 I\n\ntitanic %&lt;&gt;%\n  data.frame() %&gt;%                                                      # Data Frame 형태로 변환 \n  mutate(Survived = ifelse(Survived == 1, \"yes\", \"no\"))                 # Target을 문자형 변수로 변환\n\n# 1. Convert to Factor\nfac.col &lt;- c(\"Pclass\", \"Sex\",\n             # Target\n             \"Survived\")\n\ntitanic &lt;- titanic %&gt;% \n  mutate_at(fac.col, as.factor)                                         # 범주형으로 변환\n\nglimpse(titanic)                                                        # 데이터 구조 확인\n\nRows: 891\nColumns: 11\n$ Survived &lt;fct&gt; no, yes, yes, yes, no, no, no, no, yes, yes, yes, yes, no, no, no, yes, no, yes, no, yes, no, yes, yes, yes, no, yes, no, no, yes, no, no, yes, yes, no, no, no, yes, no, no, yes, no…\n$ Pclass   &lt;fct&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3, 2, 2, 3, 1, 3, 3, 3, 1, 3, 3, 1, 1, 3, 2, 1, 1, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 1, 1, 2, 3, 2, 3, 3…\n$ Name     &lt;chr&gt; \"Braund, Mr. Owen Harris\", \"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\", \"Heikkinen, Miss. Laina\", \"Futrelle, Mrs. Jacques Heath (Lily May Peel)\", \"Allen, Mr. William Henry…\n$ Sex      &lt;fct&gt; male, female, female, female, male, male, male, male, female, female, female, female, male, male, female, female, male, male, female, female, male, male, female, male, female, femal…\n$ Age      &lt;dbl&gt; 22.0, 38.0, 26.0, 35.0, 35.0, NA, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, NA, 31.0, NA, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, NA, 19.0, NA, NA, 40.0, NA, NA, 66.…\n$ SibSp    &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0, 0, 0, 0, 0, 3, 1, 0, 3, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 1, 0, 0, 1, 0, 2, 1, 4, 0, 1, 1, 0, 0, 0, 0, 1, 5, 0…\n$ Parch    &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 5, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 2, 2, 0…\n$ Ticket   &lt;chr&gt; \"A/5 21171\", \"PC 17599\", \"STON/O2. 3101282\", \"113803\", \"373450\", \"330877\", \"17463\", \"349909\", \"347742\", \"237736\", \"PP 9549\", \"113783\", \"A/5. 2151\", \"347082\", \"350406\", \"248706\", \"38…\n$ Fare     &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625, 21.0750, 11.1333, 30.0708, 16.7000, 26.5500, 8.0500, 31.2750, 7.8542, 16.0000, 29.1250, 13.0000, 18.0000, 7.2250, 26.0000,…\n$ Cabin    &lt;chr&gt; \"\", \"C85\", \"\", \"C123\", \"\", \"\", \"E46\", \"\", \"\", \"\", \"G6\", \"C103\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"D56\", \"\", \"A6\", \"\", \"\", \"\", \"C23 C25 C27\", \"\", \"\", \"\", \"B78\", \"\", \"\", \"\", \"\", \"\"…\n$ Embarked &lt;chr&gt; \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"C\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"Q\", \"S\", \"C\", \"C\", \"Q\", \"S\", \"C\", \"S\", \"…\n\n# 2. Generate New Variable\ntitanic &lt;- titanic %&gt;%\n  mutate(FamSize = SibSp + Parch)                                       # \"FamSize = 형제 및 배우자 수 + 부모님 및 자녀 수\"로 가족 수를 의미하는 새로운 변수\n\nglimpse(titanic)                                                        # 데이터 구조 확인\n\nRows: 891\nColumns: 12\n$ Survived &lt;fct&gt; no, yes, yes, yes, no, no, no, no, yes, yes, yes, yes, no, no, no, yes, no, yes, no, yes, no, yes, yes, yes, no, yes, no, no, yes, no, no, yes, yes, no, no, no, yes, no, no, yes, no…\n$ Pclass   &lt;fct&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3, 2, 2, 3, 1, 3, 3, 3, 1, 3, 3, 1, 1, 3, 2, 1, 1, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 1, 1, 2, 3, 2, 3, 3…\n$ Name     &lt;chr&gt; \"Braund, Mr. Owen Harris\", \"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\", \"Heikkinen, Miss. Laina\", \"Futrelle, Mrs. Jacques Heath (Lily May Peel)\", \"Allen, Mr. William Henry…\n$ Sex      &lt;fct&gt; male, female, female, female, male, male, male, male, female, female, female, female, male, male, female, female, male, male, female, female, male, male, female, male, female, femal…\n$ Age      &lt;dbl&gt; 22.0, 38.0, 26.0, 35.0, 35.0, NA, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, NA, 31.0, NA, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, NA, 19.0, NA, NA, 40.0, NA, NA, 66.…\n$ SibSp    &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0, 0, 0, 0, 0, 3, 1, 0, 3, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 1, 0, 0, 1, 0, 2, 1, 4, 0, 1, 1, 0, 0, 0, 0, 1, 5, 0…\n$ Parch    &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 5, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 2, 2, 0…\n$ Ticket   &lt;chr&gt; \"A/5 21171\", \"PC 17599\", \"STON/O2. 3101282\", \"113803\", \"373450\", \"330877\", \"17463\", \"349909\", \"347742\", \"237736\", \"PP 9549\", \"113783\", \"A/5. 2151\", \"347082\", \"350406\", \"248706\", \"38…\n$ Fare     &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625, 21.0750, 11.1333, 30.0708, 16.7000, 26.5500, 8.0500, 31.2750, 7.8542, 16.0000, 29.1250, 13.0000, 18.0000, 7.2250, 26.0000,…\n$ Cabin    &lt;chr&gt; \"\", \"C85\", \"\", \"C123\", \"\", \"\", \"E46\", \"\", \"\", \"\", \"G6\", \"C103\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"D56\", \"\", \"A6\", \"\", \"\", \"\", \"C23 C25 C27\", \"\", \"\", \"\", \"B78\", \"\", \"\", \"\", \"\", \"\"…\n$ Embarked &lt;chr&gt; \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"C\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"Q\", \"S\", \"C\", \"C\", \"Q\", \"S\", \"C\", \"S\", \"…\n$ FamSize  &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 4, 2, 1, 2, 0, 0, 6, 0, 0, 5, 0, 1, 0, 0, 0, 0, 0, 4, 6, 0, 5, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 3, 0, 0, 1, 0, 2, 1, 5, 0, 1, 1, 1, 0, 0, 0, 3, 7, 0…\n\n# 3. Select Variables used for Analysis\ntitanic1 &lt;- titanic %&gt;% \n  select(Survived, Pclass, Sex, Age, Fare, FamSize)                     # 분석에 사용할 변수 선택\n\ntitanic1 %&gt;%\n  as_tibble\n\n# A tibble: 891 × 6\n   Survived Pclass Sex      Age  Fare FamSize\n   &lt;fct&gt;    &lt;fct&gt;  &lt;fct&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;int&gt;\n 1 no       3      male      22  7.25       1\n 2 yes      1      female    38 71.3        1\n 3 yes      3      female    26  7.92       0\n 4 yes      1      female    35 53.1        1\n 5 no       3      male      35  8.05       0\n 6 no       3      male      NA  8.46       0\n 7 no       1      male      54 51.9        0\n 8 no       3      male       2 21.1        4\n 9 yes      3      female    27 11.1        2\n10 yes      2      female    14 30.1        1\n# ℹ 881 more rows",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Elastic Net Regression</span>"
    ]
  },
  {
    "objectID": "Elasticnet.html#데이터-탐색",
    "href": "Elasticnet.html#데이터-탐색",
    "title": "12  Elastic Net Regression",
    "section": "12.3 데이터 탐색",
    "text": "12.3 데이터 탐색\n\nggpairs(titanic1,                                        \n        aes(colour = Survived)) +                         # Target의 범주에 따라 색깔을 다르게 표현\n  theme_bw()\n\n\n\n\n\n\n\nggpairs(titanic1,                                     \n        aes(colour = Survived, alpha = 0.8)) +            # Target의 범주에 따라 색깔을 다르게 표현\n  scale_colour_manual(values = c(\"#E69F00\", \"#56B4E9\")) + # 특정 색깔 지정\n  scale_fill_manual(values = c(\"#E69F00\", \"#56B4E9\")) +   # 특정 색깔 지정\n  theme_bw()",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Elastic Net Regression</span>"
    ]
  },
  {
    "objectID": "Elasticnet.html#데이터-분할",
    "href": "Elasticnet.html#데이터-분할",
    "title": "12  Elastic Net Regression",
    "section": "12.4 데이터 분할",
    "text": "12.4 데이터 분할\n\n# Partition (Training Dataset : Test Dataset = 7:3)\ny      &lt;- titanic1$Survived                             # Target\n\nset.seed(200)\nind    &lt;- createDataPartition(y, p = 0.7, list  =T)     # Index를 이용하여 7:3으로 분할\ntitanic.trd &lt;- titanic1[ind$Resample1,]                 # Training Dataset\ntitanic.ted &lt;- titanic1[-ind$Resample1,]                # Test Dataset",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Elastic Net Regression</span>"
    ]
  },
  {
    "objectID": "Elasticnet.html#데이터-전처리-ii",
    "href": "Elasticnet.html#데이터-전처리-ii",
    "title": "12  Elastic Net Regression",
    "section": "12.5 데이터 전처리 II",
    "text": "12.5 데이터 전처리 II\n\n# 1. Imputation\ntitanic.trd.Imp &lt;- titanic.trd %&gt;% \n  mutate(Age = replace_na(Age, mean(Age, na.rm = TRUE)))                 # 평균으로 결측값 대체\n\ntitanic.ted.Imp &lt;- titanic.ted %&gt;% \n  mutate(Age = replace_na(Age, mean(titanic.trd$Age, na.rm = TRUE)))     # Training Dataset을 이용하여 결측값 대체\n\n# 2. Standardization\npreProcValues &lt;- preProcess(titanic.trd.Imp, \n                            method = c(\"center\", \"scale\"))               # Standardization 정의 -&gt; Training Dataset에 대한 평균과 표준편차 계산 \n\ntitanic.trd.Imp &lt;- predict(preProcValues, titanic.trd.Imp)               # Standardization for Training Dataset\ntitanic.ted.Imp &lt;- predict(preProcValues, titanic.ted.Imp)               # Standardization for Test Dataset\n\n# 3. Convert Factor Var. into Dummy Var. \ntrain.x &lt;- model.matrix(Survived ~.,                                     # Survived는 Target으로 제외  \n                        titanic.trd.Imp)[,-1]                            # [,-1] : 절편 제거\n\ntrain.x\n\n    Pclass2 Pclass3 Sexmale         Age         Fare     FamSize\n1         0       1       1 -0.61306970 -0.517763935  0.04506631\n3         0       1       0 -0.30411628 -0.504633254 -0.55421976\n4         0       0       0  0.39102893  0.374149700  0.04506631\n5         0       1       1  0.39102893 -0.502201647 -0.55421976\n6         0       1       1  0.00000000 -0.494259044 -0.55421976\n8         0       1       1 -2.15783684 -0.248828144  1.84292454\n9         0       1       0 -0.22687792 -0.442222643  0.64435239\n10        1       0       0 -1.23097656 -0.073834105  0.04506631\n11        0       1       0 -2.00336012 -0.333934407  0.64435239\n12        0       0       0  2.16751113 -0.142323735 -0.55421976\n14        0       1       1  0.69998236 -0.050408971  3.04149669\n15        0       1       0 -1.23097656 -0.506010517 -0.55421976\n18        1       0       1  0.00000000 -0.405909990 -0.55421976\n19        0       1       0  0.08207551 -0.308645689  0.04506631\n20        0       1       0  0.00000000 -0.518250257 -0.55421976\n21        1       0       1  0.39102893 -0.153022808 -0.55421976\n24        0       0       1 -0.14963956  0.031779363 -0.55421976\n25        0       1       0 -1.69440670 -0.248828144  1.84292454\n27        0       1       1  0.00000000 -0.518250257 -0.55421976\n28        0       0       1 -0.84478477  4.457305033  2.44221062\n29        0       1       0  0.00000000 -0.505524195 -0.55421976\n30        0       1       1  0.00000000 -0.505201278 -0.55421976\n31        0       0       1  0.77722072 -0.119548327 -0.55421976\n32        0       0       0  0.00000000  2.191451452  0.04506631\n33        0       1       0  0.00000000 -0.508037505 -0.55421976\n34        1       0       1  2.78541799 -0.454542140 -0.55421976\n35        0       0       1 -0.14963956  0.939659905  0.04506631\n36        0       0       1  0.93169743  0.352751554  0.04506631\n38        0       1       1 -0.69030806 -0.502201647 -0.55421976\n39        0       1       0 -0.92202313 -0.308645689  0.64435239\n40        0       1       0 -1.23097656 -0.440113953  0.04506631\n41        0       1       0  0.77722072 -0.474481321  0.04506631\n42        1       0       0 -0.22687792 -0.250287109  0.04506631\n43        0       1       1  0.00000000 -0.505201278 -0.55421976\n45        0       1       0 -0.84478477 -0.505524195 -0.55421976\n47        0       1       1  0.00000000 -0.357277839  0.04506631\n48        0       1       0  0.00000000 -0.508037505 -0.55421976\n49        0       1       1  0.00000000 -0.237074726  0.64435239\n50        0       1       0 -0.92202313 -0.312536261  0.04506631\n51        0       1       1 -1.77164505  0.113238214  2.44221062\n53        0       0       0  1.47236593  0.833805222  0.04506631\n55        0       0       1  2.70817963  0.546875535  0.04506631\n56        0       0       1  0.00000000  0.031779363 -0.55421976\n60        0       1       1 -1.46269163  0.253541968  3.64078277\n61        0       1       1 -0.61306970 -0.518168555 -0.55421976\n62        0       0       0  0.62274400  0.897431637 -0.55421976\n64        0       1       1 -2.00336012 -0.116062374  2.44221062\n65        0       0       1  0.00000000 -0.119548327 -0.55421976\n70        0       1       1 -0.30411628 -0.490286770  0.64435239\n72        0       1       0 -1.07649984  0.253541968  3.64078277\n74        0       1       1 -0.30411628 -0.377621640  0.04506631\n75        0       1       1  0.15931386  0.440207722 -0.55421976\n76        0       1       1 -0.38135463 -0.509982791 -0.55421976\n77        0       1       1  0.00000000 -0.505201278 -0.55421976\n79        1       0       1 -2.24820571 -0.094664228  0.64435239\n80        0       1       0  0.00483715 -0.416122741 -0.55421976\n82        0       1       1 -0.07240121 -0.473995000 -0.55421976\n83        0       1       0  0.00000000 -0.507308023 -0.55421976\n84        0       0       1 -0.14963956  0.257432540 -0.55421976\n85        1       0       0 -0.99926149 -0.454542140 -0.55421976\n86        0       1       0  0.23655222 -0.350469338  1.24363847\n88        0       1       1  0.00000000 -0.502201647 -0.55421976\n89        0       0       0 -0.53583135  4.457305033  2.44221062\n91        0       1       1 -0.07240121 -0.502201647 -0.55421976\n92        0       1       1 -0.76754642 -0.506010517 -0.55421976\n93        0       0       1  1.24065086  0.531231545  0.04506631\n94        0       1       1 -0.30411628 -0.258554574  1.24363847\n95        0       1       1  2.24474949 -0.517763935 -0.55421976\n96        0       1       1  0.00000000 -0.502201647 -0.55421976\n97        0       0       1  3.17160977  0.015326133 -0.55421976\n103       0       0       1 -0.69030806  0.844665754  0.04506631\n105       0       1       1  0.54550565 -0.504633254  0.64435239\n107       0       1       0 -0.69030806 -0.509982791 -0.55421976\n108       0       1       1  0.00000000 -0.507551184 -0.55421976\n110       0       1       0  0.00000000 -0.189010600  0.04506631\n111       0       0       1  1.31788921  0.352751554 -0.55421976\n112       0       1       0 -1.19235738 -0.377621640  0.04506631\n113       0       1       1 -0.61306970 -0.502201647 -0.55421976\n114       0       1       0 -0.76754642 -0.467672820  0.04506631\n115       0       1       0 -0.99926149 -0.377541884 -0.55421976\n116       0       1       1 -0.69030806 -0.504633254 -0.55421976\n117       0       1       1  3.13299059 -0.508037505 -0.55421976\n119       0       0       1 -0.45859299  4.156190321  0.04506631\n122       0       1       1  0.00000000 -0.502201647 -0.55421976\n125       0       0       1  1.85855771  0.844665754  0.04506631\n126       0       1       1 -1.38545327 -0.440113953  0.04506631\n128       0       1       1 -0.45859299 -0.519870680 -0.55421976\n129       0       1       0  0.00000000 -0.223864289  0.64435239\n130       0       1       1  1.16341250 -0.523113472 -0.55421976\n131       0       1       1  0.23655222 -0.505201278 -0.55421976\n132       0       1       1 -0.76754642 -0.521654507 -0.55421976\n134       1       0       0 -0.07240121 -0.153022808  0.04506631\n136       1       0       1 -0.53583135 -0.366113328 -0.55421976\n138       0       0       1  0.54550565  0.374149700  0.04506631\n141       0       1       0  0.00000000 -0.362222756  0.64435239\n142       0       1       0 -0.61306970 -0.508037505 -0.55421976\n143       0       1       0 -0.45859299 -0.350469338  0.04506631\n146       1       0       1 -0.84478477  0.056095438  0.64435239\n147       0       1       1 -0.22687792 -0.507146564 -0.55421976\n148       0       1       0 -1.61716834  0.009894895  1.84292454\n149       1       0       1  0.50688647 -0.153022808  0.64435239\n150       1       0       1  0.93169743 -0.405909990 -0.55421976\n151       1       0       1  1.62684264 -0.415150098 -0.55421976\n153       0       1       1  1.97441524 -0.502201647 -0.55421976\n154       0       1       1  0.81583989 -0.376730699  0.64435239\n156       0       0       1  1.62684264  0.535203819  0.04506631\n157       0       1       0 -1.07649984 -0.508362368 -0.55421976\n158       0       1       1  0.00483715 -0.502201647 -0.55421976\n160       0       1       1  0.00000000  0.694149249  5.43864100\n162       1       0       0  0.77722072 -0.352414624 -0.55421976\n163       0       1       1 -0.30411628 -0.507551184 -0.55421976\n164       0       1       1 -0.99926149 -0.490286770 -0.55421976\n167       0       0       0  0.00000000  0.411110134  0.04506631\n169       0       0       1  0.00000000 -0.154481773 -0.55421976\n171       0       0       1  2.39922620 -0.007126358 -0.55421976\n173       0       1       0 -2.23507519 -0.442222643  0.64435239\n174       0       1       1 -0.69030806 -0.504633254 -0.55421976\n176       0       1       1 -0.92202313 -0.506010517  0.64435239\n179       1       0       1  0.00483715 -0.405909990 -0.55421976\n180       0       1       1  0.46826729 -0.658797171 -0.55421976\n181       0       1       0  0.00000000  0.694149249  5.43864100\n182       1       0       1  0.00000000 -0.366031626 -0.55421976\n184       1       0       1 -2.23507519  0.099864373  1.24363847\n185       0       1       0 -2.00336012 -0.230347927  0.64435239\n188       0       0       1  1.16341250 -0.142323735 -0.55421976\n189       0       1       1  0.77722072 -0.357277839  0.64435239\n190       0       1       1  0.46826729 -0.505201278 -0.55421976\n191       1       0       0  0.15931386 -0.405909990 -0.55421976\n192       1       0       1 -0.84478477 -0.405909990 -0.55421976\n194       1       0       1 -2.08059848 -0.153022808  0.64435239\n196       0       0       0  2.16751113  2.191451452 -0.55421976\n197       0       1       1  0.00000000 -0.508037505 -0.55421976\n198       0       1       1  0.93169743 -0.495311444  0.04506631\n199       0       1       0  0.00000000 -0.508037505 -0.55421976\n200       1       0       0 -0.45859299 -0.405909990 -0.55421976\n202       0       1       1  0.00000000  0.694149249  5.43864100\n203       0       1       1  0.31379058 -0.532435282 -0.55421976\n204       0       1       1  1.20203168 -0.518250257 -0.55421976\n205       0       1       1 -0.92202313 -0.502201647 -0.55421976\n206       0       1       0 -2.15783684 -0.455271622  0.04506631\n207       0       1       1  0.15931386 -0.350469338  0.04506631\n209       0       1       0 -1.07649984 -0.508037505 -0.55421976\n211       0       1       1 -0.45859299 -0.521654507 -0.55421976\n212       1       0       0  0.39102893 -0.250287109 -0.55421976\n213       0       1       1 -0.61306970 -0.517763935 -0.55421976\n214       1       0       1  0.00483715 -0.405909990 -0.55421976\n216       0       0       0  0.08207551  1.544725556  0.04506631\n217       0       1       0 -0.22687792 -0.504633254 -0.55421976\n218       1       0       1  0.93169743 -0.133569948  0.04506631\n219       0       0       0  0.15931386  0.825294596 -0.55421976\n220       1       0       1  0.00483715 -0.454542140 -0.55421976\n223       0       1       1  1.62684264 -0.502201647 -0.55421976\n224       0       1       1  0.00000000 -0.505201278 -0.55421976\n226       0       1       1 -0.61306970 -0.476912929 -0.55421976\n227       1       0       1 -0.84478477 -0.454542140 -0.55421976\n229       1       0       1 -0.92202313 -0.405909990 -0.55421976\n230       0       1       0  0.00000000 -0.163397019  1.84292454\n232       0       1       1 -0.07240121 -0.507551184 -0.55421976\n233       1       0       1  2.24474949 -0.396183559 -0.55421976\n235       1       0       1 -0.45859299 -0.454542140 -0.55421976\n236       0       1       0  0.00000000 -0.511928077 -0.55421976\n237       1       0       1  1.08617414 -0.153022808  0.04506631\n238       1       0       0 -1.69440670 -0.148159593  0.64435239\n240       1       0       1  0.23655222 -0.420013313 -0.55421976\n242       0       1       0  0.00000000 -0.357277839  0.04506631\n243       1       0       1 -0.07240121 -0.454542140 -0.55421976\n244       0       1       1 -0.61306970 -0.520195543 -0.55421976\n245       0       1       1  0.00483715 -0.518250257 -0.55421976\n246       0       0       1  1.08617414  1.091960238  0.64435239\n247       0       1       0 -0.38135463 -0.507551184 -0.55421976\n248       1       0       0 -0.45859299 -0.376730699  0.64435239\n249       0       0       1  0.54550565  0.363532329  0.64435239\n252       0       1       0 -0.07240121 -0.455271622  0.64435239\n253       0       0       1  2.47646456 -0.142323735 -0.55421976\n254       0       1       1  0.00483715 -0.345606123  0.04506631\n255       0       1       0  0.85445907 -0.265606236  0.64435239\n257       0       0       0  0.00000000  0.881869349 -0.55421976\n258       0       0       0  0.00483715  1.023875227 -0.55421976\n259       0       0       0  0.39102893  9.307471078 -0.55421976\n262       0       1       1 -2.08059848 -0.048220525  3.04149669\n264       0       0       1  0.77722072 -0.658797171 -0.55421976\n265       0       1       0  0.00000000 -0.508037505 -0.55421976\n266       1       0       1  0.46826729 -0.454542140 -0.55421976\n267       0       1       1 -1.07649984  0.113238214  2.44221062\n269       0       0       0  2.16751113  2.326487371  0.04506631\n270       0       0       0  0.39102893  1.979658438 -0.55421976\n273       1       0       0  0.85445907 -0.279466399  0.04506631\n275       0       1       0  0.00000000 -0.508037505 -0.55421976\n276       0       0       0  2.55370292  0.857714732  0.04506631\n278       1       0       1  0.00000000 -0.658797171 -0.55421976\n280       0       1       0  0.39102893 -0.264876754  0.64435239\n281       0       1       1  2.70817963 -0.508037505 -0.55421976\n285       0       0       1  0.00000000 -0.153022808 -0.55421976\n286       0       1       1  0.23655222 -0.490286770 -0.55421976\n287       0       1       1  0.00483715 -0.473995000 -0.55421976\n288       0       1       1 -0.61306970 -0.505201278 -0.55421976\n289       1       0       1  0.93169743 -0.405909990 -0.55421976\n290       0       1       0 -0.61306970 -0.508037505 -0.55421976\n291       0       0       0 -0.30411628  0.875060848 -0.55421976\n292       0       0       0 -0.84478477  1.112953764  0.04506631\n293       1       0       1  0.46826729 -0.408341597 -0.55421976\n294       0       1       0 -0.45859299 -0.486639359 -0.55421976\n296       0       0       1  0.00000000 -0.119548327 -0.55421976\n297       0       1       1 -0.49721217 -0.518168555 -0.55421976\n298       0       0       0 -2.15783684  2.289283776  1.24363847\n299       0       0       1  0.00000000 -0.065484938 -0.55421976\n300       0       0       0  1.54960428  4.156190321  0.04506631\n302       0       1       1  0.00000000 -0.206518174  0.64435239\n303       0       1       1 -0.84478477 -0.658797171 -0.55421976\n304       1       0       0  0.00000000 -0.418554349 -0.55421976\n305       0       1       1  0.00000000 -0.502201647 -0.55421976\n306       0       0       1 -2.24125426  2.289283776  1.24363847\n307       0       0       0  0.00000000  1.498200151 -0.55421976\n309       1       0       1  0.00483715 -0.191928529  0.04506631\n311       0       0       0 -0.45859299  0.958869605 -0.55421976\n315       1       0       1  1.00893579 -0.148159593  0.64435239\n316       0       1       0 -0.30411628 -0.506010517 -0.55421976\n317       1       0       0 -0.45859299 -0.153022808  0.04506631\n319       0       0       0  0.08207551  2.548331678  0.64435239\n320       0       0       0  0.77722072  1.957612512  0.64435239\n322       0       1       1 -0.22687792 -0.505201278 -0.55421976\n323       1       0       0  0.00483715 -0.418554349 -0.55421976\n324       1       0       0 -0.61306970 -0.094664228  0.64435239\n325       0       1       1  0.00000000  0.694149249  5.43864100\n327       0       1       1  2.39922620 -0.537459956 -0.55421976\n329       0       1       0  0.08207551 -0.259527217  0.64435239\n330       0       0       0 -1.07649984  0.469064095  0.04506631\n331       0       1       0  0.00000000 -0.206518174  0.64435239\n332       0       0       1  1.20203168 -0.104390658 -0.55421976\n335       0       0       0  0.00000000  1.941077581  0.04506631\n336       0       1       1  0.00000000 -0.505201278 -0.55421976\n337       0       0       1 -0.07240121  0.636763311  0.04506631\n339       0       1       1  1.16341250 -0.502201647 -0.55421976\n340       0       0       1  1.16341250  0.031779363 -0.55421976\n341       1       0       1 -2.15783684 -0.153022808  0.64435239\n342       0       0       0 -0.45859299  4.457305033  2.44221062\n343       1       0       1 -0.14963956 -0.405909990 -0.55421976\n345       1       0       1  0.46826729 -0.405909990 -0.55421976\n346       1       0       0 -0.45859299 -0.405909990 -0.55421976\n348       0       1       0  0.00000000 -0.345606123  0.04506631\n349       0       1       1 -2.08059848 -0.349496695  0.64435239\n350       0       1       1  0.93169743 -0.490286770 -0.55421976\n352       0       0       1  0.00000000  0.022052932 -0.55421976\n353       0       1       1 -1.15373820 -0.518168555  0.64435239\n354       0       1       1 -0.38135463 -0.312536261  0.04506631\n355       0       1       1  0.00000000 -0.518250257 -0.55421976\n356       0       1       1 -0.14963956 -0.473995000 -0.55421976\n357       0       0       0 -0.61306970  0.411110134  0.04506631\n360       0       1       0  0.00000000 -0.505524195 -0.55421976\n361       0       1       1  0.77722072 -0.116062374  2.44221062\n362       1       0       1 -0.07240121 -0.119548327  0.04506631\n363       0       1       0  1.16341250 -0.377621640  0.04506631\n365       0       1       1  0.00000000 -0.357277839  0.04506631\n366       0       1       1  0.00483715 -0.517763935 -0.55421976\n367       0       0       0  2.32198785  0.805030551  0.04506631\n368       0       1       0  0.00000000 -0.518168555 -0.55421976\n370       0       0       0 -0.45859299  0.689286034 -0.55421976\n371       0       0       1 -0.38135463  0.419702463  0.04506631\n372       0       1       1 -0.92202313 -0.532435282  0.04506631\n373       0       1       1 -0.84478477 -0.502201647 -0.55421976\n374       0       0       1 -0.61306970  1.979658438 -0.55421976\n376       0       0       0  0.00000000  0.939659905  0.04506631\n377       0       1       0 -0.61306970 -0.517763935 -0.55421976\n379       0       1       1 -0.76754642 -0.580742570 -0.55421976\n381       0       0       0  0.93169743  3.767214822 -0.55421976\n382       0       1       0 -2.23507519 -0.352576083  0.64435239\n383       0       1       1  0.15931386 -0.504633254 -0.55421976\n384       0       0       0  0.39102893  0.352751554  0.04506631\n385       0       1       1  0.00000000 -0.505201278 -0.55421976\n386       1       0       1 -0.92202313  0.770988046 -0.55421976\n387       0       1       1 -2.23507519  0.253541968  3.64078277\n388       1       0       0  0.46826729 -0.405909990 -0.55421976\n389       0       1       1  0.00000000 -0.508442125 -0.55421976\n390       1       0       0 -0.99926149 -0.425362850 -0.55421976\n391       0       0       1  0.46826729  1.675546040  1.24363847\n392       0       1       1 -0.69030806 -0.507146564 -0.55421976\n393       0       1       1 -0.14963956 -0.504633254  0.64435239\n394       0       0       0 -0.53583135  1.544725556  0.04506631\n395       0       1       0 -0.45859299 -0.333934407  0.64435239\n396       0       1       1 -0.61306970 -0.507146564 -0.55421976\n397       0       1       0  0.08207551 -0.506010517 -0.55421976\n398       1       0       1  1.24065086 -0.153022808 -0.55421976\n399       1       0       1 -0.53583135 -0.454542140 -0.55421976\n401       0       1       1  0.69998236 -0.504633254 -0.55421976\n402       0       1       1 -0.30411628 -0.502201647 -0.55421976\n404       0       1       1 -0.14963956 -0.350469338  0.04506631\n405       0       1       0 -0.76754642 -0.490286770 -0.55421976\n406       1       0       1  0.31379058 -0.250287109  0.04506631\n407       0       1       1  1.62684264 -0.508037505 -0.55421976\n408       1       0       1 -2.08059848 -0.294056044  0.64435239\n410       0       1       0  0.00000000 -0.163397019  1.84292454\n411       0       1       1  0.00000000 -0.505201278 -0.55421976\n414       1       0       1  0.00000000 -0.658797171 -0.55421976\n417       1       0       0  0.31379058 -0.026579218  0.64435239\n421       0       1       1  0.00000000 -0.505201278 -0.55421976\n422       0       1       1 -0.69030806 -0.508362368 -0.55421976\n423       0       1       1 -0.07240121 -0.505605898 -0.55421976\n425       0       1       1 -0.92202313 -0.265606236  0.64435239\n426       0       1       1  0.00000000 -0.517763935 -0.55421976\n428       1       0       0 -0.84478477 -0.153022808 -0.55421976\n429       0       1       1  0.00000000 -0.508037505 -0.55421976\n431       0       0       1 -0.14963956 -0.142323735 -0.55421976\n432       0       1       0  0.00000000 -0.345606123  0.04506631\n433       1       0       0  0.93169743 -0.153022808  0.04506631\n434       0       1       1 -0.99926149 -0.520195543 -0.55421976\n435       0       0       1  1.54960428  0.428617708  0.04506631\n437       0       1       0 -0.69030806  0.009894895  1.84292454\n438       1       0       0 -0.45859299 -0.294056044  2.44221062\n439       0       0       1  2.63094127  4.457305033  2.44221062\n443       0       1       1 -0.38135463 -0.507551184  0.04506631\n444       1       0       0 -0.14963956 -0.405909990 -0.55421976\n446       0       0       1 -2.00336012  0.933580887  0.64435239\n449       0       1       0 -1.92612177 -0.284168155  1.24363847\n451       1       0       1  0.46826729 -0.118980303  1.24363847\n453       0       0       1  0.00483715 -0.118980303 -0.55421976\n454       0       0       1  1.47236593  1.074534365  0.04506631\n456       0       1       1 -0.07240121 -0.505201278 -0.55421976\n459       1       0       0  1.54960428 -0.454542140 -0.55421976\n460       0       1       1  0.00000000 -0.508037505 -0.55421976\n461       0       0       1  1.39512757 -0.142323735 -0.55421976\n463       0       0       1  1.31788921  0.090137943 -0.55421976\n464       1       0       1  1.39512757 -0.405909990 -0.55421976\n465       0       1       1  0.00000000 -0.502201647 -0.55421976\n466       0       1       1  0.62274400 -0.521654507 -0.55421976\n468       0       0       1  2.01303442 -0.142323735 -0.55421976\n470       0       1       0 -2.25438478 -0.284168155  1.24363847\n471       0       1       1  0.00000000 -0.517763935 -0.55421976\n472       0       1       1  0.62274400 -0.490286770 -0.55421976\n474       1       0       0 -0.53583135 -0.390509160 -0.55421976\n475       0       1       0 -0.61306970 -0.467429660 -0.55421976\n479       0       1       1 -0.61306970 -0.512496101 -0.55421976\n480       0       1       0 -2.15783684 -0.419770152  0.04506631\n481       0       1       1 -1.61716834  0.253541968  3.64078277\n484       0       1       0  2.55370292 -0.472292875 -0.55421976\n485       0       0       1 -0.38135463  1.112953764  0.04506631\n486       0       1       0  0.00000000 -0.163397019  1.84292454\n487       0       0       0  0.39102893  1.091960238  0.04506631\n489       0       1       1  0.00483715 -0.502201647 -0.55421976\n491       0       1       1  0.00000000 -0.270387749  0.04506631\n493       0       0       1  1.93579607 -0.065484938 -0.55421976\n494       0       0       1  3.17160977  0.304201106 -0.55421976\n497       0       0       0  1.85855771  0.863713994  0.04506631\n498       0       1       1  0.00000000 -0.365058983 -0.55421976\n499       0       0       0 -0.38135463  2.289283776  1.24363847\n500       0       1       1 -0.45859299 -0.507146564 -0.55421976\n501       0       1       1 -0.99926149 -0.490286770 -0.55421976\n502       0       1       0 -0.69030806 -0.508037505 -0.55421976\n503       0       1       0  0.00000000 -0.510387411 -0.55421976\n504       0       1       0  0.54550565 -0.472292875 -0.55421976\n505       0       0       0 -1.07649984  1.023875227 -0.55421976\n506       0       0       1 -0.92202313  1.459619293  0.04506631\n507       1       0       0  0.23655222 -0.153022808  0.64435239\n508       0       0       1  0.00000000 -0.142323735 -0.55421976\n509       0       1       1 -0.14963956 -0.220621497 -0.55421976\n511       0       1       1 -0.07240121 -0.508037505 -0.55421976\n512       0       1       1  0.00000000 -0.502201647 -0.55421976\n513       0       0       1  0.46826729 -0.147430111 -0.55421976\n514       0       0       0  1.85855771  0.496702719  0.04506631\n516       0       0       1  1.31788921  0.003004692 -0.55421976\n517       1       0       0  0.31379058 -0.454542140 -0.55421976\n518       0       1       1  0.00000000 -0.189010600 -0.55421976\n519       1       0       0  0.46826729 -0.153022808  0.04506631\n521       0       0       0  0.00483715  1.160045248 -0.55421976\n522       0       1       1 -0.61306970 -0.505201278 -0.55421976\n524       0       0       0  1.08617414  0.469064095  0.04506631\n526       0       1       1  0.81583989 -0.508037505 -0.55421976\n528       0       0       1  0.00000000  3.655442578 -0.55421976\n530       1       0       1 -0.53583135 -0.435089280  1.24363847\n532       0       1       1  0.00000000 -0.518168555 -0.55421976\n533       0       1       1 -0.99926149 -0.518168555  0.64435239\n535       0       1       0  0.00483715 -0.490286770 -0.55421976\n536       1       0       0 -1.77164505 -0.148159593  0.64435239\n537       0       0       1  1.16341250 -0.142323735 -0.55421976\n538       0       0       0  0.00483715  1.411473465 -0.55421976\n541       0       0       0  0.46826729  0.722355896  0.64435239\n542       0       1       0 -1.61716834 -0.050408971  3.04149669\n543       0       1       0 -1.46269163 -0.050408971  3.04149669\n544       1       0       1  0.15931386 -0.153022808  0.04506631\n545       0       0       1  1.54960428  1.411473465  0.04506631\n546       0       0       1  2.63094127 -0.153022808 -0.55421976\n547       1       0       0 -0.84478477 -0.153022808  0.04506631\n548       1       0       1  0.00000000 -0.389131898 -0.55421976\n549       0       1       1  0.23655222 -0.259527217  0.64435239\n552       1       0       1 -0.22687792 -0.153022808 -0.55421976\n553       0       1       1  0.00000000 -0.506496838 -0.55421976\n555       0       1       0 -0.61306970 -0.507551184 -0.55421976\n556       0       0       1  2.47646456 -0.142323735 -0.55421976\n557       0       0       0  1.39512757  0.111536089  0.04506631\n558       0       0       1  0.00000000  3.767214822 -0.55421976\n559       0       0       0  0.69998236  0.890623136  0.64435239\n560       0       1       0  0.46826729 -0.320317405  0.04506631\n561       0       1       1  0.00000000 -0.508037505 -0.55421976\n563       1       0       1 -0.14963956 -0.396183559 -0.55421976\n564       0       1       1  0.00000000 -0.502201647 -0.55421976\n565       0       1       0  0.00000000 -0.502201647 -0.55421976\n567       0       1       1 -0.84478477 -0.505201278 -0.55421976\n568       0       1       0 -0.07240121 -0.248828144  1.84292454\n569       0       1       1  0.00000000 -0.518168555 -0.55421976\n570       0       1       1  0.15931386 -0.506010517 -0.55421976\n573       0       0       1  0.46826729 -0.145484825 -0.55421976\n575       0       1       1 -1.07649984 -0.502201647 -0.55421976\n576       0       1       1 -0.84478477 -0.376730699 -0.55421976\n577       1       0       0  0.31379058 -0.405909990 -0.55421976\n578       0       0       0  0.69998236  0.428617708  0.04506631\n579       0       1       0  0.00000000 -0.377541884  0.04506631\n580       0       1       1  0.15931386 -0.504633254 -0.55421976\n581       1       0       0 -0.38135463 -0.075211368  0.64435239\n584       0       0       1  0.46826729  0.121748840 -0.55421976\n585       0       1       1  0.00000000 -0.489314127 -0.55421976\n587       1       0       1  1.31788921 -0.367004269 -0.55421976\n588       0       0       1  2.32198785  0.881869349  0.64435239\n590       0       1       1  0.00000000 -0.502201647 -0.55421976\n591       0       1       1  0.39102893 -0.520195543 -0.55421976\n592       0       0       0  1.70408100  0.863713994  0.04506631\n593       0       1       1  1.31788921 -0.517763935 -0.55421976\n594       0       1       0  0.00000000 -0.508037505  0.64435239\n595       1       0       1  0.54550565 -0.153022808  0.04506631\n596       0       1       1  0.46826729 -0.189010600  0.64435239\n597       1       0       0  0.00000000 -0.016852788 -0.55421976\n598       0       1       1  1.47236593 -0.658797171 -0.55421976\n600       0       0       1  1.47236593  0.448638592  0.04506631\n601       1       0       0 -0.45859299 -0.133569948  1.24363847\n603       0       0       1  0.00000000  0.166004097 -0.55421976\n605       0       0       1  0.39102893 -0.142323735 -0.55421976\n606       0       1       1  0.46826729 -0.356305196  0.04506631\n608       0       0       1 -0.22687792 -0.065484938 -0.55421976\n609       1       0       0 -0.61306970  0.150037190  1.24363847\n610       0       0       0  0.77722072  2.326487371 -0.55421976\n611       0       1       0  0.69998236 -0.050408971  3.04149669\n612       0       1       1  0.00000000 -0.521654507 -0.55421976\n613       0       1       0  0.00000000 -0.357277839  0.04506631\n614       0       1       1  0.00000000 -0.508037505 -0.55421976\n615       0       1       1  0.39102893 -0.502201647 -0.55421976\n616       1       0       0 -0.45859299  0.605638735  1.24363847\n617       0       1       1  0.31379058 -0.378675985  0.64435239\n618       0       1       0 -0.30411628 -0.345606123  0.04506631\n619       1       0       0 -2.00336012  0.099864373  1.24363847\n621       0       1       1 -0.22687792 -0.377621640  0.04506631\n622       0       0       1  0.93169743  0.363532329  0.04506631\n623       0       1       1 -0.76754642 -0.352576083  0.64435239\n624       0       1       1 -0.69030806 -0.506010517 -0.55421976\n625       0       1       1 -0.69030806 -0.345606123 -0.55421976\n626       0       0       1  2.39922620 -0.030065170 -0.55421976\n627       1       0       1  2.09027278 -0.418554349 -0.55421976\n631       0       0       1  3.86675498 -0.075211368 -0.55421976\n633       0       0       1  0.15931386 -0.065484938 -0.55421976\n634       0       0       1  0.00000000 -0.658797171 -0.55421976\n635       0       1       0 -1.61716834 -0.116062374  2.44221062\n637       0       1       1  0.15931386 -0.504633254 -0.55421976\n638       1       0       1  0.08207551 -0.148159593  0.64435239\n639       0       1       0  0.85445907  0.113238214  2.44221062\n640       0       1       1  0.00000000 -0.345606123  0.04506631\n641       0       1       1 -0.76754642 -0.506010517 -0.55421976\n642       0       0       0 -0.45859299  0.689286034 -0.55421976\n644       0       1       1  0.00000000  0.440207722 -0.55421976\n645       0       1       0 -2.25438478 -0.284168155  1.24363847\n646       0       0       1  1.39512757  0.833805222  0.04506631\n647       0       1       1 -0.84478477 -0.505201278 -0.55421976\n648       0       0       1  2.01303442  0.031779363 -0.55421976\n649       0       1       1  0.00000000 -0.511928077 -0.55421976\n650       0       1       0 -0.53583135 -0.511928077 -0.55421976\n651       0       1       1  0.00000000 -0.505201278 -0.55421976\n654       0       1       0  0.00000000 -0.506496838 -0.55421976\n655       0       1       0 -0.92202313 -0.527490365 -0.55421976\n656       1       0       1 -0.45859299  0.770988046  0.64435239\n658       0       1       0  0.15931386 -0.357277839  0.64435239\n659       1       0       1 -0.53583135 -0.405909990 -0.55421976\n661       0       0       1  1.54960428  1.941077581  0.64435239\n662       0       1       1  0.77722072 -0.518250257 -0.55421976\n663       0       0       1  1.31788921 -0.161047113 -0.55421976\n667       1       0       1 -0.38135463 -0.405909990 -0.55421976\n668       0       1       1  0.00000000 -0.507551184 -0.55421976\n670       0       0       0  0.00000000  0.352751554  0.04506631\n671       1       0       0  0.77722072  0.099864373  0.64435239\n674       1       0       1  0.08207551 -0.405909990 -0.55421976\n677       0       1       1 -0.41997381 -0.502201647 -0.55421976\n678       0       1       0 -0.92202313 -0.467347958 -0.55421976\n679       0       1       0  1.00893579  0.253541968  3.64078277\n681       0       1       0  0.00000000 -0.500499522 -0.55421976\n682       0       0       1 -0.22687792  0.833805222 -0.55421976\n683       0       1       1 -0.76754642 -0.479344536 -0.55421976\n687       0       1       1 -1.23097656  0.113238214  2.44221062\n689       0       1       1 -0.92202313 -0.507146564 -0.55421976\n690       0       0       0 -1.15373820  3.452321649  0.04506631\n691       0       0       1  0.08207551  0.450015854  0.04506631\n692       0       1       0 -2.00336012 -0.397803983  0.04506631\n693       0       1       1  0.00000000  0.440207722 -0.55421976\n694       0       1       1 -0.38135463 -0.518250257 -0.55421976\n695       0       0       1  2.32198785 -0.142323735 -0.55421976\n699       0       0       1  1.47236593  1.498200151  0.64435239\n701       0       0       0 -0.92202313  3.767214822  0.04506631\n702       0       0       1  0.39102893 -0.147430111 -0.55421976\n703       0       1       0 -0.92202313 -0.377621640  0.04506631\n704       0       1       1 -0.38135463 -0.508198964 -0.55421976\n705       0       1       1 -0.30411628 -0.506010517  0.04506631\n708       0       0       1  0.93169743 -0.147430111 -0.55421976\n709       0       0       0 -0.61306970  2.289283776 -0.55421976\n710       0       1       1  0.00000000 -0.362222756  0.64435239\n712       0       0       1  0.00000000 -0.142323735 -0.55421976\n713       0       0       1  1.39512757  0.352751554  0.04506631\n714       0       1       1 -0.07240121 -0.474319863 -0.55421976\n716       0       1       1 -0.84478477 -0.509982791 -0.55421976\n717       0       0       0  0.62274400  3.767214822 -0.55421976\n718       1       0       0 -0.22687792 -0.454542140 -0.55421976\n719       0       1       1  0.00000000 -0.357277839 -0.55421976\n720       0       1       1  0.23655222 -0.507551184 -0.55421976\n721       1       0       0 -1.84888341 -0.016852788  0.04506631\n723       1       0       1  0.31379058 -0.405909990 -0.55421976\n725       0       0       1 -0.22687792  0.374149700  0.04506631\n726       0       1       1 -0.76754642 -0.490286770 -0.55421976\n728       0       1       0  0.00000000 -0.508280666 -0.55421976\n729       1       0       1 -0.38135463 -0.153022808  0.04506631\n730       0       1       0 -0.38135463 -0.504633254  0.04506631\n732       0       1       1 -1.46269163 -0.293326562 -0.55421976\n735       1       0       1 -0.53583135 -0.405909990 -0.55421976\n736       0       1       1 -0.11102039 -0.345606123 -0.55421976\n737       0       1       0  1.39512757  0.009894895  1.84292454\n738       0       0       1  0.39102893  9.307471078 -0.55421976\n739       0       1       1  0.00000000 -0.505201278 -0.55421976\n740       0       1       1  0.00000000 -0.505201278 -0.55421976\n742       0       0       1  0.46826729  0.875060848  0.04506631\n743       0       0       0 -0.69030806  4.445146996  1.84292454\n744       0       1       1 -0.45859299 -0.345606123  0.04506631\n745       0       1       1  0.08207551 -0.504633254 -0.55421976\n749       0       0       1 -0.84478477  0.374149700  0.04506631\n750       0       1       1  0.08207551 -0.508037505 -0.55421976\n752       0       1       1 -1.84888341 -0.416122741  0.04506631\n753       0       1       1  0.23655222 -0.473995000 -0.55421976\n754       0       1       1 -0.53583135 -0.505201278 -0.55421976\n755       1       0       0  1.39512757  0.605638735  1.24363847\n757       0       1       1 -0.14963956 -0.507146564 -0.55421976\n759       0       1       1  0.31379058 -0.502201647 -0.55421976\n760       0       0       0  0.23655222  1.023875227 -0.55421976\n762       0       1       1  0.85445907 -0.520195543 -0.55421976\n763       0       1       1 -0.76754642 -0.518168555 -0.55421976\n764       0       0       0  0.46826729  1.675546040  1.24363847\n766       0       0       0  1.62684264  0.857714732  0.04506631\n767       0       0       1  0.00000000  0.111536089 -0.55421976\n768       0       1       0  0.04345633 -0.508037505 -0.55421976\n769       0       1       1  0.00000000 -0.189010600  0.04506631\n770       0       1       1  0.15931386 -0.496122628 -0.55421976\n771       0       1       1 -0.45859299 -0.473995000 -0.55421976\n773       1       0       0  2.09027278 -0.454542140 -0.55421976\n774       0       1       1  0.00000000 -0.518250257 -0.55421976\n777       0       1       1  0.00000000 -0.508037505 -0.55421976\n778       0       1       0 -1.92612177 -0.416122741 -0.55421976\n780       0       0       0  1.00893579  3.452321649  0.04506631\n781       0       1       0 -1.30821491 -0.518168555 -0.55421976\n782       0       0       0 -0.99926149  0.450015854  0.04506631\n783       0       0       1 -0.07240121 -0.075211368 -0.55421976\n784       0       1       1  0.00000000 -0.202627602  1.24363847\n786       0       1       1 -0.38135463 -0.517763935 -0.55421976\n789       0       1       1 -2.23507519 -0.258554574  1.24363847\n790       0       0       1  1.24065086  0.881869349 -0.55421976\n791       0       1       1  0.00000000 -0.508037505 -0.55421976\n792       1       0       1 -1.07649984 -0.153022808 -0.55421976\n793       0       1       0  0.00000000  0.694149249  5.43864100\n794       0       0       1  0.00000000 -0.061676068 -0.55421976\n795       0       1       1 -0.38135463 -0.505201278 -0.55421976\n796       1       0       1  0.69998236 -0.405909990 -0.55421976\n797       0       0       0  1.47236593 -0.154400071 -0.55421976\n799       0       1       1  0.00483715 -0.518168555 -0.55421976\n800       0       1       0  0.00483715 -0.189010600  0.64435239\n801       1       0       1  0.31379058 -0.405909990 -0.55421976\n803       0       0       1 -1.46269163  1.675546040  1.24363847\n804       0       1       1 -2.27987344 -0.493122997  0.04506631\n806       0       1       1  0.08207551 -0.507551184 -0.55421976\n808       0       1       0 -0.92202313 -0.507551184 -0.55421976\n811       0       1       1 -0.30411628 -0.505362737 -0.55421976\n812       0       1       1  0.69998236 -0.189010600 -0.55421976\n813       1       0       1  0.39102893 -0.454542140 -0.55421976\n815       0       1       1  0.04345633 -0.502201647 -0.55421976\n816       0       0       1  0.00000000 -0.658797171 -0.55421976\n817       0       1       0 -0.53583135 -0.504633254 -0.55421976\n819       0       1       1  1.00893579 -0.533326223 -0.55421976\n822       0       1       1 -0.22687792 -0.490286770 -0.55421976\n823       0       0       1  0.62274400 -0.658797171 -0.55421976\n824       0       1       0 -0.22687792 -0.416122741  0.04506631\n825       0       1       1 -2.15783684  0.113238214  2.44221062\n826       0       1       1  0.00000000 -0.523599793 -0.55421976\n827       0       1       1  0.00000000  0.440207722 -0.55421976\n828       1       0       1 -2.23507519  0.061040355  0.64435239\n831       0       1       0 -1.15373820 -0.377621640  0.04506631\n832       1       0       1 -2.24820571 -0.294056044  0.64435239\n833       0       1       1  0.00000000 -0.518168555 -0.55421976\n835       0       1       1 -0.92202313 -0.497338432 -0.55421976\n836       0       0       0  0.69998236  0.958869605  0.64435239\n838       0       1       1  0.00000000 -0.502201647 -0.55421976\n840       0       0       1  0.00000000 -0.081047226 -0.55421976\n843       0       0       0  0.00483715 -0.055758508 -0.55421976\n845       0       1       1 -0.99926149 -0.490286770 -0.55421976\n846       0       1       1  0.93169743 -0.511928077 -0.55421976\n847       0       1       1  0.00000000  0.694149249  5.43864100\n849       1       0       1 -0.14963956 -0.016852788  0.04506631\n850       0       0       0  0.00000000  1.074534365  0.04506631\n851       0       1       1 -2.00336012 -0.050408971  3.04149669\n852       0       1       1  3.40332484 -0.507551184 -0.55421976\n853       0       1       0 -1.61716834 -0.362222756  0.64435239\n855       1       0       0  1.08617414 -0.153022808  0.04506631\n856       0       1       0 -0.92202313 -0.476912929  0.04506631\n857       0       0       0  1.16341250  2.548331678  0.64435239\n858       0       0       1  1.62684264 -0.142323735 -0.55421976\n859       0       1       0 -0.45859299 -0.284168155  1.24363847\n860       0       1       1  0.00000000 -0.518168555 -0.55421976\n861       0       1       1  0.85445907 -0.384350385  0.64435239\n862       1       0       1 -0.69030806 -0.435089280  0.04506631\n864       0       1       0  0.00000000  0.694149249  5.43864100\n865       1       0       1 -0.45859299 -0.405909990 -0.55421976\n867       1       0       0 -0.22687792 -0.389213600  0.04506631\n868       0       0       1  0.08207551  0.323490562 -0.55421976\n871       0       1       1 -0.30411628 -0.505201278 -0.55421976\n872       0       0       0  1.31788921  0.363532329  0.64435239\n874       0       1       1  1.31788921 -0.483721430 -0.55421976\n877       0       1       1 -0.76754642 -0.467268201 -0.55421976\n878       0       1       1 -0.84478477 -0.505201278 -0.55421976\n879       0       1       1  0.00000000 -0.505201278 -0.55421976\n880       0       0       0  2.01303442  0.958869605  0.04506631\n881       1       0       0 -0.38135463 -0.153022808  0.04506631\n882       0       1       1  0.23655222 -0.505201278 -0.55421976\n883       0       1       0 -0.61306970 -0.454217277 -0.55421976\n885       0       1       1 -0.38135463 -0.521654507 -0.55421976\n886       0       1       0  0.69998236 -0.092232621  2.44221062\n887       1       0       1 -0.22687792 -0.405909990 -0.55421976\n888       0       0       0 -0.84478477 -0.075211368 -0.55421976\n889       0       1       0  0.00000000 -0.202627602  1.24363847\n\ntest.x &lt;- model.matrix(Survived ~.,                                      # Survived는 Target으로 제외  \n                       titanic.ted.Imp)[,-1]                             # [,-1] : 절편 제거\n\ntest.x\n\n    Pclass2 Pclass3 Sexmale         Age         Fare     FamSize\n2         0       0       0  0.62274400  0.727866891  0.04506631\n7         0       0       1  1.85855771  0.350076786 -0.55421976\n13        0       1       1 -0.76754642 -0.502201647 -0.55421976\n16        1       0       0  1.93579607 -0.347551409 -0.55421976\n17        0       1       1 -2.15783684 -0.092232621  2.44221062\n22        1       0       1  0.31379058 -0.405909990 -0.55421976\n23        0       1       0 -1.15373820 -0.502606266 -0.55421976\n26        0       1       0  0.62274400 -0.048220525  3.04149669\n37        0       1       1  0.00000000 -0.518168555 -0.55421976\n44        1       0       0 -2.08059848  0.150037190  1.24363847\n46        0       1       1  0.00000000 -0.502201647 -0.55421976\n52        0       1       1 -0.69030806 -0.507064862 -0.55421976\n54        1       0       0 -0.07240121 -0.153022808  0.04506631\n57        1       0       0 -0.69030806 -0.454542140 -0.55421976\n58        0       1       1 -0.11102039 -0.518168555 -0.55421976\n59        1       0       0 -1.92612177 -0.118980303  1.24363847\n63        0       0       1  1.16341250  0.965030325  0.04506631\n66        0       1       1  0.00000000 -0.362222756  0.64435239\n67        1       0       0 -0.07240121 -0.454542140 -0.55421976\n68        0       1       1 -0.84478477 -0.500094902 -0.55421976\n69        0       1       0 -0.99926149 -0.504633254  3.04149669\n71        1       0       1  0.15931386 -0.454542140 -0.55421976\n73        1       0       1 -0.69030806  0.770988046 -0.55421976\n78        0       1       1  0.00000000 -0.502201647 -0.55421976\n81        0       1       1 -0.61306970 -0.483721430 -0.55421976\n87        0       1       1 -1.07649984  0.009894895  1.84292454\n90        0       1       1 -0.45859299 -0.502201647 -0.55421976\n98        0       0       1 -0.53583135  0.573702975  0.04506631\n99        1       0       0  0.31379058 -0.211381389  0.04506631\n100       1       0       1  0.31379058 -0.153022808  0.04506631\n101       0       1       0 -0.14963956 -0.505201278 -0.55421976\n102       0       1       1  0.00000000 -0.505201278 -0.55421976\n104       0       1       1  0.23655222 -0.490448229 -0.55421976\n106       0       1       1 -0.14963956 -0.505201278 -0.55421976\n109       0       1       1  0.62274400 -0.505201278 -0.55421976\n118       1       0       1 -0.07240121 -0.250287109  0.04506631\n120       0       1       0 -2.15783684 -0.050408971  3.04149669\n121       1       0       1 -0.69030806  0.770988046  0.64435239\n123       1       0       1  0.19793304 -0.073834105  0.04506631\n124       1       0       0  0.19793304 -0.405909990 -0.55421976\n127       0       1       1  0.00000000 -0.508037505 -0.55421976\n133       0       1       0  1.31788921 -0.376730699  0.04506631\n135       1       0       1 -0.38135463 -0.405909990 -0.55421976\n137       0       0       0 -0.84478477 -0.147511813  0.64435239\n139       0       1       1 -1.07649984 -0.479505995 -0.55421976\n140       0       0       1 -0.45859299  0.881869349 -0.55421976\n144       0       1       1 -0.84478477 -0.527490365 -0.55421976\n145       1       0       1 -0.92202313 -0.435089280 -0.55421976\n152       0       0       0 -0.61306970  0.636763311  0.04506631\n155       0       1       1  0.00000000 -0.516548131 -0.55421976\n159       0       1       1  0.00000000 -0.490286770 -0.55421976\n161       0       1       1  1.08617414 -0.345606123  0.04506631\n165       0       1       1 -2.23507519  0.113238214  2.44221062\n166       0       1       1 -1.61716834 -0.259527217  0.64435239\n168       0       1       0  1.16341250 -0.116062374  2.44221062\n170       0       1       1 -0.14963956  0.440207722 -0.55421976\n172       0       1       1 -2.00336012 -0.092232621  2.44221062\n175       0       0       1  2.01303442 -0.061676068 -0.55421976\n177       0       1       1  0.00000000 -0.163397019  1.84292454\n178       0       0       0  1.54960428 -0.100256925 -0.55421976\n183       0       1       1 -1.61716834 -0.048220525  3.04149669\n186       0       0       1  0.00000000  0.313845834 -0.55421976\n187       0       1       0  0.00000000 -0.357277839  0.04506631\n193       0       1       0 -0.84478477 -0.506010517  0.04506631\n195       0       0       0  1.08617414 -0.119548327 -0.55421976\n201       0       1       1 -0.14963956 -0.473995000 -0.55421976\n208       0       1       1 -0.30411628 -0.293326562 -0.55421976\n210       0       0       1  0.77722072 -0.055758508 -0.55421976\n215       0       1       1  0.00000000 -0.508037505  0.04506631\n221       0       1       1 -1.07649984 -0.502201647 -0.55421976\n222       1       0       1 -0.22687792 -0.405909990 -0.55421976\n225       0       0       1  0.62274400  1.091960238  0.04506631\n228       0       1       1 -0.72892724 -0.517763935 -0.55421976\n231       0       0       0  0.39102893  0.965030325  0.04506631\n234       0       1       0 -1.92612177 -0.048220525  3.04149669\n239       1       0       1 -0.84478477 -0.454542140 -0.55421976\n241       0       1       0  0.00000000 -0.377621640  0.04506631\n250       1       0       1  1.85855771 -0.153022808  0.04506631\n251       0       1       1  0.00000000 -0.517763935 -0.55421976\n256       0       1       0 -0.07240121 -0.362222756  0.64435239\n260       1       0       0  1.54960428 -0.153022808  0.04506631\n261       0       1       1  0.00000000 -0.508037505 -0.55421976\n263       0       0       1  1.70408100  0.890623136  0.64435239\n268       0       1       1 -0.38135463 -0.507551184  0.04506631\n271       0       0       1  0.00000000 -0.055758508 -0.55421976\n272       0       1       1 -0.38135463 -0.658797171 -0.55421976\n274       0       0       1  0.54550565 -0.081047226  0.04506631\n277       0       1       0  1.16341250 -0.508037505 -0.55421976\n279       0       1       1 -1.77164505 -0.092232621  2.44221062\n282       0       1       1 -0.14963956 -0.506010517 -0.55421976\n283       0       1       1 -1.07649984 -0.473995000 -0.55421976\n284       0       1       1 -0.84478477 -0.502201647 -0.55421976\n295       0       1       1 -0.45859299 -0.505201278 -0.55421976\n301       0       1       0  0.00000000 -0.508037505 -0.55421976\n308       0       0       0 -0.99926149  1.459619293  0.04506631\n310       0       0       0  0.00483715  0.448638592 -0.55421976\n312       0       0       0 -0.92202313  4.445146996  1.84292454\n313       1       0       0 -0.30411628 -0.153022808  0.64435239\n314       0       1       1 -0.14963956 -0.505201278 -0.55421976\n318       1       0       1  1.85855771 -0.386457129 -0.55421976\n321       0       1       1 -0.61306970 -0.517763935 -0.55421976\n326       0       0       0  0.46826729  1.979658438 -0.55421976\n328       1       0       0  0.46826729 -0.405909990 -0.55421976\n333       0       0       1  0.62274400  2.326487371  0.04506631\n334       0       1       1 -1.07649984 -0.308645689  0.64435239\n338       0       0       0  0.85445907  1.957612512 -0.55421976\n344       1       0       1 -0.38135463 -0.405909990 -0.55421976\n347       1       0       0  0.77722072 -0.405909990 -0.55421976\n351       0       1       1 -0.53583135 -0.479344536 -0.55421976\n358       1       0       0  0.62274400 -0.405909990 -0.55421976\n359       0       1       0  0.00000000 -0.505524195 -0.55421976\n364       0       1       1  0.39102893 -0.521654507 -0.55421976\n369       0       1       0  0.00000000 -0.508037505 -0.55421976\n375       0       1       0 -2.08059848 -0.248828144  1.84292454\n378       0       0       1 -0.22687792  3.455482739  0.64435239\n380       0       1       1 -0.84478477 -0.507551184 -0.55421976\n400       1       0       0 -0.14963956 -0.412718491 -0.55421976\n403       0       1       0 -0.69030806 -0.467672820  0.04506631\n409       0       1       1 -0.69030806 -0.507551184 -0.55421976\n412       0       1       1  0.00000000 -0.525383620 -0.55421976\n413       0       0       0  0.23655222  1.091960238  0.04506631\n415       0       1       1  1.08617414 -0.504633254 -0.55421976\n416       0       1       0  0.00000000 -0.502201647 -0.55421976\n418       1       0       0 -0.92202313 -0.405909990  0.64435239\n419       1       0       1  0.00483715 -0.405909990 -0.55421976\n420       0       1       0 -1.53992998 -0.189010600  0.64435239\n424       0       1       0 -0.14963956 -0.378675985  0.64435239\n427       1       0       0 -0.14963956 -0.153022808  0.04506631\n430       0       1       1  0.15931386 -0.502201647 -0.55421976\n436       0       0       0 -1.23097656  1.675546040  1.24363847\n440       1       0       1  0.08207551 -0.454542140 -0.55421976\n441       1       0       0  1.16341250 -0.148159593  0.64435239\n442       0       1       1 -0.76754642 -0.473995000 -0.55421976\n445       0       1       1  0.00000000 -0.500985843 -0.55421976\n447       1       0       0 -1.30821491 -0.279466399  0.04506631\n448       0       0       1  0.31379058 -0.142323735 -0.55421976\n450       0       0       1  1.70408100 -0.065484938 -0.55421976\n452       0       1       1  0.00000000 -0.270387749  0.04506631\n455       0       1       1  0.00000000 -0.502201647 -0.55421976\n457       0       0       1  2.70817963 -0.142323735 -0.55421976\n458       0       0       0  0.00000000  0.350076786  0.04506631\n462       0       1       1  0.31379058 -0.502201647 -0.55421976\n467       1       0       1  0.00000000 -0.658797171 -0.55421976\n469       0       1       1  0.00000000 -0.508523827 -0.55421976\n473       1       0       0  0.23655222 -0.118980303  1.24363847\n476       0       0       1  0.00000000  0.352751554 -0.55421976\n477       1       0       1  0.31379058 -0.250287109  0.04506631\n478       0       1       1 -0.07240121 -0.521736209  0.04506631\n482       1       0       1  0.00000000 -0.658797171 -0.55421976\n483       0       1       1  1.54960428 -0.502201647 -0.55421976\n488       0       0       1  2.16751113 -0.081047226 -0.55421976\n490       0       1       1 -1.61716834 -0.349496695  0.64435239\n492       0       1       1 -0.69030806 -0.517763935 -0.55421976\n495       0       1       1 -0.69030806 -0.502201647 -0.55421976\n496       0       1       1  0.00000000 -0.377541884 -0.55421976\n510       0       1       1 -0.30411628  0.440207722 -0.55421976\n515       0       1       1 -0.45859299 -0.512982422 -0.55421976\n520       0       1       1  0.15931386 -0.505201278 -0.55421976\n523       0       1       1  0.00000000 -0.518250257 -0.55421976\n525       0       1       1  0.00000000 -0.518168555 -0.55421976\n527       1       0       0  1.54960428 -0.454542140 -0.55421976\n529       0       1       1  0.69998236 -0.504633254 -0.55421976\n531       1       0       0 -2.15783684 -0.153022808  0.64435239\n534       0       1       0  0.00000000 -0.223864289  0.64435239\n539       0       1       1  0.00000000 -0.376730699 -0.55421976\n540       0       0       0 -0.61306970  0.304119404  0.64435239\n550       1       0       1 -1.69440670  0.056095438  0.64435239\n551       0       0       1 -0.99926149  1.498200151  0.64435239\n554       0       1       1 -0.61306970 -0.518250257 -0.55421976\n562       0       1       1  0.77722072 -0.505201278 -0.55421976\n566       0       1       1 -0.45859299 -0.189010600  0.64435239\n571       1       0       1  2.47646456 -0.454542140 -0.55421976\n572       0       0       0  1.78131935  0.342620505  0.64435239\n574       0       1       0  0.00000000 -0.508037505 -0.55421976\n582       0       0       0  0.69998236  1.498200151  0.64435239\n583       1       0       1  1.85855771 -0.153022808 -0.55421976\n586       0       0       0 -0.92202313  0.890623136  0.64435239\n589       0       1       1 -0.61306970 -0.502201647 -0.55421976\n599       0       1       1  0.00000000 -0.518250257 -0.55421976\n602       0       1       1  0.00000000 -0.505201278 -0.55421976\n604       0       1       1  1.08617414 -0.502201647 -0.55421976\n607       0       1       1  0.00483715 -0.505201278 -0.55421976\n620       1       0       1 -0.30411628 -0.454542140 -0.55421976\n628       0       0       0 -0.69030806  0.857714732 -0.55421976\n629       0       1       1 -0.30411628 -0.505201278 -0.55421976\n630       0       1       1  0.00000000 -0.508362368 -0.55421976\n632       0       1       1  1.62684264 -0.521572805 -0.55421976\n636       1       0       0 -0.14963956 -0.405909990 -0.55421976\n643       0       1       0 -2.15783684 -0.116062374  2.44221062\n652       1       0       0 -0.92202313 -0.211381389  0.04506631\n653       0       1       1 -0.69030806 -0.494745366 -0.55421976\n657       0       1       1  0.00000000 -0.505201278 -0.55421976\n660       0       0       1  2.16751113  1.544725556  0.64435239\n664       0       1       1  0.46826729 -0.512982422 -0.55421976\n665       0       1       1 -0.76754642 -0.504633254  0.04506631\n666       1       0       1  0.15931386  0.770988046  0.64435239\n669       0       1       1  1.00893579 -0.502201647 -0.55421976\n672       0       0       1  0.08207551  0.352751554  0.04506631\n673       1       0       1  3.09437141 -0.454542140 -0.55421976\n675       1       0       1  0.00000000 -0.658797171 -0.55421976\n676       0       1       1 -0.92202313 -0.507551184 -0.55421976\n680       0       0       1  0.46826729  9.307471078  0.04506631\n684       0       1       1 -1.23097656  0.253541968  3.64078277\n685       1       0       1  2.32198785  0.099864373  0.64435239\n686       1       0       1 -0.38135463  0.150037190  1.24363847\n688       0       1       1 -0.84478477 -0.460946021 -0.55421976\n696       1       0       1  1.70408100 -0.396183559 -0.55421976\n697       0       1       1  1.08617414 -0.502201647 -0.55421976\n698       0       1       0  0.00000000 -0.508362368 -0.55421976\n700       0       1       1  0.93169743 -0.509982791 -0.55421976\n706       1       0       1  0.69998236 -0.153022808 -0.55421976\n707       1       0       0  1.16341250 -0.396183559 -0.55421976\n711       0       0       0 -0.45859299  0.304201106 -0.55421976\n715       1       0       1  1.70408100 -0.405909990 -0.55421976\n722       0       1       1 -0.99926149 -0.521572805  0.04506631\n724       1       0       1  1.54960428 -0.405909990 -0.55421976\n727       1       0       0  0.00483715 -0.250287109  1.24363847\n731       0       0       0 -0.07240121  3.452321649 -0.55421976\n733       1       0       1  0.00000000 -0.658797171 -0.55421976\n734       1       0       1 -0.53583135 -0.405909990 -0.55421976\n741       0       0       1  0.00000000 -0.075211368 -0.55421976\n746       0       0       1  3.09437141  0.722355896  0.64435239\n747       0       1       1 -1.07649984 -0.264876754  0.64435239\n748       1       0       0  0.00483715 -0.405909990 -0.55421976\n751       1       0       0 -2.00336012 -0.211381389  0.64435239\n756       1       0       1 -2.26056385 -0.376730699  0.64435239\n758       1       0       1 -0.92202313 -0.435089280 -0.55421976\n761       0       1       1  0.00000000 -0.376730699 -0.55421976\n765       0       1       1 -1.07649984 -0.507551184 -0.55421976\n772       0       1       1  1.39512757 -0.506010517 -0.55421976\n775       1       0       0  1.85855771 -0.211381389  1.84292454\n776       0       1       1 -0.92202313 -0.508037505 -0.55421976\n779       0       1       1  0.00000000 -0.508280666 -0.55421976\n785       0       1       1 -0.38135463 -0.521654507 -0.55421976\n787       0       1       0 -0.92202313 -0.512982422 -0.55421976\n788       0       1       1 -1.69440670 -0.092232621  2.44221062\n798       0       1       0  0.08207551 -0.489882151 -0.55421976\n802       1       0       0  0.08207551 -0.148159593  0.64435239\n805       0       1       1 -0.22687792 -0.523113472 -0.55421976\n807       0       0       1  0.69998236 -0.658797171 -0.55421976\n809       1       0       1  0.69998236 -0.405909990 -0.55421976\n810       0       0       0  0.23655222  0.374149700  0.04506631\n814       0       1       0 -1.84888341 -0.050408971  3.04149669\n818       1       0       1  0.08207551  0.061040355  0.64435239\n820       0       1       1 -1.53992998 -0.116062374  2.44221062\n821       0       0       0  1.70408100  1.160045248  0.64435239\n829       0       1       1  0.00000000 -0.508037505 -0.55421976\n830       0       0       0  2.47646456  0.897431637 -0.55421976\n834       0       1       1 -0.53583135 -0.506010517 -0.55421976\n837       0       1       1 -0.69030806 -0.490286770 -0.55421976\n839       0       1       1  0.15931386  0.440207722 -0.55421976\n841       0       1       1 -0.76754642 -0.504633254 -0.55421976\n842       1       0       1 -1.07649984 -0.454542140 -0.55421976\n844       0       1       1  0.35240975 -0.533569384 -0.55421976\n848       0       1       1  0.39102893 -0.505201278 -0.55421976\n854       0       0       0 -1.07649984  0.107645517  0.04506631\n863       0       0       0  1.39512757 -0.154400071 -0.55421976\n866       1       0       0  0.93169743 -0.405909990 -0.55421976\n869       0       1       1  0.00000000 -0.473995000 -0.55421976\n870       0       1       1 -2.00336012 -0.442222643  0.64435239\n873       0       0       1  0.23655222 -0.561532870 -0.55421976\n875       1       0       0 -0.14963956 -0.191928529  0.04506631\n876       0       1       0 -1.15373820 -0.518250257 -0.55421976\n884       1       0       1 -0.14963956 -0.454542140 -0.55421976\n890       0       0       1 -0.30411628 -0.075211368 -0.55421976\n891       0       1       1  0.15931386 -0.508037505 -0.55421976",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Elastic Net Regression</span>"
    ]
  },
  {
    "objectID": "Elasticnet.html#모형-훈련",
    "href": "Elasticnet.html#모형-훈련",
    "title": "12  Elastic Net Regression",
    "section": "12.6 모형 훈련",
    "text": "12.6 모형 훈련\nPackage \"glmnet\"에서 제공하는 함수 glmnet()을 이용하여 Elastic Net Regression을 수행할 수 있다. 함수 glmnet()는 Target이 2개의 클래스를 가질 때 “두 번째 클래스”에 속할 확률을 모델링하며, “두 번째 클래스”란 “Factor” 변환하였을 때 두 번째 수준(Level)을 의미한다. 예를 들어, “a”와 “b” 2개의 클래스를 가진 Target을 “Factor” 변환하였을 때 수준이 “a” “b”라면, 첫 번째 클래스는 “a”, 두 번째 클래스는 “b”가 된다. 함수 glmnet()에 대한 자세한 옵션은 여기를 참고한다.\n\nglmnet(x, y, family, alpha, lambda, ...)\n\n\nx : 예측 변수를 포함하는 행렬\ny : Target을 포함하는 변수\nfamily : Target의 분포\n\n\"gaussian\" : 수치형인 Target\n\"binomial\" : 2개의 클래스를 가지는 Target\n\"multinomial\" : 3개 이상 클래스를 가지는 Target\n\"poisson\" : Count Data인 Target\n\nalpha : Elasticnet Mixing Parameter\n\n0 : Ridge Regression\n1 : Lasso Regression\n0 &lt; alpha &lt; 1 : Elastic Net Regression\n\nlambda : Regularization Parameter\n\n직접 값을 지정하면 해당 값에 대한 결과만 보여준다.\n값을 지정하지 않으면 100개의 lambda 값에 대한 결과를 보여준다.\n\n\n\n12.6.1 람다 값 직접 지정\n\nelast.fit &lt;- glmnet(x = train.x,                 # 예측 변수를 포함하는 행렬\n                    y = titanic.trd.Imp$Survived,# Target\n                    family = \"binomial\",         # Binary Classification\n                    alpha = 0.5,                 # 0 : Ridge / 1 : Lasso / 0 &lt; alpha &lt; 1 : Elastic Net\n                    lambda = 0.1)\n\nround(coef(elast.fit), 3)                        # 회귀계수 추정치\n\n7 x 1 sparse Matrix of class \"dgCMatrix\"\n                s0\n(Intercept)  0.781\nPclass2      .    \nPclass3     -0.715\nSexmale     -1.439\nAge          .    \nFare         0.065\nFamSize      .    \n\n\nResult! 데이터 “titanic.trd.Imp”의 Target “Survived”은 “no”와 “yes” 2개의 클래스를 가지며, “Factor” 변환하면 알파벳순으로 수준을 부여하기 때문에 “yes”가 두 번째 클래스가 된다. 즉, “yes”에 속할 확률(= 탑승객이 생존할 확률)을 \\(p\\)라고 할 때, 추정된 회귀계수를 이용하여 다음과 같은 모형식을 얻을 수 있다. \\[\n\\begin{align*}\n\\log{\\frac{p}{1-p}} = &\\;0.781 -0.715 X_{\\text{Pclass3}} -1.439 X_{\\text{Sexmale}} + 0.065 Z_{\\text{Fare}}\n\\end{align*}\n\\] 여기서, \\(Z_{\\text{예측 변수}}\\)는 표준화한 예측 변수, \\(X_{\\text{예측 변수}}\\)는 더미 변수를 의미한다.\n\n\n12.6.2 교차 검증을 통한 최적의 람다 값\n\n# 100개의 람다 값에 따른 결과\nelast.fit &lt;- glmnet(x = train.x,                 # 예측 변수를 포함하는 행렬\n                    y = titanic.trd.Imp$Survived,# Target\n                    family = \"binomial\",         # Binary Classification\n                    alpha = 0.5)                 # 0 : Ridge / 1 : Lasso / 0 &lt; alpha &lt; 1 : Elastic Net\n\nplot(elast.fit, xvar = \"lambda\")                 # 람다 값에 따른 회귀계수 추정치 확인\n\n\n\n\n\n\n\n\nResult! 100개의 \\(\\lambda\\) 값에 대한 회귀계수 추정치의 변화를 보여준다. 해당 그림을 통해 \\(\\lambda\\) 값이 클수록 회귀계수 추정치는 작아진다는 것을 알 수 있다.\n\nelast.fit$lambda                                 # 100개의 람다 값\n\n [1] 0.5015509422 0.4569945389 0.4163964036 0.3794048947 0.3456996095 0.3149886090 0.2870058891 0.2615090770 0.2382773313 0.2171094299 0.1978220265 0.1802480629 0.1642353218 0.1496451085 0.1363510495\n[16] 0.1242379980 0.1132010367 0.1031445686 0.0939814894 0.0856324329 0.0780250836 0.0710935502 0.0647777951 0.0590231144 0.0537796636 0.0490020265 0.0446488215 0.0406823432 0.0370682360 0.0337751961\n[31] 0.0307747007 0.0280407611 0.0255496972 0.0232799325 0.0212118075 0.0193274090 0.0176104152 0.0160459545 0.0146204761 0.0133216333 0.0121381761 0.0110598540 0.0100773271 0.0091820851 0.0083663740\n[46] 0.0076231284 0.0069459106 0.0063288551 0.0057666170 0.0052543267 0.0047875468 0.0043622343 0.0039747054 0.0036216036 0.0032998703 0.0030067189 0.0027396103 0.0024962309 0.0022744726 0.0020724147\n[61] 0.0018883071 0.0017205551 0.0015677057 0.0014284351 0.0013015368 0.0011859119 0.0010805587 0.0009845649 0.0008970989\n\n\nCaution! \\(\\lambda\\)는 모형이 Training Dataset에 과적합 되는 것을 방지하기 위해 사용하는 모수이며, 교차 검증(Cross Validation)을 통해 최적의 값을 찾을 수 있다. 이러한 방법은 package \"glmnet\"에서 제공하는 함수 cv.glmnet()을 통해 수행할 수 있으며, 함수에 대한 자세한 옵션은 여기를 참고한다.\n\n# 교차검증을 통한 최적의 람다 값\nset.seed(200)                                          # Seed 고정 -&gt; 동일한 결과를 출력하기 위해\ncv.elast.fit &lt;- cv.glmnet(x = train.x,                 # 예측 변수를 포함하는 행렬\n                          y = titanic.trd.Imp$Survived,# Target\n                          family = \"binomial\",         # Binary Classification\n                          alpha = 0.5,                 # 0 : Ridge / 1 : Lasso / 0 &lt; alpha &lt; 1 : Elastic Net\n                          nfolds = 5,                  # 5-Fold Cross Validation\n                          type.measure = \"auc\")        # AUC에 기반하여 최적의 람다 값 찾기\n\nplot(cv.elast.fit)                                     # Plot\n\n\n\n\n\n\n\n\nResult! 100개의 \\(\\lambda\\) 값에 대한 AUC의 변화를 보여준다.\nCaution! 만약 \\(\\lambda\\) 값에 대해 직접 후보 값을 지정하고 싶으면 함수 cv.glmnet()의 옵션 lambda = 후보 값을 이용하면 된다.\n\ncv.elast.fit$lambda.min                                   # 최적의 람다 값\n\n[1] 0.0008970989\n\nmax(cv.elast.fit$cvm)                                     # 최적의 람다 값에 대한 AUC\n\n[1] 0.8502147\n\nround(coef(cv.elast.fit, s = cv.elast.fit$lambda.min), 3) # 최적의 람다 값에 대한 회귀계수 추정치\n\n7 x 1 sparse Matrix of class \"dgCMatrix\"\n                s1\n(Intercept)  2.521\nPclass2     -1.007\nPclass3     -2.320\nSexmale     -2.690\nAge         -0.515\nFare         0.127\nFamSize     -0.388\n\n\nResult! 최적의 \\(\\lambda\\) 값에 대해 추정된 회귀계수를 이용하여 다음과 같은 모형식을 얻을 수 있다. \\[\n\\begin{align*}\n\\log{\\frac{p}{1-p}} = &\\;2.521 - 1.007 X_{\\text{Pclass2}} - 2.320 X_{\\text{Pclass3}} -2.690 X_{\\text{Sexmale}} \\\\\n                      &-0.515 Z_{\\text{Age}} +0.127 Z_{\\text{Fare}} - 0.388 Z_{\\text{FamSize}}\n\\end{align*}\n\\]",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Elastic Net Regression</span>"
    ]
  },
  {
    "objectID": "Elasticnet.html#모형-평가",
    "href": "Elasticnet.html#모형-평가",
    "title": "12  Elastic Net Regression",
    "section": "12.7 모형 평가",
    "text": "12.7 모형 평가\nCaution! 모형 평가를 위해 Test Dataset에 대한 예측 class/확률 이 필요하며, 함수 predict()를 이용하여 생성한다.\n\n# 예측 class 생성\ntest.elast.class &lt;- predict(cv.elast.fit, \n                            newx = test.x,             # Test Dataset including Only 예측 변수 \n                            s = \"lambda.min\",          # 최적의 람다 값 기반\n                            type = \"class\")            # 예측 class 생성\n\ntest.elast.class %&gt;%                                      \n  as_tibble\n\n# A tibble: 266 × 1\n   lambda.min\n   &lt;chr&gt;     \n 1 yes       \n 2 no        \n 3 no        \n 4 yes       \n 5 no        \n 6 no        \n 7 yes       \n 8 no        \n 9 no        \n10 yes       \n# ℹ 256 more rows\n\n\n\n\n12.7.1 ConfusionMatrix\n\nCM   &lt;- caret::confusionMatrix(as.factor(test.elast.class), titanic.ted.Imp$Survived, \n                               positive = \"yes\")       # confusionMatrix(예측 class, 실제 class, positive = \"관심 class\")\nCM\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  no yes\n       no  148  32\n       yes  16  70\n                                         \n               Accuracy : 0.8195         \n                 95% CI : (0.768, 0.8638)\n    No Information Rate : 0.6165         \n    P-Value [Acc &gt; NIR] : 5.675e-13      \n                                         \n                  Kappa : 0.6067         \n                                         \n Mcnemar's Test P-Value : 0.03038        \n                                         \n            Sensitivity : 0.6863         \n            Specificity : 0.9024         \n         Pos Pred Value : 0.8140         \n         Neg Pred Value : 0.8222         \n             Prevalence : 0.3835         \n         Detection Rate : 0.2632         \n   Detection Prevalence : 0.3233         \n      Balanced Accuracy : 0.7944         \n                                         \n       'Positive' Class : yes            \n                                         \n\n\n\n\n\n12.7.2 ROC 곡선\n\n# 예측 확률 생성\ntest.elast.prob &lt;- predict(cv.elast.fit, \n                           newx = test.x,              # Test Dataset including Only 예측 변수 \n                           s = \"lambda.min\",           # 최적의 람다 값 기반\n                           type = \"response\")          # 예측 확률 생성\n\ntest.elast.prob %&gt;%                                    # \"Survived = yes\"에 대한 예측 확률                           \n  as_tibble\n\n# A tibble: 266 × 1\n   lambda.min\n        &lt;dbl&gt;\n 1     0.907 \n 2     0.296 \n 3     0.125 \n 4     0.665 \n 5     0.0882\n 6     0.236 \n 7     0.720 \n 8     0.213 \n 9     0.0878\n10     0.893 \n# ℹ 256 more rows\n\n\n\nac  &lt;- titanic.ted.Imp$Survived                        # Test Dataset의 실제 class \npp  &lt;- as.numeric(test.elast.prob)                     # 예측 확률을 수치형으로 변환\n\n\n12.7.2.1 Package “pROC”\n\npacman::p_load(\"pROC\")\n\nelast.roc  &lt;- roc(ac, pp, plot = T, col = \"gray\")      # roc(실제 class, 예측 확률)\nauc        &lt;- round(auc(elast.roc), 3)\nlegend(\"bottomright\", legend = auc, bty = \"n\")\n\n\n\n\n\n\n\n\nCaution! Package \"pROC\"를 통해 출력한 ROC 곡선은 다양한 함수를 이용해서 그래프를 수정할 수 있다.\n\n# 함수 plot.roc() 이용\nplot.roc(elast.roc,   \n         col=\"gray\",                                   # Line Color\n         print.auc = TRUE,                             # AUC 출력 여부\n         print.auc.col = \"red\",                        # AUC 글씨 색깔\n         print.thres = TRUE,                           # Cutoff Value 출력 여부\n         print.thres.pch = 19,                         # Cutoff Value를 표시하는 도형 모양\n         print.thres.col = \"red\",                      # Cutoff Value를 표시하는 도형의 색깔\n         auc.polygon = TRUE,                           # 곡선 아래 면적에 대한 여부\n         auc.polygon.col = \"gray90\")                   # 곡선 아래 면적의 색깔\n\n\n\n\n\n\n\n\n\n# 함수 ggroc() 이용\nggroc(elast.roc) +\nannotate(geom = \"text\", x = 0.9, y = 1.0,\nlabel = paste(\"AUC = \", auc),\nsize = 5,\ncolor=\"red\") +\ntheme_bw()\n\n\n\n\n\n\n\n\n\n\n12.7.2.2 Package “Epi”\n\npacman::p_load(\"Epi\")       \n# install_version(\"etm\", version = \"1.1\", repos = \"http://cran.us.r-project.org\")\n\nROC(pp, ac, plot = \"ROC\")                              # ROC(예측 확률, 실제 class)  \n\n\n\n\n\n\n\n\n\n\n12.7.2.3 Package “ROCR”\n\npacman::p_load(\"ROCR\")\n\nelast.pred &lt;- prediction(pp, ac)                       # prediction(예측 확률, 실제 class) \n\nelast.perf &lt;- performance(elast.pred, \"tpr\", \"fpr\")    # performance(, \"민감도\", \"1-특이도\")                      \nplot(elast.perf, col = \"gray\")                         # ROC Curve\n\nperf.auc   &lt;- performance(elast.pred, \"auc\")           # AUC\nauc        &lt;- attributes(perf.auc)$y.values\nlegend(\"bottomright\", legend = auc, bty = \"n\")\n\n\n\n\n\n\n\n\n\n\n\n\n12.7.3 향상 차트\n\n12.7.3.1 Package “ROCR”\n\nelast.perf &lt;- performance(elast.pred, \"lift\", \"rpp\")   # Lift Chart                      \nplot(elast.perf, main = \"lift curve\",\n     colorize = T,                                     # Coloring according to cutoff \n     lwd = 2)",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Elastic Net Regression</span>"
    ]
  },
  {
    "objectID": "RF.html",
    "href": "RF.html",
    "title": "13  Random Forest",
    "section": "",
    "text": "13.1 데이터 불러오기\npacman::p_load(\"data.table\", \n               \"tidyverse\", \n               \"dplyr\", \"tidyr\",\n               \"ggplot2\", \"GGally\",\n               \"caret\",\n               \"randomForest\")                                          # For randomForest\n\ntitanic &lt;- fread(\"../Titanic.csv\")                                      # 데이터 불러오기\n\ntitanic %&gt;%\n  as_tibble\n# A tibble: 891 × 11\n   Survived Pclass Name                                                Sex      Age SibSp Parch Ticket            Fare Cabin  Embarked\n      &lt;int&gt;  &lt;int&gt; &lt;chr&gt;                                               &lt;chr&gt;  &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;   \n 1        0      3 Braund, Mr. Owen Harris                             male      22     1     0 A/5 21171         7.25 \"\"     S       \n 2        1      1 Cumings, Mrs. John Bradley (Florence Briggs Thayer) female    38     1     0 PC 17599         71.3  \"C85\"  C       \n 3        1      3 Heikkinen, Miss. Laina                              female    26     0     0 STON/O2. 3101282  7.92 \"\"     S       \n 4        1      1 Futrelle, Mrs. Jacques Heath (Lily May Peel)        female    35     1     0 113803           53.1  \"C123\" S       \n 5        0      3 Allen, Mr. William Henry                            male      35     0     0 373450            8.05 \"\"     S       \n 6        0      3 Moran, Mr. James                                    male      NA     0     0 330877            8.46 \"\"     Q       \n 7        0      1 McCarthy, Mr. Timothy J                             male      54     0     0 17463            51.9  \"E46\"  S       \n 8        0      3 Palsson, Master. Gosta Leonard                      male       2     3     1 349909           21.1  \"\"     S       \n 9        1      3 Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)   female    27     0     2 347742           11.1  \"\"     S       \n10        1      2 Nasser, Mrs. Nicholas (Adele Achem)                 female    14     1     0 237736           30.1  \"\"     C       \n# ℹ 881 more rows",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Random Forest</span>"
    ]
  },
  {
    "objectID": "RF.html#데이터-전처리-i",
    "href": "RF.html#데이터-전처리-i",
    "title": "13  Random Forest",
    "section": "13.2 데이터 전처리 I",
    "text": "13.2 데이터 전처리 I\n\ntitanic %&lt;&gt;%\n  data.frame() %&gt;%                                                      # Data Frame 형태로 변환 \n  mutate(Survived = ifelse(Survived == 1, \"yes\", \"no\"))                 # Target을 문자형 변수로 변환\n\n# 1. Convert to Factor\nfac.col &lt;- c(\"Pclass\", \"Sex\",\n             # Target\n             \"Survived\")\n\ntitanic &lt;- titanic %&gt;% \n  mutate_at(fac.col, as.factor)                                         # 범주형으로 변환\n\nglimpse(titanic)                                                        # 데이터 구조 확인\n\nRows: 891\nColumns: 11\n$ Survived &lt;fct&gt; no, yes, yes, yes, no, no, no, no, yes, yes, yes, yes, no, no, no, yes, no, yes, no, yes, no, yes, yes, yes, no, yes, no, no, yes, no, no, yes, yes, no, no, no, yes, no, no, yes, no…\n$ Pclass   &lt;fct&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3, 2, 2, 3, 1, 3, 3, 3, 1, 3, 3, 1, 1, 3, 2, 1, 1, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 1, 1, 2, 3, 2, 3, 3…\n$ Name     &lt;chr&gt; \"Braund, Mr. Owen Harris\", \"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\", \"Heikkinen, Miss. Laina\", \"Futrelle, Mrs. Jacques Heath (Lily May Peel)\", \"Allen, Mr. William Henry…\n$ Sex      &lt;fct&gt; male, female, female, female, male, male, male, male, female, female, female, female, male, male, female, female, male, male, female, female, male, male, female, male, female, femal…\n$ Age      &lt;dbl&gt; 22.0, 38.0, 26.0, 35.0, 35.0, NA, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, NA, 31.0, NA, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, NA, 19.0, NA, NA, 40.0, NA, NA, 66.…\n$ SibSp    &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0, 0, 0, 0, 0, 3, 1, 0, 3, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 1, 0, 0, 1, 0, 2, 1, 4, 0, 1, 1, 0, 0, 0, 0, 1, 5, 0…\n$ Parch    &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 5, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 2, 2, 0…\n$ Ticket   &lt;chr&gt; \"A/5 21171\", \"PC 17599\", \"STON/O2. 3101282\", \"113803\", \"373450\", \"330877\", \"17463\", \"349909\", \"347742\", \"237736\", \"PP 9549\", \"113783\", \"A/5. 2151\", \"347082\", \"350406\", \"248706\", \"38…\n$ Fare     &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625, 21.0750, 11.1333, 30.0708, 16.7000, 26.5500, 8.0500, 31.2750, 7.8542, 16.0000, 29.1250, 13.0000, 18.0000, 7.2250, 26.0000,…\n$ Cabin    &lt;chr&gt; \"\", \"C85\", \"\", \"C123\", \"\", \"\", \"E46\", \"\", \"\", \"\", \"G6\", \"C103\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"D56\", \"\", \"A6\", \"\", \"\", \"\", \"C23 C25 C27\", \"\", \"\", \"\", \"B78\", \"\", \"\", \"\", \"\", \"\"…\n$ Embarked &lt;chr&gt; \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"C\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"Q\", \"S\", \"C\", \"C\", \"Q\", \"S\", \"C\", \"S\", \"…\n\n# 2. Generate New Variable\ntitanic &lt;- titanic %&gt;%\n  mutate(FamSize = SibSp + Parch)                                       # \"FamSize = 형제 및 배우자 수 + 부모님 및 자녀 수\"로 가족 수를 의미하는 새로운 변수\n\nglimpse(titanic)                                                        # 데이터 구조 확인\n\nRows: 891\nColumns: 12\n$ Survived &lt;fct&gt; no, yes, yes, yes, no, no, no, no, yes, yes, yes, yes, no, no, no, yes, no, yes, no, yes, no, yes, yes, yes, no, yes, no, no, yes, no, no, yes, yes, no, no, no, yes, no, no, yes, no…\n$ Pclass   &lt;fct&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3, 2, 2, 3, 1, 3, 3, 3, 1, 3, 3, 1, 1, 3, 2, 1, 1, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 1, 1, 2, 3, 2, 3, 3…\n$ Name     &lt;chr&gt; \"Braund, Mr. Owen Harris\", \"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\", \"Heikkinen, Miss. Laina\", \"Futrelle, Mrs. Jacques Heath (Lily May Peel)\", \"Allen, Mr. William Henry…\n$ Sex      &lt;fct&gt; male, female, female, female, male, male, male, male, female, female, female, female, male, male, female, female, male, male, female, female, male, male, female, male, female, femal…\n$ Age      &lt;dbl&gt; 22.0, 38.0, 26.0, 35.0, 35.0, NA, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, NA, 31.0, NA, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, NA, 19.0, NA, NA, 40.0, NA, NA, 66.…\n$ SibSp    &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0, 0, 0, 0, 0, 3, 1, 0, 3, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 1, 0, 0, 1, 0, 2, 1, 4, 0, 1, 1, 0, 0, 0, 0, 1, 5, 0…\n$ Parch    &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 5, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 2, 2, 0…\n$ Ticket   &lt;chr&gt; \"A/5 21171\", \"PC 17599\", \"STON/O2. 3101282\", \"113803\", \"373450\", \"330877\", \"17463\", \"349909\", \"347742\", \"237736\", \"PP 9549\", \"113783\", \"A/5. 2151\", \"347082\", \"350406\", \"248706\", \"38…\n$ Fare     &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625, 21.0750, 11.1333, 30.0708, 16.7000, 26.5500, 8.0500, 31.2750, 7.8542, 16.0000, 29.1250, 13.0000, 18.0000, 7.2250, 26.0000,…\n$ Cabin    &lt;chr&gt; \"\", \"C85\", \"\", \"C123\", \"\", \"\", \"E46\", \"\", \"\", \"\", \"G6\", \"C103\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"D56\", \"\", \"A6\", \"\", \"\", \"\", \"C23 C25 C27\", \"\", \"\", \"\", \"B78\", \"\", \"\", \"\", \"\", \"\"…\n$ Embarked &lt;chr&gt; \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"C\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"Q\", \"S\", \"C\", \"C\", \"Q\", \"S\", \"C\", \"S\", \"…\n$ FamSize  &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 4, 2, 1, 2, 0, 0, 6, 0, 0, 5, 0, 1, 0, 0, 0, 0, 0, 4, 6, 0, 5, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 3, 0, 0, 1, 0, 2, 1, 5, 0, 1, 1, 1, 0, 0, 0, 3, 7, 0…\n\n# 3. Select Variables used for Analysis\ntitanic1 &lt;- titanic %&gt;% \n  select(Survived, Pclass, Sex, Age, Fare, FamSize)                     # 분석에 사용할 변수 선택\n\nglimpse(titanic1)                                                       # 데이터 구조 확인\n\nRows: 891\nColumns: 6\n$ Survived &lt;fct&gt; no, yes, yes, yes, no, no, no, no, yes, yes, yes, yes, no, no, no, yes, no, yes, no, yes, no, yes, yes, yes, no, yes, no, no, yes, no, no, yes, yes, no, no, no, yes, no, no, yes, no…\n$ Pclass   &lt;fct&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3, 2, 2, 3, 1, 3, 3, 3, 1, 3, 3, 1, 1, 3, 2, 1, 1, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 1, 1, 2, 3, 2, 3, 3…\n$ Sex      &lt;fct&gt; male, female, female, female, male, male, male, male, female, female, female, female, male, male, female, female, male, male, female, female, male, male, female, male, female, femal…\n$ Age      &lt;dbl&gt; 22.0, 38.0, 26.0, 35.0, 35.0, NA, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, NA, 31.0, NA, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, NA, 19.0, NA, NA, 40.0, NA, NA, 66.…\n$ Fare     &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625, 21.0750, 11.1333, 30.0708, 16.7000, 26.5500, 8.0500, 31.2750, 7.8542, 16.0000, 29.1250, 13.0000, 18.0000, 7.2250, 26.0000,…\n$ FamSize  &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 4, 2, 1, 2, 0, 0, 6, 0, 0, 5, 0, 1, 0, 0, 0, 0, 0, 4, 6, 0, 5, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 3, 0, 0, 1, 0, 2, 1, 5, 0, 1, 1, 1, 0, 0, 0, 3, 7, 0…",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Random Forest</span>"
    ]
  },
  {
    "objectID": "RF.html#데이터-탐색",
    "href": "RF.html#데이터-탐색",
    "title": "13  Random Forest",
    "section": "13.3 데이터 탐색",
    "text": "13.3 데이터 탐색\n\nggpairs(titanic1,                                        \n        aes(colour = Survived)) +                         # Target의 범주에 따라 색깔을 다르게 표현\n  theme_bw()\n\n\n\n\n\n\n\nggpairs(titanic1,                                     \n        aes(colour = Survived, alpha = 0.8)) +            # Target의 범주에 따라 색깔을 다르게 표현\n  scale_colour_manual(values = c(\"#00798c\", \"#d1495b\")) + # 특정 색깔 지정\n  scale_fill_manual(values = c(\"#00798c\", \"#d1495b\")) +   # 특정 색깔 지정\n  theme_bw()",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Random Forest</span>"
    ]
  },
  {
    "objectID": "RF.html#데이터-분할",
    "href": "RF.html#데이터-분할",
    "title": "13  Random Forest",
    "section": "13.4 데이터 분할",
    "text": "13.4 데이터 분할\n\n# Partition (Training Dataset : Test Dataset = 7:3)\ny      &lt;- titanic1$Survived                           # Target\n\nset.seed(200)\nind    &lt;- createDataPartition(y, p = 0.7, list  =T)   # Index를 이용하여 7:3으로 분할\ntitanic.trd &lt;- titanic1[ind$Resample1,]               # Training Dataset\ntitanic.ted &lt;- titanic1[-ind$Resample1,]              # Test Dataset",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Random Forest</span>"
    ]
  },
  {
    "objectID": "RF.html#데이터-전처리-ii",
    "href": "RF.html#데이터-전처리-ii",
    "title": "13  Random Forest",
    "section": "13.5 데이터 전처리 II",
    "text": "13.5 데이터 전처리 II\n\n# Imputation\ntitanic.trd.Imp &lt;- titanic.trd %&gt;% \n  mutate(Age = replace_na(Age, mean(Age, na.rm = TRUE)))                 # 평균으로 결측값 대체\n\ntitanic.ted.Imp &lt;- titanic.ted %&gt;% \n  mutate(Age = replace_na(Age, mean(titanic.trd$Age, na.rm = TRUE)))     # Training Dataset을 이용하여 결측값 대체\n\nglimpse(titanic.trd.Imp)                                                 # 데이터 구조 확인\n\nRows: 625\nColumns: 6\n$ Survived &lt;fct&gt; no, yes, yes, no, no, no, yes, yes, yes, yes, no, no, yes, no, yes, no, yes, no, no, no, yes, no, no, yes, yes, no, no, no, no, no, yes, no, no, no, yes, no, yes, no, no, no, yes, n…\n$ Pclass   &lt;fct&gt; 3, 3, 1, 3, 3, 3, 3, 2, 3, 1, 3, 3, 2, 3, 3, 2, 1, 3, 3, 1, 3, 3, 1, 1, 3, 2, 1, 1, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3, 1, 3, 1, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 1, 2, 3…\n$ Sex      &lt;fct&gt; male, female, female, male, male, male, female, female, female, female, male, female, male, female, female, male, male, female, male, male, female, male, male, female, female, male,…\n$ Age      &lt;dbl&gt; 22.00000, 26.00000, 35.00000, 35.00000, 29.93737, 2.00000, 27.00000, 14.00000, 4.00000, 58.00000, 39.00000, 14.00000, 29.93737, 31.00000, 29.93737, 35.00000, 28.00000, 8.00000, 29.9…\n$ Fare     &lt;dbl&gt; 7.2500, 7.9250, 53.1000, 8.0500, 8.4583, 21.0750, 11.1333, 30.0708, 16.7000, 26.5500, 31.2750, 7.8542, 13.0000, 18.0000, 7.2250, 26.0000, 35.5000, 21.0750, 7.2250, 263.0000, 7.8792,…\n$ FamSize  &lt;int&gt; 1, 0, 1, 0, 0, 4, 2, 1, 2, 0, 6, 0, 0, 1, 0, 0, 0, 4, 0, 5, 0, 0, 0, 1, 0, 0, 1, 1, 0, 2, 1, 1, 1, 0, 0, 1, 0, 2, 1, 5, 1, 1, 0, 7, 0, 0, 5, 0, 2, 7, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 3…\n\nglimpse(titanic.ted.Imp)                                                 # 데이터 구조 확인\n\nRows: 266\nColumns: 6\n$ Survived &lt;fct&gt; yes, no, no, yes, no, yes, yes, yes, yes, yes, no, no, yes, yes, no, yes, no, yes, yes, no, yes, no, no, no, no, no, no, yes, yes, no, no, no, no, no, no, no, no, no, no, yes, no, n…\n$ Pclass   &lt;fct&gt; 1, 1, 3, 2, 3, 2, 3, 3, 3, 2, 3, 3, 2, 2, 3, 2, 1, 3, 2, 3, 3, 2, 2, 3, 3, 3, 3, 1, 2, 2, 3, 3, 3, 3, 3, 2, 3, 2, 2, 2, 3, 3, 2, 1, 3, 1, 3, 2, 1, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 1, 3…\n$ Sex      &lt;fct&gt; female, male, male, female, male, male, female, female, male, female, male, male, female, female, male, female, male, male, female, male, female, male, male, male, male, male, male,…\n$ Age      &lt;dbl&gt; 38.00000, 54.00000, 20.00000, 55.00000, 2.00000, 34.00000, 15.00000, 38.00000, 29.93737, 3.00000, 29.93737, 21.00000, 29.00000, 21.00000, 28.50000, 5.00000, 45.00000, 29.93737, 29.0…\n$ Fare     &lt;dbl&gt; 71.2833, 51.8625, 8.0500, 16.0000, 29.1250, 13.0000, 8.0292, 31.3875, 7.2292, 41.5792, 8.0500, 7.8000, 26.0000, 10.5000, 7.2292, 27.7500, 83.4750, 15.2458, 10.5000, 8.1583, 7.9250, …\n$ FamSize  &lt;int&gt; 1, 0, 0, 0, 5, 0, 0, 6, 0, 3, 0, 0, 1, 0, 0, 3, 1, 2, 0, 0, 6, 0, 0, 0, 0, 4, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 6, 2, 1, 0, 0, 1, 0, 2, 0, 0, 0, 0, 1, 0, 0, 1, 5, 2, 5, 0, 5, 0, 4, 0, 6…",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Random Forest</span>"
    ]
  },
  {
    "objectID": "RF.html#모형-훈련",
    "href": "RF.html#모형-훈련",
    "title": "13  Random Forest",
    "section": "13.6 모형 훈련",
    "text": "13.6 모형 훈련\nBagging은 “Bootstrap Aggregation”의 약어로써 Original Dataset으로부터 크기가 동일한 Bootstrap Dataset을 생성한 후 각 Dataset에 독립적으로 예측 모형을 적용하고, 예측 결과를 집계하여 최종 예측을 도출한다. Bagging은 여러 모형의 예측 결과를 집계함으로써 예측 성능을 향상시키는 앙상블 기법이다.\n\n\n\n\nRandom Forest는 Bagging 기법을 사용하는 대표적인 머신러닝 알고리듬으로 Original Dataset으로부터 크기가 동일한 Bootstrap Dataset을 생성한 후 각 Dataset에 독립적으로 의사결정나무(Decision Tree)를 적용한다. Random Forest의 가장 큰 특징은 노드를 분할할 때마다 \\(m\\)개의 예측 변수(Feature)를 랜덤하게 추출하고 그중 최적의 변수의 선택한다. 이러한 랜덤성은 생성된 트리들의 상관성을 낮춤으로써 성능을 더욱 향상시키는 역할을 한다.\n\n\n\n\nR에서 Random Forest를 수행하기 위해 package \"randomForest\"에서 제공하는 함수 randomForest()를 이용할 수 있으며, 함수의 자세한 옵션은 여기를 참고한다.\n\nrandomForest(formula, data, ntree, importance, mtry, ...)\n\n\nformula : Target과 예측 변수의 관계를 표현하기 위한 함수로써 일반적으로 Target ~ 예측 변수의 형태로 표현한다.\ndata : formula에 포함하고 있는 변수들의 데이터셋(Data Frame)\nntree : 생성하고자 하는 트리 개수\nimportance : 예측 변수에 대한 중요도 평가 여부\nmtry : 노드를 분할할 때마다 랜덤하게 추출할 예측 변수 개수\n\n\nset.seed(100)                                         # Seed 고정 -&gt; 동일한 결과를 출력하기 위해\ntitanic.rf &lt;- randomForest(Survived ~ ., \n                           data = titanic.trd.Imp,\n                           ntree = 100, \n                           importance = TRUE,\n                           mtry = 5) \n\ntitanic.rf\n\n\nCall:\n randomForest(formula = Survived ~ ., data = titanic.trd.Imp,      ntree = 100, importance = TRUE, mtry = 5) \n               Type of random forest: classification\n                     Number of trees: 100\nNo. of variables tried at each split: 5\n\n        OOB estimate of  error rate: 20.48%\nConfusion matrix:\n     no yes class.error\nno  325  60   0.1558442\nyes  68 172   0.2833333\n\n# 변수 중요도\ntitanic.rf$importance\n\n                no        yes MeanDecreaseAccuracy MeanDecreaseGini\nPclass  0.02877882 0.11071830           0.06043422         28.13215\nSex     0.11236101 0.20642716           0.14800079         78.91048\nAge     0.02601226 0.06161724           0.03958687         79.07151\nFare    0.01909336 0.08901592           0.04570532         79.19178\nFamSize 0.02494307 0.01894874           0.02247247         24.54580\n\nvarImpPlot(titanic.rf)\n\n\n\n\n\n\n\n\nResult! 정확도 측면에서는 Sex가 제일 중요하며, 지니계수 측면에서는 Fare이 Target Survived을 분류하는 데 있어 중요하다.\n\n# OBB Error\noob.error.data &lt;- data.frame(Trees = rep(1:nrow(titanic.rf$err.rate), times = 3), \n                             Type = rep(c(\"OOB\",\"No\",\"Yes\"), \n                                        each = nrow(titanic.rf$err.rate)),\n                             Error = c(titanic.rf$err.rate[,\"OOB\"],\n                                       titanic.rf$err.rate[,\"no\"],\n                                       titanic.rf$err.rate[,\"yes\"]))\n\nggplot(data = oob.error.data, aes(x = Trees, y = Error)) + \n  geom_line(aes(color = Type)) + \n  theme_bw()\n\n\n\n\n\n\n\n\nCaution! Original Dataset으로부터 Bootstrap Dataset을 생성할 때 추출되지 않은 Data Point를 Out of Bag (OBB) Sample이라고 부른다. OBB Sample을 이용하여 Random Forest가 얼마나 잘 구축되었는지 검증할 수 있는데, 이때 계산된 오차를 OBB 오차라고 한다.",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Random Forest</span>"
    ]
  },
  {
    "objectID": "RF.html#모형-평가",
    "href": "RF.html#모형-평가",
    "title": "13  Random Forest",
    "section": "13.7 모형 평가",
    "text": "13.7 모형 평가\nCaution! 모형 평가를 위해 Test Dataset에 대한 예측 class/확률 이 필요하며, 함수 predict()를 이용하여 생성한다.\n\n# 예측 class 생성 \ntest.rf.class &lt;- predict(titanic.rf,\n                         newdata = titanic.ted.Imp[,-1], # Test Dataset including Only 예측 변수   \n                         type = \"class\")                 # 예측 class 생성       \n\ntest.rf.class %&gt;%\n  as_tibble\n\n# A tibble: 266 × 1\n   value\n   &lt;fct&gt;\n 1 yes  \n 2 no   \n 3 no   \n 4 yes  \n 5 no   \n 6 no   \n 7 yes  \n 8 no   \n 9 no   \n10 no   \n# ℹ 256 more rows\n\n\n\n\n13.7.1 ConfusionMatrix\n\nCM   &lt;- caret::confusionMatrix(test.rf.class, titanic.ted.Imp$Survived, \n                               positive = \"yes\")       # confusionMatrix(예측 class, 실제 class, positive = \"관심 class\")\nCM\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  no yes\n       no  147  30\n       yes  17  72\n                                          \n               Accuracy : 0.8233          \n                 95% CI : (0.7721, 0.8672)\n    No Information Rate : 0.6165          \n    P-Value [Acc &gt; NIR] : 1.974e-13       \n                                          \n                  Kappa : 0.6171          \n                                          \n Mcnemar's Test P-Value : 0.08005         \n                                          \n            Sensitivity : 0.7059          \n            Specificity : 0.8963          \n         Pos Pred Value : 0.8090          \n         Neg Pred Value : 0.8305          \n             Prevalence : 0.3835          \n         Detection Rate : 0.2707          \n   Detection Prevalence : 0.3346          \n      Balanced Accuracy : 0.8011          \n                                          \n       'Positive' Class : yes             \n                                          \n\n\n\n\n\n13.7.2 ROC 곡선\n\n# 예측 확률 생성\ntest.rf.prob &lt;- predict(titanic.rf, \n                        newdata = titanic.ted.Imp[,-1], # Test Dataset including Only 예측 변수  \n                        type = \"prob\")                  # 예측 확률 생성     \n\ntest.rf.prob %&gt;%\n  as_tibble\n\n# A tibble: 266 × 2\n   no       yes     \n   &lt;matrix&gt; &lt;matrix&gt;\n 1 0.00     1.00    \n 2 0.72     0.28    \n 3 0.96     0.04    \n 4 0.45     0.55    \n 5 0.68     0.32    \n 6 0.99     0.01    \n 7 0.49     0.51    \n 8 1.00     0.00    \n 9 1.00     0.00    \n10 0.59     0.41    \n# ℹ 256 more rows\n\n\n\ntest.rf.prob &lt;- test.rf.prob[,2]                       # \"Survived = yes\"에 대한 예측 확률\n\nac  &lt;- titanic.ted.Imp$Survived                        # Test Dataset의 실제 class \npp  &lt;- as.numeric(test.rf.prob)                        # 예측 확률을 수치형으로 변환\n\n\n13.7.2.1 Package “pROC”\n\npacman::p_load(\"pROC\")\n\nrf.roc  &lt;- roc(ac, pp, plot = T, col = \"gray\")         # roc(실제 class, 예측 확률)\nauc     &lt;- round(auc(rf.roc), 3)\nlegend(\"bottomright\", legend = auc, bty = \"n\")\n\n\n\n\n\n\n\n\nCaution! Package \"pROC\"를 통해 출력한 ROC 곡선은 다양한 함수를 이용해서 그래프를 수정할 수 있다.\n\n# 함수 plot.roc() 이용\nplot.roc(rf.roc,   \n         col=\"gray\",                                   # Line Color\n         print.auc = TRUE,                             # AUC 출력 여부\n         print.auc.col = \"red\",                        # AUC 글씨 색깔\n         print.thres = TRUE,                           # Cutoff Value 출력 여부\n         print.thres.pch = 19,                         # Cutoff Value를 표시하는 도형 모양\n         print.thres.col = \"red\",                      # Cutoff Value를 표시하는 도형의 색깔\n         auc.polygon = TRUE,                           # 곡선 아래 면적에 대한 여부\n         auc.polygon.col = \"gray90\")                   # 곡선 아래 면적의 색깔\n\n\n\n\n\n\n\n\n\n# 함수 ggroc() 이용\nggroc(rf.roc) +\nannotate(geom = \"text\", x = 0.9, y = 1.0,\nlabel = paste(\"AUC = \", auc),\nsize = 5,\ncolor=\"red\") +\ntheme_bw()\n\n\n\n\n\n\n\n\n\n\n13.7.2.2 Package “Epi”\n\npacman::p_load(\"Epi\")       \n# install_version(\"etm\", version = \"1.1\", repos = \"http://cran.us.r-project.org\")\n\nROC(pp, ac, plot = \"ROC\")                              # ROC(예측 확률, 실제 class)  \n\n\n\n\n\n\n\n\n\n\n13.7.2.3 Package “ROCR”\n\npacman::p_load(\"ROCR\")\n\nrf.pred &lt;- prediction(pp, ac)                          # prediction(예측 확률, 실제 class) \n\nrf.perf &lt;- performance(rf.pred, \"tpr\", \"fpr\")          # performance(, \"민감도\", \"1-특이도\")                      \nplot(rf.perf, col = \"gray\")                            # ROC Curve\n\nperf.auc   &lt;- performance(rf.pred, \"auc\")              # AUC\nauc        &lt;- attributes(perf.auc)$y.values\nlegend(\"bottomright\", legend = auc, bty = \"n\")\n\n\n\n\n\n\n\n\n\n\n\n\n13.7.3 향상 차트\n\n13.7.3.1 Package “ROCR”\n\nrf.perf &lt;- performance(rf.pred, \"lift\", \"rpp\")         # Lift Chart                      \nplot(rf.perf, main = \"lift curve\",\n     colorize = T,                                     # Coloring according to cutoff \n     lwd = 2)",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Random Forest</span>"
    ]
  },
  {
    "objectID": "AdaBoost.html",
    "href": "AdaBoost.html",
    "title": "14  AdaBoost",
    "section": "",
    "text": "14.1 데이터 불러오기\npacman::p_load(\"data.table\", \n               \"tidyverse\", \n               \"dplyr\", \"tidyr\",\n               \"ggplot2\", \"GGally\",\n               \"caret\",\n               \"adabag\")                                                # For boosting\n\ntitanic &lt;- fread(\"../Titanic.csv\")                                      # 데이터 불러오기\n\ntitanic %&gt;%\n  as_tibble\n# A tibble: 891 × 11\n   Survived Pclass Name                                                Sex      Age SibSp Parch Ticket            Fare Cabin  Embarked\n      &lt;int&gt;  &lt;int&gt; &lt;chr&gt;                                               &lt;chr&gt;  &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;   \n 1        0      3 Braund, Mr. Owen Harris                             male      22     1     0 A/5 21171         7.25 \"\"     S       \n 2        1      1 Cumings, Mrs. John Bradley (Florence Briggs Thayer) female    38     1     0 PC 17599         71.3  \"C85\"  C       \n 3        1      3 Heikkinen, Miss. Laina                              female    26     0     0 STON/O2. 3101282  7.92 \"\"     S       \n 4        1      1 Futrelle, Mrs. Jacques Heath (Lily May Peel)        female    35     1     0 113803           53.1  \"C123\" S       \n 5        0      3 Allen, Mr. William Henry                            male      35     0     0 373450            8.05 \"\"     S       \n 6        0      3 Moran, Mr. James                                    male      NA     0     0 330877            8.46 \"\"     Q       \n 7        0      1 McCarthy, Mr. Timothy J                             male      54     0     0 17463            51.9  \"E46\"  S       \n 8        0      3 Palsson, Master. Gosta Leonard                      male       2     3     1 349909           21.1  \"\"     S       \n 9        1      3 Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)   female    27     0     2 347742           11.1  \"\"     S       \n10        1      2 Nasser, Mrs. Nicholas (Adele Achem)                 female    14     1     0 237736           30.1  \"\"     C       \n# ℹ 881 more rows",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>AdaBoost</span>"
    ]
  },
  {
    "objectID": "AdaBoost.html#데이터-전처리-i",
    "href": "AdaBoost.html#데이터-전처리-i",
    "title": "14  AdaBoost",
    "section": "14.2 데이터 전처리 I",
    "text": "14.2 데이터 전처리 I\n\ntitanic %&lt;&gt;%\n  data.frame() %&gt;%                                                      # Data Frame 형태로 변환 \n  mutate(Survived = ifelse(Survived == 1, \"yes\", \"no\"))                 # Target을 문자형 변수로 변환\n\n# 1. Convert to Factor\nfac.col &lt;- c(\"Pclass\", \"Sex\",\n             # Target\n             \"Survived\")\n\ntitanic &lt;- titanic %&gt;% \n  mutate_at(fac.col, as.factor)                                         # 범주형으로 변환\n\nglimpse(titanic)                                                        # 데이터 구조 확인\n\nRows: 891\nColumns: 11\n$ Survived &lt;fct&gt; no, yes, yes, yes, no, no, no, no, yes, yes, yes, yes, no, no, no, yes, no, yes, no, yes, no, yes, yes, yes, no, yes, no, no, yes, no, no, yes, yes, no, no, no, yes, no, no, yes, no…\n$ Pclass   &lt;fct&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3, 2, 2, 3, 1, 3, 3, 3, 1, 3, 3, 1, 1, 3, 2, 1, 1, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 1, 1, 2, 3, 2, 3, 3…\n$ Name     &lt;chr&gt; \"Braund, Mr. Owen Harris\", \"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\", \"Heikkinen, Miss. Laina\", \"Futrelle, Mrs. Jacques Heath (Lily May Peel)\", \"Allen, Mr. William Henry…\n$ Sex      &lt;fct&gt; male, female, female, female, male, male, male, male, female, female, female, female, male, male, female, female, male, male, female, female, male, male, female, male, female, femal…\n$ Age      &lt;dbl&gt; 22.0, 38.0, 26.0, 35.0, 35.0, NA, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, NA, 31.0, NA, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, NA, 19.0, NA, NA, 40.0, NA, NA, 66.…\n$ SibSp    &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0, 0, 0, 0, 0, 3, 1, 0, 3, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 1, 0, 0, 1, 0, 2, 1, 4, 0, 1, 1, 0, 0, 0, 0, 1, 5, 0…\n$ Parch    &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 5, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 2, 2, 0…\n$ Ticket   &lt;chr&gt; \"A/5 21171\", \"PC 17599\", \"STON/O2. 3101282\", \"113803\", \"373450\", \"330877\", \"17463\", \"349909\", \"347742\", \"237736\", \"PP 9549\", \"113783\", \"A/5. 2151\", \"347082\", \"350406\", \"248706\", \"38…\n$ Fare     &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625, 21.0750, 11.1333, 30.0708, 16.7000, 26.5500, 8.0500, 31.2750, 7.8542, 16.0000, 29.1250, 13.0000, 18.0000, 7.2250, 26.0000,…\n$ Cabin    &lt;chr&gt; \"\", \"C85\", \"\", \"C123\", \"\", \"\", \"E46\", \"\", \"\", \"\", \"G6\", \"C103\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"D56\", \"\", \"A6\", \"\", \"\", \"\", \"C23 C25 C27\", \"\", \"\", \"\", \"B78\", \"\", \"\", \"\", \"\", \"\"…\n$ Embarked &lt;chr&gt; \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"C\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"Q\", \"S\", \"C\", \"C\", \"Q\", \"S\", \"C\", \"S\", \"…\n\n# 2. Generate New Variable\ntitanic &lt;- titanic %&gt;%\n  mutate(FamSize = SibSp + Parch)                                       # \"FamSize = 형제 및 배우자 수 + 부모님 및 자녀 수\"로 가족 수를 의미하는 새로운 변수\n\nglimpse(titanic)                                                        # 데이터 구조 확인\n\nRows: 891\nColumns: 12\n$ Survived &lt;fct&gt; no, yes, yes, yes, no, no, no, no, yes, yes, yes, yes, no, no, no, yes, no, yes, no, yes, no, yes, yes, yes, no, yes, no, no, yes, no, no, yes, yes, no, no, no, yes, no, no, yes, no…\n$ Pclass   &lt;fct&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3, 2, 2, 3, 1, 3, 3, 3, 1, 3, 3, 1, 1, 3, 2, 1, 1, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 1, 1, 2, 3, 2, 3, 3…\n$ Name     &lt;chr&gt; \"Braund, Mr. Owen Harris\", \"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\", \"Heikkinen, Miss. Laina\", \"Futrelle, Mrs. Jacques Heath (Lily May Peel)\", \"Allen, Mr. William Henry…\n$ Sex      &lt;fct&gt; male, female, female, female, male, male, male, male, female, female, female, female, male, male, female, female, male, male, female, female, male, male, female, male, female, femal…\n$ Age      &lt;dbl&gt; 22.0, 38.0, 26.0, 35.0, 35.0, NA, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, NA, 31.0, NA, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, NA, 19.0, NA, NA, 40.0, NA, NA, 66.…\n$ SibSp    &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0, 0, 0, 0, 0, 3, 1, 0, 3, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 1, 0, 0, 1, 0, 2, 1, 4, 0, 1, 1, 0, 0, 0, 0, 1, 5, 0…\n$ Parch    &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 5, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 2, 2, 0…\n$ Ticket   &lt;chr&gt; \"A/5 21171\", \"PC 17599\", \"STON/O2. 3101282\", \"113803\", \"373450\", \"330877\", \"17463\", \"349909\", \"347742\", \"237736\", \"PP 9549\", \"113783\", \"A/5. 2151\", \"347082\", \"350406\", \"248706\", \"38…\n$ Fare     &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625, 21.0750, 11.1333, 30.0708, 16.7000, 26.5500, 8.0500, 31.2750, 7.8542, 16.0000, 29.1250, 13.0000, 18.0000, 7.2250, 26.0000,…\n$ Cabin    &lt;chr&gt; \"\", \"C85\", \"\", \"C123\", \"\", \"\", \"E46\", \"\", \"\", \"\", \"G6\", \"C103\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"D56\", \"\", \"A6\", \"\", \"\", \"\", \"C23 C25 C27\", \"\", \"\", \"\", \"B78\", \"\", \"\", \"\", \"\", \"\"…\n$ Embarked &lt;chr&gt; \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"C\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"Q\", \"S\", \"C\", \"C\", \"Q\", \"S\", \"C\", \"S\", \"…\n$ FamSize  &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 4, 2, 1, 2, 0, 0, 6, 0, 0, 5, 0, 1, 0, 0, 0, 0, 0, 4, 6, 0, 5, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 3, 0, 0, 1, 0, 2, 1, 5, 0, 1, 1, 1, 0, 0, 0, 3, 7, 0…\n\n# 3. Select Variables used for Analysis\ntitanic1 &lt;- titanic %&gt;% \n  dplyr::select(Survived, Pclass, Sex, Age, Fare, FamSize)              # 분석에 사용할 변수 선택\n\nglimpse(titanic1)                                                       # 데이터 구조 확인\n\nRows: 891\nColumns: 6\n$ Survived &lt;fct&gt; no, yes, yes, yes, no, no, no, no, yes, yes, yes, yes, no, no, no, yes, no, yes, no, yes, no, yes, yes, yes, no, yes, no, no, yes, no, no, yes, yes, no, no, no, yes, no, no, yes, no…\n$ Pclass   &lt;fct&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3, 2, 2, 3, 1, 3, 3, 3, 1, 3, 3, 1, 1, 3, 2, 1, 1, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 1, 1, 2, 3, 2, 3, 3…\n$ Sex      &lt;fct&gt; male, female, female, female, male, male, male, male, female, female, female, female, male, male, female, female, male, male, female, female, male, male, female, male, female, femal…\n$ Age      &lt;dbl&gt; 22.0, 38.0, 26.0, 35.0, 35.0, NA, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, NA, 31.0, NA, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, NA, 19.0, NA, NA, 40.0, NA, NA, 66.…\n$ Fare     &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625, 21.0750, 11.1333, 30.0708, 16.7000, 26.5500, 8.0500, 31.2750, 7.8542, 16.0000, 29.1250, 13.0000, 18.0000, 7.2250, 26.0000,…\n$ FamSize  &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 4, 2, 1, 2, 0, 0, 6, 0, 0, 5, 0, 1, 0, 0, 0, 0, 0, 4, 6, 0, 5, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 3, 0, 0, 1, 0, 2, 1, 5, 0, 1, 1, 1, 0, 0, 0, 3, 7, 0…",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>AdaBoost</span>"
    ]
  },
  {
    "objectID": "AdaBoost.html#데이터-탐색",
    "href": "AdaBoost.html#데이터-탐색",
    "title": "14  AdaBoost",
    "section": "14.3 데이터 탐색",
    "text": "14.3 데이터 탐색\n\nggpairs(titanic1,                                        \n        aes(colour = Survived)) +                         # Target의 범주에 따라 색깔을 다르게 표현\n  theme_bw()\n\n\n\n\n\n\n\nggpairs(titanic1,                                     \n        aes(colour = Survived, alpha = 0.8)) +            # Target의 범주에 따라 색깔을 다르게 표현\n  scale_colour_manual(values = c(\"#00798c\", \"#d1495b\")) + # 특정 색깔 지정\n  scale_fill_manual(values = c(\"#00798c\", \"#d1495b\")) +   # 특정 색깔 지정\n  theme_bw()",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>AdaBoost</span>"
    ]
  },
  {
    "objectID": "AdaBoost.html#데이터-분할",
    "href": "AdaBoost.html#데이터-분할",
    "title": "14  AdaBoost",
    "section": "14.4 데이터 분할",
    "text": "14.4 데이터 분할\n\n# Partition (Training Dataset : Test Dataset = 7:3)\ny      &lt;- titanic1$Survived                           # Target\n\nset.seed(200)\nind    &lt;- createDataPartition(y, p = 0.7, list  =T)   # Index를 이용하여 7:3으로 분할\ntitanic.trd &lt;- titanic1[ind$Resample1,]               # Training Dataset\ntitanic.ted &lt;- titanic1[-ind$Resample1,]              # Test Dataset",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>AdaBoost</span>"
    ]
  },
  {
    "objectID": "AdaBoost.html#데이터-전처리-ii",
    "href": "AdaBoost.html#데이터-전처리-ii",
    "title": "14  AdaBoost",
    "section": "14.5 데이터 전처리 II",
    "text": "14.5 데이터 전처리 II\n\n# Imputation\ntitanic.trd.Imp &lt;- titanic.trd %&gt;% \n  mutate(Age = replace_na(Age, mean(Age, na.rm = TRUE)))                 # 평균으로 결측값 대체\n\ntitanic.ted.Imp &lt;- titanic.ted %&gt;% \n  mutate(Age = replace_na(Age, mean(titanic.trd$Age, na.rm = TRUE)))     # Training Dataset을 이용하여 결측값 대체\n\nglimpse(titanic.trd.Imp)                                                 # 데이터 구조 확인\n\nRows: 625\nColumns: 6\n$ Survived &lt;fct&gt; no, yes, yes, no, no, no, yes, yes, yes, yes, no, no, yes, no, yes, no, yes, no, no, no, yes, no, no, yes, yes, no, no, no, no, no, yes, no, no, no, yes, no, yes, no, no, no, yes, n…\n$ Pclass   &lt;fct&gt; 3, 3, 1, 3, 3, 3, 3, 2, 3, 1, 3, 3, 2, 3, 3, 2, 1, 3, 3, 1, 3, 3, 1, 1, 3, 2, 1, 1, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3, 1, 3, 1, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 1, 2, 3…\n$ Sex      &lt;fct&gt; male, female, female, male, male, male, female, female, female, female, male, female, male, female, female, male, male, female, male, male, female, male, male, female, female, male,…\n$ Age      &lt;dbl&gt; 22.00000, 26.00000, 35.00000, 35.00000, 29.93737, 2.00000, 27.00000, 14.00000, 4.00000, 58.00000, 39.00000, 14.00000, 29.93737, 31.00000, 29.93737, 35.00000, 28.00000, 8.00000, 29.9…\n$ Fare     &lt;dbl&gt; 7.2500, 7.9250, 53.1000, 8.0500, 8.4583, 21.0750, 11.1333, 30.0708, 16.7000, 26.5500, 31.2750, 7.8542, 13.0000, 18.0000, 7.2250, 26.0000, 35.5000, 21.0750, 7.2250, 263.0000, 7.8792,…\n$ FamSize  &lt;int&gt; 1, 0, 1, 0, 0, 4, 2, 1, 2, 0, 6, 0, 0, 1, 0, 0, 0, 4, 0, 5, 0, 0, 0, 1, 0, 0, 1, 1, 0, 2, 1, 1, 1, 0, 0, 1, 0, 2, 1, 5, 1, 1, 0, 7, 0, 0, 5, 0, 2, 7, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 3…\n\nglimpse(titanic.ted.Imp)                                                 # 데이터 구조 확인\n\nRows: 266\nColumns: 6\n$ Survived &lt;fct&gt; yes, no, no, yes, no, yes, yes, yes, yes, yes, no, no, yes, yes, no, yes, no, yes, yes, no, yes, no, no, no, no, no, no, yes, yes, no, no, no, no, no, no, no, no, no, no, yes, no, n…\n$ Pclass   &lt;fct&gt; 1, 1, 3, 2, 3, 2, 3, 3, 3, 2, 3, 3, 2, 2, 3, 2, 1, 3, 2, 3, 3, 2, 2, 3, 3, 3, 3, 1, 2, 2, 3, 3, 3, 3, 3, 2, 3, 2, 2, 2, 3, 3, 2, 1, 3, 1, 3, 2, 1, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 1, 3…\n$ Sex      &lt;fct&gt; female, male, male, female, male, male, female, female, male, female, male, male, female, female, male, female, male, male, female, male, female, male, male, male, male, male, male,…\n$ Age      &lt;dbl&gt; 38.00000, 54.00000, 20.00000, 55.00000, 2.00000, 34.00000, 15.00000, 38.00000, 29.93737, 3.00000, 29.93737, 21.00000, 29.00000, 21.00000, 28.50000, 5.00000, 45.00000, 29.93737, 29.0…\n$ Fare     &lt;dbl&gt; 71.2833, 51.8625, 8.0500, 16.0000, 29.1250, 13.0000, 8.0292, 31.3875, 7.2292, 41.5792, 8.0500, 7.8000, 26.0000, 10.5000, 7.2292, 27.7500, 83.4750, 15.2458, 10.5000, 8.1583, 7.9250, …\n$ FamSize  &lt;int&gt; 1, 0, 0, 0, 5, 0, 0, 6, 0, 3, 0, 0, 1, 0, 0, 3, 1, 2, 0, 0, 6, 0, 0, 0, 0, 4, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 6, 2, 1, 0, 0, 1, 0, 2, 0, 0, 0, 0, 1, 0, 0, 1, 5, 2, 5, 0, 5, 0, 4, 0, 6…",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>AdaBoost</span>"
    ]
  },
  {
    "objectID": "AdaBoost.html#모형-훈련",
    "href": "AdaBoost.html#모형-훈련",
    "title": "14  AdaBoost",
    "section": "14.6 모형 훈련",
    "text": "14.6 모형 훈련\nBoosting은 다수의 약한 학습자(간단하면서 성능이 낮은 예측 모형)을 순차적으로 학습하는 앙상블 기법이다. Boosting의 특징은 이전 모형의 오차를 반영하여 다음 모형을 생성하며, 오차를 개선하는 방향으로 학습을 수행한다.\n\n\n\n\nAdaBoost는 최초로 Boosting 기법을 사용한 머신러닝 알고리듬으로 잘못 분류한 case에 대해 높은 Sample Weight를 부여하여 오차를 개선해 나가는 학습 방식이다.\n\n\n\n\nR에서 AdaBoost를 수행하기 위해 package \"adabag\"에서 제공하는 함수 boosting()를 이용할 수 있으며, 함수의 자세한 옵션은 여기를 참고한다. 게다가, package \"adabag\"는 package \"rpart\"를 이용하여 트리를 생성하기 때문에 함수 rpart.control()을 이용하여 다양한 옵션을 입력할 수 있으며, 함수의 자세한 옵션은 여기를 참고한다.\n\nboosting(formula, data, mfinal, ...)                  # AdaBoost\nboosting.cv(formula, data, v, mfinal, ...)            # AdaBoost based on Cross Validation\n\n\nformula : Target과 예측 변수의 관계를 표현하기 위한 함수로써 일반적으로 Target ~ 예측 변수의 형태로 표현한다.\ndata : formula에 포함하고 있는 변수들의 데이터셋(Data Frame)\nmfinal : 반복 횟수(= 생성하고자 하는 트리 개수)\nv : \\(k\\)-Fold Cross Validation의 \\(k\\)(= Fold 수)\n\n\nset.seed(100)                                         # Seed 고정 -&gt; 동일한 결과를 출력하기 위해\ntitanic.ada &lt;- boosting(Survived~.,\n                        data = titanic.trd.Imp,\n                        mfinal = 50)    \n\nCaution! 함수 boosting()은 기본값으로 깊이가 30인 트리를 생성한다. 만약 \"stump\"를 생성하고 싶으면 아래의 코드를 수행하면 되지만 시간이 너무 오래 걸리는 단점이 있다.\n\nrc &lt;- rpart.control(maxdepth = 1)                \n\nset.seed(100)\ntitanic.ada &lt;- boosting(Survived~.,\n                        data = titanic.trd.Imp,\n                        mfinal = 50,  \n                        control = rc)\n\n\n# 변수 중요도\ntitanic.ada$importance\n\n      Age   FamSize      Fare    Pclass       Sex \n34.064246  8.276373 37.457786  6.587923 13.613672 \n\n# 변수 중요도 plot\nimp &lt;- data.frame(Importance = titanic.ada$importance)\nimp$varnames &lt;- rownames(imp) \nrownames(imp) &lt;- NULL\n\nggplot(imp, aes(x = reorder(varnames, Importance), y = Importance)) +\n  geom_point() +\n  geom_segment(aes(x = varnames, xend = varnames,\n                   y = 0, yend = Importance)) +\n  ylab(\"Importance\") +\n  xlab(\"\") +\n  coord_flip() +\n  theme_bw()\n\n\n\n\n\n\n\n\nResult! 변수 Fare이 Target Survived을 분류하는 데 있어 중요하다.\n\n# 각 트리의 모형 가중치\ntitanic.ada$weights         \n\n [1] 0.78295582 0.56826060 0.45432590 0.38850942 0.43218725 0.36848680 0.38647782 0.34425320 0.41595276 0.34136453 0.22999285 0.32465083 0.40988159 0.33790620 0.32800254 0.30524638 0.16244452\n[18] 0.29925562 0.26506851 0.17066854 0.26151169 0.23265334 0.13550507 0.25298743 0.25622890 0.17345807 0.14746377 0.26927469 0.22046450 0.25118916 0.21297254 0.22829963 0.14653144 0.22614864\n[35] 0.24631308 0.26052245 0.23013778 0.24944529 0.21619601 0.14712742 0.19006330 0.10435622 0.24897459 0.14419243 0.13831085 0.24090084 0.05429047 0.17232969 0.14102667 0.13718293\n\n\nResult! 모형 가중치는 해당 예측 모형이 얼마나 정확한지에 따라 결정되며, 정확도가 높을수록 높은 가중치가 부여된다.",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>AdaBoost</span>"
    ]
  },
  {
    "objectID": "AdaBoost.html#모형-평가",
    "href": "AdaBoost.html#모형-평가",
    "title": "14  AdaBoost",
    "section": "14.7 모형 평가",
    "text": "14.7 모형 평가\nCaution! 모형 평가를 위해 Test Dataset에 대한 예측 class/확률 이 필요하며, 함수 predict()를 이용하여 생성한다.\n\n# 예측 class/확률 생성 \ntest.ada.pred &lt;- predict(titanic.ada,\n                         newdata = titanic.ted.Imp[,-1]) # Test Dataset including Only 예측 변수    \n\n# 예측 class\ntest.ada.pred$class\n\n  [1] \"yes\" \"no\"  \"no\"  \"yes\" \"no\"  \"no\"  \"yes\" \"no\"  \"no\"  \"yes\" \"no\"  \"yes\" \"yes\" \"yes\" \"no\"  \"yes\" \"no\"  \"no\"  \"yes\" \"no\"  \"no\"  \"yes\" \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"yes\" \"no\"  \"yes\" \"no\" \n [33] \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"yes\" \"no\"  \"no\"  \"no\"  \"yes\" \"no\"  \"no\"  \"no\"  \"no\"  \"yes\" \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"yes\" \"no\"  \"no\"  \"no\"  \"yes\" \"no\"  \"no\"  \"yes\" \"no\" \n [65] \"yes\" \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"yes\" \"no\"  \"yes\" \"no\"  \"no\"  \"no\"  \"no\"  \"yes\" \"no\"  \"yes\" \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"yes\" \"yes\" \"yes\"\n [97] \"yes\" \"yes\" \"no\"  \"no\"  \"no\"  \"yes\" \"yes\" \"no\"  \"no\"  \"yes\" \"no\"  \"yes\" \"no\"  \"yes\" \"yes\" \"no\"  \"yes\" \"no\"  \"no\"  \"no\"  \"yes\" \"no\"  \"no\"  \"no\"  \"yes\" \"yes\" \"no\"  \"yes\" \"no\"  \"no\"  \"no\"  \"yes\"\n[129] \"no\"  \"yes\" \"yes\" \"yes\" \"no\"  \"no\"  \"yes\" \"yes\" \"no\"  \"no\"  \"no\"  \"no\"  \"yes\" \"no\"  \"no\"  \"no\"  \"yes\" \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"yes\" \"no\"  \"no\"  \"no\"  \"yes\" \"no\"  \"no\"  \"no\"  \"no\" \n[161] \"yes\" \"yes\" \"yes\" \"yes\" \"no\"  \"yes\" \"yes\" \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"yes\" \"yes\" \"yes\" \"no\"  \"yes\" \"no\"  \"no\"  \"no\"  \"yes\" \"no\"  \"no\"  \"yes\" \"no\"  \"no\"  \"no\"  \"yes\" \"no\"  \"yes\" \"no\"  \"no\" \n[193] \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"yes\" \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"yes\" \"yes\" \"no\"  \"no\"  \"yes\" \"yes\" \"no\"  \"no\"  \"no\"  \"yes\" \"yes\" \"no\"  \"no\"  \"yes\" \"no\"  \"no\"  \"yes\"\n[225] \"yes\" \"yes\" \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"no\"  \"yes\" \"no\"  \"no\"  \"no\"  \"yes\" \"no\"  \"no\"  \"no\"  \"yes\" \"no\"  \"yes\" \"no\"  \"no\"  \"yes\" \"no\"  \"no\"  \"no\"  \"no\"  \"yes\"\n[257] \"yes\" \"yes\" \"no\"  \"yes\" \"no\"  \"yes\" \"yes\" \"no\"  \"yes\" \"no\" \n\n# 예측 확률\ntest.ada.pred$prob\n\n            [,1]      [,2]\n  [1,] 0.2380209 0.7619791\n  [2,] 0.5606343 0.4393657\n  [3,] 0.6880075 0.3119925\n  [4,] 0.3819148 0.6180852\n  [5,] 0.6367723 0.3632277\n  [6,] 0.6269603 0.3730397\n  [7,] 0.3918065 0.6081935\n  [8,] 0.7618416 0.2381584\n  [9,] 0.6998049 0.3001951\n [10,] 0.2820866 0.7179134\n [11,] 0.7933984 0.2066016\n [12,] 0.4975126 0.5024874\n [13,] 0.3410832 0.6589168\n [14,] 0.4374145 0.5625855\n [15,] 0.6053940 0.3946060\n [16,] 0.3022196 0.6977804\n [17,] 0.6302883 0.3697117\n [18,] 0.5137920 0.4862080\n [19,] 0.3349145 0.6650855\n [20,] 0.6059908 0.3940092\n [21,] 0.6999664 0.3000336\n [22,] 0.4579267 0.5420733\n [23,] 0.7640663 0.2359337\n [24,] 0.7933984 0.2066016\n [25,] 0.8656613 0.1343387\n [26,] 0.8494653 0.1505347\n [27,] 0.8552787 0.1447213\n [28,] 0.6003552 0.3996448\n [29,] 0.3602870 0.6397130\n [30,] 0.6438633 0.3561367\n [31,] 0.4036295 0.5963705\n [32,] 0.7051926 0.2948074\n [33,] 0.7949698 0.2050302\n [34,] 0.6110658 0.3889342\n [35,] 0.5612269 0.4387731\n [36,] 0.7964444 0.2035556\n [37,] 0.6892576 0.3107424\n [38,] 0.7394925 0.2605075\n [39,] 0.5345683 0.4654317\n [40,] 0.3441134 0.6558866\n [41,] 0.6476855 0.3523145\n [42,] 0.6410950 0.3589050\n [43,] 0.8184373 0.1815627\n [44,] 0.2310725 0.7689275\n [45,] 0.6281190 0.3718810\n [46,] 0.5575429 0.4424571\n [47,] 0.7741464 0.2258536\n [48,] 0.5085365 0.4914635\n [49,] 0.2646717 0.7353283\n [50,] 0.7763893 0.2236107\n [51,] 0.7271251 0.2728749\n [52,] 0.7519280 0.2480720\n [53,] 0.5492291 0.4507709\n [54,] 0.5013203 0.4986797\n [55,] 0.8133695 0.1866305\n [56,] 0.4638879 0.5361121\n [57,] 0.5969433 0.4030567\n [58,] 0.5399915 0.4600085\n [59,] 0.8441545 0.1558455\n [60,] 0.2910053 0.7089947\n [61,] 0.7353196 0.2646804\n [62,] 0.6919695 0.3080305\n [63,] 0.4074803 0.5925197\n [64,] 0.5813353 0.4186647\n [65,] 0.3756294 0.6243706\n [66,] 0.5296252 0.4703748\n [67,] 0.8061569 0.1938431\n [68,] 0.5519186 0.4480814\n [69,] 0.7223923 0.2776077\n [70,] 0.5726111 0.4273889\n [71,] 0.5903052 0.4096948\n [72,] 0.5797197 0.4202803\n [73,] 0.6157677 0.3842323\n [74,] 0.1726817 0.8273183\n [75,] 0.5447891 0.4552109\n [76,] 0.4916150 0.5083850\n [77,] 0.5374432 0.4625568\n [78,] 0.7754588 0.2245412\n [79,] 0.7763893 0.2236107\n [80,] 0.5972677 0.4027323\n [81,] 0.4560094 0.5439906\n [82,] 0.6476855 0.3523145\n [83,] 0.4933356 0.5066644\n [84,] 0.7559501 0.2440499\n [85,] 0.5756480 0.4243520\n [86,] 0.7776756 0.2223244\n [87,] 0.5494400 0.4505600\n [88,] 0.5523015 0.4476985\n [89,] 0.6738163 0.3261837\n [90,] 0.6164570 0.3835430\n [91,] 0.5769028 0.4230972\n [92,] 0.5955537 0.4044463\n [93,] 0.8351898 0.1648102\n [94,] 0.4525701 0.5474299\n [95,] 0.2901935 0.7098065\n [96,] 0.2560765 0.7439235\n [97,] 0.4652957 0.5347043\n [98,] 0.4421194 0.5578806\n [99,] 0.6110658 0.3889342\n[100,] 0.8157686 0.1842314\n[101,] 0.6449280 0.3550720\n[102,] 0.1667904 0.8332096\n[103,] 0.3607675 0.6392325\n[104,] 0.6027602 0.3972398\n[105,] 0.6191326 0.3808674\n[106,] 0.1026672 0.8973328\n[107,] 0.8184373 0.1815627\n[108,] 0.3458047 0.6541953\n[109,] 0.8916389 0.1083611\n[110,] 0.3990216 0.6009784\n[111,] 0.3262811 0.6737189\n[112,] 0.8664500 0.1335500\n[113,] 0.4525701 0.5474299\n[114,] 0.5819211 0.4180789\n[115,] 0.5320950 0.4679050\n[116,] 0.6141752 0.3858248\n[117,] 0.2643221 0.7356779\n[118,] 0.6353850 0.3646150\n[119,] 0.5650854 0.4349146\n[120,] 0.8368426 0.1631574\n[121,] 0.1192343 0.8807657\n[122,] 0.4051593 0.5948407\n[123,] 0.5970041 0.4029959\n[124,] 0.3471779 0.6528221\n[125,] 0.5855429 0.4144571\n[126,] 0.5109998 0.4890002\n[127,] 0.6174761 0.3825239\n[128,] 0.3586394 0.6413606\n[129,] 0.6148178 0.3851822\n[130,] 0.3939032 0.6060968\n[131,] 0.4587025 0.5412975\n[132,] 0.4153344 0.5846656\n[133,] 0.6731515 0.3268485\n[134,] 0.8141873 0.1858127\n[135,] 0.4241869 0.5758131\n[136,] 0.3694687 0.6305313\n[137,] 0.5211940 0.4788060\n[138,] 0.7391721 0.2608279\n[139,] 0.7933984 0.2066016\n[140,] 0.6338633 0.3661367\n[141,] 0.1851840 0.8148160\n[142,] 0.7419194 0.2580806\n[143,] 0.7864270 0.2135730\n[144,] 0.7080648 0.2919352\n[145,] 0.2990145 0.7009855\n[146,] 0.6317225 0.3682775\n[147,] 0.7306326 0.2693674\n[148,] 0.7792936 0.2207064\n[149,] 0.7864270 0.2135730\n[150,] 0.5557747 0.4442253\n[151,] 0.5415688 0.4584312\n[152,] 0.4663978 0.5336022\n[153,] 0.6157677 0.3842323\n[154,] 0.7638300 0.2361700\n[155,] 0.7155637 0.2844363\n[156,] 0.4377982 0.5622018\n[157,] 0.7726810 0.2273190\n[158,] 0.5309792 0.4690208\n[159,] 0.6998049 0.3001951\n[160,] 0.6998049 0.3001951\n[161,] 0.4023619 0.5976381\n[162,] 0.4431348 0.5568652\n[163,] 0.4299379 0.5700621\n[164,] 0.3859350 0.6140650\n[165,] 0.7155637 0.2844363\n[166,] 0.2602355 0.7397645\n[167,] 0.4230678 0.5769322\n[168,] 0.6393824 0.3606176\n[169,] 0.5616746 0.4383254\n[170,] 0.5883392 0.4116608\n[171,] 0.6406999 0.3593001\n[172,] 0.7973211 0.2026789\n[173,] 0.2373659 0.7626341\n[174,] 0.4525701 0.5474299\n[175,] 0.2096100 0.7903900\n[176,] 0.8111473 0.1888527\n[177,] 0.3591942 0.6408058\n[178,] 0.8293012 0.1706988\n[179,] 0.6998049 0.3001951\n[180,] 0.7051926 0.2948074\n[181,] 0.4871692 0.5128308\n[182,] 0.6758645 0.3241355\n[183,] 0.6620524 0.3379476\n[184,] 0.2489002 0.7510998\n[185,] 0.7129300 0.2870700\n[186,] 0.7080648 0.2919352\n[187,] 0.8593307 0.1406693\n[188,] 0.3217332 0.6782668\n[189,] 0.7481424 0.2518576\n[190,] 0.4447027 0.5552973\n[191,] 0.8045524 0.1954476\n[192,] 0.7051926 0.2948074\n[193,] 0.5362133 0.4637867\n[194,] 0.8629472 0.1370528\n[195,] 0.6790558 0.3209442\n[196,] 0.5407796 0.4592204\n[197,] 0.5185768 0.4814232\n[198,] 0.5117530 0.4882470\n[199,] 0.7278020 0.2721980\n[200,] 0.7864270 0.2135730\n[201,] 0.6179546 0.3820454\n[202,] 0.4894940 0.5105060\n[203,] 0.8798358 0.1201642\n[204,] 0.6764211 0.3235789\n[205,] 0.6889804 0.3110196\n[206,] 0.5792763 0.4207237\n[207,] 0.7396085 0.2603915\n[208,] 0.4871692 0.5128308\n[209,] 0.4023921 0.5976079\n[210,] 0.7315768 0.2684232\n[211,] 0.6480763 0.3519237\n[212,] 0.4575319 0.5424681\n[213,] 0.2843872 0.7156128\n[214,] 0.7396085 0.2603915\n[215,] 0.7966983 0.2033017\n[216,] 0.7118023 0.2881977\n[217,] 0.4947831 0.5052169\n[218,] 0.2229925 0.7770075\n[219,] 0.7864270 0.2135730\n[220,] 0.8425537 0.1574463\n[221,] 0.4780868 0.5219132\n[222,] 0.5971334 0.4028666\n[223,] 0.6364989 0.3635011\n[224,] 0.3384311 0.6615689\n[225,] 0.2446014 0.7553986\n[226,] 0.2985430 0.7014570\n[227,] 0.5085365 0.4914635\n[228,] 0.7155637 0.2844363\n[229,] 0.6569527 0.3430473\n[230,] 0.5085938 0.4914062\n[231,] 0.5909401 0.4090599\n[232,] 0.6164125 0.3835875\n[233,] 0.6892770 0.3107230\n[234,] 0.7776756 0.2223244\n[235,] 0.5807449 0.4192551\n[236,] 0.7390075 0.2609925\n[237,] 0.6524395 0.3475605\n[238,] 0.3334475 0.6665525\n[239,] 0.7728687 0.2271313\n[240,] 0.7590017 0.2409983\n[241,] 0.6175161 0.3824839\n[242,] 0.1432780 0.8567220\n[243,] 0.5647913 0.4352087\n[244,] 0.6279996 0.3720004\n[245,] 0.8142066 0.1857934\n[246,] 0.1825833 0.8174167\n[247,] 0.6476855 0.3523145\n[248,] 0.2205410 0.7794590\n[249,] 0.7862632 0.2137368\n[250,] 0.7871861 0.2128139\n[251,] 0.3980471 0.6019529\n[252,] 0.6431673 0.3568327\n[253,] 0.5320256 0.4679744\n[254,] 0.8664500 0.1335500\n[255,] 0.6722047 0.3277953\n[256,] 0.3126791 0.6873209\n[257,] 0.3312616 0.6687384\n[258,] 0.2780197 0.7219803\n[259,] 0.5150944 0.4849056\n[260,] 0.2449884 0.7550116\n[261,] 0.8265046 0.1734954\n[262,] 0.4466415 0.5533585\n[263,] 0.4070478 0.5929522\n[264,] 0.6364983 0.3635017\n[265,] 0.4228538 0.5771462\n[266,] 0.6430485 0.3569515\n\n\n\n\n14.7.1 ConfusionMatrix\n\ntest.ada.class &lt;- as.factor(test.ada.pred$class)       # Converting Character into Factor\n\nCM   &lt;- caret::confusionMatrix(test.ada.class, titanic.ted.Imp$Survived, \n                               positive = \"yes\")       # confusionMatrix(예측 class, 실제 class, positive = \"관심 class\")\nCM\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  no yes\n       no  151  29\n       yes  13  73\n                                          \n               Accuracy : 0.8421          \n                 95% CI : (0.7926, 0.8838)\n    No Information Rate : 0.6165          \n    P-Value [Acc &gt; NIR] : 6.804e-16       \n                                          \n                  Kappa : 0.6559          \n                                          \n Mcnemar's Test P-Value : 0.02064         \n                                          \n            Sensitivity : 0.7157          \n            Specificity : 0.9207          \n         Pos Pred Value : 0.8488          \n         Neg Pred Value : 0.8389          \n             Prevalence : 0.3835          \n         Detection Rate : 0.2744          \n   Detection Prevalence : 0.3233          \n      Balanced Accuracy : 0.8182          \n                                          \n       'Positive' Class : yes             \n                                          \n\n\n\n\n\n14.7.2 ROC 곡선\n\n# 예측 확률 \ntest.ada.prob &lt;- test.ada.pred$prob[,2]                # \"Survived = yes\"에 대한 예측 확률\n\nac  &lt;- titanic.ted.Imp$Survived                        # Test Dataset의 실제 class \npp  &lt;- as.numeric(test.ada.prob)                       # 예측 확률을 수치형으로 변환\n\n\n14.7.2.1 Package “pROC”\n\npacman::p_load(\"pROC\")\n\nada.roc  &lt;- roc(ac, pp, plot = T, col = \"gray\")        # roc(실제 class, 예측 확률)\nauc      &lt;- round(auc(ada.roc), 3)\nlegend(\"bottomright\", legend = auc, bty = \"n\")\n\n\n\n\n\n\n\n\nCaution! Package \"pROC\"를 통해 출력한 ROC 곡선은 다양한 함수를 이용해서 그래프를 수정할 수 있다.\n\n# 함수 plot.roc() 이용\nplot.roc(ada.roc,   \n         col=\"gray\",                                   # Line Color\n         print.auc = TRUE,                             # AUC 출력 여부\n         print.auc.col = \"red\",                        # AUC 글씨 색깔\n         print.thres = TRUE,                           # Cutoff Value 출력 여부\n         print.thres.pch = 19,                         # Cutoff Value를 표시하는 도형 모양\n         print.thres.col = \"red\",                      # Cutoff Value를 표시하는 도형의 색깔\n         auc.polygon = TRUE,                           # 곡선 아래 면적에 대한 여부\n         auc.polygon.col = \"gray90\")                   # 곡선 아래 면적의 색깔\n\n\n\n\n\n\n\n\n\n# 함수 ggroc() 이용\nggroc(ada.roc) +\nannotate(geom = \"text\", x = 0.9, y = 1.0,\nlabel = paste(\"AUC = \", auc),\nsize = 5,\ncolor=\"red\") +\ntheme_bw()\n\n\n\n\n\n\n\n\n\n\n14.7.2.2 Package “Epi”\n\npacman::p_load(\"Epi\")       \n# install_version(\"etm\", version = \"1.1\", repos = \"http://cran.us.r-project.org\")\n\nROC(pp, ac, plot = \"ROC\")                              # ROC(예측 확률, 실제 class)  \n\n\n\n\n\n\n\n\n\n\n14.7.2.3 Package “ROCR”\n\npacman::p_load(\"ROCR\")\n\nada.pred &lt;- prediction(pp, ac)                         # prediction(예측 확률, 실제 class) \n\nada.perf &lt;- performance(ada.pred, \"tpr\", \"fpr\")        # performance(, \"민감도\", \"1-특이도\")                      \nplot(ada.perf, col = \"gray\")                           # ROC Curve\n\nperf.auc   &lt;- performance(ada.pred, \"auc\")             # AUC\nauc        &lt;- attributes(perf.auc)$y.values\nlegend(\"bottomright\", legend = auc, bty = \"n\")\n\n\n\n\n\n\n\n\n\n\n\n\n14.7.3 향상 차트\n\n14.7.3.1 Package “ROCR”\n\nada.perf &lt;- performance(ada.pred, \"lift\", \"rpp\")       # Lift Chart                      \nplot(ada.perf, main = \"lift curve\",\n     colorize = T,                                     # Coloring according to cutoff \n     lwd = 2)",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>AdaBoost</span>"
    ]
  },
  {
    "objectID": "GBM.html",
    "href": "GBM.html",
    "title": "15  Gradient Boosting",
    "section": "",
    "text": "15.1 데이터 불러오기\npacman::p_load(\"data.table\", \n               \"tidyverse\", \n               \"dplyr\", \"tidyr\",\n               \"ggplot2\", \"GGally\",\n               \"caret\",\n               \"gbm\")                                                   # For gbm\n\ntitanic &lt;- fread(\"../Titanic.csv\")                                      # 데이터 불러오기\n\ntitanic %&gt;%\n  as_tibble\n# A tibble: 891 × 11\n   Survived Pclass Name                                                Sex      Age SibSp Parch Ticket            Fare Cabin  Embarked\n      &lt;int&gt;  &lt;int&gt; &lt;chr&gt;                                               &lt;chr&gt;  &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;   \n 1        0      3 Braund, Mr. Owen Harris                             male      22     1     0 A/5 21171         7.25 \"\"     S       \n 2        1      1 Cumings, Mrs. John Bradley (Florence Briggs Thayer) female    38     1     0 PC 17599         71.3  \"C85\"  C       \n 3        1      3 Heikkinen, Miss. Laina                              female    26     0     0 STON/O2. 3101282  7.92 \"\"     S       \n 4        1      1 Futrelle, Mrs. Jacques Heath (Lily May Peel)        female    35     1     0 113803           53.1  \"C123\" S       \n 5        0      3 Allen, Mr. William Henry                            male      35     0     0 373450            8.05 \"\"     S       \n 6        0      3 Moran, Mr. James                                    male      NA     0     0 330877            8.46 \"\"     Q       \n 7        0      1 McCarthy, Mr. Timothy J                             male      54     0     0 17463            51.9  \"E46\"  S       \n 8        0      3 Palsson, Master. Gosta Leonard                      male       2     3     1 349909           21.1  \"\"     S       \n 9        1      3 Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)   female    27     0     2 347742           11.1  \"\"     S       \n10        1      2 Nasser, Mrs. Nicholas (Adele Achem)                 female    14     1     0 237736           30.1  \"\"     C       \n# ℹ 881 more rows",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Gradient Boosting</span>"
    ]
  },
  {
    "objectID": "GBM.html#데이터-전처리-i",
    "href": "GBM.html#데이터-전처리-i",
    "title": "15  Gradient Boosting",
    "section": "15.2 데이터 전처리 I",
    "text": "15.2 데이터 전처리 I\n\n# 1. Convert to Factor\nfac.col &lt;- c(\"Pclass\", \"Sex\")\n\ntitanic &lt;- titanic %&gt;% \n  data.frame() %&gt;%                                                      # Data Frame 형태로 변환 \n  mutate_at(fac.col, as.factor)                                         # 범주형으로 변환\n\nglimpse(titanic)                                                        # 데이터 구조 확인\n\nRows: 891\nColumns: 11\n$ Survived &lt;int&gt; 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0…\n$ Pclass   &lt;fct&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3, 2, 2, 3, 1, 3, 3, 3, 1, 3, 3, 1, 1, 3, 2, 1, 1, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 1, 1, 2, 3, 2, 3, 3…\n$ Name     &lt;chr&gt; \"Braund, Mr. Owen Harris\", \"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\", \"Heikkinen, Miss. Laina\", \"Futrelle, Mrs. Jacques Heath (Lily May Peel)\", \"Allen, Mr. William Henry…\n$ Sex      &lt;fct&gt; male, female, female, female, male, male, male, male, female, female, female, female, male, male, female, female, male, male, female, female, male, male, female, male, female, femal…\n$ Age      &lt;dbl&gt; 22.0, 38.0, 26.0, 35.0, 35.0, NA, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, NA, 31.0, NA, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, NA, 19.0, NA, NA, 40.0, NA, NA, 66.…\n$ SibSp    &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0, 0, 0, 0, 0, 3, 1, 0, 3, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 1, 0, 0, 1, 0, 2, 1, 4, 0, 1, 1, 0, 0, 0, 0, 1, 5, 0…\n$ Parch    &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 5, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 2, 2, 0…\n$ Ticket   &lt;chr&gt; \"A/5 21171\", \"PC 17599\", \"STON/O2. 3101282\", \"113803\", \"373450\", \"330877\", \"17463\", \"349909\", \"347742\", \"237736\", \"PP 9549\", \"113783\", \"A/5. 2151\", \"347082\", \"350406\", \"248706\", \"38…\n$ Fare     &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625, 21.0750, 11.1333, 30.0708, 16.7000, 26.5500, 8.0500, 31.2750, 7.8542, 16.0000, 29.1250, 13.0000, 18.0000, 7.2250, 26.0000,…\n$ Cabin    &lt;chr&gt; \"\", \"C85\", \"\", \"C123\", \"\", \"\", \"E46\", \"\", \"\", \"\", \"G6\", \"C103\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"D56\", \"\", \"A6\", \"\", \"\", \"\", \"C23 C25 C27\", \"\", \"\", \"\", \"B78\", \"\", \"\", \"\", \"\", \"\"…\n$ Embarked &lt;chr&gt; \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"C\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"Q\", \"S\", \"C\", \"C\", \"Q\", \"S\", \"C\", \"S\", \"…\n\n# 2. Generate New Variable\ntitanic &lt;- titanic %&gt;%\n  mutate(FamSize = SibSp + Parch)                                       # \"FamSize = 형제 및 배우자 수 + 부모님 및 자녀 수\"로 가족 수를 의미하는 새로운 변수\n\nglimpse(titanic)                                                        # 데이터 구조 확인\n\nRows: 891\nColumns: 12\n$ Survived &lt;int&gt; 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0…\n$ Pclass   &lt;fct&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3, 2, 2, 3, 1, 3, 3, 3, 1, 3, 3, 1, 1, 3, 2, 1, 1, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 1, 1, 2, 3, 2, 3, 3…\n$ Name     &lt;chr&gt; \"Braund, Mr. Owen Harris\", \"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\", \"Heikkinen, Miss. Laina\", \"Futrelle, Mrs. Jacques Heath (Lily May Peel)\", \"Allen, Mr. William Henry…\n$ Sex      &lt;fct&gt; male, female, female, female, male, male, male, male, female, female, female, female, male, male, female, female, male, male, female, female, male, male, female, male, female, femal…\n$ Age      &lt;dbl&gt; 22.0, 38.0, 26.0, 35.0, 35.0, NA, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, NA, 31.0, NA, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, NA, 19.0, NA, NA, 40.0, NA, NA, 66.…\n$ SibSp    &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0, 0, 0, 0, 0, 3, 1, 0, 3, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 1, 0, 0, 1, 0, 2, 1, 4, 0, 1, 1, 0, 0, 0, 0, 1, 5, 0…\n$ Parch    &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 5, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 2, 2, 0…\n$ Ticket   &lt;chr&gt; \"A/5 21171\", \"PC 17599\", \"STON/O2. 3101282\", \"113803\", \"373450\", \"330877\", \"17463\", \"349909\", \"347742\", \"237736\", \"PP 9549\", \"113783\", \"A/5. 2151\", \"347082\", \"350406\", \"248706\", \"38…\n$ Fare     &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625, 21.0750, 11.1333, 30.0708, 16.7000, 26.5500, 8.0500, 31.2750, 7.8542, 16.0000, 29.1250, 13.0000, 18.0000, 7.2250, 26.0000,…\n$ Cabin    &lt;chr&gt; \"\", \"C85\", \"\", \"C123\", \"\", \"\", \"E46\", \"\", \"\", \"\", \"G6\", \"C103\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"D56\", \"\", \"A6\", \"\", \"\", \"\", \"C23 C25 C27\", \"\", \"\", \"\", \"B78\", \"\", \"\", \"\", \"\", \"\"…\n$ Embarked &lt;chr&gt; \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"C\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"Q\", \"S\", \"C\", \"C\", \"Q\", \"S\", \"C\", \"S\", \"…\n$ FamSize  &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 4, 2, 1, 2, 0, 0, 6, 0, 0, 5, 0, 1, 0, 0, 0, 0, 0, 4, 6, 0, 5, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 3, 0, 0, 1, 0, 2, 1, 5, 0, 1, 1, 1, 0, 0, 0, 3, 7, 0…\n\n# 3. Select Variables used for Analysis\ntitanic1 &lt;- titanic %&gt;% \n  dplyr::select(Survived, Pclass, Sex, Age, Fare, FamSize)              # 분석에 사용할 변수 선택\n\nglimpse(titanic1)                                                       # 데이터 구조 확인\n\nRows: 891\nColumns: 6\n$ Survived &lt;int&gt; 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0…\n$ Pclass   &lt;fct&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3, 2, 2, 3, 1, 3, 3, 3, 1, 3, 3, 1, 1, 3, 2, 1, 1, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 1, 1, 2, 3, 2, 3, 3…\n$ Sex      &lt;fct&gt; male, female, female, female, male, male, male, male, female, female, female, female, male, male, female, female, male, male, female, female, male, male, female, male, female, femal…\n$ Age      &lt;dbl&gt; 22.0, 38.0, 26.0, 35.0, 35.0, NA, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, NA, 31.0, NA, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, NA, 19.0, NA, NA, 40.0, NA, NA, 66.…\n$ Fare     &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625, 21.0750, 11.1333, 30.0708, 16.7000, 26.5500, 8.0500, 31.2750, 7.8542, 16.0000, 29.1250, 13.0000, 18.0000, 7.2250, 26.0000,…\n$ FamSize  &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 4, 2, 1, 2, 0, 0, 6, 0, 0, 5, 0, 1, 0, 0, 0, 0, 0, 4, 6, 0, 5, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 3, 0, 0, 1, 0, 2, 1, 5, 0, 1, 1, 1, 0, 0, 0, 3, 7, 0…",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Gradient Boosting</span>"
    ]
  },
  {
    "objectID": "GBM.html#데이터-탐색",
    "href": "GBM.html#데이터-탐색",
    "title": "15  Gradient Boosting",
    "section": "15.3 데이터 탐색",
    "text": "15.3 데이터 탐색\n\nggpairs(titanic1,                                        \n        aes(colour = as.factor(Survived))) +                         # Target의 범주에 따라 색깔을 다르게 표현\n  theme_bw()\n\n\n\n\n\n\n\nggpairs(titanic1,                                     \n        aes(colour = as.factor(Survived), alpha = 0.8)) +            # Target의 범주에 따라 색깔을 다르게 표현\n  scale_colour_manual(values = c(\"#00798c\", \"#d1495b\")) +            # 특정 색깔 지정\n  scale_fill_manual(values = c(\"#00798c\", \"#d1495b\")) +              # 특정 색깔 지정\n  theme_bw()",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Gradient Boosting</span>"
    ]
  },
  {
    "objectID": "GBM.html#데이터-분할",
    "href": "GBM.html#데이터-분할",
    "title": "15  Gradient Boosting",
    "section": "15.4 데이터 분할",
    "text": "15.4 데이터 분할\n\n# Partition (Training Dataset : Test Dataset = 7:3)\ny      &lt;- titanic1$Survived                           # Target\n\nset.seed(200)\nind    &lt;- createDataPartition(y, p = 0.7, list  =T)   # Index를 이용하여 7:3으로 분할\ntitanic.trd &lt;- titanic1[ind$Resample1,]               # Training Dataset\ntitanic.ted &lt;- titanic1[-ind$Resample1,]              # Test Dataset",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Gradient Boosting</span>"
    ]
  },
  {
    "objectID": "GBM.html#데이터-전처리-ii",
    "href": "GBM.html#데이터-전처리-ii",
    "title": "15  Gradient Boosting",
    "section": "15.5 데이터 전처리 II",
    "text": "15.5 데이터 전처리 II\n\n# Imputation\ntitanic.trd.Imp &lt;- titanic.trd %&gt;% \n  mutate(Age = replace_na(Age, mean(Age, na.rm = TRUE)))                 # 평균으로 결측값 대체\n\ntitanic.ted.Imp &lt;- titanic.ted %&gt;% \n  mutate(Age = replace_na(Age, mean(titanic.trd$Age, na.rm = TRUE)))     # Training Dataset을 이용하여 결측값 대체\n\nglimpse(titanic.trd.Imp)                                                 # 데이터 구조 확인\n\nRows: 624\nColumns: 6\n$ Survived &lt;int&gt; 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1…\n$ Pclass   &lt;fct&gt; 1, 3, 1, 3, 1, 3, 2, 3, 3, 3, 3, 2, 3, 3, 3, 2, 2, 3, 1, 3, 1, 3, 3, 1, 1, 2, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 1, 1, 2, 3, 2, 3, 3, 1, 3, 1, 3, 2, 3, 3, 2, 3, 3, 3, 3, 3, 2…\n$ Sex      &lt;fct&gt; female, female, female, male, male, female, female, female, male, male, female, female, male, female, female, male, male, female, male, female, male, female, male, male, female, mal…\n$ Age      &lt;dbl&gt; 38.00000, 26.00000, 35.00000, 35.00000, 54.00000, 27.00000, 14.00000, 4.00000, 20.00000, 39.00000, 14.00000, 55.00000, 2.00000, 31.00000, 29.92818, 35.00000, 34.00000, 15.00000, 28.…\n$ Fare     &lt;dbl&gt; 71.2833, 7.9250, 53.1000, 8.0500, 51.8625, 11.1333, 30.0708, 16.7000, 8.0500, 31.2750, 7.8542, 16.0000, 29.1250, 18.0000, 7.2250, 26.0000, 13.0000, 8.0292, 35.5000, 21.0750, 263.000…\n$ FamSize  &lt;int&gt; 1, 0, 1, 0, 0, 2, 1, 2, 0, 6, 0, 0, 5, 1, 0, 0, 0, 0, 0, 4, 5, 0, 0, 0, 1, 0, 1, 1, 0, 0, 2, 0, 0, 0, 1, 0, 5, 0, 1, 1, 1, 0, 0, 0, 3, 7, 0, 1, 5, 0, 2, 0, 0, 6, 0, 7, 0, 0, 0, 0, 0…\n\nglimpse(titanic.ted.Imp)                                                 # 데이터 구조 확인\n\nRows: 267\nColumns: 6\n$ Survived &lt;int&gt; 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0…\n$ Pclass   &lt;fct&gt; 3, 3, 3, 1, 2, 3, 3, 3, 3, 3, 2, 2, 3, 3, 1, 3, 2, 3, 3, 3, 2, 3, 3, 1, 3, 3, 3, 1, 3, 3, 3, 3, 3, 2, 1, 3, 2, 3, 2, 3, 3, 2, 3, 3, 3, 3, 1, 3, 3, 3, 1, 3, 2, 3, 3, 1, 3, 3, 3, 3, 3…\n$ Sex      &lt;fct&gt; male, male, male, female, male, female, male, female, female, female, female, female, male, female, female, male, male, male, male, male, male, male, female, male, male, male, male,…\n$ Age      &lt;dbl&gt; 22.00000, 29.92818, 2.00000, 58.00000, 29.92818, 38.00000, 29.92818, 29.92818, 14.00000, 40.00000, 27.00000, 3.00000, 29.92818, 18.00000, 38.00000, 26.00000, 21.00000, 26.00000, 25.…\n$ Fare     &lt;dbl&gt; 7.2500, 8.4583, 21.0750, 26.5500, 13.0000, 31.3875, 7.2250, 7.7500, 11.2417, 9.4750, 21.0000, 41.5792, 21.6792, 17.8000, 80.0000, 8.6625, 73.5000, 14.4542, 7.6500, 7.8958, 29.0000, …\n$ FamSize  &lt;int&gt; 1, 0, 4, 0, 0, 6, 0, 0, 1, 1, 1, 3, 2, 1, 0, 2, 0, 1, 0, 0, 2, 0, 0, 0, 4, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 2, 0, 4, 0, 2, 1, 0, 0, 0, 0, 2, 4, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 1…",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Gradient Boosting</span>"
    ]
  },
  {
    "objectID": "GBM.html#모형-훈련",
    "href": "GBM.html#모형-훈련",
    "title": "15  Gradient Boosting",
    "section": "15.6 모형 훈련",
    "text": "15.6 모형 훈련\nBoosting은 다수의 약한 학습자(간단하면서 성능이 낮은 예측 모형)을 순차적으로 학습하는 앙상블 기법이다. Boosting의 특징은 이전 모형의 오차를 반영하여 다음 모형을 생성하며, 오차를 개선하는 방향으로 학습을 수행한다.\n\n\n\n\nGradient Boosting은 손실함수를 이용하여 손실함수가 작아지는 방향으로 예측값을 업데이트하며 이전 모형의 오차를 기반으로 다음 모형을 생성한다.\n\n\n\n\n\n\n\n\nR에서 Gradient Boosting을 수행하기 위해 package \"gbm\"에서 제공하는 함수 gbm()를 이용할 수 있으며, 함수의 자세한 옵션은 여기를 참고한다.\n\ngbm(formula, data, distribution, n.trees, interaction.depth, shrinkage, cv.folds, ...)       \n\n\nformula : Target과 예측 변수의 관계를 표현하기 위한 함수로써 일반적으로 Target ~ 예측 변수의 형태로 표현한다.\ndata : formula에 포함하고 있는 변수들의 데이터셋(Data Frame)\ndistribution : 손실함수\n\nClassification : \"bernoulli\" (이진 분류)\nRegression : \"gaussian\" (Squared Error)\n\nn.trees : 생성하고자 하는 트리 개수\ninteraction.depth : 트리의 최대 깊이\nshrinkage : 학습률\ncv.folds : \\(k\\)-Fold Cross Validation의 \\(k\\)(= Fold 수)\n\n값을 입력하면 Cross Validation를 통해 n.trees의 최적값을 찾을 수 있다.\n\n\n\nset.seed(100)                                         # Seed 고정 -&gt; 동일한 결과를 출력하기 위해\ntitanic.gbm &lt;- gbm(Survived~.,\n                   data = titanic.trd.Imp,\n                   distribution = \"bernoulli\",               \n                   n.trees = 50,                    \n                   interaction.depth = 30, \n                   shrinkage = 0.1)\n\nCaution! 함수 gbm()을 사용하려면 이진 분류문제에서 Target은 \"0\" 또는 \"1\" 값을 가지는 수치형이어야 한다.\n\n# 변수 중요도\nsummary.gbm(titanic.gbm, las = 2)  \n\n\n\n\n\n\n\n\n            var   rel.inf\nSex         Sex 29.100291\nFare       Fare 28.998586\nAge         Age 22.193140\nPclass   Pclass 11.287106\nFamSize FamSize  8.420878\n\n\nResult! 변수 Sex가 Target Survived을 분류하는 데 있어 중요하다.",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Gradient Boosting</span>"
    ]
  },
  {
    "objectID": "GBM.html#모형-평가",
    "href": "GBM.html#모형-평가",
    "title": "15  Gradient Boosting",
    "section": "15.7 모형 평가",
    "text": "15.7 모형 평가\nCaution! 모형 평가를 위해 Test Dataset에 대한 예측 class/확률 이 필요하며, 함수 predict()를 이용하여 생성한다.\n\n# 예측 확률 생성 \ntest.gbm.prob &lt;- predict(titanic.gbm,\n                         newdata = titanic.ted.Imp[,-1],# Test Dataset including Only 예측 변수 \n                         type = \"response\")             # \"Survived = 1\"에 대한 예측 확률 생성\n\ntest.gbm.prob %&gt;%\n  as_tibble\n\n# A tibble: 267 × 1\n    value\n    &lt;dbl&gt;\n 1 0.113 \n 2 0.0571\n 3 0.412 \n 4 0.936 \n 5 0.249 \n 6 0.0670\n 7 0.0433\n 8 0.655 \n 9 0.801 \n10 0.215 \n# ℹ 257 more rows\n\n\n\n\n15.7.1 ConfusionMatrix\n\n# 예측 class 생성\ncv &lt;- 0.5                                                          # Cutoff Value\ntest.gbm.class &lt;- as.factor(ifelse(test.gbm.prob &gt; cv, \"1\", \"0\"))  # 예측 확률 &gt; cv이면 \"Survived = 1\" 아니면 \"Survived = 0\"\n\ntest.gbm.class %&gt;%\n  as_tibble\n\n# A tibble: 267 × 1\n   value\n   &lt;fct&gt;\n 1 0    \n 2 0    \n 3 0    \n 4 1    \n 5 0    \n 6 0    \n 7 0    \n 8 1    \n 9 1    \n10 0    \n# ℹ 257 more rows\n\n\n\nCM   &lt;- caret::confusionMatrix(test.gbm.class, as.factor(titanic.ted.Imp$Survived), \n                               positive = \"1\")         # confusionMatrix(예측 class, 실제 class, positive = \"관심 class\")\nCM\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 156  26\n         1  12  73\n                                          \n               Accuracy : 0.8577          \n                 95% CI : (0.8099, 0.8973)\n    No Information Rate : 0.6292          \n    P-Value [Acc &gt; NIR] : &lt; 2e-16         \n                                          \n                  Kappa : 0.6859          \n                                          \n Mcnemar's Test P-Value : 0.03496         \n                                          \n            Sensitivity : 0.7374          \n            Specificity : 0.9286          \n         Pos Pred Value : 0.8588          \n         Neg Pred Value : 0.8571          \n             Prevalence : 0.3708          \n         Detection Rate : 0.2734          \n   Detection Prevalence : 0.3184          \n      Balanced Accuracy : 0.8330          \n                                          \n       'Positive' Class : 1               \n                                          \n\n\n\n\n\n15.7.2 ROC 곡선\n\nac  &lt;- titanic.ted.Imp$Survived                        # Test Dataset의 실제 class \npp  &lt;- as.numeric(test.gbm.prob)                       # 예측 확률을 수치형으로 변환\n\n\n15.7.2.1 Package “pROC”\n\npacman::p_load(\"pROC\")\n\ngbm.roc  &lt;- roc(ac, pp, plot = T, col = \"gray\")        # roc(실제 class, 예측 확률)\nauc      &lt;- round(auc(gbm.roc), 3)\nlegend(\"bottomright\", legend = auc, bty = \"n\")\n\n\n\n\n\n\n\n\nCaution! Package \"pROC\"를 통해 출력한 ROC 곡선은 다양한 함수를 이용해서 그래프를 수정할 수 있다.\n\n# 함수 plot.roc() 이용\nplot.roc(gbm.roc,   \n         col=\"gray\",                                   # Line Color\n         print.auc = TRUE,                             # AUC 출력 여부\n         print.auc.col = \"red\",                        # AUC 글씨 색깔\n         print.thres = TRUE,                           # Cutoff Value 출력 여부\n         print.thres.pch = 19,                         # Cutoff Value를 표시하는 도형 모양\n         print.thres.col = \"red\",                      # Cutoff Value를 표시하는 도형의 색깔\n         auc.polygon = TRUE,                           # 곡선 아래 면적에 대한 여부\n         auc.polygon.col = \"gray90\")                   # 곡선 아래 면적의 색깔\n\n\n\n\n\n\n\n\n\n# 함수 ggroc() 이용\nggroc(gbm.roc) +\nannotate(geom = \"text\", x = 0.9, y = 1.0,\nlabel = paste(\"AUC = \", auc),\nsize = 5,\ncolor=\"red\") +\ntheme_bw()\n\n\n\n\n\n\n\n\n\n\n15.7.2.2 Package “Epi”\n\npacman::p_load(\"Epi\")       \n# install_version(\"etm\", version = \"1.1\", repos = \"http://cran.us.r-project.org\")\n\nROC(pp, ac, plot = \"ROC\")                              # ROC(예측 확률, 실제 class)  \n\n\n\n\n\n\n\n\n\n\n15.7.2.3 Package “ROCR”\n\npacman::p_load(\"ROCR\")\n\ngbm.pred &lt;- prediction(pp, ac)                         # prediction(예측 확률, 실제 class) \n\ngbm.perf &lt;- performance(gbm.pred, \"tpr\", \"fpr\")        # performance(, \"민감도\", \"1-특이도\")                      \nplot(gbm.perf, col = \"gray\")                           # ROC Curve\n\nperf.auc   &lt;- performance(gbm.pred, \"auc\")             # AUC\nauc        &lt;- attributes(perf.auc)$y.values\nlegend(\"bottomright\", legend = auc, bty = \"n\")\n\n\n\n\n\n\n\n\n\n\n\n\n15.7.3 향상 차트\n\n15.7.3.1 Package “ROCR”\n\ngbm.perf &lt;- performance(gbm.pred, \"lift\", \"rpp\")       # Lift Chart                      \nplot(gbm.perf, main = \"lift curve\",\n     colorize = T,                                     # Coloring according to cutoff \n     lwd = 2)",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Gradient Boosting</span>"
    ]
  },
  {
    "objectID": "XGBoost.html",
    "href": "XGBoost.html",
    "title": "16  XGBoost",
    "section": "",
    "text": "16.1 데이터 불러오기\npacman::p_load(\"data.table\", \n               \"tidyverse\", \n               \"dplyr\", \"tidyr\",\n               \"ggplot2\", \"GGally\",\n               \"caret\",\n               \"Matrix\",                                                # For sparse.model.matrix\n               \"xgboost\")                                               # For xgb.train\n\ntitanic &lt;- fread(\"../Titanic.csv\")                                      # 데이터 불러오기\n\ntitanic %&gt;%\n  as_tibble\n# A tibble: 891 × 11\n   Survived Pclass Name                                                Sex      Age SibSp Parch Ticket            Fare Cabin  Embarked\n      &lt;int&gt;  &lt;int&gt; &lt;chr&gt;                                               &lt;chr&gt;  &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;            &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;   \n 1        0      3 Braund, Mr. Owen Harris                             male      22     1     0 A/5 21171         7.25 \"\"     S       \n 2        1      1 Cumings, Mrs. John Bradley (Florence Briggs Thayer) female    38     1     0 PC 17599         71.3  \"C85\"  C       \n 3        1      3 Heikkinen, Miss. Laina                              female    26     0     0 STON/O2. 3101282  7.92 \"\"     S       \n 4        1      1 Futrelle, Mrs. Jacques Heath (Lily May Peel)        female    35     1     0 113803           53.1  \"C123\" S       \n 5        0      3 Allen, Mr. William Henry                            male      35     0     0 373450            8.05 \"\"     S       \n 6        0      3 Moran, Mr. James                                    male      NA     0     0 330877            8.46 \"\"     Q       \n 7        0      1 McCarthy, Mr. Timothy J                             male      54     0     0 17463            51.9  \"E46\"  S       \n 8        0      3 Palsson, Master. Gosta Leonard                      male       2     3     1 349909           21.1  \"\"     S       \n 9        1      3 Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)   female    27     0     2 347742           11.1  \"\"     S       \n10        1      2 Nasser, Mrs. Nicholas (Adele Achem)                 female    14     1     0 237736           30.1  \"\"     C       \n# ℹ 881 more rows",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>XGBoost</span>"
    ]
  },
  {
    "objectID": "XGBoost.html#데이터-전처리-i",
    "href": "XGBoost.html#데이터-전처리-i",
    "title": "16  XGBoost",
    "section": "16.2 데이터 전처리 I",
    "text": "16.2 데이터 전처리 I\n\n# 1. Convert to Factor\nfac.col &lt;- c(\"Pclass\", \"Sex\",\n             # Target\n             \"Survived\")\n\ntitanic &lt;- titanic %&gt;% \n  data.frame() %&gt;%                                                      # Data Frame 형태로 변환 \n  mutate_at(fac.col, as.factor)                                         # 범주형으로 변환\n\nglimpse(titanic)                                                        # 데이터 구조 확인\n\nRows: 891\nColumns: 11\n$ Survived &lt;fct&gt; 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0…\n$ Pclass   &lt;fct&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3, 2, 2, 3, 1, 3, 3, 3, 1, 3, 3, 1, 1, 3, 2, 1, 1, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 1, 1, 2, 3, 2, 3, 3…\n$ Name     &lt;chr&gt; \"Braund, Mr. Owen Harris\", \"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\", \"Heikkinen, Miss. Laina\", \"Futrelle, Mrs. Jacques Heath (Lily May Peel)\", \"Allen, Mr. William Henry…\n$ Sex      &lt;fct&gt; male, female, female, female, male, male, male, male, female, female, female, female, male, male, female, female, male, male, female, female, male, male, female, male, female, femal…\n$ Age      &lt;dbl&gt; 22.0, 38.0, 26.0, 35.0, 35.0, NA, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, NA, 31.0, NA, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, NA, 19.0, NA, NA, 40.0, NA, NA, 66.…\n$ SibSp    &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0, 0, 0, 0, 0, 3, 1, 0, 3, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 1, 0, 0, 1, 0, 2, 1, 4, 0, 1, 1, 0, 0, 0, 0, 1, 5, 0…\n$ Parch    &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 5, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 2, 2, 0…\n$ Ticket   &lt;chr&gt; \"A/5 21171\", \"PC 17599\", \"STON/O2. 3101282\", \"113803\", \"373450\", \"330877\", \"17463\", \"349909\", \"347742\", \"237736\", \"PP 9549\", \"113783\", \"A/5. 2151\", \"347082\", \"350406\", \"248706\", \"38…\n$ Fare     &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625, 21.0750, 11.1333, 30.0708, 16.7000, 26.5500, 8.0500, 31.2750, 7.8542, 16.0000, 29.1250, 13.0000, 18.0000, 7.2250, 26.0000,…\n$ Cabin    &lt;chr&gt; \"\", \"C85\", \"\", \"C123\", \"\", \"\", \"E46\", \"\", \"\", \"\", \"G6\", \"C103\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"D56\", \"\", \"A6\", \"\", \"\", \"\", \"C23 C25 C27\", \"\", \"\", \"\", \"B78\", \"\", \"\", \"\", \"\", \"\"…\n$ Embarked &lt;chr&gt; \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"C\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"Q\", \"S\", \"C\", \"C\", \"Q\", \"S\", \"C\", \"S\", \"…\n\n# 2. Generate New Variable\ntitanic &lt;- titanic %&gt;%\n  mutate(FamSize = SibSp + Parch)                                       # \"FamSize = 형제 및 배우자 수 + 부모님 및 자녀 수\"로 가족 수를 의미하는 새로운 변수\n\nglimpse(titanic)                                                        # 데이터 구조 확인\n\nRows: 891\nColumns: 12\n$ Survived &lt;fct&gt; 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0…\n$ Pclass   &lt;fct&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3, 2, 2, 3, 1, 3, 3, 3, 1, 3, 3, 1, 1, 3, 2, 1, 1, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 1, 1, 2, 3, 2, 3, 3…\n$ Name     &lt;chr&gt; \"Braund, Mr. Owen Harris\", \"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\", \"Heikkinen, Miss. Laina\", \"Futrelle, Mrs. Jacques Heath (Lily May Peel)\", \"Allen, Mr. William Henry…\n$ Sex      &lt;fct&gt; male, female, female, female, male, male, male, male, female, female, female, female, male, male, female, female, male, male, female, female, male, male, female, male, female, femal…\n$ Age      &lt;dbl&gt; 22.0, 38.0, 26.0, 35.0, 35.0, NA, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, NA, 31.0, NA, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, NA, 19.0, NA, NA, 40.0, NA, NA, 66.…\n$ SibSp    &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0, 0, 0, 0, 0, 3, 1, 0, 3, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 1, 0, 0, 1, 0, 2, 1, 4, 0, 1, 1, 0, 0, 0, 0, 1, 5, 0…\n$ Parch    &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 5, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 2, 2, 0…\n$ Ticket   &lt;chr&gt; \"A/5 21171\", \"PC 17599\", \"STON/O2. 3101282\", \"113803\", \"373450\", \"330877\", \"17463\", \"349909\", \"347742\", \"237736\", \"PP 9549\", \"113783\", \"A/5. 2151\", \"347082\", \"350406\", \"248706\", \"38…\n$ Fare     &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625, 21.0750, 11.1333, 30.0708, 16.7000, 26.5500, 8.0500, 31.2750, 7.8542, 16.0000, 29.1250, 13.0000, 18.0000, 7.2250, 26.0000,…\n$ Cabin    &lt;chr&gt; \"\", \"C85\", \"\", \"C123\", \"\", \"\", \"E46\", \"\", \"\", \"\", \"G6\", \"C103\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"D56\", \"\", \"A6\", \"\", \"\", \"\", \"C23 C25 C27\", \"\", \"\", \"\", \"B78\", \"\", \"\", \"\", \"\", \"\"…\n$ Embarked &lt;chr&gt; \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"C\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"Q\", \"S\", \"C\", \"C\", \"Q\", \"S\", \"C\", \"S\", \"…\n$ FamSize  &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 4, 2, 1, 2, 0, 0, 6, 0, 0, 5, 0, 1, 0, 0, 0, 0, 0, 4, 6, 0, 5, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 3, 0, 0, 1, 0, 2, 1, 5, 0, 1, 1, 1, 0, 0, 0, 3, 7, 0…\n\n# 3. Select Variables used for Analysis\ntitanic1 &lt;- titanic %&gt;% \n  dplyr::select(Survived, Pclass, Sex, Age, Fare, FamSize)              # 분석에 사용할 변수 선택\n\nglimpse(titanic1)                                                       # 데이터 구조 확인\n\nRows: 891\nColumns: 6\n$ Survived &lt;fct&gt; 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0…\n$ Pclass   &lt;fct&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3, 2, 2, 3, 1, 3, 3, 3, 1, 3, 3, 1, 1, 3, 2, 1, 1, 3, 3, 3, 3, 3, 2, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 1, 2, 1, 1, 2, 3, 2, 3, 3…\n$ Sex      &lt;fct&gt; male, female, female, female, male, male, male, male, female, female, female, female, male, male, female, female, male, male, female, female, male, male, female, male, female, femal…\n$ Age      &lt;dbl&gt; 22.0, 38.0, 26.0, 35.0, 35.0, NA, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, NA, 31.0, NA, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, NA, 19.0, NA, NA, 40.0, NA, NA, 66.…\n$ Fare     &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625, 21.0750, 11.1333, 30.0708, 16.7000, 26.5500, 8.0500, 31.2750, 7.8542, 16.0000, 29.1250, 13.0000, 18.0000, 7.2250, 26.0000,…\n$ FamSize  &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 4, 2, 1, 2, 0, 0, 6, 0, 0, 5, 0, 1, 0, 0, 0, 0, 0, 4, 6, 0, 5, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 3, 0, 0, 1, 0, 2, 1, 5, 0, 1, 1, 1, 0, 0, 0, 3, 7, 0…",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>XGBoost</span>"
    ]
  },
  {
    "objectID": "XGBoost.html#데이터-탐색",
    "href": "XGBoost.html#데이터-탐색",
    "title": "16  XGBoost",
    "section": "16.3 데이터 탐색",
    "text": "16.3 데이터 탐색\n\nggpairs(titanic1,                                        \n        aes(colour = Survived)) +                         # Target의 범주에 따라 색깔을 다르게 표현\n  theme_bw()\n\n\n\n\n\n\n\nggpairs(titanic1,                                     \n        aes(colour = Survived, alpha = 0.8)) +            # Target의 범주에 따라 색깔을 다르게 표현\n  scale_colour_manual(values = c(\"#00798c\", \"#d1495b\")) + # 특정 색깔 지정\n  scale_fill_manual(values = c(\"#00798c\", \"#d1495b\")) +   # 특정 색깔 지정\n  theme_bw()",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>XGBoost</span>"
    ]
  },
  {
    "objectID": "XGBoost.html#데이터-분할",
    "href": "XGBoost.html#데이터-분할",
    "title": "16  XGBoost",
    "section": "16.4 데이터 분할",
    "text": "16.4 데이터 분할\n\n# Partition (Training Dataset : Test Dataset = 7:3)\ny      &lt;- titanic1$Survived                           # Target\n\nset.seed(200)\nind    &lt;- createDataPartition(y, p = 0.7, list  =T)   # Index를 이용하여 7:3으로 분할\ntitanic.trd &lt;- titanic1[ind$Resample1,]               # Training Dataset\ntitanic.ted &lt;- titanic1[-ind$Resample1,]              # Test Dataset",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>XGBoost</span>"
    ]
  },
  {
    "objectID": "XGBoost.html#데이터-전처리-ii",
    "href": "XGBoost.html#데이터-전처리-ii",
    "title": "16  XGBoost",
    "section": "16.5 데이터 전처리 II",
    "text": "16.5 데이터 전처리 II\n\n# Imputation\ntitanic.trd.Imp &lt;- titanic.trd %&gt;% \n  mutate(Age = replace_na(Age, mean(Age, na.rm = TRUE)))                 # 평균으로 결측값 대체\n\ntitanic.ted.Imp &lt;- titanic.ted %&gt;% \n  mutate(Age = replace_na(Age, mean(titanic.trd$Age, na.rm = TRUE)))     # Training Dataset을 이용하여 결측값 대체\n\nglimpse(titanic.trd.Imp)                                                 # 데이터 구조 확인\n\nRows: 625\nColumns: 6\n$ Survived &lt;fct&gt; 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1…\n$ Pclass   &lt;fct&gt; 3, 3, 1, 3, 3, 3, 3, 2, 3, 1, 3, 3, 2, 3, 3, 2, 1, 3, 3, 1, 3, 3, 1, 1, 3, 2, 1, 1, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 3, 3, 1, 3, 1, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 1, 2, 3…\n$ Sex      &lt;fct&gt; male, female, female, male, male, male, female, female, female, female, male, female, male, female, female, male, male, female, male, male, female, male, male, female, female, male,…\n$ Age      &lt;dbl&gt; 22.00000, 26.00000, 35.00000, 35.00000, 29.93737, 2.00000, 27.00000, 14.00000, 4.00000, 58.00000, 39.00000, 14.00000, 29.93737, 31.00000, 29.93737, 35.00000, 28.00000, 8.00000, 29.9…\n$ Fare     &lt;dbl&gt; 7.2500, 7.9250, 53.1000, 8.0500, 8.4583, 21.0750, 11.1333, 30.0708, 16.7000, 26.5500, 31.2750, 7.8542, 13.0000, 18.0000, 7.2250, 26.0000, 35.5000, 21.0750, 7.2250, 263.0000, 7.8792,…\n$ FamSize  &lt;int&gt; 1, 0, 1, 0, 0, 4, 2, 1, 2, 0, 6, 0, 0, 1, 0, 0, 0, 4, 0, 5, 0, 0, 0, 1, 0, 0, 1, 1, 0, 2, 1, 1, 1, 0, 0, 1, 0, 2, 1, 5, 1, 1, 0, 7, 0, 0, 5, 0, 2, 7, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 3…\n\nglimpse(titanic.ted.Imp)                                                 # 데이터 구조 확인\n\nRows: 266\nColumns: 6\n$ Survived &lt;fct&gt; 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0…\n$ Pclass   &lt;fct&gt; 1, 1, 3, 2, 3, 2, 3, 3, 3, 2, 3, 3, 2, 2, 3, 2, 1, 3, 2, 3, 3, 2, 2, 3, 3, 3, 3, 1, 2, 2, 3, 3, 3, 3, 3, 2, 3, 2, 2, 2, 3, 3, 2, 1, 3, 1, 3, 2, 1, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 1, 3…\n$ Sex      &lt;fct&gt; female, male, male, female, male, male, female, female, male, female, male, male, female, female, male, female, male, male, female, male, female, male, male, male, male, male, male,…\n$ Age      &lt;dbl&gt; 38.00000, 54.00000, 20.00000, 55.00000, 2.00000, 34.00000, 15.00000, 38.00000, 29.93737, 3.00000, 29.93737, 21.00000, 29.00000, 21.00000, 28.50000, 5.00000, 45.00000, 29.93737, 29.0…\n$ Fare     &lt;dbl&gt; 71.2833, 51.8625, 8.0500, 16.0000, 29.1250, 13.0000, 8.0292, 31.3875, 7.2292, 41.5792, 8.0500, 7.8000, 26.0000, 10.5000, 7.2292, 27.7500, 83.4750, 15.2458, 10.5000, 8.1583, 7.9250, …\n$ FamSize  &lt;int&gt; 1, 0, 0, 0, 5, 0, 0, 6, 0, 3, 0, 0, 1, 0, 0, 3, 1, 2, 0, 0, 6, 0, 0, 0, 0, 4, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 6, 2, 1, 0, 0, 1, 0, 2, 0, 0, 0, 0, 1, 0, 0, 1, 5, 2, 5, 0, 5, 0, 4, 0, 6…",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>XGBoost</span>"
    ]
  },
  {
    "objectID": "XGBoost.html#모형-훈련",
    "href": "XGBoost.html#모형-훈련",
    "title": "16  XGBoost",
    "section": "16.6 모형 훈련",
    "text": "16.6 모형 훈련\nBoosting은 다수의 약한 학습자(간단하면서 성능이 낮은 예측 모형)을 순차적으로 학습하는 앙상블 기법이다. Boosting의 특징은 이전 모형의 오차를 반영하여 다음 모형을 생성하며, 오차를 개선하는 방향으로 학습을 수행한다.\n\n\n\n\nXGBoost는 Extreme Gradient Boosting의 약어로 Gradient Boosting의 단점을 해결하기 위해 제안되었다. R에서 XGBoost을 수행하기 위해 package \"xgboost\"에서 제공하는 함수 xgb.train()를 이용할 수 있으며, 함수의 자세한 옵션은 여기를 참고한다.\nCaution! 함수 xgb.train()을 사용하려면 예측 변수와 Target 모두 수치형이여야 하며, “xgb.DMatrix”로 변환해야 한다. 이를 위해 다음과 같은 절차를 수행한다.\n\n범주형 예측 변수를 더미 변수로 변환하기 위해 함수 sparse.model.matrix()를 이용한다.\n\nTarget을 수치형으로 변환한다.\n함수 xgb.DMatrix()를 이용하여 “xgb.DMatrix”로 변환한다.\n\n\n# 1. Convert Factor Var. into Dummy Var. \ntrainm       &lt;- sparse.model.matrix(Survived ~.-1, # Survived Target으로 제외 \n                                    data = titanic.trd.Imp)  \n\ntrainm\n\n625 x 7 sparse Matrix of class \"dgCMatrix\"\n    Pclass1 Pclass2 Pclass3 Sexmale      Age     Fare FamSize\n1         .       .       1       1 22.00000   7.2500       1\n3         .       .       1       . 26.00000   7.9250       .\n4         1       .       .       . 35.00000  53.1000       1\n5         .       .       1       1 35.00000   8.0500       .\n6         .       .       1       1 29.93737   8.4583       .\n8         .       .       1       1  2.00000  21.0750       4\n9         .       .       1       . 27.00000  11.1333       2\n10        .       1       .       . 14.00000  30.0708       1\n11        .       .       1       .  4.00000  16.7000       2\n12        1       .       .       . 58.00000  26.5500       .\n14        .       .       1       1 39.00000  31.2750       6\n15        .       .       1       . 14.00000   7.8542       .\n18        .       1       .       1 29.93737  13.0000       .\n19        .       .       1       . 31.00000  18.0000       1\n20        .       .       1       . 29.93737   7.2250       .\n21        .       1       .       1 35.00000  26.0000       .\n24        1       .       .       1 28.00000  35.5000       .\n25        .       .       1       .  8.00000  21.0750       4\n27        .       .       1       1 29.93737   7.2250       .\n28        1       .       .       1 19.00000 263.0000       5\n29        .       .       1       . 29.93737   7.8792       .\n30        .       .       1       1 29.93737   7.8958       .\n31        1       .       .       1 40.00000  27.7208       .\n32        1       .       .       . 29.93737 146.5208       1\n33        .       .       1       . 29.93737   7.7500       .\n34        .       1       .       1 66.00000  10.5000       .\n35        1       .       .       1 28.00000  82.1708       1\n36        1       .       .       1 42.00000  52.0000       1\n38        .       .       1       1 21.00000   8.0500       .\n39        .       .       1       . 18.00000  18.0000       2\n40        .       .       1       . 14.00000  11.2417       1\n41        .       .       1       . 40.00000   9.4750       1\n42        .       1       .       . 27.00000  21.0000       1\n43        .       .       1       1 29.93737   7.8958       .\n45        .       .       1       . 19.00000   7.8792       .\n47        .       .       1       1 29.93737  15.5000       1\n48        .       .       1       . 29.93737   7.7500       .\n49        .       .       1       1 29.93737  21.6792       2\n50        .       .       1       . 18.00000  17.8000       1\n51        .       .       1       1  7.00000  39.6875       5\n53        1       .       .       . 49.00000  76.7292       1\n55        1       .       .       1 65.00000  61.9792       1\n56        1       .       .       1 29.93737  35.5000       .\n60        .       .       1       1 11.00000  46.9000       7\n61        .       .       1       1 22.00000   7.2292       .\n62        1       .       .       . 38.00000  80.0000       .\n64        .       .       1       1  4.00000  27.9000       5\n65        1       .       .       1 29.93737  27.7208       .\n70        .       .       1       1 26.00000   8.6625       2\n72        .       .       1       . 16.00000  46.9000       7\n74        .       .       1       1 26.00000  14.4542       1\n75        .       .       1       1 32.00000  56.4958       .\n76        .       .       1       1 25.00000   7.6500       .\n77        .       .       1       1 29.93737   7.8958       .\n79        .       1       .       1  0.83000  29.0000       2\n80        .       .       1       . 30.00000  12.4750       .\n82        .       .       1       1 29.00000   9.5000       .\n83        .       .       1       . 29.93737   7.7875       .\n84        1       .       .       1 28.00000  47.1000       .\n85        .       1       .       . 17.00000  10.5000       .\n86        .       .       1       . 33.00000  15.8500       3\n88        .       .       1       1 29.93737   8.0500       .\n89        1       .       .       . 23.00000 263.0000       5\n91        .       .       1       1 29.00000   8.0500       .\n92        .       .       1       1 20.00000   7.8542       .\n93        1       .       .       1 46.00000  61.1750       1\n94        .       .       1       1 26.00000  20.5750       3\n95        .       .       1       1 59.00000   7.2500       .\n96        .       .       1       1 29.93737   8.0500       .\n97        1       .       .       1 71.00000  34.6542       .\n103       1       .       .       1 21.00000  77.2875       1\n105       .       .       1       1 37.00000   7.9250       2\n107       .       .       1       . 21.00000   7.6500       .\n108       .       .       1       1 29.93737   7.7750       .\n110       .       .       1       . 29.93737  24.1500       1\n111       1       .       .       1 47.00000  52.0000       .\n112       .       .       1       . 14.50000  14.4542       1\n113       .       .       1       1 22.00000   8.0500       .\n114       .       .       1       . 20.00000   9.8250       1\n115       .       .       1       . 17.00000  14.4583       .\n116       .       .       1       1 21.00000   7.9250       .\n117       .       .       1       1 70.50000   7.7500       .\n119       1       .       .       1 24.00000 247.5208       1\n122       .       .       1       1 29.93737   8.0500       .\n125       1       .       .       1 54.00000  77.2875       1\n126       .       .       1       1 12.00000  11.2417       1\n128       .       .       1       1 24.00000   7.1417       .\n129       .       .       1       . 29.93737  22.3583       2\n130       .       .       1       1 45.00000   6.9750       .\n131       .       .       1       1 33.00000   7.8958       .\n132       .       .       1       1 20.00000   7.0500       .\n134       .       1       .       . 29.00000  26.0000       1\n136       .       1       .       1 23.00000  15.0458       .\n138       1       .       .       1 37.00000  53.1000       1\n141       .       .       1       . 29.93737  15.2458       2\n142       .       .       1       . 22.00000   7.7500       .\n143       .       .       1       . 24.00000  15.8500       1\n146       .       1       .       1 19.00000  36.7500       2\n147       .       .       1       1 27.00000   7.7958       .\n148       .       .       1       .  9.00000  34.3750       4\n149       .       1       .       1 36.50000  26.0000       2\n150       .       1       .       1 42.00000  13.0000       .\n151       .       1       .       1 51.00000  12.5250       .\n153       .       .       1       1 55.50000   8.0500       .\n154       .       .       1       1 40.50000  14.5000       2\n156       1       .       .       1 51.00000  61.3792       1\n157       .       .       1       . 16.00000   7.7333       .\n158       .       .       1       1 30.00000   8.0500       .\n160       .       .       1       1 29.93737  69.5500      10\n162       .       1       .       . 40.00000  15.7500       .\n163       .       .       1       1 26.00000   7.7750       .\n164       .       .       1       1 17.00000   8.6625       .\n167       1       .       .       . 29.93737  55.0000       1\n169       1       .       .       1 29.93737  25.9250       .\n171       1       .       .       1 61.00000  33.5000       .\n173       .       .       1       .  1.00000  11.1333       2\n174       .       .       1       1 21.00000   7.9250       .\n176       .       .       1       1 18.00000   7.8542       2\n179       .       1       .       1 30.00000  13.0000       .\n180       .       .       1       1 36.00000   .            .\n181       .       .       1       . 29.93737  69.5500      10\n182       .       1       .       1 29.93737  15.0500       .\n184       .       1       .       1  1.00000  39.0000       3\n185       .       .       1       .  4.00000  22.0250       2\n188       1       .       .       1 45.00000  26.5500       .\n189       .       .       1       1 40.00000  15.5000       2\n190       .       .       1       1 36.00000   7.8958       .\n191       .       1       .       . 32.00000  13.0000       .\n192       .       1       .       1 19.00000  13.0000       .\n194       .       1       .       1  3.00000  26.0000       2\n196       1       .       .       . 58.00000 146.5208       .\n197       .       .       1       1 29.93737   7.7500       .\n198       .       .       1       1 42.00000   8.4042       1\n199       .       .       1       . 29.93737   7.7500       .\n200       .       1       .       . 24.00000  13.0000       .\n202       .       .       1       1 29.93737  69.5500      10\n203       .       .       1       1 34.00000   6.4958       .\n204       .       .       1       1 45.50000   7.2250       .\n205       .       .       1       1 18.00000   8.0500       .\n206       .       .       1       .  2.00000  10.4625       1\n207       .       .       1       1 32.00000  15.8500       1\n209       .       .       1       . 16.00000   7.7500       .\n211       .       .       1       1 24.00000   7.0500       .\n212       .       1       .       . 35.00000  21.0000       .\n213       .       .       1       1 22.00000   7.2500       .\n214       .       1       .       1 30.00000  13.0000       .\n216       1       .       .       . 31.00000 113.2750       1\n217       .       .       1       . 27.00000   7.9250       .\n218       .       1       .       1 42.00000  27.0000       1\n219       1       .       .       . 32.00000  76.2917       .\n220       .       1       .       1 30.00000  10.5000       .\n223       .       .       1       1 51.00000   8.0500       .\n224       .       .       1       1 29.93737   7.8958       .\n226       .       .       1       1 22.00000   9.3500       .\n227       .       1       .       1 19.00000  10.5000       .\n229       .       1       .       1 18.00000  13.0000       .\n230       .       .       1       . 29.93737  25.4667       4\n232       .       .       1       1 29.00000   7.7750       .\n233       .       1       .       1 59.00000  13.5000       .\n235       .       1       .       1 24.00000  10.5000       .\n236       .       .       1       . 29.93737   7.5500       .\n237       .       1       .       1 44.00000  26.0000       1\n238       .       1       .       .  8.00000  26.2500       2\n240       .       1       .       1 33.00000  12.2750       .\n242       .       .       1       . 29.93737  15.5000       1\n243       .       1       .       1 29.00000  10.5000       .\n244       .       .       1       1 22.00000   7.1250       .\n245       .       .       1       1 30.00000   7.2250       .\n246       1       .       .       1 44.00000  90.0000       2\n247       .       .       1       . 25.00000   7.7750       .\n248       .       1       .       . 24.00000  14.5000       2\n249       1       .       .       1 37.00000  52.5542       2\n252       .       .       1       . 29.00000  10.4625       2\n253       1       .       .       1 62.00000  26.5500       .\n254       .       .       1       1 30.00000  16.1000       1\n255       .       .       1       . 41.00000  20.2125       2\n257       1       .       .       . 29.93737  79.2000       .\n258       1       .       .       . 30.00000  86.5000       .\n259       1       .       .       . 35.00000 512.3292       .\n262       .       .       1       1  3.00000  31.3875       6\n264       1       .       .       1 40.00000   .            .\n265       .       .       1       . 29.93737   7.7500       .\n266       .       1       .       1 36.00000  10.5000       .\n267       .       .       1       1 16.00000  39.6875       5\n269       1       .       .       . 58.00000 153.4625       1\n270       1       .       .       . 35.00000 135.6333       .\n273       .       1       .       . 41.00000  19.5000       1\n275       .       .       1       . 29.93737   7.7500       .\n276       1       .       .       . 63.00000  77.9583       1\n278       .       1       .       1 29.93737   .            .\n280       .       .       1       . 35.00000  20.2500       2\n281       .       .       1       1 65.00000   7.7500       .\n285       1       .       .       1 29.93737  26.0000       .\n286       .       .       1       1 33.00000   8.6625       .\n287       .       .       1       1 30.00000   9.5000       .\n288       .       .       1       1 22.00000   7.8958       .\n289       .       1       .       1 42.00000  13.0000       .\n290       .       .       1       . 22.00000   7.7500       .\n291       1       .       .       . 26.00000  78.8500       .\n292       1       .       .       . 19.00000  91.0792       1\n293       .       1       .       1 36.00000  12.8750       .\n294       .       .       1       . 24.00000   8.8500       .\n296       1       .       .       1 29.93737  27.7208       .\n297       .       .       1       1 23.50000   7.2292       .\n298       1       .       .       .  2.00000 151.5500       3\n299       1       .       .       1 29.93737  30.5000       .\n300       1       .       .       . 50.00000 247.5208       1\n302       .       .       1       1 29.93737  23.2500       2\n303       .       .       1       1 19.00000   .            .\n304       .       1       .       . 29.93737  12.3500       .\n305       .       .       1       1 29.93737   8.0500       .\n306       1       .       .       1  0.92000 151.5500       3\n307       1       .       .       . 29.93737 110.8833       .\n309       .       1       .       1 30.00000  24.0000       1\n311       1       .       .       . 24.00000  83.1583       .\n315       .       1       .       1 43.00000  26.2500       2\n316       .       .       1       . 26.00000   7.8542       .\n317       .       1       .       . 24.00000  26.0000       1\n319       1       .       .       . 31.00000 164.8667       2\n320       1       .       .       . 40.00000 134.5000       2\n322       .       .       1       1 27.00000   7.8958       .\n323       .       1       .       . 30.00000  12.3500       .\n324       .       1       .       . 22.00000  29.0000       2\n325       .       .       1       1 29.93737  69.5500      10\n327       .       .       1       1 61.00000   6.2375       .\n329       .       .       1       . 31.00000  20.5250       2\n330       1       .       .       . 16.00000  57.9792       1\n331       .       .       1       . 29.93737  23.2500       2\n332       1       .       .       1 45.50000  28.5000       .\n335       1       .       .       . 29.93737 133.6500       1\n336       .       .       1       1 29.93737   7.8958       .\n337       1       .       .       1 29.00000  66.6000       1\n339       .       .       1       1 45.00000   8.0500       .\n340       1       .       .       1 45.00000  35.5000       .\n341       .       1       .       1  2.00000  26.0000       2\n342       1       .       .       . 24.00000 263.0000       5\n343       .       1       .       1 28.00000  13.0000       .\n345       .       1       .       1 36.00000  13.0000       .\n346       .       1       .       . 24.00000  13.0000       .\n348       .       .       1       . 29.93737  16.1000       1\n349       .       .       1       1  3.00000  15.9000       2\n350       .       .       1       1 42.00000   8.6625       .\n352       1       .       .       1 29.93737  35.0000       .\n353       .       .       1       1 15.00000   7.2292       2\n354       .       .       1       1 25.00000  17.8000       1\n355       .       .       1       1 29.93737   7.2250       .\n356       .       .       1       1 28.00000   9.5000       .\n357       1       .       .       . 22.00000  55.0000       1\n360       .       .       1       . 29.93737   7.8792       .\n361       .       .       1       1 40.00000  27.9000       5\n362       .       1       .       1 29.00000  27.7208       1\n363       .       .       1       . 45.00000  14.4542       1\n365       .       .       1       1 29.93737  15.5000       1\n366       .       .       1       1 30.00000   7.2500       .\n367       1       .       .       . 60.00000  75.2500       1\n368       .       .       1       . 29.93737   7.2292       .\n370       1       .       .       . 24.00000  69.3000       .\n371       1       .       .       1 25.00000  55.4417       1\n372       .       .       1       1 18.00000   6.4958       1\n373       .       .       1       1 19.00000   8.0500       .\n374       1       .       .       1 22.00000 135.6333       .\n376       1       .       .       . 29.93737  82.1708       1\n377       .       .       1       . 22.00000   7.2500       .\n379       .       .       1       1 20.00000   4.0125       .\n381       1       .       .       . 42.00000 227.5250       .\n382       .       .       1       .  1.00000  15.7417       2\n383       .       .       1       1 32.00000   7.9250       .\n384       1       .       .       . 35.00000  52.0000       1\n385       .       .       1       1 29.93737   7.8958       .\n386       .       1       .       1 18.00000  73.5000       .\n387       .       .       1       1  1.00000  46.9000       7\n388       .       1       .       . 36.00000  13.0000       .\n389       .       .       1       1 29.93737   7.7292       .\n390       .       1       .       . 17.00000  12.0000       .\n391       1       .       .       1 36.00000 120.0000       3\n392       .       .       1       1 21.00000   7.7958       .\n393       .       .       1       1 28.00000   7.9250       2\n394       1       .       .       . 23.00000 113.2750       1\n395       .       .       1       . 24.00000  16.7000       2\n396       .       .       1       1 22.00000   7.7958       .\n397       .       .       1       . 31.00000   7.8542       .\n398       .       1       .       1 46.00000  26.0000       .\n399       .       1       .       1 23.00000  10.5000       .\n401       .       .       1       1 39.00000   7.9250       .\n402       .       .       1       1 26.00000   8.0500       .\n404       .       .       1       1 28.00000  15.8500       1\n405       .       .       1       . 20.00000   8.6625       .\n406       .       1       .       1 34.00000  21.0000       1\n407       .       .       1       1 51.00000   7.7500       .\n408       .       1       .       1  3.00000  18.7500       2\n410       .       .       1       . 29.93737  25.4667       4\n411       .       .       1       1 29.93737   7.8958       .\n414       .       1       .       1 29.93737   .            .\n417       .       1       .       . 34.00000  32.5000       2\n421       .       .       1       1 29.93737   7.8958       .\n422       .       .       1       1 21.00000   7.7333       .\n423       .       .       1       1 29.00000   7.8750       .\n425       .       .       1       1 18.00000  20.2125       2\n426       .       .       1       1 29.93737   7.2500       .\n428       .       1       .       . 19.00000  26.0000       .\n429       .       .       1       1 29.93737   7.7500       .\n431       1       .       .       1 28.00000  26.5500       .\n432       .       .       1       . 29.93737  16.1000       1\n433       .       1       .       . 42.00000  26.0000       1\n434       .       .       1       1 17.00000   7.1250       .\n435       1       .       .       1 50.00000  55.9000       1\n437       .       .       1       . 21.00000  34.3750       4\n438       .       1       .       . 24.00000  18.7500       5\n439       1       .       .       1 64.00000 263.0000       5\n443       .       .       1       1 25.00000   7.7750       1\n444       .       1       .       . 28.00000  13.0000       .\n446       1       .       .       1  4.00000  81.8583       2\n449       .       .       1       .  5.00000  19.2583       3\n451       .       1       .       1 36.00000  27.7500       3\n453       1       .       .       1 30.00000  27.7500       .\n454       1       .       .       1 49.00000  89.1042       1\n456       .       .       1       1 29.00000   7.8958       .\n459       .       1       .       . 50.00000  10.5000       .\n460       .       .       1       1 29.93737   7.7500       .\n461       1       .       .       1 48.00000  26.5500       .\n463       1       .       .       1 47.00000  38.5000       .\n464       .       1       .       1 48.00000  13.0000       .\n465       .       .       1       1 29.93737   8.0500       .\n466       .       .       1       1 38.00000   7.0500       .\n468       1       .       .       1 56.00000  26.5500       .\n470       .       .       1       .  0.75000  19.2583       3\n471       .       .       1       1 29.93737   7.2500       .\n472       .       .       1       1 38.00000   8.6625       .\n474       .       1       .       . 23.00000  13.7917       .\n475       .       .       1       . 22.00000   9.8375       .\n479       .       .       1       1 22.00000   7.5208       .\n480       .       .       1       .  2.00000  12.2875       1\n481       .       .       1       1  9.00000  46.9000       7\n484       .       .       1       . 63.00000   9.5875       .\n485       1       .       .       1 25.00000  91.0792       1\n486       .       .       1       . 29.93737  25.4667       4\n487       1       .       .       . 35.00000  90.0000       1\n489       .       .       1       1 30.00000   8.0500       .\n491       .       .       1       1 29.93737  19.9667       1\n493       1       .       .       1 55.00000  30.5000       .\n494       1       .       .       1 71.00000  49.5042       .\n497       1       .       .       . 54.00000  78.2667       1\n498       .       .       1       1 29.93737  15.1000       .\n499       1       .       .       . 25.00000 151.5500       3\n500       .       .       1       1 24.00000   7.7958       .\n501       .       .       1       1 17.00000   8.6625       .\n502       .       .       1       . 21.00000   7.7500       .\n503       .       .       1       . 29.93737   7.6292       .\n504       .       .       1       . 37.00000   9.5875       .\n505       1       .       .       . 16.00000  86.5000       .\n506       1       .       .       1 18.00000 108.9000       1\n507       .       1       .       . 33.00000  26.0000       2\n508       1       .       .       1 29.93737  26.5500       .\n509       .       .       1       1 28.00000  22.5250       .\n511       .       .       1       1 29.00000   7.7500       .\n512       .       .       1       1 29.93737   8.0500       .\n513       1       .       .       1 36.00000  26.2875       .\n514       1       .       .       . 54.00000  59.4000       1\n516       1       .       .       1 47.00000  34.0208       .\n517       .       1       .       . 34.00000  10.5000       .\n518       .       .       1       1 29.93737  24.1500       .\n519       .       1       .       . 36.00000  26.0000       1\n521       1       .       .       . 30.00000  93.5000       .\n522       .       .       1       1 22.00000   7.8958       .\n524       1       .       .       . 44.00000  57.9792       1\n526       .       .       1       1 40.50000   7.7500       .\n528       1       .       .       1 29.93737 221.7792       .\n530       .       1       .       1 23.00000  11.5000       3\n532       .       .       1       1 29.93737   7.2292       .\n533       .       .       1       1 17.00000   7.2292       2\n535       .       .       1       . 30.00000   8.6625       .\n536       .       1       .       .  7.00000  26.2500       2\n537       1       .       .       1 45.00000  26.5500       .\n538       1       .       .       . 30.00000 106.4250       .\n541       1       .       .       . 36.00000  71.0000       2\n542       .       .       1       .  9.00000  31.2750       6\n543       .       .       1       . 11.00000  31.2750       6\n544       .       1       .       1 32.00000  26.0000       1\n545       1       .       .       1 50.00000 106.4250       1\n546       1       .       .       1 64.00000  26.0000       .\n547       .       1       .       . 19.00000  26.0000       1\n548       .       1       .       1 29.93737  13.8625       .\n549       .       .       1       1 33.00000  20.5250       2\n552       .       1       .       1 27.00000  26.0000       .\n553       .       .       1       1 29.93737   7.8292       .\n555       .       .       1       . 22.00000   7.7750       .\n556       1       .       .       1 62.00000  26.5500       .\n557       1       .       .       . 48.00000  39.6000       1\n558       1       .       .       1 29.93737 227.5250       .\n559       1       .       .       . 39.00000  79.6500       2\n560       .       .       1       . 36.00000  17.4000       1\n561       .       .       1       1 29.93737   7.7500       .\n563       .       1       .       1 28.00000  13.5000       .\n564       .       .       1       1 29.93737   8.0500       .\n565       .       .       1       . 29.93737   8.0500       .\n567       .       .       1       1 19.00000   7.8958       .\n568       .       .       1       . 29.00000  21.0750       4\n569       .       .       1       1 29.93737   7.2292       .\n570       .       .       1       1 32.00000   7.8542       .\n573       1       .       .       1 36.00000  26.3875       .\n575       .       .       1       1 16.00000   8.0500       .\n576       .       .       1       1 19.00000  14.5000       .\n577       .       1       .       . 34.00000  13.0000       .\n578       1       .       .       . 39.00000  55.9000       1\n579       .       .       1       . 29.93737  14.4583       1\n580       .       .       1       1 32.00000   7.9250       .\n581       .       1       .       . 25.00000  30.0000       2\n584       1       .       .       1 36.00000  40.1250       .\n585       .       .       1       1 29.93737   8.7125       .\n587       .       1       .       1 47.00000  15.0000       .\n588       1       .       .       1 60.00000  79.2000       2\n590       .       .       1       1 29.93737   8.0500       .\n591       .       .       1       1 35.00000   7.1250       .\n592       1       .       .       . 52.00000  78.2667       1\n593       .       .       1       1 47.00000   7.2500       .\n594       .       .       1       . 29.93737   7.7500       2\n595       .       1       .       1 37.00000  26.0000       1\n596       .       .       1       1 36.00000  24.1500       2\n597       .       1       .       . 29.93737  33.0000       .\n598       .       .       1       1 49.00000   .            .\n600       1       .       .       1 49.00000  56.9292       1\n601       .       1       .       . 24.00000  27.0000       3\n603       1       .       .       1 29.93737  42.4000       .\n605       1       .       .       1 35.00000  26.5500       .\n606       .       .       1       1 36.00000  15.5500       1\n608       1       .       .       1 27.00000  30.5000       .\n609       .       1       .       . 22.00000  41.5792       3\n610       1       .       .       . 40.00000 153.4625       .\n611       .       .       1       . 39.00000  31.2750       6\n612       .       .       1       1 29.93737   7.0500       .\n613       .       .       1       . 29.93737  15.5000       1\n614       .       .       1       1 29.93737   7.7500       .\n615       .       .       1       1 35.00000   8.0500       .\n616       .       1       .       . 24.00000  65.0000       3\n617       .       .       1       1 34.00000  14.4000       2\n618       .       .       1       . 26.00000  16.1000       1\n619       .       1       .       .  4.00000  39.0000       3\n621       .       .       1       1 27.00000  14.4542       1\n622       1       .       .       1 42.00000  52.5542       1\n623       .       .       1       1 20.00000  15.7417       2\n624       .       .       1       1 21.00000   7.8542       .\n625       .       .       1       1 21.00000  16.1000       .\n626       1       .       .       1 61.00000  32.3208       .\n627       .       1       .       1 57.00000  12.3500       .\n631       1       .       .       1 80.00000  30.0000       .\n633       1       .       .       1 32.00000  30.5000       .\n634       1       .       .       1 29.93737   .            .\n635       .       .       1       .  9.00000  27.9000       5\n637       .       .       1       1 32.00000   7.9250       .\n638       .       1       .       1 31.00000  26.2500       2\n639       .       .       1       . 41.00000  39.6875       5\n640       .       .       1       1 29.93737  16.1000       1\n641       .       .       1       1 20.00000   7.8542       .\n642       1       .       .       . 24.00000  69.3000       .\n644       .       .       1       1 29.93737  56.4958       .\n645       .       .       1       .  0.75000  19.2583       3\n646       1       .       .       1 48.00000  76.7292       1\n647       .       .       1       1 19.00000   7.8958       .\n648       1       .       .       1 56.00000  35.5000       .\n649       .       .       1       1 29.93737   7.5500       .\n650       .       .       1       . 23.00000   7.5500       .\n651       .       .       1       1 29.93737   7.8958       .\n654       .       .       1       . 29.93737   7.8292       .\n655       .       .       1       . 18.00000   6.7500       .\n656       .       1       .       1 24.00000  73.5000       2\n658       .       .       1       . 32.00000  15.5000       2\n659       .       1       .       1 23.00000  13.0000       .\n661       1       .       .       1 50.00000 133.6500       2\n662       .       .       1       1 40.00000   7.2250       .\n663       1       .       .       1 47.00000  25.5875       .\n667       .       1       .       1 25.00000  13.0000       .\n668       .       .       1       1 29.93737   7.7750       .\n670       1       .       .       . 29.93737  52.0000       1\n671       .       1       .       . 40.00000  39.0000       2\n674       .       1       .       1 31.00000  13.0000       .\n677       .       .       1       1 24.50000   8.0500       .\n678       .       .       1       . 18.00000   9.8417       .\n679       .       .       1       . 43.00000  46.9000       7\n681       .       .       1       . 29.93737   8.1375       .\n682       1       .       .       1 27.00000  76.7292       .\n683       .       .       1       1 20.00000   9.2250       .\n687       .       .       1       1 14.00000  39.6875       5\n689       .       .       1       1 18.00000   7.7958       .\n690       1       .       .       . 15.00000 211.3375       1\n691       1       .       .       1 31.00000  57.0000       1\n692       .       .       1       .  4.00000  13.4167       1\n693       .       .       1       1 29.93737  56.4958       .\n694       .       .       1       1 25.00000   7.2250       .\n695       1       .       .       1 60.00000  26.5500       .\n699       1       .       .       1 49.00000 110.8833       2\n701       1       .       .       . 18.00000 227.5250       1\n702       1       .       .       1 35.00000  26.2875       .\n703       .       .       1       . 18.00000  14.4542       1\n704       .       .       1       1 25.00000   7.7417       .\n705       .       .       1       1 26.00000   7.8542       1\n708       1       .       .       1 42.00000  26.2875       .\n709       1       .       .       . 22.00000 151.5500       .\n710       .       .       1       1 29.93737  15.2458       2\n712       1       .       .       1 29.93737  26.5500       .\n713       1       .       .       1 48.00000  52.0000       1\n714       .       .       1       1 29.00000   9.4833       .\n716       .       .       1       1 19.00000   7.6500       .\n717       1       .       .       . 38.00000 227.5250       .\n718       .       1       .       . 27.00000  10.5000       .\n719       .       .       1       1 29.93737  15.5000       .\n720       .       .       1       1 33.00000   7.7750       .\n721       .       1       .       .  6.00000  33.0000       1\n723       .       1       .       1 34.00000  13.0000       .\n725       1       .       .       1 27.00000  53.1000       1\n726       .       .       1       1 20.00000   8.6625       .\n728       .       .       1       . 29.93737   7.7375       .\n729       .       1       .       1 25.00000  26.0000       1\n730       .       .       1       . 25.00000   7.9250       1\n732       .       .       1       1 11.00000  18.7875       .\n735       .       1       .       1 23.00000  13.0000       .\n736       .       .       1       1 28.50000  16.1000       .\n737       .       .       1       . 48.00000  34.3750       4\n738       1       .       .       1 35.00000 512.3292       .\n739       .       .       1       1 29.93737   7.8958       .\n740       .       .       1       1 29.93737   7.8958       .\n742       1       .       .       1 36.00000  78.8500       1\n743       1       .       .       . 21.00000 262.3750       4\n744       .       .       1       1 24.00000  16.1000       1\n745       .       .       1       1 31.00000   7.9250       .\n749       1       .       .       1 19.00000  53.1000       1\n750       .       .       1       1 31.00000   7.7500       .\n752       .       .       1       1  6.00000  12.4750       1\n753       .       .       1       1 33.00000   9.5000       .\n754       .       .       1       1 23.00000   7.8958       .\n755       .       1       .       . 48.00000  65.0000       3\n757       .       .       1       1 28.00000   7.7958       .\n759       .       .       1       1 34.00000   8.0500       .\n760       1       .       .       . 33.00000  86.5000       .\n762       .       .       1       1 41.00000   7.1250       .\n763       .       .       1       1 20.00000   7.2292       .\n764       1       .       .       . 36.00000 120.0000       3\n766       1       .       .       . 51.00000  77.9583       1\n767       1       .       .       1 29.93737  39.6000       .\n768       .       .       1       . 30.50000   7.7500       .\n769       .       .       1       1 29.93737  24.1500       1\n770       .       .       1       1 32.00000   8.3625       .\n771       .       .       1       1 24.00000   9.5000       .\n773       .       1       .       . 57.00000  10.5000       .\n774       .       .       1       1 29.93737   7.2250       .\n777       .       .       1       1 29.93737   7.7500       .\n778       .       .       1       .  5.00000  12.4750       .\n780       1       .       .       . 43.00000 211.3375       1\n781       .       .       1       . 13.00000   7.2292       .\n782       1       .       .       . 17.00000  57.0000       1\n783       1       .       .       1 29.00000  30.0000       .\n784       .       .       1       1 29.93737  23.4500       3\n786       .       .       1       1 25.00000   7.2500       .\n789       .       .       1       1  1.00000  20.5750       3\n790       1       .       .       1 46.00000  79.2000       .\n791       .       .       1       1 29.93737   7.7500       .\n792       .       1       .       1 16.00000  26.0000       .\n793       .       .       1       . 29.93737  69.5500      10\n794       1       .       .       1 29.93737  30.6958       .\n795       .       .       1       1 25.00000   7.8958       .\n796       .       1       .       1 39.00000  13.0000       .\n797       1       .       .       . 49.00000  25.9292       .\n799       .       .       1       1 30.00000   7.2292       .\n800       .       .       1       . 30.00000  24.1500       2\n801       .       1       .       1 34.00000  13.0000       .\n803       1       .       .       1 11.00000 120.0000       3\n804       .       .       1       1  0.42000   8.5167       1\n806       .       .       1       1 31.00000   7.7750       .\n808       .       .       1       . 18.00000   7.7750       .\n811       .       .       1       1 26.00000   7.8875       .\n812       .       .       1       1 39.00000  24.1500       .\n813       .       1       .       1 35.00000  10.5000       .\n815       .       .       1       1 30.50000   8.0500       .\n816       1       .       .       1 29.93737   .            .\n817       .       .       1       . 23.00000   7.9250       .\n819       .       .       1       1 43.00000   6.4500       .\n822       .       .       1       1 27.00000   8.6625       .\n823       1       .       .       1 38.00000   .            .\n824       .       .       1       . 27.00000  12.4750       1\n825       .       .       1       1  2.00000  39.6875       5\n826       .       .       1       1 29.93737   6.9500       .\n827       .       .       1       1 29.93737  56.4958       .\n828       .       1       .       1  1.00000  37.0042       2\n831       .       .       1       . 15.00000  14.4542       1\n832       .       1       .       1  0.83000  18.7500       2\n833       .       .       1       1 29.93737   7.2292       .\n835       .       .       1       1 18.00000   8.3000       .\n836       1       .       .       . 39.00000  83.1583       2\n838       .       .       1       1 29.93737   8.0500       .\n840       1       .       .       1 29.93737  29.7000       .\n843       1       .       .       . 30.00000  31.0000       .\n845       .       .       1       1 17.00000   8.6625       .\n846       .       .       1       1 42.00000   7.5500       .\n847       .       .       1       1 29.93737  69.5500      10\n849       .       1       .       1 28.00000  33.0000       1\n850       1       .       .       . 29.93737  89.1042       1\n851       .       .       1       1  4.00000  31.2750       6\n852       .       .       1       1 74.00000   7.7750       .\n853       .       .       1       .  9.00000  15.2458       2\n855       .       1       .       . 44.00000  26.0000       1\n856       .       .       1       . 18.00000   9.3500       1\n857       1       .       .       . 45.00000 164.8667       2\n858       1       .       .       1 51.00000  26.5500       .\n859       .       .       1       . 24.00000  19.2583       3\n860       .       .       1       1 29.93737   7.2292       .\n861       .       .       1       1 41.00000  14.1083       2\n862       .       1       .       1 21.00000  11.5000       1\n864       .       .       1       . 29.93737  69.5500      10\n865       .       1       .       1 24.00000  13.0000       .\n867       .       1       .       . 27.00000  13.8583       1\n868       1       .       .       1 31.00000  50.4958       .\n871       .       .       1       1 26.00000   7.8958       .\n872       1       .       .       . 47.00000  52.5542       2\n874       .       .       1       1 47.00000   9.0000       .\n877       .       .       1       1 20.00000   9.8458       .\n878       .       .       1       1 19.00000   7.8958       .\n879       .       .       1       1 29.93737   7.8958       .\n880       1       .       .       . 56.00000  83.1583       1\n881       .       1       .       . 25.00000  26.0000       1\n882       .       .       1       1 33.00000   7.8958       .\n883       .       .       1       . 22.00000  10.5167       .\n885       .       .       1       1 25.00000   7.0500       .\n886       .       .       1       . 39.00000  29.1250       5\n887       .       1       .       1 27.00000  13.0000       .\n888       1       .       .       . 19.00000  30.0000       .\n889       .       .       1       . 29.93737  23.4500       3\n\ntestm        &lt;- sparse.model.matrix(Survived ~.-1, # Survived Target으로 제외 \n                                    data = titanic.ted.Imp) \ntestm\n\n266 x 7 sparse Matrix of class \"dgCMatrix\"\n    Pclass1 Pclass2 Pclass3 Sexmale      Age     Fare FamSize\n2         1       .       .       . 38.00000  71.2833       1\n7         1       .       .       1 54.00000  51.8625       .\n13        .       .       1       1 20.00000   8.0500       .\n16        .       1       .       . 55.00000  16.0000       .\n17        .       .       1       1  2.00000  29.1250       5\n22        .       1       .       1 34.00000  13.0000       .\n23        .       .       1       . 15.00000   8.0292       .\n26        .       .       1       . 38.00000  31.3875       6\n37        .       .       1       1 29.93737   7.2292       .\n44        .       1       .       .  3.00000  41.5792       3\n46        .       .       1       1 29.93737   8.0500       .\n52        .       .       1       1 21.00000   7.8000       .\n54        .       1       .       . 29.00000  26.0000       1\n57        .       1       .       . 21.00000  10.5000       .\n58        .       .       1       1 28.50000   7.2292       .\n59        .       1       .       .  5.00000  27.7500       3\n63        1       .       .       1 45.00000  83.4750       1\n66        .       .       1       1 29.93737  15.2458       2\n67        .       1       .       . 29.00000  10.5000       .\n68        .       .       1       1 19.00000   8.1583       .\n69        .       .       1       . 17.00000   7.9250       6\n71        .       1       .       1 32.00000  10.5000       .\n73        .       1       .       1 21.00000  73.5000       .\n78        .       .       1       1 29.93737   8.0500       .\n81        .       .       1       1 22.00000   9.0000       .\n87        .       .       1       1 16.00000  34.3750       4\n90        .       .       1       1 24.00000   8.0500       .\n98        1       .       .       1 23.00000  63.3583       1\n99        .       1       .       . 34.00000  23.0000       1\n100       .       1       .       1 34.00000  26.0000       1\n101       .       .       1       . 28.00000   7.8958       .\n102       .       .       1       1 29.93737   7.8958       .\n104       .       .       1       1 33.00000   8.6542       .\n106       .       .       1       1 28.00000   7.8958       .\n109       .       .       1       1 38.00000   7.8958       .\n118       .       1       .       1 29.00000  21.0000       1\n120       .       .       1       .  2.00000  31.2750       6\n121       .       1       .       1 21.00000  73.5000       2\n123       .       1       .       1 32.50000  30.0708       1\n124       .       1       .       . 32.50000  13.0000       .\n127       .       .       1       1 29.93737   7.7500       .\n133       .       .       1       . 47.00000  14.5000       1\n135       .       1       .       1 25.00000  13.0000       .\n137       1       .       .       . 19.00000  26.2833       2\n139       .       .       1       1 16.00000   9.2167       .\n140       1       .       .       1 24.00000  79.2000       .\n144       .       .       1       1 19.00000   6.7500       .\n145       .       1       .       1 18.00000  11.5000       .\n152       1       .       .       . 22.00000  66.6000       1\n155       .       .       1       1 29.93737   7.3125       .\n159       .       .       1       1 29.93737   8.6625       .\n161       .       .       1       1 44.00000  16.1000       1\n165       .       .       1       1  1.00000  39.6875       5\n166       .       .       1       1  9.00000  20.5250       2\n168       .       .       1       . 45.00000  27.9000       5\n170       .       .       1       1 28.00000  56.4958       .\n172       .       .       1       1  4.00000  29.1250       5\n175       1       .       .       1 56.00000  30.6958       .\n177       .       .       1       1 29.93737  25.4667       4\n178       1       .       .       . 50.00000  28.7125       .\n183       .       .       1       1  9.00000  31.3875       6\n186       1       .       .       1 29.93737  50.0000       .\n187       .       .       1       . 29.93737  15.5000       1\n193       .       .       1       . 19.00000   7.8542       1\n195       1       .       .       . 44.00000  27.7208       .\n201       .       .       1       1 28.00000   9.5000       .\n208       .       .       1       1 26.00000  18.7875       .\n210       1       .       .       1 40.00000  31.0000       .\n215       .       .       1       1 29.93737   7.7500       1\n221       .       .       1       1 16.00000   8.0500       .\n222       .       1       .       1 27.00000  13.0000       .\n225       1       .       .       1 38.00000  90.0000       1\n228       .       .       1       1 20.50000   7.2500       .\n231       1       .       .       . 35.00000  83.4750       1\n234       .       .       1       .  5.00000  31.3875       6\n239       .       1       .       1 19.00000  10.5000       .\n241       .       .       1       . 29.93737  14.4542       1\n250       .       1       .       1 54.00000  26.0000       1\n251       .       .       1       1 29.93737   7.2500       .\n256       .       .       1       . 29.00000  15.2458       2\n260       .       1       .       . 50.00000  26.0000       1\n261       .       .       1       1 29.93737   7.7500       .\n263       1       .       .       1 52.00000  79.6500       2\n268       .       .       1       1 25.00000   7.7750       1\n271       1       .       .       1 29.93737  31.0000       .\n272       .       .       1       1 25.00000   .            .\n274       1       .       .       1 37.00000  29.7000       1\n277       .       .       1       . 45.00000   7.7500       .\n279       .       .       1       1  7.00000  29.1250       5\n282       .       .       1       1 28.00000   7.8542       .\n283       .       .       1       1 16.00000   9.5000       .\n284       .       .       1       1 19.00000   8.0500       .\n295       .       .       1       1 24.00000   7.8958       .\n301       .       .       1       . 29.93737   7.7500       .\n308       1       .       .       . 17.00000 108.9000       1\n310       1       .       .       . 30.00000  56.9292       .\n312       1       .       .       . 18.00000 262.3750       4\n313       .       1       .       . 26.00000  26.0000       2\n314       .       .       1       1 28.00000   7.8958       .\n318       .       1       .       1 54.00000  14.0000       .\n321       .       .       1       1 22.00000   7.2500       .\n326       1       .       .       . 36.00000 135.6333       .\n328       .       1       .       . 36.00000  13.0000       .\n333       1       .       .       1 38.00000 153.4625       1\n334       .       .       1       1 16.00000  18.0000       2\n338       1       .       .       . 41.00000 134.5000       .\n344       .       1       .       1 25.00000  13.0000       .\n347       .       1       .       . 40.00000  13.0000       .\n351       .       .       1       1 23.00000   9.2250       .\n358       .       1       .       . 38.00000  13.0000       .\n359       .       .       1       . 29.93737   7.8792       .\n364       .       .       1       1 35.00000   7.0500       .\n369       .       .       1       . 29.93737   7.7500       .\n375       .       .       1       .  3.00000  21.0750       4\n378       1       .       .       1 27.00000 211.5000       2\n380       .       .       1       1 19.00000   7.7750       .\n400       .       1       .       . 28.00000  12.6500       .\n403       .       .       1       . 21.00000   9.8250       1\n409       .       .       1       1 21.00000   7.7750       .\n412       .       .       1       1 29.93737   6.8583       .\n413       1       .       .       . 33.00000  90.0000       1\n415       .       .       1       1 44.00000   7.9250       .\n416       .       .       1       . 29.93737   8.0500       .\n418       .       1       .       . 18.00000  13.0000       2\n419       .       1       .       1 30.00000  13.0000       .\n420       .       .       1       . 10.00000  24.1500       2\n424       .       .       1       . 28.00000  14.4000       2\n427       .       1       .       . 28.00000  26.0000       1\n430       .       .       1       1 32.00000   8.0500       .\n436       1       .       .       . 14.00000 120.0000       3\n440       .       1       .       1 31.00000  10.5000       .\n441       .       1       .       . 45.00000  26.2500       2\n442       .       .       1       1 20.00000   9.5000       .\n445       .       .       1       1 29.93737   8.1125       .\n447       .       1       .       . 13.00000  19.5000       1\n448       1       .       .       1 34.00000  26.5500       .\n450       1       .       .       1 52.00000  30.5000       .\n452       .       .       1       1 29.93737  19.9667       1\n455       .       .       1       1 29.93737   8.0500       .\n457       1       .       .       1 65.00000  26.5500       .\n458       1       .       .       . 29.93737  51.8625       1\n462       .       .       1       1 34.00000   8.0500       .\n467       .       1       .       1 29.93737   .            .\n469       .       .       1       1 29.93737   7.7250       .\n473       .       1       .       . 33.00000  27.7500       3\n476       1       .       .       1 29.93737  52.0000       .\n477       .       1       .       1 34.00000  21.0000       1\n478       .       .       1       1 29.00000   7.0458       1\n482       .       1       .       1 29.93737   .            .\n483       .       .       1       1 50.00000   8.0500       .\n488       1       .       .       1 58.00000  29.7000       .\n490       .       .       1       1  9.00000  15.9000       2\n492       .       .       1       1 21.00000   7.2500       .\n495       .       .       1       1 21.00000   8.0500       .\n496       .       .       1       1 29.93737  14.4583       .\n510       .       .       1       1 26.00000  56.4958       .\n515       .       .       1       1 24.00000   7.4958       .\n520       .       .       1       1 32.00000   7.8958       .\n523       .       .       1       1 29.93737   7.2250       .\n525       .       .       1       1 29.93737   7.2292       .\n527       .       1       .       . 50.00000  10.5000       .\n529       .       .       1       1 39.00000   7.9250       .\n531       .       1       .       .  2.00000  26.0000       2\n534       .       .       1       . 29.93737  22.3583       2\n539       .       .       1       1 29.93737  14.5000       .\n540       1       .       .       . 22.00000  49.5000       2\n550       .       1       .       1  8.00000  36.7500       2\n551       1       .       .       1 17.00000 110.8833       2\n554       .       .       1       1 22.00000   7.2250       .\n562       .       .       1       1 40.00000   7.8958       .\n566       .       .       1       1 24.00000  24.1500       2\n571       .       1       .       1 62.00000  10.5000       .\n572       1       .       .       . 53.00000  51.4792       2\n574       .       .       1       . 29.93737   7.7500       .\n582       1       .       .       . 39.00000 110.8833       2\n583       .       1       .       1 54.00000  26.0000       .\n586       1       .       .       . 18.00000  79.6500       2\n589       .       .       1       1 22.00000   8.0500       .\n599       .       .       1       1 29.93737   7.2250       .\n602       .       .       1       1 29.93737   7.8958       .\n604       .       .       1       1 44.00000   8.0500       .\n607       .       .       1       1 30.00000   7.8958       .\n620       .       1       .       1 26.00000  10.5000       .\n628       1       .       .       . 21.00000  77.9583       .\n629       .       .       1       1 26.00000   7.8958       .\n630       .       .       1       1 29.93737   7.7333       .\n632       .       .       1       1 51.00000   7.0542       .\n636       .       1       .       . 28.00000  13.0000       .\n643       .       .       1       .  2.00000  27.9000       5\n652       .       1       .       . 18.00000  23.0000       1\n653       .       .       1       1 21.00000   8.4333       .\n657       .       .       1       1 29.93737   7.8958       .\n660       1       .       .       1 58.00000 113.2750       2\n664       .       .       1       1 36.00000   7.4958       .\n665       .       .       1       1 20.00000   7.9250       1\n666       .       1       .       1 32.00000  73.5000       2\n669       .       .       1       1 43.00000   8.0500       .\n672       1       .       .       1 31.00000  52.0000       1\n673       .       1       .       1 70.00000  10.5000       .\n675       .       1       .       1 29.93737   .            .\n676       .       .       1       1 18.00000   7.7750       .\n680       1       .       .       1 36.00000 512.3292       1\n684       .       .       1       1 14.00000  46.9000       7\n685       .       1       .       1 60.00000  39.0000       2\n686       .       1       .       1 25.00000  41.5792       3\n688       .       .       1       1 19.00000  10.1708       .\n696       .       1       .       1 52.00000  13.5000       .\n697       .       .       1       1 44.00000   8.0500       .\n698       .       .       1       . 29.93737   7.7333       .\n700       .       .       1       1 42.00000   7.6500       .\n706       .       1       .       1 39.00000  26.0000       .\n707       .       1       .       . 45.00000  13.5000       .\n711       1       .       .       . 24.00000  49.5042       .\n715       .       1       .       1 52.00000  13.0000       .\n722       .       .       1       1 17.00000   7.0542       1\n724       .       1       .       1 50.00000  13.0000       .\n727       .       1       .       . 30.00000  21.0000       3\n731       1       .       .       . 29.00000 211.3375       .\n733       .       1       .       1 29.93737   .            .\n734       .       1       .       1 23.00000  13.0000       .\n741       1       .       .       1 29.93737  30.0000       .\n746       1       .       .       1 70.00000  71.0000       2\n747       .       .       1       1 16.00000  20.2500       2\n748       .       1       .       . 30.00000  13.0000       .\n751       .       1       .       .  4.00000  23.0000       2\n756       .       1       .       1  0.67000  14.5000       2\n758       .       1       .       1 18.00000  11.5000       .\n761       .       .       1       1 29.93737  14.5000       .\n765       .       .       1       1 16.00000   7.7750       .\n772       .       .       1       1 48.00000   7.8542       .\n775       .       1       .       . 54.00000  23.0000       4\n776       .       .       1       1 18.00000   7.7500       .\n779       .       .       1       1 29.93737   7.7375       .\n785       .       .       1       1 25.00000   7.0500       .\n787       .       .       1       . 18.00000   7.4958       .\n788       .       .       1       1  8.00000  29.1250       5\n798       .       .       1       . 31.00000   8.6833       .\n802       .       1       .       . 31.00000  26.2500       2\n805       .       .       1       1 27.00000   6.9750       .\n807       1       .       .       1 39.00000   .            .\n809       .       1       .       1 39.00000  13.0000       .\n810       1       .       .       . 33.00000  53.1000       1\n814       .       .       1       .  6.00000  31.2750       6\n818       .       1       .       1 31.00000  37.0042       2\n820       .       .       1       1 10.00000  27.9000       5\n821       1       .       .       . 52.00000  93.5000       2\n829       .       .       1       1 29.93737   7.7500       .\n830       1       .       .       . 62.00000  80.0000       .\n834       .       .       1       1 23.00000   7.8542       .\n837       .       .       1       1 21.00000   8.6625       .\n839       .       .       1       1 32.00000  56.4958       .\n841       .       .       1       1 20.00000   7.9250       .\n842       .       1       .       1 16.00000  10.5000       .\n844       .       .       1       1 34.50000   6.4375       .\n848       .       .       1       1 35.00000   7.8958       .\n854       1       .       .       . 16.00000  39.4000       1\n863       1       .       .       . 48.00000  25.9292       .\n866       .       1       .       . 42.00000  13.0000       .\n869       .       .       1       1 29.93737   9.5000       .\n870       .       .       1       1  4.00000  11.1333       2\n873       1       .       .       1 33.00000   5.0000       .\n875       .       1       .       . 28.00000  24.0000       1\n876       .       .       1       . 15.00000   7.2250       .\n884       .       1       .       1 28.00000  10.5000       .\n890       1       .       .       1 26.00000  30.0000       .\n891       .       .       1       1 32.00000   7.7500       .\n\n# 2. Convert Factor Var. into Numeric Var. for Target\ntrain.y &lt;- as.numeric( as.character( titanic.trd.Imp$Survived ))  \n\ntrain.y\n\n  [1] 0 1 1 0 0 0 1 1 1 1 0 0 1 0 1 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 1 1 1 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 0 1 1\n [98] 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 1 1 0 0 1 0 1 1 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 1 1 1 1 0 0 0 0 1 1 1 1 1 0 1 0 0 0\n[195] 1 0 1 1 1 1 0 0 0 0 0 1 1 1 0 1 0 1 1 0 1 0 1 1 1 1 0 1 1 0 0 1 1 1 0 1 0 0 1 0 1 1 0 0 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 1 1 0 0 0 1 1 0 1 1 0 1 0 0 0 1 0 1 1 1 0 1 1 0 0 0 0 1 0 0 0 0 0 1 0\n[292] 0 0 1 0 0 0 0 0 1 0 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 1 0 1 1 0 1 0 1 1 0 1 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 1 1 0 0 0 1 0 1\n[389] 0 1 1 0 0 0 0 0 0 0 1 1 0 0 1 1 0 1 1 0 0 0 1 0 0 1 0 0 0 0 1 0 1 1 0 1 0 1 1 1 0 0 1 0 0 1 0 0 1 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 1 1 1 0 1 0 0 1 0 0 0 1 1\n[486] 1 1 0 0 0 1 1 0 0 0 1 1 1 0 1 0 0 1 1 0 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 1 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1\n[583] 1 1 0 0 1 0 1 1 0 0 0 0 1 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0\n\n# 3. Convert to xgb.DMatrix object\ntrain_matrix &lt;- xgb.DMatrix(data = as.matrix(trainm),\n                            label = train.y)\n\ntrain_matrix\n\nxgb.DMatrix  dim: 625 x 7  info: label  colnames: yes\n\ntest_matrix  &lt;- xgb.DMatrix(data = as.matrix(testm))\n\ntest_matrix\n\nxgb.DMatrix  dim: 266 x 7  info: NA  colnames: yes\n\n\n\nset.seed(100)                                                         # Seed 고정 -&gt; 동일한 결과를 출력하기 위해\ntitanic.xgb &lt;- xgb.train(data = train_matrix,  \n                         watchlist = list(train = train_matrix),      # 모형 구축하는 동안 오차를 계산하기 위해\n                         nrounds = 50,                                # nrounds : 반복 수(= 생성하고자 하는 트리 개수) \n                         params = list(objective = \"binary:logistic\", # 손실함수\n                                       eta = 0.01,                    # 학습률\n                                       gamma = 0,                     # 분할하기 위해 필요한 최소 손실 감소/ 클수록 분할이 쉽게 일어나지 않음\n                                       max_depth = 5,                 # 트리의 최대 깊이\n                                       min_child_weight = 1,          # 분할하기 위해 필요한 case의 최소 가중치 합/ 클수록 분할이 쉽게 일어나지 않음\n                                       subsample = 1,                 # 트리를 생성할 때 Dataset으로부터 사용할 case 비율\n                                       lambda = 1),                   # 규제항\n                         early_stopping_rounds = 10)                  # 만약 10번 이후의 반복에서 손실이 개선되지 않으면 조기 종료\n\n[1] train-logloss:0.688079 \nWill train until train_logloss hasn't improved in 10 rounds.\n\n[2] train-logloss:0.683130 \n[3] train-logloss:0.678273 \n[4] train-logloss:0.673507 \n[5] train-logloss:0.668828 \n[6] train-logloss:0.664236 \n[7] train-logloss:0.659727 \n[8] train-logloss:0.655300 \n[9] train-logloss:0.650952 \n[10]    train-logloss:0.646683 \n[11]    train-logloss:0.642489 \n[12]    train-logloss:0.638370 \n[13]    train-logloss:0.634324 \n[14]    train-logloss:0.630348 \n[15]    train-logloss:0.626442 \n[16]    train-logloss:0.622604 \n[17]    train-logloss:0.618832 \n[18]    train-logloss:0.615125 \n[19]    train-logloss:0.611482 \n[20]    train-logloss:0.607900 \n[21]    train-logloss:0.604354 \n[22]    train-logloss:0.600892 \n[23]    train-logloss:0.597488 \n[24]    train-logloss:0.594115 \n[25]    train-logloss:0.590823 \n[26]    train-logloss:0.587585 \n[27]    train-logloss:0.584375 \n[28]    train-logloss:0.581246 \n[29]    train-logloss:0.578169 \n[30]    train-logloss:0.575088 \n[31]    train-logloss:0.572083 \n[32]    train-logloss:0.569150 \n[33]    train-logloss:0.566249 \n[34]    train-logloss:0.563356 \n[35]    train-logloss:0.560515 \n[36]    train-logloss:0.557747 \n[37]    train-logloss:0.554994 \n[38]    train-logloss:0.552294 \n[39]    train-logloss:0.549525 \n[40]    train-logloss:0.546895 \n[41]    train-logloss:0.544207 \n[42]    train-logloss:0.541557 \n[43]    train-logloss:0.539005 \n[44]    train-logloss:0.536474 \n[45]    train-logloss:0.533901 \n[46]    train-logloss:0.531511 \n[47]    train-logloss:0.529220 \n[48]    train-logloss:0.526885 \n[49]    train-logloss:0.524640 \n[50]    train-logloss:0.522387 \n\n\n\n# Training Error Plot\nplot(titanic.xgb$evaluation_log$train_logloss, \n     col = \"blue\",\n     type = \"l\",\n     xlab = \"iter\",\n     ylab = \"Error\")\n\n\n\n\n\n\n\n\n\n# 변수 중요도\nimportance &lt;- xgb.importance(feature_names = colnames(trainm), model = titanic.xgb)\n\nimportance\n\n   Feature       Gain      Cover  Frequency\n    &lt;char&gt;      &lt;num&gt;      &lt;num&gt;      &lt;num&gt;\n1: Sexmale 0.53265933 0.24761708 0.07331378\n2: Pclass3 0.16199525 0.09080070 0.07771261\n3: FamSize 0.10389248 0.06846369 0.22727273\n4:     Age 0.09835220 0.22891257 0.22873900\n5: Pclass1 0.06029680 0.13526143 0.06598240\n6:    Fare 0.04280394 0.22894454 0.32697947\n\n# 변수 중요도 plot\nxgb.plot.importance(importance_matrix = importance) \n\n\n\n\n\n\n\n\nResult! 변수 Sexmale이 Target Survived을 분류하는 데 있어 중요하다.",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>XGBoost</span>"
    ]
  },
  {
    "objectID": "XGBoost.html#모형-평가",
    "href": "XGBoost.html#모형-평가",
    "title": "16  XGBoost",
    "section": "16.7 모형 평가",
    "text": "16.7 모형 평가\nCaution! 모형 평가를 위해 Test Dataset에 대한 예측 class/확률 이 필요하며, 함수 predict()를 이용하여 생성한다.\n\n# \"Survived = 1\"에 대한 예측 확률 생성\ntest.xgb.prob &lt;- predict(titanic.xgb,\n                         newdata = test_matrix)        # Test Dataset including Only 예측 변수\n\ntest.xgb.prob %&gt;%\n  as_tibble\n\n# A tibble: 266 × 1\n   value\n   &lt;dbl&gt;\n 1 0.676\n 2 0.442\n 3 0.342\n 4 0.653\n 5 0.420\n 6 0.342\n 7 0.497\n 8 0.331\n 9 0.342\n10 0.636\n# ℹ 256 more rows\n\n\n\n\n16.7.1 ConfusionMatrix\n\n# 예측 class 생성\ncv &lt;- 0.5                                                          # Cutoff Value\ntest.xgb.class &lt;- as.factor(ifelse(test.xgb.prob &gt; cv, \"1\", \"0\"))  # 예측 확률 &gt; cv이면 \"Survived = 1\" 아니면 \"Survived = 0\"\n\ntest.xgb.class %&gt;%\n  as_tibble\n\n# A tibble: 266 × 1\n   value\n   &lt;fct&gt;\n 1 1    \n 2 0    \n 3 0    \n 4 1    \n 5 0    \n 6 0    \n 7 0    \n 8 0    \n 9 0    \n10 1    \n# ℹ 256 more rows\n\n\n\nCM   &lt;- caret::confusionMatrix(test.xgb.class, titanic.ted.Imp$Survived, \n                               positive = \"1\")         # confusionMatrix(예측 class, 실제 class, positive = \"관심 class\")\nCM\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction   0   1\n         0 156  33\n         1   8  69\n                                          \n               Accuracy : 0.8459          \n                 95% CI : (0.7968, 0.8871)\n    No Information Rate : 0.6165          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.6582          \n                                          \n Mcnemar's Test P-Value : 0.0001781       \n                                          \n            Sensitivity : 0.6765          \n            Specificity : 0.9512          \n         Pos Pred Value : 0.8961          \n         Neg Pred Value : 0.8254          \n             Prevalence : 0.3835          \n         Detection Rate : 0.2594          \n   Detection Prevalence : 0.2895          \n      Balanced Accuracy : 0.8138          \n                                          \n       'Positive' Class : 1               \n                                          \n\n\n\n\n\n16.7.2 ROC 곡선\n\nac  &lt;- titanic.ted.Imp$Survived                        # Test Dataset의 실제 class \npp  &lt;- as.numeric(test.xgb.prob)                       # 예측 확률을 수치형으로 변환\n\n\n16.7.2.1 Package “pROC”\n\npacman::p_load(\"pROC\")\n\nxgb.roc  &lt;- roc(ac, pp, plot = T, col = \"gray\")        # roc(실제 class, 예측 확률)\nauc      &lt;- round(auc(xgb.roc), 3)\nlegend(\"bottomright\", legend = auc, bty = \"n\")\n\n\n\n\n\n\n\n\nCaution! Package \"pROC\"를 통해 출력한 ROC 곡선은 다양한 함수를 이용해서 그래프를 수정할 수 있다.\n\n# 함수 plot.roc() 이용\nplot.roc(xgb.roc,   \n         col=\"gray\",                                   # Line Color\n         print.auc = TRUE,                             # AUC 출력 여부\n         print.auc.col = \"red\",                        # AUC 글씨 색깔\n         print.thres = TRUE,                           # Cutoff Value 출력 여부\n         print.thres.pch = 19,                         # Cutoff Value를 표시하는 도형 모양\n         print.thres.col = \"red\",                      # Cutoff Value를 표시하는 도형의 색깔\n         auc.polygon = TRUE,                           # 곡선 아래 면적에 대한 여부\n         auc.polygon.col = \"gray90\")                   # 곡선 아래 면적의 색깔\n\n\n\n\n\n\n\n\n\n# 함수 ggroc() 이용\nggroc(xgb.roc) +\nannotate(geom = \"text\", x = 0.9, y = 1.0,\nlabel = paste(\"AUC = \", auc),\nsize = 5,\ncolor=\"red\") +\ntheme_bw()\n\n\n\n\n\n\n\n\n\n\n16.7.2.2 Package “Epi”\n\npacman::p_load(\"Epi\")       \n# install_version(\"etm\", version = \"1.1\", repos = \"http://cran.us.r-project.org\")\n\nROC(pp, ac, plot = \"ROC\")                              # ROC(예측 확률, 실제 class)  \n\n\n\n\n\n\n\n\n\n\n16.7.2.3 Package “ROCR”\n\npacman::p_load(\"ROCR\")\n\nxgb.pred &lt;- prediction(pp, ac)                         # prediction(예측 확률, 실제 class) \n\nxgb.perf &lt;- performance(xgb.pred, \"tpr\", \"fpr\")        # performance(, \"민감도\", \"1-특이도\")                      \nplot(xgb.perf, col = \"gray\")                           # ROC Curve\n\nperf.auc   &lt;- performance(xgb.pred, \"auc\")             # AUC\nauc        &lt;- attributes(perf.auc)$y.values\nlegend(\"bottomright\", legend = auc, bty = \"n\")\n\n\n\n\n\n\n\n\n\n\n\n\n16.7.3 향상 차트\n\n16.7.3.1 Package “ROCR”\n\nxgb.perf &lt;- performance(xgb.pred, \"lift\", \"rpp\")       # Lift Chart                      \nplot(xgb.perf, main = \"lift curve\",\n     colorize = T,                                     # Coloring according to cutoff \n     lwd = 2)",
    "crumbs": [
      "Welcome",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>XGBoost</span>"
    ]
  }
]