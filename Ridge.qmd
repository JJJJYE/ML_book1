---
title: "Ridge Regression"
format: 
  html:
    theme: zephyr
    smooth-scroll: true
    toc: true
    toc-location: right
    # self-contained: true
# author: 
#     - name: J.I. Seo
#       affiliations:
#       - Gyeongguk National University
#     - name: J.W. Lee
#       # affiliations:
#       # - University of Missouri
      
number-sections: true
highlight-style: pygments
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
options(width=200)
```

> Ridge Regression의 장점
 
- 규제항을 통해 회귀계수를 "0"에 가깝게 추정한다.
    - 회귀계수 추정치의 분산을 감소시켜 `Training Dataset`의 변화에도 회귀계수 추정치가 크게 변하지 않는다.


</br>

> Ridge Regression의 단점

- $\lambda = \infty$가 아닌 한 회귀계수를 정확하게 "0"으로 추정하지 못한다.
    - 변수 선택을 수행할 수 없다.
- 예측변수가 많을 경우 해석이 어렵다.

</br>

> 실습 자료 : 1912년 4월 15일 타이타닉호 침몰 당시 탑승객들의 정보를 기록한 데이터셋이며, 총 11개의 변수를 포함하고 있다. 이 자료에서 **Target**은 `Survived`이다.

<center>![](./image/그림_titanic.png)</center>

<br />

<center><img src="./image/Titanic_표.png" width="400" height="400"></center>

<br />
 

## 데이터 불러오기


```{r, eval=F}
pacman::p_load("data.table", 
               "tidyverse", 
               "dplyr", "tidyr",
               "ggplot2", "GGally",
               "caret",
               "glmnet")                                                # For glmnet

titanic <- fread("../Titanic.csv")                                      # 데이터 불러오기

titanic %>%
  as_tibble
```

```{r, echo=F}
pacman::p_load("data.table", 
               "tidyverse", 
               "dplyr", "tidyr",
               "ggplot2", "GGally",
               "caret",
               "glmnet")                                               # For glmnet

titanic <- fread(paste(getwd(), "/DATA/Titanic.csv", sep = "/"))             # 데이터 불러오기

titanic %>%
  as_tibble
```

 
## 데이터 전처리 I

```{r}
titanic %<>%
  data.frame() %>%                                                      # Data Frame 형태로 변환 
  mutate(Survived = ifelse(Survived == 1, "yes", "no"))                 # Target을 문자형 변수로 변환

# 1. Convert to Factor
fac.col <- c("Pclass", "Sex",
             # Target
             "Survived")

titanic <- titanic %>% 
  mutate_at(fac.col, as.factor)                                         # 범주형으로 변환

glimpse(titanic)                                                        # 데이터 구조 확인

# 2. Generate New Variable
titanic <- titanic %>%
  mutate(FamSize = SibSp + Parch)                                       # "FamSize = 형제 및 배우자 수 + 부모님 및 자녀 수"로 가족 수를 의미하는 새로운 변수

glimpse(titanic)                                                        # 데이터 구조 확인

# 3. Select Variables used for Analysis
titanic1 <- titanic %>% 
  select(Survived, Pclass, Sex, Age, Fare, FamSize)                     # 분석에 사용할 변수 선택

titanic1 %>%
  as_tibble
```

 
## 데이터 탐색

```{r}
ggpairs(titanic1,                                        
        aes(colour = Survived)) +                         # Target의 범주에 따라 색깔을 다르게 표현
  theme_bw()

ggpairs(titanic1,                                     
        aes(colour = Survived, alpha = 0.8)) +            # Target의 범주에 따라 색깔을 다르게 표현
  scale_colour_manual(values = c("#E69F00", "#56B4E9")) + # 특정 색깔 지정
  scale_fill_manual(values = c("#E69F00", "#56B4E9")) +   # 특정 색깔 지정
  theme_bw()
```

 
## 데이터 분할

```{r}
# Partition (Training Dataset : Test Dataset = 7:3)
y      <- titanic1$Survived                             # Target

set.seed(200)
ind    <- createDataPartition(y, p = 0.7, list  =T)     # Index를 이용하여 7:3으로 분할
titanic.trd <- titanic1[ind$Resample1,]                 # Training Dataset
titanic.ted <- titanic1[-ind$Resample1,]                # Test Dataset
```

 
## 데이터 전처리 II

```{r}
# 1. Imputation
titanic.trd.Imp <- titanic.trd %>% 
  mutate(Age = replace_na(Age, mean(Age, na.rm = TRUE)))                 # 평균으로 결측값 대체

titanic.ted.Imp <- titanic.ted %>% 
  mutate(Age = replace_na(Age, mean(titanic.trd$Age, na.rm = TRUE)))     # Training Dataset을 이용하여 결측값 대체

# 2. Standardization
preProcValues <- preProcess(titanic.trd.Imp, 
                            method = c("center", "scale"))               # Standardization 정의 -> Training Dataset에 대한 평균과 표준편차 계산 

titanic.trd.Imp <- predict(preProcValues, titanic.trd.Imp)               # Standardization for Training Dataset
titanic.ted.Imp <- predict(preProcValues, titanic.ted.Imp)               # Standardization for Test Dataset

# 3. Convert Factor Var. into Dummy Var. 
train.x <- model.matrix(Survived ~.,                                     # Survived는 Target으로 제외  
                        titanic.trd.Imp)[,-1]                            # [,-1] : 절편 제거

train.x

test.x <- model.matrix(Survived ~.,                                      # Survived는 Target으로 제외  
                       titanic.ted.Imp)[,-1]                             # [,-1] : 절편 제거

test.x
```

 
## 모형 훈련

Package `"glmnet"`에서 제공하는 함수 `glmnet()`을 이용하여 `Ridge Regression`을 수행할 수 있다. 함수 `glmnet()`는 Target이 2개의 클래스를 가질 때 "두 번째 클래스"에 속할 확률을 모델링하며, "두 번째 클래스"란 "Factor" 변환하였을 때 두 번째 수준(Level)을 의미한다. 예를 들어, "a"와 "b" 2개의 클래스를 가진 Target을 "Factor" 변환하였을 때 수준이 "a" "b"라면, 첫 번째 클래스는 "a", 두 번째 클래스는 "b"가 된다. 함수 `glmnet()`에 대한 자세한 옵션은 [여기](https://www.rdocumentation.org/packages/glmnet/versions/4.1-8/topics/glmnet)를 참고한다.


```{r, eval = FALSE}
glmnet(x, y, family, alpha, lambda, ...)
```

- `x` : 예측 변수를 포함하는 행렬
- `y` : Target을 포함하는 변수
- `family` : Target의 분포
    - `"gaussian"` : 수치형인 Target
    - `"binomial"` : 2개의 클래스를 가지는 Target
    - `"multinomial"` : 3개 이상 클래스를 가지는 Target
    - `"poisson"` : Count Data인 Target
- `alpha` : Elasticnet Mixing Parameter
    - `0` : Ridge Regression
    - `1` : Lasso Regression
    - `0 < alpha < 1` : Elastic Net Regression
- `lambda` : Regularization Parameter 
    - 직접 값을 지정하면 해당 값에 대한 결과만 보여준다.
    - 값을 지정하지 않으면 100개의 `lambda` 값에 대한 결과를 보여준다.
    

### 람다 값 직접 지정

```{r}
ridge.fit <- glmnet(x = train.x,                 # 예측 변수를 포함하는 행렬
                    y = titanic.trd.Imp$Survived,# Target
                    family = "binomial",         # Binary Classification
                    alpha = 0,                   # 0 : Ridge / 1 : Lasso / 0 < alpha < 1 : Elastic Net
                    lambda = 1)

round(coef(ridge.fit), 3)                        # 회귀계수 추정치
```

`Result!` 데이터 "titanic.trd.Imp"의 Target "Survived"은 "no"와 "yes" 2개의 클래스를 가지며, "Factor" 변환하면 알파벳순으로 수준을 부여하기 때문에 "yes"가 두 번째 클래스가 된다. 즉, "yes"에 속할 확률(= 탑승객이 생존할 확률)을 $p$라고 할 때, 추정된 회귀계수를 이용하여 다음과 같은 모형식을 얻을 수 있다.
$$
\begin{align*}
\log{\frac{p}{1-p}} = &-0.099 + 0.063 X_{\text{Pclass2}} - 0.240 X_{\text{Pclass3}} -0.409 X_{\text{Sexmale}} \\
                      &-0.036 Z_{\text{Age}} +0.090 Z_{\text{Fare}} - 0.013 Z_{\text{FamSize}}
\end{align*}
$$
여기서, $Z_{\text{예측 변수}}$는 표준화한 예측 변수, $X_{\text{예측 변수}}$는 더미 변수를 의미한다.

### 교차 검증을 통한 최적의 람다 값

```{r}
# 100개의 람다 값에 따른 결과
ridge.fit <- glmnet(x = train.x,                 # 예측 변수를 포함하는 행렬
                    y = titanic.trd.Imp$Survived,# Target
                    family = "binomial",         # Binary Classification
                    alpha = 0)                   # 0 : Ridge / 1 : Lasso / 0 < alpha < 1 : Elastic Net

plot(ridge.fit, xvar = "lambda")                 # 람다 값에 따른 회귀계수 추정치 확인
```

`Result!` 100개의 $\lambda$ 값에 대한 회귀계수 추정치의 변화를 보여준다. 해당 그림을 통해 $\lambda$ 값이 클수록 회귀계수 추정치는 작아진다는 것을 알 수 있다.

```{r}
ridge.fit$lambda                                 # 100개의 람다 값
coef(ridge.fit)                                  # 100개의 람다 값에 따른 회귀계수 추정치
coef(ridge.fit)[,100]                            # 100번째 람다 값에 대한 회귀계수 추정치
```

 

`Caution!` $\lambda$는 모형이 `Training Dataset`에 과적합 되는 것을 방지하기 위해 사용하는 모수이며, 교차 검증(Cross Validation)을 통해 최적의 값을 찾을 수 있다. 이러한 방법은 package `"glmnet"`에서 제공하는 함수 `cv.glmnet()`을 통해 수행할 수 있으며, 함수에 대한 자세한 옵션은 [여기](https://www.rdocumentation.org/packages/glmnet/versions/4.1-8/topics/cv.glmnet)를 참고한다.

```{r}
set.seed(200)                                          # Seed 고정 -> 동일한 결과를 출력하기 위해
cv.ridge.fit <- cv.glmnet(x = train.x,                 # 예측 변수를 포함하는 행렬
                          y = titanic.trd.Imp$Survived,# Target
                          family = "binomial",         # Binary Classification
                          alpha = 0,                   # 0 : Ridge / 1 : Lasso / 0 < alpha < 1 : Elastic Net
                          nfolds = 5,                  # 5-Fold Cross Validation
                          type.measure = "auc")        # AUC에 기반하여 최적의 람다 값 찾기

plot(cv.ridge.fit)                                     # Plot
```

`Result!` 100개의 $\lambda$ 값에 대한 AUC의 변화를 보여준다.  
`Caution!` 만약 $\lambda$ 값에 대해 직접 후보 값을 지정하고 싶으면 함수 `cv.glmnet()`의 옵션 `lambda = 후보 값`을 이용하면 된다.

```{r}
cv.ridge.fit$lambda.min                                   # 최적의 람다 값
max(cv.ridge.fit$cvm)                                     # 최적의 람다 값에 대한 AUC
round(coef(cv.ridge.fit, s = cv.ridge.fit$lambda.min), 3) # 최적의 람다 값에 대한 회귀계수 추정치
```

`Result!` 최적의 $\lambda$ 값에 대해 추정된 회귀계수를 이용하여 다음과 같은 모형식을 얻을 수 있다.
$$
\begin{align*}
\log{\frac{p}{1-p}} =&\; 1.623 - 0.381 X_{\text{Pclass2}} - 1.452 X_{\text{Pclass3}} -2.103 X_{\text{Sexmale}} \\
                      &-0.325 Z_{\text{Age}} +0.241 Z_{\text{Fare}} - 0.268 Z_{\text{FamSize}}
\end{align*}
$$

 
## 모형 평가

`Caution!` 모형 평가를 위해 `Test Dataset`에 대한 `예측 class/확률` 이 필요하며, 함수 `predict()`를 이용하여 생성한다. 
```{r}
# 예측 class 생성
test.ridge.class <- predict(cv.ridge.fit, 
                            newx = test.x,             # Test Dataset including Only 예측 변수 
                            s = "lambda.min",          # 최적의 람다 값 기반
                            type = "class")            # 예측 class 생성

test.ridge.class %>%                                      
  as_tibble
```

<br />

### ConfusionMatrix

```{r}
CM   <- caret::confusionMatrix(as.factor(test.ridge.class), titanic.ted.Imp$Survived, 
                               positive = "yes")       # confusionMatrix(예측 class, 실제 class, positive = "관심 class")
CM
```

<br />

### ROC 곡선

```{r}
# 예측 확률 생성
test.ridge.prob <- predict(cv.ridge.fit, 
                           newx = test.x,              # Test Dataset including Only 예측 변수 
                           s = "lambda.min",           # 최적의 람다 값 기반
                           type = "response")          # 예측 확률 생성

test.ridge.prob %>%                                    # "Survived = yes"에 대한 예측 확률                           
  as_tibble
```

```{r}
ac  <- titanic.ted.Imp$Survived                        # Test Dataset의 실제 class 
pp  <- as.numeric(test.ridge.prob)                     # 예측 확률을 수치형으로 변환
```

#### Package "pROC"

```{r}
pacman::p_load("pROC")

ridge.roc  <- roc(ac, pp, plot = T, col = "gray")      # roc(실제 class, 예측 확률)
auc        <- round(auc(ridge.roc), 3)
legend("bottomright", legend = auc, bty = "n")

```

`Caution!` Package `"pROC"`를 통해 출력한 ROC 곡선은 다양한 함수를 이용해서 그래프를 수정할 수 있다.

```{r}
# 함수 plot.roc() 이용
plot.roc(ridge.roc,   
         col="gray",                                   # Line Color
         print.auc = TRUE,                             # AUC 출력 여부
         print.auc.col = "red",                        # AUC 글씨 색깔
         print.thres = TRUE,                           # Cutoff Value 출력 여부
         print.thres.pch = 19,                         # Cutoff Value를 표시하는 도형 모양
         print.thres.col = "red",                      # Cutoff Value를 표시하는 도형의 색깔
         auc.polygon = TRUE,                           # 곡선 아래 면적에 대한 여부
         auc.polygon.col = "gray90")                   # 곡선 아래 면적의 색깔
```


```{r}
# 함수 ggroc() 이용
ggroc(ridge.roc) +
annotate(geom = "text", x = 0.9, y = 1.0,
label = paste("AUC = ", auc),
size = 5,
color="red") +
theme_bw()
```



#### Package "Epi"

```{r}
pacman::p_load("Epi")       
# install_version("etm", version = "1.1", repos = "http://cran.us.r-project.org")

ROC(pp, ac, plot = "ROC")                              # ROC(예측 확률, 실제 class)  

```

#### Package "ROCR"

```{r}
pacman::p_load("ROCR")

ridge.pred <- prediction(pp, ac)                       # prediction(예측 확률, 실제 class) 

ridge.perf <- performance(ridge.pred, "tpr", "fpr")    # performance(, "민감도", "1-특이도")                      
plot(ridge.perf, col = "gray")                         # ROC Curve

perf.auc   <- performance(ridge.pred, "auc")           # AUC
auc        <- attributes(perf.auc)$y.values
legend("bottomright", legend = auc, bty = "n")
```

<br />

### 향상 차트

#### Package "ROCR"

```{r}
ridge.perf <- performance(ridge.pred, "lift", "rpp")   # Lift Chart                      
plot(ridge.perf, main = "lift curve",
     colorize = T,                                     # Coloring according to cutoff 
     lwd = 2) 

```


```{r, eval=F, echo=F, include=FALSE}
#### **2) Package "lift"**

pacman::p_load("lift")

ac.numeric <- ifelse(UB.ted$Personal.Loan == "yes", 1, 0)             # Target을 수치형으로 변환

plotLift(test.logis.prob, ac.numeric, cumulative = T, n.buckets = 24) # plotLift(7-2에서 생성한 예측 확률, 실제 class)
TopDecileLift(test.logis.prob, ac.numeric)		                        # Top 10%의 향상도 출력
```
